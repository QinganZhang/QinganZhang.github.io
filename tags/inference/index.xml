<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>inference on Paul&#39;s Blog</title>
    <link>https://qinganzhang.github.io/tags/inference/</link>
    <description>Recent content in inference on Paul&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 24 May 2024 14:06:01 +0800</lastBuildDate><atom:link href="https://qinganzhang.github.io/tags/inference/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>推理框架设计</title>
      <link>https://qinganzhang.github.io/posts/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 24 May 2024 14:06:01 +0800</pubDate>
      
      <guid>https://qinganzhang.github.io/posts/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1/</guid>
      <description>Tensor 背景 在推理框架中，只需要进行模型结构的加载、模型权重的加载，然后进行前向运算，整个过程不需要反向传播。 有时模型结构和权重信息会放在一个文件</description>
      <content:encoded><![CDATA[<h2 id="tensor">Tensor</h2>
<h3 id="背景">背景</h3>
<p>在推理框架中，只需要进行模型结构的加载、模型权重的加载，然后进行前向运算，整个过程不需要反向传播。</p>
<blockquote>
<p>有时模型结构和权重信息会放在一个文件中，比如ONNX格式；但也可以将模型结构和权重文件分开存放，比如该项目用到的PNNX格式</p>
</blockquote>
<p>其中模型结构涉及到计算图的构建，模型权重会在构建时加载到Tensor类中</p>
<h3 id="设计">设计</h3>
<p>Tensor一般保存的是三维的数组，最简单的方法就是<code>std::vector&lt;std::vector&lt;std::vector&lt;float&gt;&gt;&gt;</code>，但是这种方法非常不利于<strong>数据的访问（尤其是内存不连续的问题，访问会变慢） 、修改以及查询，特别是在扩容的时候非常不方便。不能满足使用需求</strong>。因此最后基于Armadillo类中的<code>arma::Cube</code>来进行封装，一个Cube由多个Mat组成，实现了效率与工作量两方面的折中。（需要注意的是，Armadillo类中的<code>arma::Cube&lt;T&gt;</code>是以列优先方式存储数据，而PyTorch中导出的文件是以行优先方式存储数据，读取模型权重文件到Tensor类中时，中间要进行一步转置）</p>
<p>模型权重文件是通过PyTorch导出的，但是PyTorch直接导出的文件具有特定的格式，不方便解析。因此PyTorch首先读取模型的权重文件，然后将权重文件转换为numpy管理，再保存为本地csv文件格式，这样方便解析和读取。</p>
<h2 id="计算图">计算图</h2>
<h3 id="背景-1">背景</h3>
<p>从PyTorch导出的模型结构的保存方法有两种，一种是将模型结构和模型权重保存在一起，比如ONNX，另一种是将模型结构和模型权重分开保存，比如PNNX，这里使用后一种方法，理由如下：</p>
<ul>
<li>ONNX计算图过于细碎，不易理解和阅读
<ul>
<li>算子过于细碎，有助于兼容更多的框架</li>
<li>而PNNX导出的算子可以保持完整的大算子不被拆分</li>
</ul>
</li>
<li>ONNX计算图过于细碎，也不利于推理的优化</li>
</ul>
<p><code>PNNX</code>是<code>PyTorch Neural Network Exchange</code>的缩写，能够将<code>PyTorch</code>模型文件直接导出为高效、简洁的计算图，作为一种中间格式，PNNX可以进行一些图优化、算子融合的工作，它有以下几个特点：</p>
<ul>
<li>用模板匹配（<code>pattern matching</code>）的方法将匹配到的子图用对应等价的大算子替换掉，例如可以将上图子图中的多个小算子（可能是在<code>TorchScript</code>中被拆分的）重新替换为<code>LayerNorm</code>算子。或者在对<code>PyTorch</code>模型导出时，也可以自定义某个<code>nn.Module</code>不被拆分；</li>
<li>在<code>PyTorch</code>中编写的简单算术表达式在转换为<code>PNNX</code>后，会保留表达式的整体结构，而不会被拆分成许多小的加减乘除算子。例如表达式<code>add(mul(@0, @1),add(@2, @3))</code>不会被拆分为两个<code>add</code>算子和一个<code>mul</code>算子，而是会生成一个表达式算子<code>Expression</code> ;</li>
<li><code>PNNX</code>项目中有大量图优化的技术，包括了算子融合，常量折叠和移除，公共表达式消除等技术。
<ul>
<li>算子融合优化是一种针对深度学习神经网络的优化策略，通过将多个相邻的计算算子合并为一个算子来减少计算量和内存占用。</li>
<li>常量折叠是将<strong>在编译时期间将表达式中的常量计算出来，然后将结果替换为一个等价的常量</strong>，以减少模型在运行时的计算量。</li>
<li>常量移除就是将计算图中不需要的常数（<strong>计算图推理的过程中未使用</strong>）节点删除，从而减少计算图的文件和加载后的资源占用大小。</li>
<li>公共表达式消除优化是一种针对计算图中重复计算的优化策略，<strong>它可以通过寻找并合并重复计算的计算节点，减少模型的计算量和内存占用。<strong>公共子表达式检测是指</strong>查找计算图中相同的子表达式</strong>，公共子表达式消除是指<strong>将这些重复计算的计算节点合并为一个新的计算节点</strong>，从而减少计算和内存开销。</li>
</ul>
</li>
</ul>
<h3 id="设计-1">设计</h3>
<p>PNNX计算图中有两个核心的部分，<code>Operand</code>（操作数）和 <code>Operator</code>（节点），整个计算图<code>Graph</code>主要就是针对操作数和节点的管理。</p>
<h4 id="pnnx计算图核心结构">PNNX计算图核心结构</h4>
<h5 id="operand操作数"><code>Operand</code>操作数</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Operand</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="n">remove_consumer</span><span class="p">(</span><span class="k">const</span> <span class="n">Operator</span><span class="o">*</span> <span class="n">c</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">Operator</span><span class="o">*</span> <span class="n">producer</span><span class="p">;</span>		<span class="c1">// 产生这个操作数的节点，即这个producer输出了当前这个Operand
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Operator</span><span class="o">*&gt;</span> <span class="n">consumers</span><span class="p">;</span>	<span class="c1">// 使用这个操作数的节点，即当前这个Operand是comsumers中每个的输入
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">shape</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">name</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">Parameter</span><span class="o">&gt;</span> <span class="n">params</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="operator节点"><code>Operator</code>节点</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Operator</span> <span class="c1">// 计算图中的运算符（算子）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Operand</span><span class="o">*&gt;</span> <span class="n">inputs</span><span class="p">;</span>	<span class="c1">// 该算子需要的输入操作数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Operand</span><span class="o">*&gt;</span> <span class="n">outputs</span><span class="p">;</span>	<span class="c1">// 该算子计算得到的输出操作数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">name</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">inputnames</span><span class="p">;</span>	<span class="c1">// 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">Parameter</span><span class="o">&gt;</span> <span class="n">params</span><span class="p">;</span> <span class="c1">// 该运算符的参数，比如conv中的stride，padding，kernel_size等
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">Attribute</span><span class="o">&gt;</span> <span class="n">attrs</span><span class="p">;</span>	 <span class="c1">// 该运算符的权重，比如conv中的weight，bias
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>Parameter</code>参数</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Parameter</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">type</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>Attribute</code>权重</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Attribute</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">type</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">shape</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="graph计算图"><code>Graph</code>计算图</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Graph</span> <span class="c1">// 管理计算图中的运算符和和操作数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Operator</span><span class="o">*&gt;</span> <span class="n">ops</span><span class="p">;</span>		<span class="c1">// 运算符（算子）的集合
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Operand</span><span class="o">*&gt;</span> <span class="n">operands</span><span class="p">;</span> <span class="c1">// 操作数的集合
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="对pnnx中间格式进行封装">对PNNX中间格式进行封装</h4>
<h5 id="对operand的封装runtimeoperand">对<code>Operand</code>的封装：<code>RuntimeOperand</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">RuntimeOperandBase</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">     * @brief Name of the operand
</span></span></span><span class="line"><span class="cl"><span class="cm">     * 比如当前operand是输入operand，则此时name是输出当前operand的节点的name
</span></span></span><span class="line"><span class="cl"><span class="cm">    */</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">name</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Shape of the operand
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span> <span class="n">shapes</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Vector containing operand data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&gt;</span> <span class="n">datas</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Data type of the operand
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">RuntimeDataType</span> <span class="n">type</span> <span class="o">=</span> <span class="n">RuntimeDataType</span><span class="o">::</span><span class="n">kTypeUnknown</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="对operator的封装runtimeoperator">对<code>Operator</code>的封装：<code>RuntimeOperator</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">RuntimeOperatorBase</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">/// Execution order index of this operator，记录拓扑排序中节点的执行顺序
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int32_t</span> <span class="n">forward_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Whether this operator has run in current execution，在拓扑排序中判断当前节点是否已经遍历过
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">bool</span> <span class="n">has_forward</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Name of the operator,全局唯一,比如Conv_1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">name</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Type of the operator, such as Convolution
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Layer for this operator,节点对应的算子，负责完成具体计算
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Layer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="n">layer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Names of output operators, 当前节点的后继节点的名字
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">output_names</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Output operand, 注意只有一个输出operand
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperandBase</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="n">output_operand</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Output operators mapped by output name, 当前节点的后继节点的按名访问映射
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperatorBase</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&gt;</span> <span class="n">output_operators</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Input operands in sequence
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperandBase</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&gt;</span> <span class="n">input_operands_seq</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">     * @brief Input operands mapped by provider name
</span></span></span><span class="line"><span class="cl"><span class="cm">     * &lt;上一个节点的名字，当前节点的输入Operand&gt;的map
</span></span></span><span class="line"><span class="cl"><span class="cm">    */</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperandBase</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&gt;</span> <span class="n">input_operands</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Operator parameters, such kernel_size, stride for conv
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeParameter</span><span class="o">&gt;&gt;</span> <span class="n">params</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// Operator attributes like weights and bias
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeAttribute</span><span class="o">&gt;&gt;</span> <span class="n">attribute</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>对<code>Parameter</code>的封装：<code>RuntimeParameter</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">RuntimeParameter</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">RuntimeParameterType</span> <span class="n">type</span> <span class="o">=</span> <span class="n">RuntimeParameterType</span><span class="o">::</span><span class="n">kParameterUnknown</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>对<code>Attribute</code>的封装：<code>RuntimeAttribute</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">RuntimeAttribute</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="c1">/// Attribute data，节点中的权重信息，注意保存的是二进制数据（所以是char类型）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span> <span class="n">weight_data</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span> <span class="n">shape</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">RuntimeDataType</span> <span class="n">type</span> <span class="o">=</span> <span class="n">RuntimeDataType</span><span class="o">::</span><span class="n">kTypeUnknown</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="对graph的封装runtimegraph">对<code>Graph</code>的封装：<code>RuntimeGraph</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">RuntimeGraph</span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">bin_path_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">param_path_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">pnnx</span><span class="o">::</span><span class="n">Graph</span><span class="o">&gt;</span> <span class="n">graph_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">GraphState</span> <span class="n">graph_state_</span> <span class="o">=</span> <span class="n">GraphState</span><span class="o">::</span><span class="n">NeedInit</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1">/// 整个图的输入节点，这些节点的input_operands都是空的，直接将计算图的输入作为input_operands
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperator</span><span class="o">&gt;&gt;</span> <span class="n">input_ops_</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1">/// 整个图的输出节点，这些节点的output_names都是空的，直接其output_operand作为整个计算图的输出
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperator</span><span class="o">&gt;&gt;</span> <span class="n">output_ops_</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperator</span><span class="o">&gt;&gt;</span> <span class="n">operators_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>整体计算图的<a href="http://www.plantuml.com/plantuml/dsvg/dLTFRzn45B_xKup4WHQI7k1cHQlI8b0br5QG0pThTZt9Ml6EtPbnqYXOGcqHAcfAfAGgj18j4bK0YQG73kasQRvCl4vFV0MUPsOdunsleyqbYjzxytlpVk_FlBtA1MOY6yJUXwXuCIn__txqvFLeSwzykptwxO7NYp7dQ95Gdh25nGxQy12QHo4ME40-mco0_UjPbu1AAXXU2tWVfuHNQYv2trybFG5diuYAJpy9HCVBFOtwTKP5D22V2S6YRYQ81FyOhP5ekI-2oiS4Hg-FMKVQI1zrfSPNUh6U4kIFFNmEK8iWyVAwvzkOuG4HX85dzvJHwgD0qEZbGN5ytoP8szvA2SCql8OvqIvSXQOF_5307OV68NYwZCwYugWbhegKIGC50zIGC4W5Mp39whHnWRmSUUubKJ8_hzFjDKQ2Dd9lGdBbodSTr404JGH1CLaIAA4eZkWAyfjeMOeJB3hdqmknElmQJPtWfOIjOHO64Gt9NV2gEPIwFkQ1reEccoGncf8KYpr77EDrmhJS9lyha4lkfLMIYJGJ0K0xQRK0QxQ99jM5Rgmezoo0ys20qp42_6ixcsl1jPdKo16rBYLnBm9BmrPKJkwqbNGxLbgrAPyrMjFS6WMR8JGZa9bU09Hx3fUwezm0Matj2xOQsXTeD5m0GwX95yRfMdEalM-DeMbSstwfoT3txJu0kbK_WB6I8rEtSwWusYuURfPxJuj_jifd3ugjn-NRNVLPR6sMkwyzGaDKUPp1houqy2pw18AAr-4FCTwLrW2Z6P5Dnm7-hOc048XJ4gBkklOcO_TGMvpmENhq4A8ztJj-_tHljdkv_GhEq0rg1MfVAcN9QXGIfgurcoUdXy4J9smL136AQXujvDOv_oN3QTyUy5garuvkH8CKYtxW3EHvDGQQj4YgboiOeybeT2SZierJIk_wllJIiKsvm89K1wJgc-fBgSTnEnlEENEre-5DvSmEeCxhpulwlq4ZSUcoVlhaxBkMHN4eHQj9528f-qAza9SgepDD3icpyoB7YqgQBNP67hXtIygO-xx5ANWVFVdtvE3lulaxw8JJTzl53wzEVxfNtdlpt-6Zq-DVJuRFrITetMf_V_zezCj--TSGjARgMdr3FjgS_pYSvjmUQirkPR7Vlddpsz7Bm-BmPz3LTkiKzrRmCf4Mii9LuPl9lu50PkqW4HKWo8sXcVmRJNPceNJtoKuDHZzA5m6PkZUT_p2VXQc1gbaKPZsvLOsBvYEjwYMKPmF29fSeOpUEICTIrQK1iSI9BGQvNHRQ2C3DHQJta-5kkVFYTF-LraCMrPm6hSdqL2npSuLrT5pk_5d3kbJyyGmAxhABQH9adcox81pEMvEXvt43UpIKv9ajiit809s_qCvU0Ne9csvkobqds_0Yqsh09XNc69hKwD3EY3PlZQ8ZRIatRQ8dJmjd-RWq6FoghMf3U_6HzV9uI4lj0dM5L0xdAGCuz_GFDhNlgHz26xWBzE6UoFL4LtE-UiuoVZq9oJGhcMO-fsk2EuS-KB-0vFHpdcFGCdL9io0PcpM2LngV9o-lJMaLXUyxG01_Sl0OUaXlXVjlYk4ED9AQoxLDuofyP8FuVm00">UML类图</a>及<a href="https://github.com/QinganZhang/UtilityRoom/blob/main/KuiperInfer_ComputeGraph_Structure.wsd">Plantuml代码</a></p>
<p>
  <img loading="lazy" src="https://www.plantuml.com/plantuml/svg/dLTFQzn65B_hKmpqaAIrSsXlmYnfN5e29GcD3xs9sTNOAwmTAJCZEyOLb2IbfCIfmGvf4sXIQ71Rg9r33yx6Zh-CjRivzIlqQMPsFDhHogmlndhlpUytxyzxy_OQ5vY9h1UZnQINPe9ynN3Q3Uu8bdL4neXt2HKl-yFVlnyyVJFOsX--sndyzj3hn9Xpj4GeJzZ2KWjjUWZDen0B720VOTR3_cBM9g2I2eRN0zx5AU6bcelGzzT8Hy3PBABYiqy3qV9oJwD-ar4HzSZdGh2e3HUIu9-WTHAjT4LGSanWTBgOjQIDvAWgDRxIYusK87_Cy0L0BO74owlCjp73FI880sRtbD7gen2WmQl3ukI17I1jUoib3DFmEkP4KxWAY97ceO0xTes3ytG5dNd5KODVPL0c3HGCX8Q4GIhOWabMgoaMoCkHvruI9VFpEjrUhITeC_Sc95UlVjT2DO6WYI0e9ii29HJ54Lr5VbrObkC4YzRvuGLVtVWQJIN0ombRnomC8XgIUy2gOoXrNSm3hGTDEqbYD2KfLlGSSOmt2DDoE_XVWnnYhqEVP08wBG1e9wqMOCKsqK5reMihoZqBu3peuNIC0F_QP7DDk5OaDN94hKj9t8l0qh0HbPExJINTZ9MMRSfdzTOqjqR1PWZD26Ic5m3bdXDBtL6k0yscrWMR3QqBr1ekW27Kf0jZkjOvqjotnj0qhcs_N6Ve-tOVGBXLFu2naYDJjtEeEDuf7cqDzvyL_smFdpyijfyCt-sfps9xQxZtnYFG72NZ3Bowq81PT0au5M_07sBObTO0encHJSS1_gq9Xn28KnAYzePcaxvxgCbF-1myVWJUZlPFFZpRd-rURhy26Rf1BKVjIwKiMOj2mjIrPcDoUXYOE65h88XHL66qaHlcl5f9x06lHNhjQ4SqIB7e1iv0dbTZe4wBf7gbX36QZ4PtCoBREANqdkzBbfPjoWKMf3mWLNVABwKU--riEEVCrPQ6DvKpEu0whpylod-3HkBo5VtqoTbtFOlYK8hMaYX4KlQbUY4lbqPdcjoxLCrBELvKqconC_A0tYqfO-xxLao1VV3qtzF3luiNxw4JHkztYXzUZtwwFxp_zh-ZnwEJNq_xBzGdQDrg__3WUF3BmV2lFcXDrJLoGpwQo7_iJoEtXrezhIpsspTlVZjuTLGS_GowocwTuiugNY7IGbQuAdmp-JSHoAmT9A821BanD9D_iyxEB9JkFjcgmEX7wI8WK_Ucyn_cCpV7G32BmgmZjwfnqNoiLPs4ygn7sEGIPUp67cbVoheq89OuiSKWjyj26m6ukOXaF-tl3NTVZWvUQpraKSrfq9fCJyKoDrTOnoV3tJyhM9UBFvv3mLrnCKs2p9Dj5uGRywPaw7bS4pqQok2PBRB9o02Tlz3ENW5w2PjkRigzacoWbcarO9CASmnDQhHhPu4sRuqAHzfORc1YthU6cENZqc3bhrge3StY8-lbyP2MsWNg2cavdASDuDpJFzZKlgT-26tYDeGFTqIk9xgQy-Lpbl7592JJh6IQ-Pok2UuS-aZz0fBJptcEGSlK9Ss2P6pM2LwjVPwyl3AbbHU-xm01_EdX4-WXlHKUl2twkz18QYvNDerhy97ruly1" alt=""  /></p>
<h3 id="根据pnnx的graph构建kuiperinfer的runtimegraph">根据PNNX的<code>Graph</code>构建KuiperInfer的<code>RuntimeGraph</code></h3>
<ol>
<li>
<p>加载模型结构和权重信息的文件，得到PNNX的Graph</p>
</li>
<li>
<p>根据PNNX Graph中的节点信息，为KuiperInfer构建相同信息的节点（<code>RuntimeGraph::Init()</code>）。对于PNNX Graph中的每个节点Operator，构造一个对应的RuntimeOperator，进行以下初始化</p>
<ul>
<li>根据Operator的输入Operand，初始化RuntimeOperator中相关信息（注意只是将输入Operand的属性复制过来，没有将对应数据复制）。<code>RuntimeGraph::InitGraphOperatorsInput</code></li>
<li>根据Operator的输出Operand，初始化RuntimeOperator中相关信息（注意只是将输出Operand的属性复制过来，没有将对应数据复制）。<code>RuntimeGraph::InitGraphOperatorsOutput</code></li>
<li>将Operator的权重Attribute，属性复制，数据内容移动过来（<code>std::move</code>）。<code>RuntimeGraph::InitGraphAttrs</code></li>
<li>将Operator的参数Parameter，属性复制，数据内容移动过来（<code>std::move</code>）。<code>RuntimeGraph::InitGraphParams</code></li>
</ul>
</li>
<li>
<p>根据PNNX Graph中的图结构，为KuiperInfer构建相同的图结构（<code>RuntimeGraph::Build()</code>）。</p>
<ul>
<li>
<p>首先构建节点关系，主要包含两个方面：</p>
<ul>
<li>
<p>找到当前节点的后继节点，更新每个RuntimeOperator的output_operators信息（即找到当前节点的后继节点有哪些，这样才能构建计算图）。<code>RuntimeGraph::CreateNodeRelation</code></p>
</li>
<li>
<p>为每个节点创建算子（除了输入和输出算子）。在<code>RuntimeGraph::CreateLayer</code>中，调用基于工厂模式设计的<code>LayerRegisterer::CreateLayer</code>，返回创建的算子，赋值给节点的<code>layer</code>属性</p>
<blockquote>
<p>之前也没有显示注册算子，是什么时候添加的呢？在刚开始运行推理框架时，算子的注册过程都是全局变量（在对应算子的实现文件最后面），一开始就已经将所有算子注册了</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>然后根据后继节点信息，得到计算图的逆拓扑排序（当然先拓扑排序，然后再resever）,此时<code>RuntimeGraph::operators_</code>中节点按照逆拓扑顺序进行排列</p>
<blockquote>
<p>逆拓扑排序的结果是，靠近计算图输入的节点排的靠前，靠近计算图输出的节点排的靠后</p>
</blockquote>
</li>
<li>
<p>最后为每个节点的输出Operand分配空间（<code>RuntimeOperatorUtils&lt;float&gt;::InitOperatorOutput</code>），但是输入Operand不用分配空间（<code>RuntimeOperatorUtils&lt;float&gt;::InitOperatorInput</code>），输入Operand可以复用前一个节点输出Operand的空间。</p>
<blockquote>
<p>这两个函数的代码有点没太看懂</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>图结构和权重信息转换和构建完毕</p>
</li>
</ol>
<h2 id="算子">算子</h2>
<p>上面计算图中最核心的数据结构就是节点<code>RuntimeOperator</code>，其中封装了输入和输出的操作数，封装了参数和权重，维护了图的结构，除此之外还需要有算子的计算过程，可以将其抽象为Layer（这里将<code>Layer</code>称为算子，<code>RuntimeOperator</code>称为节点），Layer获取<code>RuntimeOperator</code>的输入操作数，基于Layer的派生类中的多态特性，对输出操作数进行计算，将结果放在输出操作数中，完成算子的计算过程。</p>
<h3 id="设计-2">设计</h3>
<h4 id="层次设计">层次设计</h4>
<h5 id="算子基类layer">算子基类<code>Layer</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Layer</span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">	<span class="k">virtual</span> <span class="n">StatusCode</span> <span class="n">Forward</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="n">StatusCode</span> <span class="nf">Forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;&gt;&gt;&amp;</span> <span class="n">inputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    	<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;&gt;&gt;&amp;</span> <span class="n">outputs</span>
</span></span><span class="line"><span class="cl">    <span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">layer_name_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">weak_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperator</span><span class="o">&gt;</span> <span class="n">runtime_operator_</span><span class="p">;</span> <span class="c1">// 算子对应的节点，因为算子需要访问节点中保存的输入操作数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Layer是虚基类，只有Layer虚基类实现了不带参的Forward方法，每个实现的派生类算子都需要重写带参的Forward方法，实现各个算子的计算过程，不带参的Forward方法中会基于多态特性来调用带参的Forward方法</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cp"># layer_input_datas 是当前节点输入Operands中的Tensors的数组，即算子的输入
</span></span></span><span class="line"><span class="cl"><span class="cp"># output_operand_datas 是指向当前节点输出Operand的指针，其datas成员是指向Tensors的数组
</span></span></span><span class="line"><span class="cl"><span class="cp"># 带参的Forward将输入进行计算，将结果放在输出中，因为函数传参传的是引用，所以会修改输出的值
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="n">StatusCode</span> <span class="n">status</span> <span class="o">=</span> <span class="n">runtime_operator</span><span class="o">-&gt;</span><span class="n">layer</span><span class="o">-&gt;</span><span class="n">Forward</span><span class="p">(</span><span class="n">layer_input_datas</span><span class="p">,</span> <span class="n">output_operand_datas</span><span class="o">-&gt;</span><span class="n">datas</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h6 id="不带参算子nonparamlayer">不带参算子<code>NonParamLayer</code></h6>
<h6 id="带参算子paramlayer">带参算子<code>ParamLayer</code></h6>
<p>很多算子在初始化时需要一些参数（比如卷积的stride），这些参数封装在节点的attribute数据成员中，在初始化算子的过程中，需要使用入参节点的信息来进行初始化，初始化使用的方法可以进行复用，因此具体的带参算子可以继承自<code>ParamLayer</code></p>
<h5 id="算子注册类layerregisterer">算子注册类<code>LayerRegisterer</code></h5>
<p>使用单例模式，在算子注册类<code>LayerRegisterer</code>中创建一个private的全局唯一的注册表<code>register</code>，这个注册表是一个map类型，key是算子类型（<code>std::string</code>类型），val是一个函数指针，所指向的函数完成一个算子的创建过程。在<code>LayerRegisterer::RegisterCreator</code>中，使用单例模式获取全局注册表，然后向全局注册表中添加{算子名称，算子创建过程的函数}，就向全局注册表中添加了算子。</p>
<p>这里详细介绍一下这个函数指针，<code>LayerRegisterer::Creator</code>就是一个函数指针，所指向的函数第一个参数是<code>const std::shared_ptr&lt;RuntimeOperator&gt;&amp; op</code> ，表示从这个节点中读取相关信息（比如参数、weight、bias等）；第二个参数是<code>std::shared_ptr&lt;Layer&lt;float&gt;&gt;&amp; layer</code>，表示一个待创建的算子（即<code>layer</code>传入时是指向空，而调用该函数完成后指向创建的节点）</p>
<p>然后还使用了工厂模式。单例模式确保了只有一个全局注册表实例，并且可以在代码的任何地方访问该注册表，并向注册表添加算子。在向注册表添加算子之后，工厂模式则负责根据算子的类型返回相应的算子实例。在<code>LayerRegisterer::CreateLayer</code>中，根据算子名字从注册表中得到创建算子的函数，有函数，还有节点中保存的相关信息，就可以初始化一个节点，返回一个算子实例。</p>
<h5 id="表达式类expressionlayer">表达式类<code>ExpressionLayer</code></h5>
<p>算子与表达式的区别在于输入，算子的输入是一个操作数，这一个操作数在Forward传参时，将操作数中的datas属性（<code>std::vector&lt;std::shared_ptr&lt;Tensor&lt;T&gt;&gt;&gt;</code>类型）传入；而表达式的输入有两个（或多个）操作数，在Forward传参时，这两个输入操作数的datas都拼接放入到入参inputs（<code>std::vector&lt;std::shared_ptr&lt;Tensor&lt;T&gt;&gt;&gt;</code>类型）中。因此，虽然带参Forward函数形式是相同的，但是inputs参数中未必只有一个操作数的数据。</p>
<p>如何进行表达式的计算呢？大体过程与算子类似，但是其中多了几步，下面从头开始捋一下：</p>
<ol>
<li>
<p>与算子注册相同，表达式类<code>ExpressionLayer</code>一开始就添加到全局注册表中（见<code>layer/details/expression.cpp</code>）</p>
</li>
<li>
<p>在前面根据PNNX的<code>Graph</code>构建KuiperInfer的<code>RuntimeGraph</code>的第三步中，在构建图结构的过程中需要为每个节点创建算子；表达式作为一种特殊的算子，只需要保存表达式字符串（比如<code>mul(@0,@1)</code>）这个属性即可，使用这个字符串构造表达式类<code>ExpressionLayer</code>的一个实例，添加到节点的<code>layer</code>属性中</p>
</li>
<li>
<p>在表达式运行时，大致过程与算子类似，都是调用各自重写的带参Forward方法，不同的是算子类的输入inputs只有一个Tensors，表达式类的输入inputs有多个Tensors。在具体执行的过程逻辑中，需要根据表达式的含义，对输入inputs中多个Tensors进行相应运算，写回到输出Outputs中。（见<code>expression.cpp</code>中的<code>ExpressionLayer::Forward</code>函数）</p>
<blockquote>
<p>到底如何根据字符串表达式，对多个Tensors进行运算呢？这里举个例子：比如<code>std::vector&lt;std::shared_ptr&lt;Tensor&lt;T&gt;&gt;&gt; a</code>和<code>std::vector&lt;std::shared_ptr&lt;Tensor&lt;T&gt;&gt;&gt; b</code>相加</p>
<ul>
<li>首先对表达式进行词法解析，将字符串分成一个一个的token（<code>ExpressionParser::Tokenizer</code>）</li>
<li>然后对这些token进行语法解析，转换成一棵语法树（<code>ExpressionParser::Generate</code>中调用<code>ExpressionParser::Generate_</code>）</li>
<li>输出语法树的后缀表达式，即表达式的逆波兰表达式（在<code>ExpressionParser::Generate</code>中调用<code>ReversePolish</code>）</li>
<li>使用栈结构，遇到数据类型的token就入栈，遇到运算符号类型的出栈两次，计算完再入栈</li>
</ul>
<p>即抽象表达式-&gt;词法解析-&gt;语法解析-&gt;语法树后序遍历得到逆波兰表达式-&gt;用栈计算，本来应该这样计算的，但是可以进行一些优化（这也是代码中实际上的过程）：</p>
<ul>
<li>词法解析，但是注意表达式的形式（<code>mul(@1,add(@2,@3))</code>，而不是<code>1*(2+3)</code>），词法解析后，tokens中的token，是表达式的前缀遍历：<code>mul ( 1 , add ( 2 , 3 ) )</code></li>
<li>在遍历过程中，逆序遍历，同样栈计算</li>
</ul>
<p>参考：https://github.com/zjhellofss/KuiperInfer/issues/33#issuecomment-1718600527</p>
</blockquote>
</li>
</ol>
<p>，首先在表达式外部，将a和b都添加拼接到一个<code>std::vector&lt;std::shared_ptr&lt;Tensor&lt;T&gt;&gt;&gt; inputs</code>中。然后由于之前已经注册过表达式类<code>ExpressionLayer</code>（与算子注册相同，都是添加到全局注册表中），而且构建KuiperInfer图结构时，已经为节点添加过算子</p>
<h5 id="overview">Overview</h5>
<p>整体算子结构的<a href="http://www.plantuml.com/plantuml/dsvg/xLTVRzDM57_tfxZI94X7WWHxix88w62gDlw88l4ONU9Ri71iw_gwq6MPiee0XV27KOP6KGSF7TK4j1qJj6bBlqok4vxu2ZlsSHmxJgC6RJpjpRtdtDyvlz_vSviZZg1Sk6M3V4zd69yKt2q9bpD5sK_Qhn_BL_SxlpsHlpVRQvjAoQ2EWtuLXP03f48lE8BJagYI4nQ_GhcM6ICgcHHKkCwufR7Tl7JJTeMJ9POh_8_KfI-8uKSfchJCYc1qXAQg0AAR5mChTqsXWyco6QV2uf7F5KOl5st1ysVHutJeK52gYca9HWms9OWrXInKDGK4yAtrkvsL9IGlLpPaSxxzv5hdrcnxTaDXfaO275yVx_4pUMyM7KDnJbdc6SffEO0dbQgIF3XuyCS2XevdOn93DoyJ5ItvASEYeX04U3hN7o2E7aXnXUaNBmadKc2QbO177XMxH3dJ0ZtECTEnkjY5Gd3rWav7lbTLFfqE4l7UBClhZRv-Eiikweu8ILMcT6PeLP8ZuvnHmT38PyZNc6gPslbOHsJH3OfC4fShqDf2BrK93-y3rpx4BvCtGfn4DsR6CYNBT0H9AfFki7tPb4jSWCA-CPo6RbRT739ZWzDAkJ8UvXTF22M0s7WMUkppCQSjNUi3mZ11Mdjb1KZ3UIKZuDoA6PivFh5qRs72VYCb2v_FvS9MIWzgvAMglLf2N5bVbcirER_IMgzXMtMUByTdT1XIA9KFSsFRUxJgDMvy-ENcnwr6--LBm6kj_mcpX-Vo_WES_z3QRFHPG__tTNbpGMusOLzWh-yrbrulG3eVjsuYZDnu-t5hhhCpBnSMvPr7hVUt8xozm34Ue_Xq6SMAP6gjl_BURSfRpp1tp1SIznQlGMZlrmsvTG_eoZjly0gwZKOhrcx1Ncssjfx9-bAqJf7cQ9Yn1WFCK9mqjRaQBC-e3h1jvEBjU8W1kuVnyvpQDYwXU4-hk_ZX22MDiSw2eKmFwfXI9SfWE1o1k4c1hNcM6MxY1V0FSFsogm8OzJywcFnUNzg8v85mEKoOS6AMMCQoipZDVNVsn-6Hu0WF28WoYdSgzf24_wqrdGnP3TkHmpCRz6Ealwec4r18O1iuIJZMC4poZzdMzgFMzavxVXc703nREy-zdrTm6k9p1Wi06npMGDIyYPw0LWSW7mAkDHVakoLPVuVxp1_UrJMvUbtMttfp3sK3bjCg0p743DnIy8lGaj2dGL3BJ3ozHwFZ4wvPwZwyK_3jd-NzfoKpLHH1jOeEY9WbYJ_7_6VXg6qRCvEJntjWcTxdEPXWaBelaaBY1s6J2N3Dag6TJFh-lulnKjLq7i7ZyNgnVNUrrRpUkRqaD_xoTchUtvie7UW9ChQs7tfpBphF6nzgcvtt3te5Y6cMonLw3T7TAYVfrJEMPS2uVxOv_NzE2SaHcseQg5u4YwkRugl3HK7GWEKeEleFB6trLxFMTrxrT--uPKudTkynwZ3_q39Sl_p9ydx6sfBuZweS6RVA0CnE1_YPdw9__eRwJO8MWI_gR5ETvxlyiv4I-4lXgAOTqwcJW8RZziAwhB-HQujUxOMl68gqgq03rQi49PXm3bqzz1tZ9ZDEMMUmZ1Zj0fGENKnTJ9GFZrl6-U0dJoQUop0DFfruBk3oxV6J9zFiqOO9eONoCeKTMQQYfyKth3IQ6lyX5ym5qZqyKKxpGJko7SJd22Jjber_0000">UML类图</a>及<a href="https://github.com/QinganZhang/UtilityRoom/blob/main/KuiperInfer_Layer_Structure">PlantUML代码</a></p>
<p>
  <img loading="lazy" src="https://www.plantuml.com/plantuml/svg/xLZTRnF75d_VlsAaAu5phur4xjigrm9o0KKj7oAHUAWgQ_5EO8MzkzsT3KbJLsuW8O40eIH59IY4LYbH1IHf4EGx_undRPxu5tfspcO_niOrgF3Kj_MSCxyvvtS-peoFkKnpc5SkaI-r4UeK-fdZ5PddK4KvJEel7_8NCusV7_4dM_MrRQLOqbmN5KSLGlv3HhLBBdEq8gkGKvPpJNFqJ1THIJ_JcEVsMZfzdvPXsXvpiyJoMF3HjEbVf2JCCRKoBO3GPRgg0eXXNXPInpEP0IBBfex6B2VIkKQrgmMREJqNKEDSg91NAeffCKfAT90HQn2zKDKc882lRTnjh2oXytnbas_DrX_TQDmQguzjAjJKYS1Hb9WXVtsPJqnB35sWbmsNKOS4L8qE6hIaLqYEz3fKOnI5pWZv7vfTrkoUX8zPL0EpIMhpg0ia6SKASSBzuBU4-E_qZX0dnM-cArEqJ9U5h5xH7AgtvEnGjab5kDOpMB8qbiyVwXBnZQmwi27JrTgi9bNgXFOb3K8Au6nS2pKE1PX3bg5BG7YCCAjJhm2flL_f4p0JsOXDtKoqTOWM0IiPio33qe7loUKm5PJcr8kqL3ME9PpBnvVvMfNFhjGsgfXMZQVBSTQrHmgf2c1kxlfpg_xqpRS_JhxRcQu_VmvujOtV-RqnNESpzp6ZG-dMj2GDzVV6-UGytzw22i1SxzIME1V0d7SxamZ3Dr-_svbgxC_o-GL-PwwsTpl2wmIEEWaN7oyZMH5DjOqN_fjjVciHRKTxmN1_uGOSxV-qoNVkWRlypZfkGRKFSokHRg9JRDLs5lduKjGWqCqFmqma660YEIrScwhwZwUYE42tuGktaqUqw3tKkUXejerDA9dJQakzg8GaOPHPM9HIeNOf5QAqXiCII8f4r_GVBaAgeH-XsMSjyxpcQ6MXJ4OhIdhXo97lyWYKPD8a9SEyYiv4rHiS04J91oJHnGYvHetBLvXRa2fQRWm3r7Ijg3FanTPBXlR1-ohAnxl3Dwv3CZHMh_jphnH4o7rrnT1rQdwTovCqUQ6_AEuDley2dwHvNqf5WHyqlTA4q_tNEDrDEDqjDiJ6Ic7EoJObVCYbKLDsvPAGmDW5Ml9IqGyMy0WwpA1cf8J3ykZqTXAL4Mp1Vj1dmefPf1dBpkAyaFOSJi9Z2NMUF3Y7EzUMpsvdyDzq4P2Eh4WDBw9VLTFdAqJ8MhPgd1lGhVblOxNTkThkVdrs6RiiQDRsd_e_h62xJJPoc33OGM7EHDqnbHBGIm48889jM_FypH8VVuC3CvWEgsjyTOAFl_Qd7l1fc7wh5BXW8x1BmI-Y5Pan17nQPkfkTpnQFkMPnOERtI1y1sizmTqbCrXW8bW55pZCajJFhg2v7BVjqaX__yaOB1D_3i280AQbanIIN0XpZ85gbhHDP29VYME_LBNP3d4xURbGlxjQsvfet5xYct_u-rN_rJPI1tm2ZRNT1_xKiyRJwRVLxSRU_JW02SvokNoS40f-oHqYLZ-OQsUquVEMLOA1yzdg-9yw9YH7R4tNWVK2I3p3PF_jBZ220Wn7mJM-fStIu7AWI-kLe3VtMkPGgZUVq5mQB5ebBmXuEhoVCROa-L25bvDL1c1wJk1dle-U7str-e4BeOiysvhXz1pudusOm5l4SLq_OMXk2XgMw_CRV7oThoturMS1OqZIUmbgoTwe246VUtJuw1VKCMdfh7KUmuYdNOBGeOffiBvoTwzLkYYkGvcaBUqu-7Z7SyANqoVFd6ds7cLe44eqfwn14orhBERY_xJu4Mny6b_G5Z2tkw_Sx0_AqTjM_a0vmEM-iRS7uuwlZM7eGoy7hAlK39EU1T_YXK1K50m4tq8c_i0fs1RK0b0GV80EsWXd9C7E1ar_57UPNhbWc3eTZfLH40o3B762P4W_atiYZ3o9S4yEsmvrNKCqOJVYMjWhNv4H81yh55pcI4hIYneRYSPecPfC-Xy8-JrDJUg0GY4JUj7oTH-RBdmKFo78JYOeXDGV2n5WgwT-QqnnkPU8m9UFK6ajYdRBRqDPMrKZQuF7uSeTVtskyUnNVo5wNdO04JibC5v46C7hV_Q9Fpc3Y_xYVL3m7rVvp5syHRsjJlZhl_3nrIXFayV2J4hcRrDIj1tL7KJN5lP78iyqll6eO5_sCV-9XqEKDdtkmJJDYDy7xPIGe2hIhcEePLE1jcF0XrSk_Ga0" alt=""  /></p>
<p>整个推理框架的总体结构Overview的UML类图及PlantUML代码</p>
<h3 id="算子开发流程">算子开发流程</h3>
<ol>
<li>写算子
<ul>
<li>根据是否含参数，继承<code>NonParamLayer</code>或者<code>ParamLayer</code>，因为如果含参数，设置weight和bias的过程是可以复用的</li>
<li>在具体算子类中，必须实现两个函数
<ul>
<li>带参的Forward函数，是算子执行的具体逻辑，输入Tensors在计算之后，写入到输出Tensors中。函数签名为：<code>StatusCode Forward(const std::vector&lt;std::shared_ptr&lt;Tensor&lt;float&gt;&gt;&gt;&amp; inputs,std::vector&lt;std::shared_ptr&lt;Tensor&lt;float&gt;&gt;&gt;&amp; outputs) override</code></li>
<li>根据节点的信息（比如参数和权重），创建算子的函数，使用时经常作为函数指针传入到注册函数中。函数签名为：<code>static StatusCode CreateInstance(const std::shared_ptr&lt;RuntimeOperator&gt;&amp; op, std::shared_ptr&lt;Layer&lt;float&gt;&gt;&amp; layer);</code></li>
</ul>
</li>
</ul>
</li>
<li>注册算子
<ul>
<li>在<code>LayerRegisterer::RegisterCreator</code>中，使用单例模式获取全局注册表，然后向全局注册表中添加{算子名称，算子创建过程的函数}</li>
<li>在对应算子的实现文件中，重写完算子的Forward函数之后，顺便将其注册。
<ul>
<li>比如relu算子在<code>relu.cpp</code>中重写完Forward函数之后，紧接着进行了注册：<code>LayerRegistererWrapper kReluCreateInstance(ReluLayer::CreateInstance, &quot;nn.ReLU&quot;);</code></li>
</ul>
</li>
</ul>
</li>
<li>创建算子实例
<ul>
<li>在<code>LayerRegisterer::CreateLayer</code>中，因为算子已经注册到全局注册表，所以可以得到该创建该算子的函数（拿到了函数指针），根据节点中的信息（比如参数、权重等），创建一个算子并返回该算子</li>
</ul>
</li>
</ol>
<h3 id="计算图的执行过程">计算图的执行过程</h3>
<ol>
<li>
<p>在<code>RuntimeGraph::Forward(bool)</code>中，节点按照逆拓扑顺序进行遍历（此时<code>RuntimeGraph::operators_</code>中节点已经按照逆拓扑顺序排好）</p>
<ul>
<li>
<p>每个节点调用其指向算子的<code>Forward()</code>方法，执行算子的计算过程，得到输出操作数，这个过程在<code>runtime_ir.cpp</code>中的<code>ExecuteLayer</code>函数中</p>
<ul>
<li>算子的计算过程：当前节点op调用其算子的<code>Forward()</code>方法，此时进入了Layer虚基类的<code>Forward()</code>方法，首先从节点op中得到输入操作数和输出操作数，然后因为算子与节点关联，所以在Layer类中有指向op的指针，<code>op-&gt;layer</code>是指向Layer虚基类的指针，但是由于多态特性，此时<code>op-&gt;layer</code>的动态类型是指向特定算子的指针，因此调用带参的<code>Forward()</code>方法，就进入了具体算子的计算过程</li>
</ul>
</li>
<li>
<p>将当前节点的输出，传播到当前节点后继节点的输入中，对应函数是<code>RuntimeGraph::PropagateLayerOutputs</code>，这个函数很重要，其中数据结构比较复杂，而且进行的只是指针的修改，而没有真的将前一个节点的输出复制到后一个节点的输入</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">RuntimeGraph</span><span class="o">::</span><span class="n">PropagateLayerOutputs</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">RuntimeOperatorBase</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&amp;</span> <span class="n">current_op</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&gt;&amp;</span> <span class="n">layer_output_datas</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="p">[</span><span class="n">_</span><span class="p">,</span> <span class="n">output_op</span><span class="p">]</span> <span class="o">:</span> <span class="n">current_op</span><span class="o">-&gt;</span><span class="n">output_operators_map</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// current_op的后继节点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 对于当前节点的每一个后继节点output_op，得到其输入Operands的map
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">next_input_operands_map</span> <span class="o">=</span> <span class="n">output_op</span><span class="o">-&gt;</span><span class="n">input_operands_map</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">        <span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">next_input_op_iter</span> <span class="o">=</span> <span class="n">next_input_operands_map</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">current_op</span><span class="o">-&gt;</span><span class="n">name</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 在后继节点的输入Operands的map中，找到了当前节点的名字
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">if</span> <span class="p">(</span><span class="n">next_input_op_iter</span> <span class="o">!=</span> <span class="n">next_input_operands_map</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="c1">// 后继节点的输入Operand中保存的Tensors
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>            <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">tensor_sptr</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;&amp;</span> <span class="n">next_input_datas</span> <span class="o">=</span> <span class="n">next_input_op_iter</span><span class="o">-&gt;</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">datas</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="p">(</span><span class="kt">uint32_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">next_input_datas</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="c1">// 从当前节点的输出Tensors中，取出指向第i维Tensor的指针
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                <span class="k">const</span> <span class="n">tensor_sptr</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&amp;</span> <span class="n">layer_output_data</span> <span class="o">=</span> <span class="n">layer_output_datas</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">next_input_datas</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">!=</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                    <span class="n">CHECK</span><span class="p">(</span><span class="n">next_input_datas</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">shapes</span><span class="p">()</span> <span class="o">==</span> <span class="n">layer_output_data</span><span class="o">-&gt;</span><span class="n">shapes</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">                <span class="p">}</span>
</span></span><span class="line"><span class="cl">                <span class="c1">// 检查输入输出形状相同后，将后继节点的对应于当前节点的输入Operand，将对应维度的数据成员（即Tensor）指向当前节点对应的Tensor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                <span class="c1">// 即整个过程没有出现数据复制，只是将后继节点中指向输入Tensor的指针也指向了当前节点输出Tensor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                <span class="c1">// 这与构建时，为输出Operand开辟空间，而不为输入Operand开辟空间相一致
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                <span class="n">next_input_datas</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">=</span> <span class="n">layer_output_data</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>重复上述过程</p>
</li>
</ul>
</li>
</ol>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
