[{"content":"首先声明一些符号：\n模型参数量：$\\Phi$ GPU数量：$N$（有时候可能误写成了$n$） Pipeline degree（或者说PP size）：$p$ TP size：$t$ 除非特殊声明，某些未说明的符号可能遵循LLM时代的transformer参数量、计算量、激活值的分析的符号表示。\n数据并行 传统数据并行DP 使用场景：每张卡上都有一份完整的模型（因此模型不会太大），通常单机多卡（比如单机八卡进行数据并行）\n具体方法：基本使用参数服务器的编程框架，\n最基本的范式为：\n将一个batch分成若干份mini-batch，每个worker上进行一份mini-batch的计算（前向和反向），得到一份模型参数的梯度\nAllReduce梯度：每个worker将梯度push到Server上，Server对梯度进行reduce（或者说求平均），再boardcast给每个worker\nServer即称为参数服务器，可以是GPU，也可以是CPU，也可以是多张GPU/CPU。如果是CPU，则通过PCIe通信，慢；如果是GPU，则通过Nvlink通信，更快；如果Server是多张GPU/CPU，则Server之间也要进行通信\n每个worker更新参数\n在第一步得到worker上自己的梯度之后，更新梯度有两种方式： 第一种方式就是上面的，AllReduce梯度后，每个worker得到平均后的梯度，然后每个worker再更新参数（下面的DDP也是这种方式） 第二种方式是，每个worker的梯度push到Server上，Server同样对梯度取平均，并且Server上也有一份模型参数，Server对这份模型参数进行更新，最后将更新后的参数boardcast给每个worker。这种方式明显对Server压力更大（原来只要allreduce梯度，现在还要自己有一份模型参数，还有更新参数），但是worker就省了更新参数。\n另一种参数服务器的范式为：每个GPU都是参数服务器，比如说GPU1负责w1的AllReduce，GPU2负责w2的AllReduce，\u0026hellip;\n缺点：\n每张卡上都要存储一份完整的模型，而且没法与其他并行方式组合使用\n通讯开销大，因为push和boardcast传输的都是一份完整的参数的梯度\n每次迭代，每个Worker（共N-1个）push的通讯量为$\\Phi$，Server总通讯量（boardcast）为$(N-1)\\Phi$，所以更大的问题在于通讯负载不均，系统总通讯量为$(N-1)\\Phi + (N-1)\\Phi = 2(N-1)\\Phi \\approx 2N\\Phi$（与DDP相同） Server进行allreduce的过程中，其他所有worker都在等待\n针对这一点，某些框架提出了一些异步的解决方法，但其实都是一个效果与性能的tradeoff，比如参数服务器中3.4节提到了 Asynchronous Tasks and Dependency（其实我没太看懂），这篇博客图解大模型训练之：数据并行上篇(DP, DDP与ZeRO)中对这一部分进行了说明，文中叫做“梯度异步更新”，比如在延迟为1的异步更新中，下面重新画一下示意图（这里是针对某一个worker进行示意）。其实感觉就是梯度累计的意思（这篇博客中也简要提到了梯度累计，搜索\u0026quot;gradient accumulation\u0026quot;）\n分布式数据并行DDP 使用场景：每张卡上都有一份完整的模型，常用于多机多卡\n具体方法：\n将一个batch分成若干份mini-batch，每个worker上进行一份mini-batch的计算（前向和反向），得到一份模型的梯度\n使用Ring-AllReduce，使得每个Worker都得到一份完整的reduced梯度（聚合后的梯度）\n有几个关键词需要注意：一份完整的/一块不完整的，reduced/un-reduced，完整是指tensor没有切开，reduced是指多个tensor经过allreduce聚合\n一开始每个Worker只有自己的一份完整的un-reduced梯度，而且将梯度分成N块 Reduce-Scatter：每次每个Worker向相邻的下一个Worker发送一块不完整的un-reduced梯度（大小是$\\frac{\\Phi}{N}$，进行一次reduce），一共N-1次，通讯量$(N-1)\\times \\frac{\\Phi}{N}$，此时每个Worker都有一块不完整的reduced梯度 All-Gather：每次每个Worker向相邻的下一个Worker发送一块不完整的reduced梯度（大小是$\\frac{\\Phi}{N}$，直接进行替换），一共N-1次，通讯量$(N-1)\\times \\frac{\\Phi}{N}$，此时每个Worker都有一份完整的reduced梯度 因此通信量为：$2\\times(N-1)\\times \\frac{\\Phi}{N} \\approx 2\\Phi$ 效果：\n摆脱了参数服务器的编程框架，各个Worker地位相同，解决了参数服务器方式中通讯负载不均的问题 每次iteration，单卡总通讯量为$2\\times(N-1)\\times \\frac{\\Phi}{N} \\approx 2\\Phi$，系统总通讯量为$2\\times(N-1)\\times \\frac{\\Phi}{N} \\times N \\approx 2N\\Phi$。DDP与DP通讯量相同，但是DDP通讯负载均衡 实现细节：梯度分桶（Gradient Bucketing）\n原理：（不局限于大模型）\n论文中的原话是：instead of launching a dedicated AllReduce immediately when each gradient tensor becomes available, DDP can achieve higher throughput and lower latency if it waits for a short period of time and buckets multiple gradients into one AllReduce operation. This would be especially helpful for models with many small parameters. However, DDP should not communicate all gradients in one single AllReduce, otherwise, no communication can start before the computation is over.\n集合通信在小tensor上性能较差，在大tensor上性能较好，因此尽可能将模型的梯度lazy allreduce，将多个小梯度打包然后再allreduce。下图中表示对于一个60M的fp32 torc.Tensor，横轴是将该tensor切成不同大小的tensor进行allreduce，纵轴表示通信时间。\n对于一个大梯度，也不要只使用一个allreduce来通信。这主要考虑到计算和通信的overlap，将梯度的计算和梯度的allreduce通信进行重叠\n所以梯度分桶的做法将模型的Model的参数逆序插入每个Bucket中，当一个Bucket的参数的梯度都已经更新时，开启Allreduce，向另一个节点的对应Bucket传递梯度，这样也同时实现了异步AllReduce。更详细的过程可以阅读这篇博客：Pytorch Distributed Data Parallal\n参考：\n第3篇 - 分布式训练常用的集合通信及其通信原语 图解大模型训练之：数据并行上篇(DP, DDP与ZeRO) PyTorch DDP desigin doc ZeRO内存优化 背景：DP或DDP中，每个GPU中都有一份完整的模型，模型变大后，不仅仅是模型参数量更占显存了，同时训练过程中的优化器状态、梯度等也相应变大了，而显存是有限的，因此要尽可能节省显存。ZeRO就是对优化器状态、梯度这部分显存的优化。\n核心思想：通信换空间。优化器状态、优化器中混合精度训练时使用的fp32参数 在前向、反向时不使用，只有在参数更新时才使用，即计算过程中内存出现了冗余。因此将这些内容放在放在不同的GPU上，使用时再经过通讯获取到完成的一份。\n关于模型在训练时，显存中到底存了哪些东西，可以参考GPU上都存了哪些东西；混合精度训练，可以参考混合精度训练\n具体方法：ZeRO-DP、ZeRO-R，ZeRO-Offload是三种正交的显存优化方法\nZeRO-DP：是针对model states的优化，ZeRO-1、ZeRO-2、ZeRO-3是三种不同程度的优化\nZeRO-1（$P_{os}$）：将optimizer states和fp32参数切分，每次迭代中，\n将batch分成N个mini-batch，每个GPU输入一个mini-batch，每个GPU有一份完整的fp16的参数，经过前向反向，可以得到一份完整的un-reduced梯度\n每个GPU上的完整的un-reduced梯度进行一次All-Reduce，每个GPU上都得到了一份完整的reduced梯度，单卡通信$2\\times(N-1)\\times \\frac{\\Phi}{N} \\approx 2\\Phi$\n每个GPU上只有一块不完整的optimizer states，因此只能更新对应的一块不完整的参数\n每个GPU上不完整的参数进行一次All-Gather，此时每个GPU上都得到了一次迭代后、更新后的完整的参数，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$\n但是上述方法不是最优的（单卡通信量为$3\\Phi$），更优的方法（单卡通信量为$2\\Phi$）为：\n将batch分成N个mini-batch，每个GPU输入一个mini-batch，每个GPU有一份完整的fp16的参数，因此可以得到一份完整的un-reduced梯度（同上） 每个GPU上的完整的un-reduced梯度进行一次Reduce-Scatter，每个GPU上都有一块不完整的reduced梯度，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ 每个GPU上有且只有对应的一块不完整的optimizer states，因此正好更新一块不完整的参数，得到updated参数 每个GPU上不完整的updated参数进行一次All-Gather，此时每个GPU上都得到了一次迭代后、更新后的完整的参数，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ ZeRO-2（$P_{os}+P_g$）：将optimizer state和fp32参数、梯度切分，（过程同上面那种更优的方法）\n将batch分成N个mini-batch，每个GPU输入一个mini-batch，每个GPU有一份完整的fp16的参数，因此可以得到一份完整的un-reduced梯度 每个GPU上的完整的un-reduced梯度进行一次Reduce-Scatter，每个GPU上都有一块不完整的reduced梯度，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ 每个GPU上有且只有对应的一块不完整的optimizer states，因此正好更新一块不完整的参数，得到updated参数 每个GPU上不完整的updated参数进行一次All-Gather，此时每个GPU上都得到了一次迭代后、更新后的完整的参数，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ ZeRO-3（$P_{os} + P_g + P_p$）：将optimizer state和fp32参数、梯度、fp16参数切分\n将batch分成N个mini-batch，每个GPU输入一个mini-batch，此时每个GPU只有一份不完整的fp16参数 forward过程中，对不完整的fp16参数进行一次All-Gather，每个GPU得到了一份完整的fp16参数，可以进行forward。forward完成后，丢弃掉刚才All-Gather得到的fp16参数。单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ backward过程中，再次同样对不完整的fp16参数进行一次All-Gather，每个GPU得到了一份完整的fp16参数，可以进行backward，得到一份完整的un-reduced梯度，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ 每个GPU上的完整的un-reduced梯度进行一次Reduce-Scatter，每个GPU上都有一块不完整的reduced梯度，并且丢弃掉剩余的梯度，单卡通信$(N-1)\\times \\frac{\\Phi}{N} \\approx \\Phi$ 此时每个GPU上有一块不完整的optmizer states和一块不完整的reduced梯度，正好更新对应的一块不完整的参数，得到一块不完整的updated参数，而且此时不需要对不完整的update参数进行All-Gather操作（因为本来就是被切开的） ZeRO-R：针对residual state的优化\n$P_a$：针对中间激活值，激活值只起到一个加速计算梯度的作用，这里将激活值也进行切分，每个GPU上保存一份，在反向计算梯度需要完整的激活值时再经过通讯获取完整的激活值 $C_B$：针对一些操作或算子需要开辟buffer或者临时数组，这里预先开辟较大的内存buffer，并在后续保持固定 $M_D$：针对频繁内存申请和释放可能导致的内存碎片，这里将内存大致分为两个部分，long lived参数放在一个部分，将另一些经常构造析构的中间激活值等放在另一个部分 ZeRO-Offload：\nforward和backward计算量大，因此将fp16的参数、激活值放在显存中 更新参数的计算量小，因此将optimizer state（和fp32参数）、梯度放在内存中 效果：\n通信方面：ZeRO-1和ZeRO-2相较于DP或者DDP没有增加通信量，ZeRO-3仅仅增加了0.5倍的通信量。 显存方面：极大降低了（单卡）显存占用。图中K=12，是对应fp32 param（4）+fp32 momentum（4）+fp32 variance（4）；前面两个2分别是fp16 param（2）和fp16 grad（2） 其他说明：\n为什么ZeRO是数据并行？明明把优化器状态、梯度甚至参数切开了 模型并行是只使用自己那部分参数进行计算，将中间结果（激活值）进行通讯（比如TP） ZeRO-DP将优化器状态、参数、梯度等切分放到多个GPU上，ZeRO-R将输入和中间激活值切分开放到多个GPU上，在实际运算时，每张卡上输入的mini-batch不相同，首先需要经过通讯，拿来完整的输入和完整的参数进行前向计算，拿来完整的中间激活和完整的权重反向传播计算梯度，因此ZeRO只是内存优化后的数据并行 参考：\n图解大模型训练之：数据并行下篇( DeepSpeed ZeRO，零冗余优化) ZeRO: Zero Redundancy Optimizer，一篇就够了 分布式训练：了解Deepspeed中的ZeRO1/2/3 FSDP(FullyShardedDataParallel) FSDP是DeepSpeed ZeRO-DP的进一步发展，主要实现了与PyTorch的co-design，改进主要体现在计算和通信的粒度，FSDP中前反向的计算都是以FSDP unit为粒度执行的。\n(need further understanding)\n推荐好文：\nPyTorch FSDP 设计解读\nFSDP 完全分片数据并行\n流水线并行 流水线并行大致可以这样进行分类：\n同步流水线 F-then-B：GPipe 1F1B non-itlv：PipeDream-flush itlv： parallel-shape：Megatron-2 v-shape：Zero-Bubble-V 1F2B：Zero-Bubble 异步流水线： PipeDream PipeDream-2BW 使用流水线并行有两点需要注意：\n流水线并行的通信量不大，因为只涉及到不同stage输入的通信（后面一维张量并行中会比较PP、DP、TP的通信量）。这里符号沿用LLM时代的transformer参数量、计算量、激活值的分析，并设置一些新的符号表示：设micro-batch数量为m，每个micro-batch的大小为$b_m$（因此有$m \\times b_m = b$，将模型划分为$N_s+1$个stage（或者叫做cell，chunk，在interleave场景下是virutal stage的数量），流水并行度即文章开头提到的$p$。（下面以transformer为例进行分析）\n一个micro-batch在一个stage的通信量是$w \\times 2\\times b_m sh$（2表示FWD过程中要将输出激活值通信+BWD过程中要将对输入激活值的梯度进行通信），m个micro-batch在切分成$N_s+1$个stage时，总的需要通信的数据大小为$m \\times 2wb_msh \\times N_s=2wbshN_s$，每个Device的通信量为$\\frac{2wbshN_s}{p}$\n我们来举几个例子，来量化感受一下（假设使用缓和精度训练，w=2，1F1B，non-itlv）\nmodel b s h 单层单次通信量$wbsh$ GPT-3 175B 1 2048 12288 96MB Llama-2 70B 1 2048 8192 128MB Llama-3 405B 1 4096 12288 192MB PP不推荐ZeRO-2/ZeRO-3同时使用，原因在于增加了很多通信，但是缺节省不了多少下显存。\n下图中是PP+ZeRO-2的示意图，dp_size = 2，每个DP内部又划分为p = 4的PP。每个DP吃掉的mini-batch都是不同的，PP又将每个DP吃掉的mini-batch再次切分为micro-batch，即图中DP1对应micro-batch1~4，DP2对应micro-batch5~8。注意，由于使用ZeRO-2（或ZeRO-3），会对反向得到的梯度进行切分，DP1反向得到完整的un-reduced梯度，DP2反向得到完整的un-reduced梯度，然后进行Reduce-Scatter通信（比如GPU4上mbs1的梯度要与GPU8上mbs5的梯度进行Reduce-Scatter通信），DP1得到不完整的reduced梯度（即前半部分参数对应的梯度），DP2得到不完整的reduced梯度（即后半部分参数对应的梯度）。除此之外，由于PP使用梯度累计，所以最后UPD先进行梯度累积，然后使用不完整的redued梯度更新完权重后，还要进行All-Gather通信拿到完整的权重（因为ZeRO-2没有切权重）。如果是PP+ZeRO-3，则要在每个mbs的前向过程之前进行一次All-Gather，在mbs的反向过程之前进行一次All-Gather，反向过程之后进行一次Reduce-Scatter，最后的All-Gather可以省去。\n针对大模型而言，PP一般是要使用的，此时再使用ZeRO就是想减少单卡的内存占用。一方面，我们来看一下PP+ZeRO-2对减少内存占用的一个效果，PP切分模型后，每个stage上的参数量基本上是整个模型参数量的$\\frac{1}{N_s+1}$，ZeRO-2又切分了梯度，相比于ZeRO-1内存占用减少了$\\frac{1}{N_s+1}(1-\\frac{1}{N})w\\Phi$（如果进一步使用TP并行进行切分，则会进一步减小内存占用，这个内存减少的量也会进一步减小），因此，使用PP后再使用ZeRO-2可能节省不了多少显存。另一方面，从通信量来分析，由于ZeRO-2的梯度切分，反向得到梯度后要在DP group间通信，PP将mini-batch切分为micro-batch，又使得梯度Reduce-Scatter变得很频繁（相当于DP group变多），每一次Reduce-Scatter通信量都是两倍的对应梯度大小再乘以数值精度，通信量直接暴涨（虽然有可能做到计算和通信overlap，我也不太确定这一点，但是毕竟性能肯定还是有损失的）。PP+ZeRO-3也是同理，显存占用可能再少一点，但是带来的通信量增加是很大的。因此，在PP基础上使用ZeRO-2（或者ZeRO-3）节省不了多少显存，还会增加很多通信量，对性能的提升可能很有限甚至负提升。可以参考知乎问题：大模型训练时ZeRO-2、ZeRO-3能否和Pipeline并行相结合？\n但是可以PP+ZeRO-1（比如下图），由于梯度（和权重）都是完整的，先进行完整的un-reduced梯度的梯度累积，然后进行Reduce-Scatter通信，得到不完整的reduced梯度，ZeRO-1只会切分optimizer_states（和混合精度中使用到的fp32权重），正好更新那一部分权重，最后使用All-Gather通信拿到全部的权重。\n参考：\n大模型分布式训练并行技术（三）-流水线并行 好文推荐：大模型效率工程（五）：一文读懂流水线并行训练升级之路 —— From Naive to V-shape Zero Bubble naive流水线并行：F-then-B 如果模型太大（参数量太大），单卡装不下时，将模型横着切，每个部分（可能是多层，称为一个chunk）放在一个GPU上：\n模型可以训练起来，但是一个缺点，就是GPU利用率不高，bubble很多，某一时刻只有一个GPU在进行计算。\nGPipe：micro-batch GPipe主要是针对naive流水线并行的改进，主要是提升GPU利用率，减少bubble占比。\n具体方法是，同样将模型横切，划分为多个cell（每个cell包含若干个连续的层，原来叫做chunk，后面PipeDream又叫做stage，一个意思），每个cell放在一块GPU上。将输入mini-batch再划分为micro-batch，将多个micro-batch依次送入到模型中，形成流水线，这种策略也叫F-then-B。简单来说，模型切法没变，batch切开。\n第一个下标表示GPU编号（或者cell编号），第二个下标表示micro-batch编号，横轴表示时间，纵轴表示不同GPU。比如$F_{0,1}$ 表示第1个micro-batch作为cell0（对应GPU0）的输入。假设划分为M个micro-batch，则bubble占比为$\\frac{N-1}{M+N-1}$。\n有一个细节需要注意，将mini-batch切成micro-batch，会对Batch norm的计算有影响，因为原来BN是对整个batch的相同channel进行norm，现在整个batch被拆开成好几个micro-batch，每个micro-batch都能单独计算一个BN，但是同时还维护一个全局的、针对所有micro-batch的移动平均和方差，以供最后推理阶段使用。但是LLM或者NLP中使用BN好像不多，且micro-batch对LN没有影响（本来LN就是对每个token内部算均值方差）。\nGPipe论文中还提出了一个优化显存的方法：重计算（re-materialization，或者re-compute，也叫做active checkpoint，activation checkpoint），重计算不属于流水线并行（也不属于各种并行），这里简单介绍一下。在反向传播计算梯度的时候，需要上一层传来的梯度、该层的参数，还可能需要该层的输入激活值，如果在前向过程中这个激活值没有保留的话，就需要从之前的某个起点开始重新走一遍前向过程得到这个激活值，流水线并行恰巧比较方便确定这个起点，就是每个cell的输入。重计算降低的是峰值显存。\nGPipe有两个缺点：\n只有将模型划分得比较均匀时，流水线并行才能得到较为理想的效果；但是有的模型不太好均匀划分\n每个GPU，需要缓存每个micro-batch前向过程中的输入和所有的中间激活，一个解决方法是开重计算，开重计算后，每个GPU只需要缓存每个cell的输入即可，属于是时间换空间了。\n为了降低空泡比，就要增大micro-batch的数量，假设原来mini-batch大小不变，中间激活大小也没变，但是每个micro-batch大小就变小了，太小会导致计算效率变低。可以参考大模型效率工程（五）：一文读懂流水线并行训练升级之路 —— From Naive to V-shape Zero Bubble中3.2节 但是也会增加峰值显存。\n参考：\n图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例 PipeDream：1F1B PipeDream是一种异步流水线的方案，同时维护多个版本的权重，每次反向传播都会更新权重，PipeDream论文中提到的weight Stashing和vertical Sync（论文中说vertical Sync可以忽略），个人理解不是很透彻（水平方向上可以使用weight stash保证每个micro-batch更新的是对应版本的权重，但是竖直方向上Device4每次都更新权重，Device1上将梯度更新平均到了4个版本的weight上，最后训练出来，权重到底怎么算？），这里先暂且略过，待后续更新。\nPipeDream论文中提出了1F1B流水线并行策略，但它是异步的；Memory-Efficient Pipeline-Parallel DNN Training中提出了PipeDream-Flush（这是同步版本的1F1B流水线）和PipeDream-2BW（这也是异步版本的1F1B流水线，但它减少了对weight stash的维护）\n这里主要来描述一下同步流水线1F1B流水线并行策略，一个micro-batch的前向计算可以和另一个micro-batch的反向计算交叉进行，从而可以及时释放不必要的中间激活。因为是同步的，所以此时没有了weight stash。图中标号表示不同的micro-batch；蓝色块表示前向过程，每个同步阶段、每个stage都是基于相同的参数、吃掉不同的micro-batch；绿色块表示反向过程，每个stage基于相同的参数、使用与对应前向过程的中间激活（比如GPU0上吃掉micro-batch0，前向和反向中间有间隔，需要保证对应），得到梯度（实际上应该是累计的梯度）；红色块表示使用梯度更新参数。\n第一行三个图实际上是相同的，区别只是在于一开始前面几个micro-batch输入顺序有稍许不同（只要能保证上下游的依赖关系，可以随便调整）。这幅图除了示意说明1F1B，还说明了1F1B与F-then-B的耗时是相同的，bubble也是相同的。1F1B相较于F-then-B的优点，在于减少了中间激活，节省显存。GPipe前向过程中需要将每个micro-batch计算的中间激活值保留下来，而在1F1B中，分别需要保存4、3、2、1份中间激活，stage0中需要保存micro-batch 1~4计算的中间激活值，stage1中需要保存micro-batch 1~3计算的中间激活值，stage2中需要保存micro-batch 1~2计算的中间激活值，stage3中只需要保存一份micro-batch计算的中间激活值，因为随后的对应的反向计算中会使用该中间激活，使用完可以丢弃（或者由于LLM的规整性，可以复用），以后不会用到这些中间激活了。节省显存之后，就可以使用更多的micro-batch数量，从而达到减少bubble的目的。\n有一点需要注意，GPipe中，增大micro-batch数量不会降低显存占用，但是在1F1B中是可以的，更准确来说是，增大micro-batch数量，Device1的峰值显存在1F1B中会更少，相较于GPipe。比如原来micro-batch数量是4，现在micro-batch增大到8，那么GPipe中还是F-then-B的方法，但是1F1B中可以调整流水线编排：（上面GPipe的图中省略了micro-batch的标号，下面1F1B的编排中Device1最多只有4份中间激活）\n针对PipeDream和GPipe，而且也属于是1F1B的一个改进是PipeDream-2BW，可以看作是PipeDream和GPipe的折中和结合，PipeDream的异步+Gpipe的梯度累计更新参数+double-buffer。具体而言，就是流水线总体上是异步的没有flush（类似PipeDream），但是现在只维护了两个weight buffer；每输入m个micro-batch使用相同的权重，然后进行一次梯度累计和梯度更新（类似于GPipe，不像PipeDream是每输入一个micro-batch都要梯度更新）；对权重使用double-buffer，每隔m个micro-batch，更新旧的weight，后面接着的m个micro-batch切换weight。\nMegatron-2：interleave(itlv) 将模型分为多个chuck（若干个连续的层构成一个chuck，或者叫做virtual stage），每张卡上放2个以上的chuck，比如下面图示中，比如Device1上有两个chunk（0、1层组成一个chunk，8、9层组成一个chunk），micro-batch1分别经过device1的chunk1（0，1层）、device2的chunk1（2，3层）、device3的chunk1（4，5层）、device4的chunk1（6，7层）后，再返回，经过device1的chunk2（8，9层）、device2的chunk2（10，11层）、device3的chunk2（12，13层）、device4的chunk2（14，15层）。深色表示该Device上的第一个chunk，浅色表示第二个chunk。\n该方案要求micro-batch数量是Device数量的整数倍，因此才能最大程度的减少bubble。假设原来一个stage切成了v个virtual stage（或者chunk），一个mini-batch切成了m个micro-batch，气泡占比从原来的$\\frac{(p-1)(Time_{FWD}+Time_{BWD})}{m(Time_{FWD}+Time_{BWD})}=\\frac{p-1}{m}$降低到$\\frac{(p-1)(Time_{FWD} / v+Time_{BWD} / v)}{m (Time_{FWD}+Time_{BWD})}=\\frac{1}{v} \\times \\frac{p-1}{m}$，但是代价是PP之间的通信也变为原来的v倍。\nZero-Bubble：1F2B 原来流水线基本都是FWD和BWD相重叠，Zeor-Bubble中将BWD的过程进一步细化，进行拆分：\n反向过程中要计算对权重的梯度，这个过程记为W\n反向过程中要计算对输入的梯度，这个过程记为B\n一般来说，参数梯度计算耗时W \u0026lt; 前向过程计算耗时F \u0026lt; 激活值梯度计算耗时B\n原来B过程和W过程都融合在一起，只有二者都完成，才能进行下一个stage的反向。但是中间存在一个不必要的依赖：第i-1层的B过程隐式的依赖于第i层的W过程，或者说，原来只有$B_i$和$W_i$都完成了，才能进行$B_{i-1}$和$W_{i-1}$的过程，而实际上，只要$B_i$完成了，就能进行$B_{i-1}$和$W_{i-1}$的过程。甚至最极端的情况是，先完成所有的B过程，然后再进行W过程，来更新参数。\n来自相同micro-batch的F过程和B过程仍然要保持先F后B的dependency，W过程只要保证在上一个micro-batch的B过程之后就可以，比较灵活，因此可以进行手工调整以减少气泡，这是两个手工设计的流水线方案：\nZB-H1：相较于1F1B，ZB-H1气泡更少，峰值显存相同，主要是因为B过程提前，而且尾部的气泡可以被W填充 B过程和W过程计算时需要的激活值的显存分别记为$M_B=bs(34h+5as)$和$M_W=32bsh$，第i个Device： ZB-H1占用显存$(p-i+1)M_B+(i-1)M_W$，其他Device的显存占用不会比Device1显存少太多 1F1B占用显存$(p-i+1)M_B$，其他Device的显存占用明显少于Device1 ZB-H2：ZB-H2的气泡更少，但是峰值显存会变多 第i个Device，ZB-H2占用显存$(2p-2i+1)M_B+2(i-1)M_W$，相比于ZB-H1显存几乎翻倍 论文中附录F中说到，用显存换ZB-H2是值得的，在相同显存的情况下，ZB-H2的micro-batch size可以是1F1B的一半，由于大模型训练中几乎不存在设备利用率不饱和的情况，所以减小micro-batch size，以换取更少的bubble，这么看是值得的，况且显存可以使用ZeRO等方式进行优化。 参考：\nAI Infra论文阅读之将流水线并行气泡几乎降到零（附基于Meagtron-LM的ZB-H1开源代码实现解读）\n模型并行训练：零气泡流水线并行 ZERO BUBBLE PIPELINE PARALLELISM\nV-shape 首先说明，V-shape是在1F1B itlv的情况下的一个流水线模式。1F1B itlv（vpp）是左边的模式，第二次通过流水线的时候是顺序的，比如3个Device，模型6层（分成6个chunk，每层两个chunk），Device1上放1、4层，Device2上放2、5层，Device3上放3，6层。V-shape中，第二次通过流水线是倒序的，Device1上放1、6层，Device2上放2、5层，Device3上放3，4层。\nZero Bubble Pipeline Parallelism （Arxiv版本）在第6节介绍了 V-shape Zero Bubble Pipeline Parallelism，名为ZB-V，Pipeline Parallelism with Controllable Memory 对 V-shape 进行了系统性介绍，称 V-shape Zero Bubble PP 为 V-ZB。V-shape最主要的作用就是减少峰值显存，峰值显存降低到与1F1B相同（V-shape和Parallel-shape的通信还是相同的），下面是对比：\nHanayo 【分布式训练技术分享九】聊聊高效流水并行Hanayo: Harnessing Wave-like Pipeline Parallelism\n张量并行 流水线并行是将模型按层横着切分，张量并行是将模型按列切分，每张卡上放一块不完整的权重，以减少内存占用。\n首先来看如何对$Y=XW$的矩阵乘法进行TP切分，这是模型张量并行的基础。\nRowParallel：对W按行切分，此时X要按列切分，比如切成两份，X1、W1、Y1放在GPU1上，X2、W2、Y2放在GPU2上，Y在每个GPU上都有一份\n深度学习中，不仅要有Y=XW的前向计算，还要进行反向计算，求得对权重W和对输入X的梯度\nf： forward：split（或者说only keep one part），原来X在每张卡上都有一份，现在GPU1上keep X1，GPU2上keep X2 backward：all-gather，将GPU1上的X1的梯度和GPU2上X2的梯度进行all-gather通信，每张卡上都能拿到完整的X的梯度 g： forward：all-reduce，将GPU1上的Y1和GPU2上的Y2进行all-reduce通信，每张卡上都有reduced的Y1+Y2 backward：identity，或者说将Y的梯度broadcast给GPU1和GPU2 ColumParallel：对W按列切分，此时X要按行切分，比如切成两份，W1、Y1在GPU1上，W2、Y2在GPU2上，X、Y在每张卡上都有一份\n同样还要可以计算对权重W和对输入X的梯度\nf： forward：identity，或者说将X复制到每张卡上完整一份 backward：all-reduce，将GPU1上的X的梯度和GPU2上的X的梯度进行all-reduce通信，每张卡上都有reduced的X梯度 g： forward：all-gather，将GPU1上的Y1和GPU2上的Y2进行all-gather通信，每张卡上都有一份完整的Y backward：split（或者说only keep one part），原来Y的梯度在每张卡上都有一份，现在GPU1上keep Y1的梯度，GPU2上keep Y2的梯度 一维张量并行：Megatron-LM 具体过程 总的通信量为：$w(vh+4bsh \\times l + 2bs + N)$\n简要分析 DP、PP、TP通信量比较：（以整个transformer模型为例，假设w=2）\nDP：输入batch，经过前向反向后得到参数的梯度，然后对梯度进行all-reduce，transformer 的参数量为$2Vh + (4h+4+3I)hl$，因此DP的通信量为：$2w\\Phi = 4wVh + 2w(4h+4+3I)hl$，该通信量只与模型相关\nPP：m个micro-batch（即一个mini-batch）在一个stage（一个stage可能包含多个transformer block）的通信量是$m \\times 2 \\times w(b_msh)=2wbsh$（non-itlv），如果整个模型切成了$N_s+1$个stage，那么通信量为$2wbshN_s$，如果是itlv（假设原来一个chunk切分为2个virtual stage）则通信量翻倍，可以看出该通信量与输入token数量、模型的隐藏层维度、模型切分的stage数量相关\nTP：$w(vh+4bsh \\times l + 2bs + N) \\approx w(vh + 4bshl) \\approx 2wbsh \\times 2l$，可以看出该通信量与输入token数量、模型大小相关，而且$2l$一般大于$N_s$，所以现在就可以分析出通信量TP\u0026gt;PP\n然后进行一个case study，来直观感受一下。因为我们在训练时总想在显存允许的范围内增大batch size、增大序列长度，一般来说TP通信量还是要比DP通信量多的（可能会有例外），但是可能没有数量级上的差距。但是TP需要频繁的进行通信，所以TP更适合在单机多卡间并行。\nmodel h I b s $N_s$ DP通信量$\\approx 4\\Phi$ PP通信量$=4bshN_s$ TP通信量$\\approx 8bshl$ GPT-3 175B 12288 96 8 2048 16 651.92GB 12GB 144GB Llama-2 7B(6.7B) 4096 32 8 4096 4 24.96GB 1GB 32GB Llama-2 13B 5120 40 8 4096 8 48.43GB 2.5GB 50GB Llama-2 70B 8192 80 8 4096 8 260GB 8GB 160GB Llama-3 405B 16384 126 8 4096 16 391.15GB 32GB 504GB 辨析一下TP和ZeRO-3：Github issus\n相同点：都是将权重（和梯度）竖着切开，放在不同卡上 不同点： 输入方面：TP可以使用不完整的输入进行计算，ZeRO-3必须使用完整的输入进行计算 通信方面：TP通信是为了对激活值进行reduce，ZeRO-3通信是为了拿到完整的权重和梯度 总结就是，TP使用本地不完整的输入、本地不完整的权重进行计算，通信是为了对结果进行all-reduce；而ZeRO-3使用本地完整的输入、全局完整的权重（由通信拿来的）进行计算，通信是为了拿来全局完整的权重 TP与ZeR-3是兼容的，但是TP+ZeRO-3（和TP+ZeRO-2）实际上就退化成了TP+ZeRO-1（TP已经切分了权重和梯度，ZeRO只是切optimizer_states和fp32权重） 效果\n计算量 参数量 激活值 通信带宽 通信时延 without TP $(24h+4s)bshl+2bshV$ $2Vh+(12h^2+13h)l$ $2bsh+[34bsh+5bas^2]l$ $O(1)$ $O(1)$ with TP $\\frac{(24h+4s)bshl}{t}+2bshV$ $\\frac{2Vh}{t}+(4h+\\frac{12h^2+9h}{t})l$ $2bsh+[10bsh+\\frac{24bsh+5bas^2}{t}]l$ $O(2(t-1)t)$ $O(2(t-1))$ 参考和推荐好文：\n图解大模型训练之：张量模型并行(TP)，Megatron-LM 多维张量并行：Colossal-AI 个人对多维张量并行了解不深入，也没有使用过，看一些解读，感觉就像是对矩阵乘法各种拆分和在多处理器上并行，这里简单进行一下记录。\n参考：大模型分布式训练并行技术（四）-张量并行\n2D Tensor Parallel 背景：Megatron-LM的张量并行中，每个GPU上都要保留完整的激活，激活值没有被切分，如下图（绿色表示激活，蓝色表示权重）：\n解决方法：将激活和权重划分成二维网格，一个限制是输入激活和权重需要是方阵，需要有$q\\times q$个处理器，每个处理器上保留网格中的一块权重和激活值（而非完整的激活值），因为Transformer中很多都是矩阵乘，所以中间可以使用SUMMA并行矩阵进行并行计算。\n效果：每张GPU上，中间激活值变为1D TP的$\\frac{1}{q^2}$，因此可以使用更大的batch size，计算量和参数量变为1D TP的$\\frac{1}{q}$，但是代价是通信带宽和通信时延变大了（变为原来的3倍）\n2.5D Tensor Parallel 2D TP虽然减小了激活值、计算量和参数量，但是增加了通信带宽和通信时延。对于Y=XA，2D-TP中将X和A划分为二维网格（对应$q\\times q$个处理器）；2.5D-TP中将X划分为三维网格，将A划分为二维网格，然后再使用SUMMA算法计算并行矩阵乘（需要$d\\times q\\times q$个处理器）。在d=1时，2.5D-TP退化为2D-TP，d=q时，2.5D-TP变成了3D-TP。\n上图中，将输入X划分为d个二维网格，图中排布成了三维的结构（但是感觉排布成多个二维网格stack的形式更好？）。效果是，每张GPU上，中间激活值和计算量变为2D-TP的$\\frac{1}{d}$，参数量没变，通信带宽减小了，通信时延没变。\n3D Tensor Paralllel 类似的，对于Y=XA，3D-TP中将A和X划分为三维网格（对应$q \\times q \\times q$个处理器），计算量、参数量、中间激活都变成了2D-TP的$\\frac{1}{q}$，通信带宽变为2D-TP的$\\frac{1}{q^2}$，通信延时与2D-TP相同。\n序列并行 原来Transformer的Attention部分的计算复杂度是输入序列长度的二次方，因此一般输入序列长度不会太长。序列并行没有在算法角度上改变Attention的计算，Attention的输入仍然是是[b, s, h]的形状，序列并行在s维度上切分，将每一个输入分块放在一个GPU上，在计算过程中进行通信。经过s维度的切分，这样每个GPU上Attention的输入就变成了[b, s/N, h]，因此输入序列可以很长。\nmore reading：\n图解序列并行云台28将（上篇） 图解序列并行云台28将（云长单刀赴会） 图解序列并行云台28将（下篇） Colossal-SP 原来Attention的计算为：$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$，Colossal-SP中将Attention变成了分布式环境下的Ring Self-Attention，具体过程为（下面是单头的示意图，每个Q、K、V大小为[b, s/n, h/a]）：\n（一开始的输入已经在s维度进行了切分，每张卡的输入为[b, s/n, h]）\n在计算$QK^T$的过程中，通过Ring的方式传递K，因此每个GPU上分块的Q可以看见所有的K\n在计算$attn_score \\times V$的过程中，通过Ring的方式传递V，类似上面的过程\n需要注意的有以下几点：\nColossal-SP针对的是encoder-only架构的的SP并行，针对decoder-only架构，因为attn_score后还要加上一个mask，比如上图GPU1在step4阶段需要mask掉 attn_score[1, 2:8]和 attn_score[2, 3:8]，mask矩阵较大；而GPU4只需要mask掉attn_score[7,8]即可，被mask掉的部分，$Q_iK_j^T$即使算了也是白算，所以这些部分可能不会实际进行计算，后面直接加上一份负无穷大的数，这样就导致不同GPU计算负载不均衡，前面mask多的部分计算少，后面mask少的部分计算多。 在该论文中，除了提出了Colossal-SP，还针对FFN部分进行了分析。\n原来Megatron-LM的TP并行中，输入的是完整的中间激活[b, s, h]，对Linear的权重进行了切分。 当序列s比较长的时候，可能输入的中间激活占用显存比权重更大。因此，论文中对输入的中间激活也在s维度进行切分，每张卡上FFN部分的输入的中间激活形状为[b, s/n, h]，此时需要每张卡上保留完成的Linear权重 到底哪个更省显存，需要根据模型结构、序列长度等进行计算，比如GPT类的FFN和Llama类的FFN结构就稍有区别，但总的来说就是将FFN部分的激活占用的显存和参数占用的显存加在一起，比一下，也不复杂。论文中举了一个GPT FFN的例子，结论是当$bs \\gt 32h$时，序列并行更省显存（这里符号表示与论文不一样，参考文章开头的描述）\nMegatron-SP Colossal-SP与Megatron-SP都是将[b, s, h]的输入在s维度进行切分，但是其实是解决的不同的问题。Colossal-SP通过SP切分，解决了在分布式环境下训练超长序列的问题，解决方式是s维度切分+Ring通信。Megatron-SP通过SP切分，解决了每张卡上Transformer Block中LN和Dropout都要保留一份完整的[b, s, h]的输入的问题，解决方式是s维度切分+修改通信方式，具体过程为：（上图是Megatron-TP，下图是Megatron-SP）\n将LN后面的通信从$f$替换为$g$\nMegatron-TP中，LN之前是完整的[b, s, h]激活，经过LN之后仍然是完整的[b, s, h]激活，正好输入到Self-Attention中。反向过程中，每张卡都有对输入激活的完整的un-reduced梯度，需要先all-reduce平均后，才能继续向前进行反向传播 Megatron-SP中，LN之前是沿s维度切分的[b, s/n, h]激活，经过LN之后，需要先经过all-gather通信，每张卡拿到完整的[b, s, h]激活，才能输入到Self-Attention中。反向过程中，每张卡都有完整的un-reduced梯度，需要先经过reduce-scatter，每张卡拿到对不完整的输入激活对应的不完整的reduced梯度，才能继续向前反向传播 将Dropout前面的通信从$\\bar{f}$替换为$\\bar{g}$\nMegatron-TP中，Dropout之前是每张卡上MHA部分的计算的输出激活，前向过程中需要先对不同卡上该输入激活进行一个all-reduce平均，然后再Dropout。反向过程中，梯度在FFN部分的$f$进行过一次all-reduce，再经过LN和Dropout后，此时还没有必要使得对MHA输入的梯度都相同，所以直接$\\bar{f}$的反向是no op Megatron-SP中，经过TP切分之后的MHA和FFN，每张卡都有一份完整的、un-reduced输入激活，进行一次reduce-scatter正好可以使得中间激活恢复到每张卡上只有一份不完整的reduced激活。反向过程中，MHA和FFN部分的反向需要使用到对输出的完整的梯度，此时每张卡上只有一块不完整的梯度，所以要进行一次all-gather拿到对输出激活的完整的梯度。 $f$：FWD=no_operation, BWD=all-reduce\n$\\bar{f}$：FWD=all-reduce, BWD=no_operation\n$g$：FWD=all-gather, BWD=reduce-scatter\n$\\bar{g}$：FWD=reduce-scatter, BWD=all-gather\n需要说明的有两点：\nMegatron-SP需要配合Megatron-TP使用，Megatron-TP在MHA和FFN之前仍然需要使用完整的输入激活，但是Colossal-SP可以使用序列切分之后的不完整的输入进行Self-Attention的计算（Ring Self-Attention） Megatron-SP的通信量与Megatron-TP的参数量和通信量相同，中间激活减少，计算量也减少 该论文中还提到一点优化，叫做selective re-compute，就是对于那些占据大量中间激活、但是计算量小的部分，这些部分可以开启重计算（之前全部重计算叫做full re-compute）。比如Transformer block中，$QK^T$矩阵乘法，softmax，softmax dropout，attn_score和V的矩阵乘法，这是一个连续的部分，占用激活多，但是计算量不大，这部分可以在训练过程中进行重计算，比如实际训练中，论文中提到GPT-3的例子，这样开启selective re-compute后，节省了70%的显存，但是只增加了2.7%的FLOPs，看起来很划算。\nUlysses Ulysses可以认为是对前面Colossal-SP的改进，Colossal-SP中在序列s的维度进行了切分，在计算Attention的时候，采用了Ring Self-Attention方法，假如有N个GPU，那么需要进行N-1次的Ring，每次单卡通信量为$[b, \\frac{s}{N}, \\frac{h}{a}] \\times a$个头，因此单卡每次前向需要的通信量为：$2(N-1) \\times (b \\times \\frac{s}{N} \\times h) = 2bsh \\times \\frac{N-1}{N}$。Ulysses对这个通信量进行了优化，Attention部分具体过程为：\n（一开始的输入已经在s维度进行了切分，每张卡的输入为[b, s/n, h]） 每张卡上先乘$W_Q, W_K, W_V$得到Q，K，V 极其注意此时$W_Q, W_K, W_V$的维度是[h, h]，而Colossal-SP和Megatron-SP中$W_Q, W_K, W_V$的维度是[h, h/a] 也就是说，对于[b, s/n, h]的输入，Ulysses在每张卡上都保留了所有head的Q、K、V（Q、K、V的维度是[b, s/n, h]），而Colossal-SP和Megatron-SP只在每张卡上保留了该卡上对应head的Q、K、V（Q、K、V的维度是[b, s/n, h/a]） 此时每张卡上Q、K、V的维度是[b, s/n, h]，对Q、K、V在h维度上切分，一共a个头，正好切成a份（这个部分没有在图虫表示），后续每张卡上都会进行$\\frac{a}{N}$个头Attention的计算（比如下图中a=8，N=4，每张卡上进行2个头的Attention的计算）。这个操作也是很好理解，因为本来QKV就应该划分成多头，每个头计算一部分。 进行All-to-All通信。刚才在每张卡上都对QKV按头进行了切分，现在将每张卡上QKV对应head1、head2的部分（颜色最浅）发送到GPU1，将每张卡上QKV对应head3、head4的部分发送到GPU2，将每张卡上QKV对应head5、head6的部分发送到GPU3，将每张卡上QKV对应head7、head8的部分（颜色最深）发送到GPU4。 每张卡上进行多头注意力的计算，就像Megatron-TP那样 算完了多头注意力，然后再All-to-All通信，将计算结果物归原主 分析一下单卡通信量，每个Q、K、V的大小是[b, s/n, h]，需要发送给其他GPU的部分是其中的$\\frac{N-1}{N}$，通信量=$3 \\times (b \\times \\frac{s}{N} \\times h) \\times \\frac{N-1}{N} = 3bh \\times \\frac{s}{N} \\times \\frac{N-1}{N} = 2bsh \\times \\frac{N-1}{N} \\times \\frac{3}{2N}$，从复杂度上看是Colossal-SP通信量的$\\frac{1}{N}$。而且注意到一点，如果序列长度翻倍，那么只要GPU数量也翻倍，则通信量不变。\n还有两点需要说明：\nUlysses可以和ZeRO-3一起使用，因为Ulysses中通信的都是中间激活值，每张卡上Wq、Wk、Wv、Wo及其梯度和optimizer_states可以切分放在不同的DP上，进一步节省显存\nUlysses的一个缺点是，每张卡上负责$\\frac{a}{N}$个head的计算，每个head可以使用FA进行单卡优化，但是如果模型使用MQA、GQA等方式，头数a本来就不大，也就限制了N的大小\n参考：\n大模型训练之序列并行双雄：DeepSpeed Ulysses \u0026amp; Ring-Attention Ring-Attention Ring-Attention的提出还是在Colossal-SP这篇论文中，此时Ring-Attention还是使用two-pass的方式，先Ring K，再Ring V。在后续的论文中，基于FA online-softmax的思路（或者直接调用flash-attention的接口），成功将two-pass的方式优化成one-pass的方式，一次Ring就可以计算最后的输出$O$。还有一个优化点是针对Ring-Attention由于casual mask导致的计算负载不均衡问题。一个优秀的开源实现是ring attention + flash attention：超长上下文之路，这里基本按照该实现的思路，简单描述一下过程。\n首先还是针对[b, s, h]的输入，在s维度上进行切分，每个GPU上分别有一个$V_i, Q_i, K_i$分块，然后使用flash-attention进行计算，得到一个局部的$O_i$，以及flash-attention函数特有的一个返回值$lse_i$\n关于flash-attention和这个返回值$lse$，可以查看flash_attention简要笔记中的记录，简单来说，$lse=log[\\sum_j e^{S_{ij}-rowmax(S_{ij})}]$，其中$S_{ij}=Q_i\\times K_j^T$\n对于每个头，每个step都会有：\n每个GPU上有一个$Q_i, K_i, V_i$分块，基于flash-attention算出的局部的输出$O_i$（记为$block_O_i$），和一个$lse_i$（记为$block_lse_i$或者$new_lse_i$）\n（除了第一个step）还有全局的、未修正的输出$O_i$和$lse_i$\n此时对全局的、未修正的输出$O_i$和$lse_i$进行修正，具体修正公式见上图的step2（第一个下标表示rank id，第二个下标(if have)表示step），这里以GPU1为例，此时进行$Q_1, K_2, V_2$的flash-attention计算，其中$S_{12}=Q_1K_2^T$\n实际代码中没有采用这种修正方式，进行了一些优化，具体介绍见：improve readability and potential numerical stability of out and lse in _update_out_and_lse by refactoring their computational expressions. #34\n（除了最后一个step）在每个step的最后，会进行Ring KV的通信\n还有针对由于mask导致的计算负载不均衡的问题，采用stripped ring-attention或者zigzag ring-attention的方法，该实现中为了调用flash-attention的接口，使用zigzag ring-attention的方法，这里解释一下（或者可以见USP: A Unified Sequence Parallelism Approach for Long Context Generative AI中的load balance partition）：\n如果使用stripped ring-attention，比如GPU0上的Q分块是$Q_0, Q_4, Q_8, Q_{12}$，K分块是$K_0, K_4, K_8, K_{12}$，然后在Ring的过程中，还可能与GPU2的K分块$K_2, K_6, K_{10}, K_{14}$算attention，比如$Q_0, Q_4, Q_8, Q_{12}$与$K_2, K_6, K_{10}, K_{14}$算attention，$S_{ij}=Q_iK_j^T$需要进行mask的部分是：\n注意到Q和K都是分块，每个分块有若干行向量，标准attention的mask是上三角矩阵，但是上面示意的mask部分是台阶形状的（比如$Q_0$的最后一个向量和$K_2$的第一个向量需要进行mask，但是转到Q的下一行，即$Q_4$，$Q_4$又不需要与$K_2$进行mask，所以mask一下就断层了），由于这个原因，就没法调用标准的flash-attention\n如果使用zigzag ring-attention，比如GPU0上的Q分块是$Q_0, Q_1, Q_{14}, Q_{15}$，K分块是$K_0, K_1, K_{14}, K_{15}$，然后在Ring的过程中，还可能与GPU2的K分块$K_4, K_5, K_{10}, K_{11}$算attention，比如$Q_0, Q_1, Q_{14}, Q_{15}$与$K_4, K_5, K_{10}, K_{11}$算attention，$S_{ij}=Q_iK_j^T$需要进行mask的部分是：\n所以博客中说是一个完整的方形，因此可以直接调用flash-attention的接口了\n大模型训练之序列并行双雄：DeepSpeed Ulysses \u0026amp; Ring-Attention中有对Ulysses和Ring-Attention的比较，，参考这篇博客，自己重新进行了理解：\n通信量 Ulysses单卡通信量为$2bsh \\times \\frac{N-1}{N} \\times \\frac{3}{2N}$ Ring-Attention每个step会Ring KV，KV大小为$bsh$，需要Ring N-1次，每张卡通信量都是相同的，所以单卡通信量为$2bsh\\times \\frac{N-1}{N}$ 可以看出Ulysses的通信量大约为Ring-Attention的$\\frac{1}{N}$ 通信方式：Ulysses需要All2All通信，更加复杂 内存使用：近似 其他特点： 模型结构的适配：Ring-Attention对头数没有要求，而Ulysses会受到头数的限制 输入长度的适配：Ulysses对输入长度没有要求，而Ring-Attention需要进行负载均衡 more reading:\n我爱DeepSpeed-Ulysses：重新审视大模型序列并行技术 USP(Unified Sequence Parallelism) 总的来说就是将Ulysses-SP和Flash-Ring-Attention结合结合起来，具体过程是：（假设一个node有2张卡，一个2个node，总的序列长度为8，头数为2）\nstep0，进行Ulysses的操作，在每个节点内进行All2All通信（每个节点内部构成一个通信组，比如GPU0、GPU1构成一个通信组，GPU2和GPU3构成一个通信组，通信组内部进行All2All的通信），此时每个节点得到一份节点内部完整序列的、按头切分的QKV， 然后进行Flash-Ring-Attention的操作，接下来每个step中： 基于局部的Q、K、V，进行flash-attention的计算，如果当前不是Ring-Attention的第一个step，则对输出O要进行修正 如果不是Ring-Attention的最后一个step，要进行K、V的Ring通信。在图中，对位于不同GPU上的、相同head的、不同部分序列的K、V进行Ring通信，比如GPU0和GPU2、GPU1和GPU3分别构成通信组，Ring通信在通信组内进行P2P通信 最后（step3）再进行Ulysses的操作，将输出All2All通信，对应的token物归原主 more reading：\n通过将USP用在Megatron-LM中，给出了USP加入之后4D混合并行最佳实践方案：序列并行做大模型训练，你需要知道的六件事\n给出了一个USP潜在适合应用的场景，序列长度变化的SFT训练任务：LLM变长序列分布式训练迷思\nUSP应用在Megatron-LM中，如何做通信计算重叠来追求更极致通信优化：大模型训练优化：论反向传播中序列并行和张量并行的通信计算重叠方法\nContext Parallel Context Parallel很像（甚至就是）Ring-Attention，这里从历史发展的角度，进行一个简单的辨析：\n首先说一下Sequence Parallel。一开始（2021.05）有two-pass的Colossal-SP；然后后来（2023.10）改进成了one-pass的Ring-Attention，此时的one-pass是作者基于jax框架重新实现的、对输出O的调整逻辑（比如手动更新denominator和max_score，分别对应flash-attention原始论文中的$l$和$m$）；再后来（2024.02）朱小霖实现了一版开源的Ring-Attention，特点是仍然保持了one-pass的Ring-Attention，但是中间通过调用现有的flash-attention接口（会返回lse，用这个可以对输出O进行修正）避免了one-pass FA部分内部逻辑的改动（因此这个开源实现叫做ring-flash-attention），而且使用zigzag的方式实现了计算负载均衡。\n然后说到Context Parallel，Context Parallel主要是针对Megatron-LM的。\n一开始（22.05）Megatron-LM也提出了序列并行，这里把它叫做Megatron-SP，Megatron-SP和Colossal-SP都是针对序列维度进行切分，但是采用的不同的优化方法，Megatron-SP主要是在LN和Dropout的前面对输入在序列维度上进行切分，self-attention的前面经过All-Gather拿到了全部序列。\n后来，Megatron-LM也采取了Ring-Attention的思想，原来attention之前不是要【前向All-Gather/反向Reduce-Scatter】吗，现在将这个【前向All-Gather/反向Reduce-Scatter】转换为P2P通信（比较困惑，后续需要结合代码看一下）。Megatron-LM中说CP相对于Ring-Attention的优势是（这里指的Ring-Attention，指的是Ring Attention with Blockwise Transformers for Near-Infinite Context，此处的实现，作者基于jax框架，将flash-attention重新时间并融合到Ring-Attention中）：\n充分利用最新开源的cuDNN flash attention kernel\ntip: OSS 表示 Open Source Software\n移除由于上三角mask导致的不必要计算，从而实现负载均衡\nMegatron中对CP的介绍部分的原话是：\nContext Parallelism (\u0026ldquo;CP\u0026rdquo;) is a parallelization scheme on the dimension of sequence length. Unlike prior SP (sequence parallelism) which only splits the sequence of Dropout and LayerNorm activations, CP partitions the network inputs and all activations along sequence dimension. With CP, all modules except attention (e.g., Linear, LayerNorm, etc.) can work as usual without any changes, because they do not have inter-token operations. As for attention, the Q (query) of each token needs to compute with the KV (key and value) of all tokens in the same sequence. Hence, CP requires additional all-gather across GPUs to collect the full sequence of KV. （计算Attention之前，要进行一次all-gather通信）Correspondingly, reduce-scatter should be applied to the activation gradients of KV in backward propagation. To reduce activation memory footprint, each GPU only stores the KV of a sequence chunk in forward and gathers KV again in backward.（为了省显存，前向all-gather拿到全部的KV后，算完attention后只保存一块KV，反向时类似重计算一样重新all-gather一次） KV communication happens between a GPU and its counterparts in other TP groups. The all-gather and reduce-scatter are transformed to point-to-point communications in ring topology under the hood.（all-gather和reduce-scatter） Exchanging KV also can leverage MQA/GQA to reduce communication volumes, as they only have one or few attention heads for KV.\n而且附了一张图：\n意思是在TP2CP2的情况下，GPU0和GPU1、GPU2和GPU3分别构成两个TP group，GPU0和GPU2、GPU1和GPU3分别构成两个CP group，按序列切分的输入经过第一个AG/RS，在一个TP group上得到了一个half的输入，然后得到QKV。接下来进行CP的通信操作，这里在CP group内部进行all-gather通信，后面的过程基本与原来相同。\n（橙色的通信都是TP的，深蓝色的通信是CP的）\n在具体实现上，Megaron-LM中设置好CP的相关通信组cp_group之类的，然后将该cp_group传入到Megatron-LM调用的TransformerEngine中；在TransformerEngine中，如果使用flash-attention，调用的是attn_forward_func_with_cp，内部根据cp通信方式的不同，又进一步调用了以下实现：\n如果cp_comm_type=='p2p'，则调用AttnFuncWithCPAndKVP2P\n内部通信调用的是torch.distributed.P2POp 如果cp_comm_type=='all_gather'，则调用AttnFuncWithCPAndKVAllGather\n内部通信调用的是torch.distributed.all_gather_into_tensor 在llama3 3.3.2节 Context parallelism for long sequences 中，首先给出了负载均衡的办法，类似于上面朱小霖开源Ring-Attention中的zigzag方式，然后原来Ring-Attention中用的是P2P通信（可以通信计算重叠），现在改成先All-Gather拿来K和V，原因有二：\nit is easier and more flexible to support different types of attention masks in all-gather based CP attention, such as the document mask 由于使用了GQA，通信的K和V都比原来小了很多，通信时延也变小了 如果cp_comm_type=='a2a'，则调用AttnFuncWithCPAndKVPA2A\n类似Ulysses-SP，没有Ring的操作\nmore reading：\nContext Parallelism的原理与代码浅析\nMegatron-LM 中 Context Parallel 的工作原理是什么？\nMegatron-LM源码系列(八)： Context Parallel并行\n专家并行Expert Parallel 进入到具体模型结构之前，首先要明确一个概念：MoE是在多个GPU上共享的，或者说，非MoE的部分像数据并行一样在多个GPU上有一份模型的replica（一份复制），但是MoE的部分是这多个GPU共享的，即每个GPU上放几个专家（注意这个不是专家并行EP，EP指的是一个专家放在多个GPU上），这些专家共同组成一个MoE结构。MoE在算法方面的改进更多一些，本文也会简单介绍，但是更多侧重还在于工程角度和具体过程。\nMoE基本范式是：（图中红色表示输入输出，紫色表示中间变量，黑色表示通信和操作）\ngating：[b, s, h]的输入先经过gating，输出是[b, s, e]，表示每个token分配到每个专家的概率，其中e指的是专家数量（实际上就一个linear+softmax的过程）。然后取topk专家，输出是[b, s, k]，表示每个token根据上面计算的概率选择了概率最大的k个专家，[b, s, k]中记录的是选择的专家的index dispatch（上图中上半部分）：将[b, s, h]的输入tokens根据[b, s, k]的专家index，路由到特定的专家 需要注意的一点是，原来输入是batched，首先经过一次all2all通信，将token发送到对应专家所在的GPU上；如果一个GPU上有多个专家，那么还要进行一个本地的重排，使得发送给一个专家的tokens batch到一起 专家计算 undispatch（上图中下半部分）：dispatch的逆过程 Gshard 这是首次将MoE引入到Transformer的工作，将Encoder中的那一个FFN替换为一个MoE，相当于就是在FFN前面加了一个gating来进行路由选择（top2），而且每间隔一层来进行MoE的替换（比如一层MoE，一层FFN，这样交替循环）\nSwitch Transformer Switch Transformer主要针对Gshard进行了三点改进：\n简化路由：从原来top2简化到top1，也能保证模型的质量\n高效路由：\n专家容量（expert capacity）和容量因子（capacity factor）：由于Switch Transformer是基于Mesh-TensorFlow实现的，该框架要求每个专家输入的Tensor shape是固定的，即需要提前分配好大小，但是由于动态路由，不到运行时也不知道每个专家有多少输入token。因此，干脆固定某个大小算了，这个固定的大小就叫做专家容量（expert capacity），具体来说就是$expert_capacity=capacity_factor \\times \\frac{tokens_per_batch}{number_of_experts}$，其中这个分数表示一个mini-batch平均分到每个专家的token数量，容量因子就是来扩大这个平均值的\n如果容量因子太大，则提前分配的专家容量越大，其中需要padding的token越多，增加了无效计算\n如果容量因子太小，如果某个token分配到某个专家，但是该专家的输入缓冲区已经满了，只能将该token丢弃，然后最后残差连接加回去，比如说像下面这个图（图中采取top2，但是Switch Transformer采取top1，这里只是为了说明drop token的例子），token7分配到expert2和expert3，但是这两个专家的输入缓冲已经满了，只能丢弃，然后残差跳过MoE连接到后续非MoE部分，或者说相当于MoE部分对该token的输出是0\nLoad balance loss：由于token进行动态路由，可能有的专家要处理很多token，有的专家处理很少token，为了负载均衡，提高模型训练和推理效果和性能，最好做到token在不同专家之间分配大致相同，添加的$P_i$一项只是为了保证loss可以求导（前面那些部分无法求导）\n还提出了四条有助于提升预训练和微调稳定性的技巧，由于本文更多关注于工程角度和具体流程，这里省略\nFastMoE 该论文的创新点：\n之前分布式MoE主要是基于TPU和Mesh-Tensorflow框架，FastMoE基于GPU和PyTorch框架，实现了EP并行 工程优化： 将专家模块进行抽象，使得任意网络可以作为专家 将一个GPU上多个专家的计算过程整合为一个batched_gemm 在all2all通信token之前，先all2all通信一下token的数量和大小，由此来动态分配空间 DeepSpeed-MoE 该论文对Switch Transformer有两点改进：\n提出了新的MoE结构（叫做PR-MoE，金字塔MoE），变化有两处：\n观察到在模型靠后的层使用MoE比模型前面层使用MoE的算法效果更好，所以随着模型层数增加，后面的层使用更多的专家，这样同时也减小吗MoE的显存\n观察到top2 gating比top1 gating算法效果好，因此固定一个expert，然后剩下再进行top1 gating，这样路由过程与Switch Transformer相同，但是达到了top2 gating的效果\n从推理角度改进了模型的并行方法，推理场景主要特征是batch_size比较小，所以可能不适合训练场景\nTUTEL 静态的策略不能满足MoE的动态特性（即专家的输入缓冲是固定大小的，但是训练过程中专家处理token数量是不固定的，有可能drop token损失精度，有可能padding浪费计算资源）\nTutel允许在每次训练迭代中，设置不同的expert_capacity，所以Tutel可以保证不drop tokens，但是没法避免zero-padding。\n参考：\nMoE训练论文解读之Tutel: 动态切换并行策略实现动态路由\nMegaBlocks 该论文针对一个GPU上多个专家、而且没有专家容量限制（即没有drop token，没有padding，来多少token就计算多少token）的MoE场景。\n原来一个GPU上多个专家、有专家容量限制时，像左图，token3被drop，专家2的input buffer需要padding，此时输入大小都相等，可以直接调用cutlass中的batched gemm操作。现在一个GPU上多个专家、没有专家容量限制时，像右图，每个专家的input buffer大小不同，\ncutlass中的grouped gemm操作需要输入维度大小相同，Megablocks中提出了Variable Sized Grouped GEMM操作\n但是该论文的一个缺陷是，该论文要求专家数量\u0026gt;GPU数量，但是在实际场景中往往GPU数量是更多的\n评测指标 MFU+HFU共同衡量了某一模型实现对某种芯片计算性能的利用情况：\nMFU（Model FLOPs Utilization）：模型算力利用率，指模型一次前反向计算消耗的矩阵算力与机器算力的比值 实际计算中，$MFU=\\frac{每token模型的FLOPs \\times 每秒的token数量}{机器峰值FLOPs}$ HFU（Hardware FLOPs Utlization）：硬件算力利用率，指考虑重计算后，模型一次前反向计算消耗的矩阵算力与机器算力的比值 还有一点需要说明，MoE的MFU一般相对较低\n更新 发现了更加优质的系列好文：\n大规模分布式 AI 模型训练系列——数据并行 大规模分布式 AI 模型训练系列——流水线并行 大规模分布式 AI 模型训练系列——张量并行 大规模分布式 AI 模型训练系列——序列并行 大规模分布式 AI 模型训练系列——专家并行 llama3 pipeline：https://mp.weixin.qq.com/s/1syPf8XNQfgk7mClMDSqhw\n","permalink":"https://qinganzhang.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%A1%8C%E6%8A%80%E6%9C%AF%E6%A2%B3%E7%90%86%E6%80%BB%E7%BB%93/","summary":"首先声明一些符号： 模型参数量：$\\Phi$ GPU数量：$N$（有时候可能误写成了$n$） Pipeline degree（或者说PP size）：$p$ TP siz","title":"分布式训练并行技术梳理总结"},{"content":"之前一直对LLM推理过程中的prefill阶段和decode阶段有些困惑，prefill阶段处理prompt，decode阶段自回归地逐token生成。欸，那之前传统机器翻译不也是这样吗，输出一个中文句子，然后再自回归地逐token生成英文句子，有点混乱了。下面我们来重新梳理一下，LLM的发展过程、典型模型架构和训练过程。\n开山之作：Attention is all you need 模型架构和训练过程 模型架构自不必多说，就像下面最左边和最右边经典的模型架构图所示，是典型的encoder-decoder架构。Transformer一开始，解决的是一个seq2seq的任务（下面以中译英机器翻译任务为例），模型结构中包含了encoder和decoder（将此时的decoder称为naive-decoder），下面图中是encoder-decoder的Transformer的训练过程，左边是encoder部分，右边是decoder部分。在训练阶段，将中文句子经过encoder生成编码矩阵C，将shifted right的ground truth（开头加了BOS的英文句子）作为decoder的输入，整体模型的监督信号是对应的英文句子。因此，训练是并行的，一个iteration就可以将一个中英pair训练完（假设batch size=1），训练任务就是next token predicate。\n推理过程 训练完成后，实际使用中开始进行推理。首先encoder部分要输入一个中文句子，还是经过encoder生成编码矩阵C。然后是decoder部分，一开始输入一个BOS，通过自回归的方式逐token生成，渐变的颜色就表示token生成的不同次序。\n这里有一个问题需要明确一下，每次decoder部分的输入，是一个token呢，还是前面的所有token呢？比如要预测“a”这个token，那么此时decoder的输入是“have”这个token呢，还是BOS+“I”+“have”这三个token都输入呢？其实都可以，\n比如每次decoder部分的输入是前面所有的token（比如BOS+“I”+“have”这三个token都输入），那么Masked MHA、MHA部分的Q、K、V都有多行（比如现在是三行），最终decoder出来的这个矩阵，我们只需要最后一个向量（下面红框的这个向量），进行linear+softmax+采样，得到next token\n也可以每次decoder部分的输入是一个token（比如预测“a”这个token，只输入“have”这个token），那么此时就需要将之前token的K、V向量缓存下来（即KV-Cache），一个Q向量和concat(当前的KV向量，之前缓存下来的KV向量)算注意力，Masked MHA、MHA部分的attn-score只有一行，然后最终decoder出来的矩阵也只是一个向量，直接进行linear+softmax+采样，得到next token\n采用kv-cache的方式，可以在推理过程中减少很多不必要的运算，而且从显存占用来看，kv-cache也是划算的。如果不使用kv-cache，那么每次都要输入之前生成的所有token，Q、K、V都是完整的矩阵；如果使用kv-cache，K、V显存占用与之前相同，Q只是一个行向量而原来只是一个多行的矩阵，使用kv-cache的显存占用相对于不使用kv-cache的峰值显存占用是更少的。虽然说“相对峰值显存更少”，但是需要留意的是，kv-cache还是很占显存的，尤其是大batch_size和长序列的情况下，后面产生了MQA、GQA等优化，这是后话了。\n这样看来，似乎在很早以前就有kv-cache的概念，但是似乎在LLM中才真正被普遍应用起来，我想有这么几个原因（not for sure, hope your discussion）：\n之前可能更关注模型架构的改进，之前encoder-decoder架构、encoder-only架构、decoder-only架构没有一个特别突出的模型，直到GPT-3（decoder-only）的出现，掀起了LLM的时代，现在的LLM基本上都是decoder-only的架构 在推理场景中，之前的模型上下文长度（或者叫最长序列长度）比较小，计算强度没那么大（但是比如语音流式识别等场景中也会用到kv-cache，不是很确定），LLM时代的transformer上下文长度普遍较大，而且往往是chat场景，对延迟有要求，因此要想法设法减少计算 encoder-only的代表：Bert Bert是典型的encoder-only架构，其训练和推理过程很相似，训练怎么训，往往推理就是直接一个前向的过程。现在LLM基本都是生成式任务，encoder-only的架构总是感觉很别扭，decoder-only架构就很自然。可以关注知乎问题：为什么现在的LLM都是Decoder only的架构？\nLLM时代 模型架构和训练过程 在模型架构方面，GPT-3和Llama只是Decoder-only架构的两个典型代表，基本保持了Vanilla-Transformer-decoder的结构，但是中间很多地方做了改动，比如去掉了与encoder的cross-attn，在masked-MHA的输入QK前面在加上旋转位置编码RoPE，将LayerNomr调整为post-norm结构，MLP部分可能会进行一些调整等，如果仅仅是走一遍训练和推理的流程，那么不会有影响。\n从LLM训练过程来看，预训练阶段与之前的语言模型基本一致（如下图，这里不讨论微调、RLHF等过程，更侧重工程和流程方面），都是next token predicate任务，没有了encoder部分，模型结构看起来更加简洁。\n推理过程 Decoder-only架构的推理过程和训练过程基本保持了相同的形式，推理过程就是先输入prompt，然后自回归的逐token生成。这里提一下prompt，LLM可以认为是一种特殊的语言模型，语言模型通俗来说就是续写，但是LLM包含了in-context learning的能力，prompt可以认为是一个指令，一个问题，使得“续写”的内容能够反映prompt的意图。\n这里我们可以尝试分析一下文章开头提出的疑惑：\n在encoder-decoder架构的机器翻译任务中， 训练过程：中文句子输入到encoder，decoder部分的训练就是语言模型 推理过程：中文句子输入到encoder，BOS输入到decoder，然后自回归的逐token进行生成 在decoder-only架构的LLM中， 预训练过程：没有encoder，就是训练语言模型 推理过程：prompt输入到decoder（prefill阶段），然后自回归的逐token进行生成（decode阶段） LLM推理过程分为prefill阶段和decode阶段，不仅仅是从推理过程上看起来可以分成两个阶段，更重要的是，这两个阶段的特点不同，性质不同，为了尽可能推理加速，才有必要分成两个阶段。\nprefill阶段：输入prompt，生成第一个token。由于prompt往往较长，或者实际使用中将多个prompt打成一个batch（小batch），以提高模型吞吐，所以这个阶段计算量较大。衡量该阶段的一个指标是首字延迟（TTFT，Time To First Token）。还有一个需要注意的是，为了减小decode阶段的计算量，prefill阶段在计算prompt的注意力机制的时候，会将K、V矩阵缓存下来，空间换时间，即kv-cache。 decode阶段：后续自回归的逐token进行生成的过程，直到生成一个终止符（或者达到长度限制）。该阶段中，每次自回归过程中，输入一个token，然后生成q、k、v向量，k、v向量更新到kv-cache中，然后q向量和矩阵的计算（gemv），计算量较小，访存逐渐称为bottleneck。为了提高计算强度，往往会将多个请求decoder阶段的计算组成一个大batch。衡量该阶段的一个指标是TPOT（Time Per Output Token，生成每个token的耗时）。 上面TTFT和TPOT指标是针对streaming generate场景，如果是non-streaming generate场景，则还是使用经典的延迟（Latency，生成一个完整输出的耗时）、吞吐（Throughput，每秒可以生成几个完整的输出）作为指标。\nreference and more reading：\n一些已成为LLM 推理引擎中事实标准的方法\n大模型高效推理 I 推理技术框架总结\nLLM推理到底需要什么样的芯片？（1） LLM推理到底需要什么样的芯片？（2)\n大模型推理原理\u0026amp;流程详解\n","permalink":"https://qinganzhang.github.io/posts/encoder-decoder%E5%92%8Cdecoder-only%E6%9E%B6%E6%9E%84%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E6%B5%85%E6%9E%90/","summary":"之前一直对LLM推理过程中的prefill阶段和decode阶段有些困惑，prefill阶段处理prompt，decode阶段自回归地逐to","title":"Encoder Decoder和decoder Only架构训练和推理浅析"},{"content":"导读：本文可以看作是对分析transformer模型的参数量、计算量、中间激活、KV cache的详细说明\n定性分析 GPU上都存了哪些东西 首先我们来从全局整体的角度看一看，在训练阶段GPU显存上都有哪些内容：\nModel States：模型训练过程中必须存储的states params（下面有时也叫做weights）：模型参数，记参数量为$\\Phi$ grads：模型梯度，梯度数量同参数量$\\Phi$ optimizer states：Adam优化器中的momentum和variance，数量分别是$\\Phi$，共$2\\Phi$ Residual States：模型训练过程中，中间临时的、动态产生的states activation：中间激活值，这个部分可能在训练过程中占据很大一部分显存，下面会详细分析。但是激活值不是必须存储的，可以使用重计算（recompute，也叫做activation checkpoint），在反向算梯度的时候，再重新算一遍，当然计算增加了，时间换空间，实际使用中可以部分选择性的进行重计算。 temporary buffers：临时存储，比如cuda、nccl等临时申请的显存。 unusable fragment memory：内存碎片导致的内存浪费，比如在开启重计算（或者叫做activation checkpointing）的情况下，中间激活不持久保留，这部分显存不断申请、释放，中间可能带来大量的内存碎片 推理阶段就相对简单一些，最主要的是Model States中的params和Residual States中的activation。\n参考：图解大模型训练之：数据并行下篇( DeepSpeed ZeRO，零冗余优化)\n混合精度训练 上面只是列出了训练过程中，显存中存放的内容和保存的数值数量，但是实际训练过程中，为了节省显存，以及考虑到训练过程中间某些过程对精度不是特别敏感，所以中间有些部分会使用fp32，有些部分会使用fp16/bf16。下面以Megatron为例，简单分析混合精度训练的一个大致流程。\n首先我们来看一下不使用混合精度训练的场景，数值精度全使用fp32，作为一个分析的baseline。具体过程是：\n占用显存为：$4\\Phi$（fp32 weights）+$4\\Phi$（fp32 momentum）+$4\\Phi$（fp32 variance）+$4\\Phi$（fp32 grad）+fp32 activation（可能很大）=$16\\Phi$ Bytes + fp32 activation（4代表fp32的4Bytes，2代表fp16/bf16的2Bytes）\n如果使用fp16的混合精度训练（bf16应该也可以，但是实际Megatron有点不同，下面会提到），具体过程是：\n占用显存为：$4\\Phi$（fp32 weights）+$4\\Phi$（fp32 momentum）+$4\\Phi$（fp32 variance）+$2\\Phi$（fp16 grad）+$2\\Phi$（fp16 scaled grad）+$4\\Phi$（fp32 unscaled and cliped grad）+fp16 activation（可能很大）=$20\\Phi$ Bytes + fp16 activation\n需要说明的有两点：\n当fp16 scaled grad转为为fp32 unscaled and cliped grad后，fp16 scaled grad就没用了，但是此时Megatron中仍然保留着一份fp16 scaled grad，所以显存占用中这两部分都会计算在内，这也符合Megatron offical readme中的描述： 注意到上面流程中多了一个scale/unscale的操作，这叫做“loss scaling”\n​\t在使用混合精度训练时，如果直接使用fp16的grad来更新fp16的梯度，一是会产生舍入误差（比如梯度很小，权重更新后，由于精度不够，累加上的lr * grad被舍入，权重没变，一句话来说就是大数吃小数），二是会产生梯度下溢（比如梯度过小，fp16范围不够，导致很小的梯度下溢成为0，而这样的小梯度占比很大，一句话来说就是下溢成0）。对于舍入误差，可以在更新权重时，将fp16的梯度转换为fp32，再更新fp32的权重，从而避免精度问题。对于梯度下溢，需要使用loss scale。\n​\tloss scale就是FWD计算出loss后，对loss放大若干倍，由于求导的链式法则，放大的若干倍同样会传导到fp16梯度，这样fp16梯度就不会产生梯度下溢。在更新权重时，将fp16的梯度转换为fp32，同时进行unscale。\n刚才说到bf16有一点点特殊，我们看相应的代码：（Megatron中的arguments.py）\n注意到如果使用bf16，那么会强行设置accumulate_allreduce_grads_in_fp32=True，这与上面Megatron offical readme截图（Distributed Optimizer）表格中的第二行【bf16 param, fp32 grads】相对应。具体过程应该是（not for sure, hope for discuss）：\naccumulate_allreduce_grads_in_fp32：If true, do the gradient accumulation and communication in fp32. from here\ngradient accumulation：在若干次iteration中，每次都会反向得到一份梯度，将这若干次iteration得到的梯度进行累加、求平均，在最后一次iteration才更新权重。gradient accumulation与data parallel是等价的，gradient accumulation在时间维度上训练多个mini-batch，而data parallel在相同时间内将不同mini-batch放在不同的机器上训练，结果都是一样的。\n参考：\n聊聊梯度累加(Gradient Accumulation)\n梯度累积算法\nHugging Face:Performing gradient accumulation with 🤗 Accelerate 这里找到一个为什么要将bf16与accumulate_allreduce_grads_in_fp32绑定的issue，里面提到“We found this to lead to more stable training before, but you could also try to perform the all-reduce in bf16 (it might hurt convergence but will be faster).”\n参考：\n图解大模型训练之：数据并行下篇( DeepSpeed ZeRO，零冗余优化) 图解大模型训练系列之：Megatron源码解读3，分布式混合精度训练 NVIDIA Docs Hub：Train With Mixed Precision 全网最全-混合精度训练原理 量化分析 transformer结构详解 LLM中的transformer一般是decoder-only结构，所以下面的transformer block主要是decoder，但是与Vanilla Transformer中的decoder不同的是，这里没有了cross-attn，因此结构看起来反而有点像encoder（但不是，因为有casual mask）。\n下面图中的Transformer，没有上kv-cache、GQA等优化，这部分后面会分析。其中，参数量$\\Phi$表示有多少个参数；中间激活值$A$的单位是Bytes，主要参考的是分析transformer模型的参数量、计算量、中间激活、KV cache\n在Reducing Activation Recomputation in Large Transformer Models 4.1节中也对transformer激活值进行了一个分析，但是该论文中，self-attention block部分softmax之前没有加mask，上图中添加了mask，具体在Attention部分stage SA_3，其中mask由于是整个transformer共享的，所以就省略了，$QK^T$的乘积被mask原地修改，所以$wbas^2$也省略了，这样激活值与原论文中仍然是一样的。\nKV cache对参数量、计算量、激活值的影响 关于KV Cache的来龙去脉，Encoder Decoder和decoder Only架构训练和推理浅析中简单捋了一下。简单来说，kv cache在推理过程中使用，而且模型只能是decoder-only架构。由于自回归的方式逐token生成，self-attention部分必须使用casual mask，因此Q矩阵部分只需要计算最新token的q向量即可，K、V矩阵部分只需要拼接新token的k、v向量即可：\n上面又重新回顾了一下kv cache。首先kv cache不会对参数量有影响，kv cache主要是用来减少不必要的计算的，显存因此也可能有相应的减少，上面只是一个示意图，中间省略了一些部分，详细的量化分析见下图，需要说明的有两点：\nkv cache使用场景是推理场景，LLM推理分为prefill阶段和decode阶段，prefill阶段创建kv-cache，decode阶段更新kv-cache。在输入prompt的这个prefill阶段中，with kv-cache和without kv-cache的计算量是相同的（显存占用由于分配kv-cache，可能with kv-cache会更多一点）。计算量的减少主要体现在decode阶段，因此下面的分析主要是针对单次decode阶段的，因此固定$s==1$ 下图中说的“相对于原来“指的是without kv-cache时，每次都输入之前所有的token，计算完整的attention-score方阵，因而此时的序列长度$s=s_n \\le s_m$。在最终分析时，取最大值$s=s_m$进行比较，对应decode阶段的最后一个token的生成过程，有的博客可能会将输入序列长度（prompt长度）和输出序列长度分开，这里合起来了，注意区别。 原来（without kv-cache） 现在（with kv-cache） 变化 参数量 $2Vh+(12h^2+13h)l$ $2Vh+(12h^2+13h)l$ 不变 中间激活 $2bsh+(34bs_mh+5bas_m^2)l$ $2bsh+(30bh+4bs_mh+5bas_m)l$ 减少了$(30bh(s_m-1)+5bas_m(s_m-1))l$，原来中间激活是最长序列长度$s_m$的二次方，现在随着$s_m$线性增长 计算量 $(24h+4s_m)bs_mhl+2bs_mhV$ $(24h+4s_m)bhl+2bhV$ 减少了$(24h+4s_m)bhl(s_m-1)+2bhV(s_m-1)$，原来计算量是最长序列长度$s_m$的二次方，现在随着$s_m$线性增长 code: from 【手撕LLM-KVCache】显存刺客的前世今生\u0026ndash;文末含代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # author: xiaodongguaAIGC # KV-Cache + Generation + decoder import torch import torch.nn.functional as F from transformers import LlamaModel, LlamaConfig, LlamaForCausalLM D = 128 # single-head-dim V = 64 # vocab_size class xiaodonggua_kv_cache(torch.nn.Module): def __init__(self, D, V): super().__init__() self.D = D self.V = V self.Embedding = torch.nn.Embedding(V,D) self.Wq = torch.nn.Linear(D,D) self.Wk = torch.nn.Linear(D,D) self.Wv = torch.nn.Linear(D,D) self.lm_head = torch.nn.Linear(D,V) # LM_head self.cache_K = self.cache_V = None # initial def forward(self,X): X = self.Embedding(X) Q,K,V = self.Wq(X),self.Wk(X),self.Wv(X) print(\u0026#34;input_Q:\u0026#34;, Q.shape) print(\u0026#34;input_K:\u0026#34;, K.shape) print(\u0026#34;input_V:\u0026#34;, V.shape) # Easy KV_Cache if self.cache_K == None: # first time self.cache_K = K self.cache_V = V else: self.cache_K = torch.cat((self.cache_K, K), dim = 1) self.cache_V = torch.cat((self.cache_V, V), dim = 1) K = self.cache_K V = self.cache_V print(\u0026#34;cache_K:\u0026#34;, self.cache_K.shape) print(\u0026#34;cache_V:\u0026#34;, self.cache_K.shape) # ignore proj/MLP/scaled/mask/multi-head when calculate Attention attn =Q@K.transpose(1,2)@V # output output=self.lm_head(attn) return output model = xiaodonggua_kv_cache(D,V) # 创建数据、不使用tokenizer X = torch.randint(0, 64, (1,10)) print(X.shape) for i in range(4): print(f\u0026#34;\\nGeneration {i} step input_shape: {X.shape}：\u0026#34;) output = model.forward(X) print(output.shape) next_token = torch.argmax(F.softmax(output, dim = -1),-1)[:,-1] print(next_token.shape) X = next_token.unsqueeze(0) reference and more reading：\n【大模型理论篇】Transformer KV Cache原理深入浅出\n大模型推理优化技术-KV Cache\n一文读懂KVCache\nMQA和GQA对显存占用的影响 在实际推理场景中，kv-cache已经是默认的选项。但是kv-cache是很占显存的，占用显存为$2 w_{kv} b s_m (a h_a) l$（其中$h=a * h_a$），后面会有case study分析。针对kv cache的各种优化层出不穷，下面的参考中有几篇博客总结了一下对kv cache的各种优化，简单来说，从上面的显存分析入手，有以下几种优化方法：\n针对attention 窗口（或者叫做context，上下文，或者当作最长序列长度$s_m$）$s_m$的优化，比如window attention，sparse attention，StreamingLLM 针对注意力头$a$的优化，比如MQA，GQA共享kv-cache（sharing） 针对层数$l$的优化，比如YOCO层间共享kv-cache（sharing） 针对精度$w_{kv}$的优化，比如kv-cache采用int8量化 针对内存分配的优化，减少内存碎片等，比如PagedAttention 其他优化。。。 其中MQA/GQA在LLM中广泛使用，比如Llama2中就使用到了GQA。下面简单分析一下。\nGQA方法很简单，原来MHA中每个q向量对应一个k向量和v向量，进行attention计算；现在好几个q向量对应（或者说共享）一个k向量和v向量，这“好几个q向量”构成一组，一共有g组，每组就有$\\frac{a}{g}$个q向量。如果g=1，那么就是MQA，a个q向量构成一组，共享一个k、v向量；如果g=a，那么就是MHA，每个q向量构成一组，对应一个k、v向量。实际场景中，往往g=8，比如推理场景中单卡放不下，正好单机八卡，每张卡对应一组q向量。\n虽然MQA/GQA是针对推理过程中kv-cache的优化，但是在训练中也能用，也能省显存。下面对GQA在推理场景中的使用（with kv_cache）进行一个量化分析。\n因为GQA只影响self-attention计算部分，因此其他部分省略，下面的表格也是只分析这个变化的部分。可以看出，由于kv-cache在长序列的情况下会占用很多显存，GQA针对中间激活的优化与序列长度相关，实际上GQA对中间激活的优化就是将kv-cache变为原来的$\\frac{g}{a}$倍。\n原来（MHA）-现在（GQA） 说明 参数量 $\\left [3(h^2+h) \\right ]l - \\left [ (\\frac{2g}{a}+1)(h^2+h) \\right ]l=2(1-\\frac{g}{a})(h^2+h)l$ 中间激活 $\\left [ wbsh+2w_{kv}bs_mh \\right]l - \\left [ wbsh + 2w_{kv}bs_mh \\times\\frac{g}{a} \\right ]l = 2w_{kv}bs_mhl(1-\\frac{g}{a})$ 尤其当长序列（$bs_m$较大），大模型（$hl$较大）时，前面系数较大，整体激活减少比较可观 计算量 $\\left [ 6bsh^2 \\right ]l - \\left [ 2bsh^2 (\\frac{2g}{a}+1) \\right ] l = 4bsh^2l(1-\\frac{g}{a}) \\overset{s=1}{=} 4bh^2l(1-\\frac{g}{a}) $ 在训练场景中，同样给出量化分析。需要说明的是，上述分析是在推理场景+kv_cache+GQA的情况下进行的分析，下面公式是针对的是训练场景+GQA。\ncode： from MHA，MQA，GQA注意力\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import torch import torch.nn as nn class GroupedQueryAttention(nn.Module): def __init__(self, embed_dim, num_heads, num_groups): super().__init__() self.num_heads = num_heads self.num_groups = num_groups self.head_dim = embed_dim // num_heads # attention weights self.wq = nn.Linear(embed_dim, embed_dim) self.wk = nn.Linear(embed_dim, num_groups * self.head_dim) self.wv = nn.Linear(embed_dim, num_groups * self.head_dim) self.wo = nn.Linear(embed_dim, embed_dim) def split_heads(self, x: torch.Tensor, num_groups=None): # n == num_heads or num_groups x = x.view(x.size(0), x.size(1), -1, self.head_dim) # (batch_size, seq_len, n, head_dim) batch_size, seq_len, n, head_dim = x.size() if num_groups is not None: x = x.unsqueeze(dim=2) x = x.expand(size=(batch_size, seq_len, self.num_heads // num_groups, n, head_dim)) x = x.reshape(batch_size, seq_len, self.num_heads, head_dim) x = x.permute(0, 2, 1, 3) # (batch_size, num_heads, seq_len, head_dim) return x def merge_heads(self, x: torch.Tensor): \u0026#34;\u0026#34;\u0026#34; :param x: (batch_size, num_heads, seq_len, head_dim) \u0026#34;\u0026#34;\u0026#34; x = x.permute(0, 2, 1, 3).contiguous() # (batch_size, seq_len, num_heads, head_dim) x = x.view(x.size(0), x.size(1), -1) # ( batch_size, seq_len, embed_dim) return x def forward(self, hidden_states: torch.Tensor, causal_mask=None): q, k, v = self.wq(hidden_states), self.wk(hidden_states), self.wv(hidden_states) # 分割注意力头 q = self.split_heads(q) k = self.split_heads(k, num_groups=self.num_groups) v = self.split_heads(v, num_groups=self.num_groups) # 注意力计算 attn_weights = torch.matmul(q, k.transpose(-1, -2)) / torch.tensor(k.size(-1), dtype=q.dtype) # causal mask mask_value = torch.finfo(attn_weights.dtype).min if causal_mask is None: seq_len = hidden_states.size(1) causal_mask = torch.tril(torch.ones((1, 1, seq_len, seq_len), dtype=torch.bool)) attn_weights = torch.where(causal_mask, attn_weights, mask_value) # 归一化 attn_weights = torch.softmax(attn_weights, dim=-1) attn_output = torch.matmul(attn_weights, v) # 合并注意力头 attn_output = self.merge_heads(attn_output) attn_output = self.wo(attn_output) return attn_output 参考：\n大模型百倍推理加速之KV cache篇\nLLM（二十）：漫谈 KV Cache 优化方法，深度理解 StreamingLLM\n[KV Cache优化]🔥MQA/GQA/YOCO/CLA/MLKV笔记: 层内和层间KV Cache共享\n大模型推理加速：KV Cache 和 GQA\ncase study 我们以GPT和Llama为例，进行case study。\n关于参数量的分析 GPT-3 GPT-3模型结构就大致上面【transformer结构详解】中的结构，但是多了一个可学习的position embedding，包含$n_{ctx} * h$个参数，其中$n_{ctx}=2048$，rectified这一列是加上这些参数后的参数量。\nparams h l a b V from GPT-2 calculated params=$Vh+(12h^2+13h)l$ rectified GPT-3 Small: 125M 768 12 64 0.5M 50257 123651840 $\\approx$ 123.7M 125224704 $\\approx$ 125.2M GPT-3 Medium: 350M 1024 24 64 0.5M 50257 353772544 $\\approx$353.8M 355869696 $\\approx$ 355.9M GPT-3 Large: 760M 1536 24 96 0.5M 50257 757151232 $\\approx$ 757.1M 760296960 $\\approx$ 760.3M GPT-3 2.7B 2560 32 80 1M 50257 2646305280 $\\approx$ 2.64B 2651548160 $\\approx$ 2.65B GPT-3 6.7B 4096 32 128 2M 50257 6650007552 $\\approx$ 6.65B 6658396160 $\\approx$ 6.67B GPT-3 13B 5140 40 128 2M 50257 12942401780 $\\approx$ 12.94B 12952928500 $\\approx$ 12.95B GPT-3 175B 12288 96 128 3.2M 50257 174579068928 $\\approx$ 174.58B 174604234752 $\\approx$ 174.60B 说明：\nGPT-3词表大小V在论文中没找到，所以用的GPT-2的词表大小，这里论文中是提到的 more relative reading：\nHow does GPT-3 spend its 175B parameters? Llama 1: LLaMa: Open and Efficient Foundation Language Models 模型结构：from hugging face transformers LLaMA\n论文中说，该模型与Vanilla Transformer有三处区别：\nPre-normalization and RMSNorm\n​\t原始Transformer中使用post-norm居多，后来使用pre-norm居多，而且往往在FFN之前也加一个norm。尤其在大模型中，可能在通过LN之后MHA之前，Q和K还要加上旋转位置编码。\n参考：【重新了解Transformer模型系列_1】PostNorm/PreNorm的差别\nSwiGLU activation function\nSwiGLU激活函数不太像传统的ReLU等激活函数那样简单，比如ReLU都不带参数，而SwiGLU乍一看上去不明觉厉，实际上将SwiGLU理解成对传统FFM的替换，感觉更合适一些。直接看公式有点懵，看图更容易理解，下面是FFM和SwiGLU的对比\nSwiGLU写成公式就是$SwiGLU(x) = \\left [ SiGU \\left( gate_proj(x) \\right) \\odot up_proj(x) \\right] \\times down_proj(x)$，其中可能有点困惑的是这个$\\frac{8h}{3}$是怎么来的，实际上就是为了左右这两个结构的参数量相等：$2 \\times h \\times 4h \\equiv 2 \\times h \\times \\frac{8h}{3} + \\frac{8h}{3} \\times h$\nRotary Embedding\n下面是模型配置，验证一下前面推出来的参数量相关的公式能否对上：\nparams h l a b V intermediate_size calculated params=$2Vh+(12h^2+13h)l$ 6.7B 4096 32 32 4M 32K 11008 6706298880 $\\approx$ 6.71B 13.0B 5120 40 40 4M 32K 13824 12913254400 $\\approx$ 12.91B 32.5B 6656 60 52 4M 32K 17920 32328857600 $\\approx$ 32.33B 65.2B 8192 80 64 4M 32K 22016 64957317120 $\\approx$ 64.96B 每次总是差一点，但是差的不多，差在了哪里呢？MLP部分，理论上intermediate_size=$\\frac{8h}{3}$，但是实际上可能会比这个值大一些，往往向上取到256、512、1024等的倍数，对矩阵乘法性能更好，因此来修正一下参数量、计算量、激活值的量化分析：\n重新计算一下，这次参数量就很接近了\nparams h l a b V intermediate_size calculated params=$2Vh+(4h+4+3I)hl$ 6.7B 4096 32 32 4M 32K 11008 6738673664 $\\approx$ 6.74B 13.0B 5120 40 40 4M 32K 13824 13016268800 $\\approx$ 13.02B 32.5B 6656 60 52 4M 32K 17920 32529735680 $\\approx$ 32.53B 65.2B 8192 80 64 4M 32K 22016 65286963200 $\\approx$ 65.29B Llama 2: Llama 2: Open Foundation and Fine-Tuned Chat Models Llama2在模型结构方面与Llama1相差不大，只是将MHA替换为GQA，将attention的context length从2k提升到4k。下面是Llama2的模型配置\nconfig h l a b V intermediate_size MHA or GQA calculated params=$2Vh+(12h^2+13h)l$ calculated params=$2Vh+(4h+4+3I)hl$ 7B, config 4096 32 32 4M 32K 11008 MHA 6706298880 $\\approx$ 6.71B 6738673664 $\\approx$ 6.74B 13B, config 5120 40 40 4M 32K 13824 MHA 12913254400 $\\approx$ 12.91B 13016268800 $\\approx$ 13.02B 至于70B的config（h=8192, l=80, a=64, b=4M, V=32K, intermediate_size=28672, g=8）使用了group=8的GQA，只有attention部分的参数量会发生一些变化，调整公式后，分别计算一下：\ncalculated params=$2Vh+\\left[ 10h^2 + 11h + \\frac{2g}{a}(h^2+h)\\right] l$ = 5556092928 $\\approx$ 55.56B，相差较大 llama calculated params=$2Vh + \\left [ (2+\\frac{2g}{a}) h ^ 2 + 4h + 3hI \\right ] l$ = 68977950720 $\\approx$ 68.98B，比较接近了 因此，对于transformer而言，\n如果MLP是传统FFN那样的结构，calculated params=$2Vh+(12h^2+13h)l$ 如果attention部分使用了GQA，则calculated params=$2Vh+\\left[ 10h^2 + 11h + \\frac{2g}{a}(h^2+h)\\right] l$ 如果MLP是SwiGLU那样的结构，calculated params=$2Vh+(4h+4+3I)hl$ 如果attention部分使用了GQA，则calculated params=$2Vh + \\left [ (2+\\frac{2g}{a}) h ^ 2 + 4h + 3hI \\right ] l$ 但是总的来说，transformer的复杂度还是$O(h^2l)$级别的\nmore relative reading：\n“Mastering Llama Math (Part-1): A Step-by-Step Guide to Counting Parameters in Llama-2”\nLLM - Transformer \u0026amp;\u0026amp; LLaMA2 结构分析与 LoRA 详解\nLlama 3: The Llama 3 Herd of Models Llama3的改进相对于Llama2和Llama1，主要体现在使用了更高质量的数据和更大规模的训练，模型结构基本没变。下面是模型配置，\nconfig h l a b V intermediate_size GQA group calculated params=$2Vh + \\left [ (2+\\frac{2g}{a}) h ^ 2 + 4h + 3hI \\right ] l$ 8B, config 32 4096 32 4M-\u0026gt;8M-\u0026gt;16M 128K 14336 8 8028422144 $\\approx$ 8.03B 70B, config 80 8192 64 4M-\u0026gt;8M-\u0026gt;16M 128K 28672 8 70550814720 $\\approx$ 70.55B 405B 126 16384 128 4M-\u0026gt;8M-\u0026gt;16M 128K 53248 8 405849112576 $\\approx$ 405.85B 参考：\nLLaMa-1/2/3 原理+源码——拆解 (KV-Cache, RoPE, RMSNorm, GQA, SwiGLU)\n关于激活的分析 前面总说中间激活可能很占显存，我们来分析几个case。\nGPT-3\nconfig h l a b s V from GPT-2 activation $\\approx (34bsh+5bas^2)l$ activation （with GQA）$\\approx \\left [ (28+\\frac{4g}{a})bsh+5bas^2\\right]l$ GPT-3 Small: 125M 768 12 64 1 2048 50257 15972.0MB $\\approx 67.0 \\times 2\\Phi$ 15873.0MB $\\approx 66.58 \\times 2\\Phi$ GPT-3 Medium: 350M 1024 24 64 1 2048 50257 32352.0MB $\\approx 48.5 \\times 2\\Phi$ 32088.0 $\\approx 48.1 \\times 2\\Phi$ GPT-3 Large: 760M 1536 24 96 1 2048 50257 48528.0 MB $\\approx 33.5 \\times 2\\Phi$ 48120.0MB $\\approx 33.2 \\times 2\\Phi$ GPT-3 2.7B 2560 32 80 1 2048 50257 55.3GB $\\approx 11.0 \\times 2\\Phi$ wrong 54.4GB $\\approx 10.82 \\times 2\\Phi$ GPT-3 6.7B 4096 32 128 1 2048 50257 88.5GB $\\approx 7.10 \\times 2\\Phi$ 87.1GB $\\approx 6.98 \\times 2\\Phi$ GPT-3 13B 5140 40 128 1 2048 50257 113.3GB $\\approx 4.68 \\times 2\\Phi$ 111.1GB $\\approx 4.59 \\times 2\\Phi$ GPT-3 175B 12288 96 128 1 2048 50257 316.5GB $\\approx 0.97 \\times 2\\Phi$ 303.6GB $\\approx 0.93 \\times 2\\Phi$ GPT-3 175B 12288 96 128 8 2048 50257 2532.0GB $\\approx 7.77 \\times 2\\Phi$ 2428.5GB $\\approx 7.45 \\times 2\\Phi$ GPT-3 175B 12288 96 128 64 2048 50257 19.78TB $\\approx 62.14 \\times 2\\Phi$ 18.97TB $\\approx 59.60 \\times 2 \\Phi$ Llama-2：\nconfig h l a b s V intermediate_size GQA: group activation （with GQA）$\\approx \\left [ (13+\\frac{4g}{a})bsh+5bas^2 + 6bsI\\right]l$ 7B, config 4096 32 32 1 4096 32K 11008 32(MHA) 96.6GB $\\approx 7.4 \\times 2\\Phi$ 13B, config 5120 40 40 1 4096 32K 13824 40(MHA) 150.9GB $\\approx 6.2 \\times 2\\Phi$ 70B, config 8192 80 64 1 4096 32K 28672 8 486.25GB $\\approx 3.7 \\times 2\\Phi$ 70B, config 8192 80 64 8 4096 32K 28672 8 3890.0GB $\\approx 29.8 \\times 2\\Phi$ 70B, config 8192 80 64 64 4096 32K 28672 8 30.39TB $\\approx 238.7 \\times 2\\Phi$ 由于前面分析过，intermediate_size往往会略微大于$\\frac{8h}{3}$，因此根据前面分析的llama结构，重新推导一下激活的计算公式，这里省略了。\n可以看出，当大batch、长序列的情况下，中间激活可以是模型参数所占显存的很多倍，即使使用了GQA。\n上面都是在训练场景下的激活值分析，在推理阶段中，可以使用kv-cache减少模型计算量，同时中间激活也大幅度减少，kv-cache的大小为$2w_{kv}bs_mh$（单层），我们也来量化分析一下（假设$w_{kv}$=2，且s=1，推理context长度最后一个token的情况，即最坏情况）\nconfig b $s_m$ h a l kv_cache size=$2w_{kv}bs_mhl$ without kv-cache activation$\\approx (34bs_mh+5bas_m^2)l$ with kv-cache activation $\\approx (30bh+4bs_mh+5bas_m)l$ GPT-3 Small: 125M 1 2048 768 64 12 72MB $\\approx 0.30 \\times 2\\Phi$ 15972.0MB $\\approx 67.0 \\times 2\\Phi$ 79.8MB $\\approx 0.33 \\times 2\\Phi$ GPT-3 Medium: 350M 1 2048 1024 64 24 192MB $\\approx 0.29 \\times 2\\Phi$ 32352.0MB $\\approx 48.5 \\times 2\\Phi$ 207.7MB $\\approx 0.31 \\times 2\\Phi$ GPT-3 Large: 760M 1 2048 1536 96 24 288MB $\\approx 0.20 \\times 2\\Phi$ 48528.0MB $\\approx 33.5 \\times 2\\Phi$ 311.6MB $\\approx 0.21 \\times 2\\Phi$ GPT-3 2.7B 1 2048 2560 80 32 640MB $\\approx 0.12 \\times 2\\Phi$ 55.3GB $\\approx 11.0 \\times 2\\Phi$ 667.3MB $\\approx 0.13 \\times 2\\Phi$ GPT-3 6.7B 1 2048 4096 128 40 1280MB $\\approx 0.1 \\times 2\\Phi$ 110.6GB $\\approx 8.9 \\times 2 \\Phi$ 1334.7MB $\\approx 0.1 \\times 2 \\Phi$ GPT-3 13B 1 2048 5140 128 96 3.76GB $\\approx 0.15 \\times 2\\Phi$ 272.0GB $\\approx 11.2 \\times 2\\Phi$ 3.89GB $\\approx 0.16 \\times 2\\Phi$ GPT-3 175B 1 2048 12288 128 96 9.0GB $\\approx 0.02 \\times 2\\Phi$ 316.5GB $\\approx 0.97\\times 2\\Phi $ 9.15GB $\\approx 0.03 \\times 2\\Phi$ GPT-3 175B 8 2048 12288 128 96 72.0GB $\\approx 0.22 \\times 2\\Phi$ 2532.0GB $\\approx 7.77 \\times 2\\Phi$ 73.2GB $\\approx 0.22 \\times 2\\Phi$ GPT-3 175B 64 2048 12288 128 96 576.0GB $\\approx 1.77 \\times 2\\Phi$ 19.78TB $\\approx 62.1 \\times 2\\Phi$ 585.6GB $\\approx 1.80 \\times 2\\Phi$ 可以看出在推理时，kv-cache大幅度减少了中间激活。而且使用了kv-cache以后，kv-cache在激活中占据了绝大部分的比例，kv-cache甚至可以超过模型所占内存。\n关于计算量的分析 量化分析模型的计算量，主要是为了预估模型训练时间。根据前面的分析，一个FWD+BWD的iteration训练过程中，计算量FLOPs=$6 \\times \\Phi \\times 输入tokens数量$，因此可以大致估计训练时间=$\\frac{6 \\times \\Phi \\times 输入tokens数量}{GPU数量\\times GPU算力(flops) \\times MFU}$。\n其他说明 1. LayerNorm的计算 LayerNorm的计算过程见pytorch LayerNorm参数详解，计算过程，总结一下就是：\n比如输入是[b,s,h]，LN的normalized_shape=[h]，此时就是对每一个大小为h的向量分别进行归一化（一共b*s个） 然后如果LN的elementwise_affine=True，就需要对每个大小为h的向量elementwise的乘上$\\gamma: [h]$，再elementwise的加上$\\beta:[h]$，$\\gamma$和$\\beta$就是该LN层的两个可学习的参数。如果LN的elementwise_affine=False，则只会进行第一步的归一化，不会进行第二步的affine 一个有趣的问题是，Transformer中的LayerNorm可以并行吗？\n关键词： Welford online Algorithm，当一个集合新增加一个元素$x_N$的时候，可以通过前N-1个样本的corrected sum of squares($\\sum_{i=1}^{N-1}(x_i-\\bar{x})^2$)，计算出前N个样本的corrected sum of squares，从而只需要one pass就可以完成LN的计算（之前navie的方法是two pass）\n2. 关于dropout的位置 一共（可能）在有四个地方有dropout：\n在PositionalEmbedding中有一个dropout：dropout(x + PositionEmbedding(x))，不过好像LLM现在使用旋转位置编码RoPE多一些，在计算attention之前在Q和K上加上RoPE，一开始输入的embedding不加PositionalEmbedding了 在softmax计算得到的attention score之后有一个droput：$dropout( softmax(\\frac{QK^T}{scale}+casual_mask) )$ 在sublayer（Attention和MLP）计算完之后，各有一个dropout：x+dropout(sublayer(norm(x))) 总结 transformer的参数量的复杂度是$O(h^2l)$级别的，粗略估计可以认为是$12h^2l$或者$(4h+3I)hl$，如果要详细分析，就要看一看每个部分的结构，是否使用了bias，使用的不同优化，比如：\n如果MLP是传统FFN那样的结构，calculated params=$2Vh+(12h^2+13h)l$ 如果attention部分使用了GQA，则calculated params=$2Vh+\\left[ 10h^2 + 11h + \\frac{2g}{a}(h^2+h)\\right] l$ 如果MLP是SwiGLU那样的结构，calculated params=$2Vh+(4h+4+3I)hl$ 如果attention部分使用了GQA，则calculated params=$2Vh + \\left [ (2+\\frac{2g}{a}) h ^ 2 + 4h + 3hI \\right ] l$ 对transformer中间激活的分析要分训练场景和推理场景\n在训练场景中，中间激活可以是模型参数所占显存的很多倍，尤其在大batch、长序列的情况下。 中间激活值所占显存粗略估计可以认为是$(34bsh+5bas^2)l$或者$(17bsh+5bas^2+6bsI)l$，可以看出与输入token数量（batch和seq_len）、隐藏层维度、头数、intermediate_size、层数相关，因此相对参数量的分析稍微复杂一点。 在推理场景中，prefill阶段基本同训练场景，decode阶段每次输入的序列长度为1，而且默认使用kv-cache。由于使用kv-cache，中间激活相对于训练时的中间激活大幅度减小，但是在大batch、长序列的情况下，kv-cache的显存占用仍然可能超过模型参数的显存占用。还有一点需要注意，推理场景中kv-cache在中间激活中占据了绝大部分。 中间激活值所占显存粗略估计可以认为是$(30bh+4bs_mh+5bas_m)l$或者$(13bh+4bs_mh+5bs_ma+6bI)l$ 对transformer的计算量的分析比较简单，transformer中计算较为规整，计算量体现在若干个大块矩阵的乘法。一般量化分析计算量主要是为了预估模型训练时间，所以一般分析的不多（一般也没有机会训练大模型，如果训练普通规模的网络，尝试跑几个iteration就能估计）。\n","permalink":"https://qinganzhang.github.io/posts/llm%E6%97%B6%E4%BB%A3%E7%9A%84transformer%E9%87%8F%E5%8C%96%E5%88%86%E6%9E%90-%E5%8F%82%E6%95%B0%E9%87%8F%E8%AE%A1%E7%AE%97%E9%87%8F%E6%BF%80%E6%B4%BB%E5%80%BC/","summary":"导读：本文可以看作是对分析transformer模型的参数量、计算量、中间激活、KV cache的详细说明 定性分析 GPU上都存了哪些东西 首先我","title":"LLM时代的transformer参数量、计算量、激活值的分析"},{"content":"本文中有较多Latex数学公式，博客上有一些数学公式格式渲染不正确，可以查看flash_attention简要笔记\n优化效果 原来，attention部分的计算量和中间激活占用显存的复杂度都是$O(N^2)$\n计算量部分原来QK矩阵乘和attn_score@V矩阵乘的计算量，复杂度都是$O(N^2)$；中间激活因为中间有一个attn_score，所以复杂度也是$O(N^2)$\n现在，attention部分的中间激活占用显存的复杂度变为$O(N)$，计算量的复杂度没有变但是通过减少访存加快了计算速度，而且fa与原attention完全等价\n具体过程 flash-attention还是基于kernel融合的思想，将QK矩阵乘法、mask、softmax、dropout合并成一个kernel，这样不仅减少了中间变量对显存的占用，而且也减少了计算过程中的访存\n一些符号表示：\n$S_{ij}=Q_i \\times K_j^T$，Q分块和K分块的乘积，形状为$[B_r, B_c]$\n$\\widetilde{m}{ij}=rowmax(S{ij})$：对分块$S_{ij}$而言，得到其每行的最大值，形状为$[B_r, 1]$\n$\\widetilde{P}{ij}=e^{S{ij}-\\widetilde{m}{ij}}=e^{S{ij}-rowmax(S_{ij})}$：每个分块$S_{ij}$减去其局部rowmax $\\widetilde{m}_{ij}$，形状为$[B_r, B_c]$\n$\\widetilde{l}{ij}=rowsum(\\widetilde{P}{ij})=rowsum(e^{S_{ij}-rowmax(S_{ij})})$：对$\\widetilde{P}_{ij}$而言，按行求和，形状为$[B_r, 1]$\n$m^{new}i=max(\\widetilde{m}{i0}, \\widetilde{m}{i1}, \u0026hellip; , \\widetilde{m}{ij})=rowmax(concat(S_{i0}, S_{i1}, \u0026hellip; , S_{ij}))$：即$contcat(S_{i0}, S_{i1}, \u0026hellip; , S_{ij})$这j+1个分块的每行的最大值，形状为$[Br, 1]$\n$m_i$：$m_i^{new}$位于SRAM上，将$m_i^{new}$写回到HBM就是$m_i$，初始化$m=-\\infty$\n$l^{new}i=e^{m_i-m_i^{new}}l_i + e^{\\widetilde{m}{ij}-m_i^{new}} \\widetilde{l}{ij}=rowsum[e^{S{00}-max(\\widetilde{m}{00},\u0026hellip;,\\widetilde{m}{0j})}] + \u0026hellip; + rowsum[e^{S_{0j}-max(\\widetilde{m}{00},\u0026hellip;,\\widetilde{m}{0j})}]$：\n$l_i$：$l_i^{new}$位于SRAM上，将$l_i^{new}$写回到HBM就是$l_i$，初始化$l=0$\n如果不使用flash-attention，具体过程为：\n$S = Q K ^T $ $P = softmax(S+mask)$ $O = P V$ 如果使用flash-attention，前向过程为：\n大致过程为：\n首先对QKV进行分块，K、V分块方法相同（V的分块图中没画出来），首先可以计算$S_{ij}=Q_i\\times K_j^T$。因为对QKV进行了分块，所以每次SRAM上能保留$S_{ij}$和$\\widetilde{P}_{ij}$（橙黄色表示存储在SRAM上；橙红色表示虽然也存储在SRAM上，但是这些部分每次outer loop会写回到HBM中） 如果有mask，此时对$S_{ij}$进行mask 使用一个局部变量$\\widetilde{m}{ij}$和一个全局变量$m$（或者说$m^{new}$，$m^{new}$的值在SRAM上，但是每次outer loop会写回到HBM中）来记录分块$S{ij}$局部rowmax和中间遍历过的分块$S_{i:}$的历史rowmax 然后基于分块$S_{ij}$计算局部的safe softmax的分子部分，即$e^{S_{ij}-rowmax(S_{ij})}$，safe softmax的分子部分累加就是分母部分，这样，就得到了一个针对分块$S_{ij}$的、局部的safe softmax的分母$\\widetilde{l}{ij}$，和 一个 遍历过的历史分块$S{i:}$的 safe softmax分子部分的 累加和$l^{new}$（注意断句，写公式有点晦涩难懂，用语言描述又不太好描述），局部的$\\widetilde{l}{ij}$就是用来更新全局的$l$（或者说$l^{new}$，$l^{new}$的值在SRAM上，但是每次outer loop会写回到HBM中），对$\\widetilde{l}{ij}$举一个例子： 当j=0，i=0时，$l_0^{new}=e^{m_0-m_0^{new}} l_0+e^{\\widetilde{m}{00}-m_0^{new}} \\widetilde{l}{00}=\\widetilde{l}_{00}$ 当j=1，i=0时，$l_0^{new} = rowsum(e^{S_{00}-max⁡(\\widetilde{m}{00}, \\widetilde{m}{01})})+rowsum(e^{S_{01}-max⁡(\\widetilde{m}{00}, \\widetilde{m}{01})})$ 然后对$\\widetilde{P}_{ij}$进行dropout 然后相当于要进行$O+=\\widetilde{P}_{ij} V_i$了，对于算法的第15行，可以使用分配律拆开看，其中有两个操作： 后半部分：对于当前的$\\widetilde{P}{ij} V_i$相乘，$\\widetilde{P}{ij}$中减去的是分块$S_{ij}$局部的rowmax，需要调整到 此时已经见过的、所有分块$S_{i:}$的rowmax，就是第15行后半部分中$e^{\\widetilde{m}_{ij}-m_i^{new}}$的意思 前半部分：调整上一次的$O$，先乘旧的$l_i$恢复到safe softmax的分子部分，然后乘以$e^{m_i-m_i^{new}}$更新一下safe softmax分子部分中减去的全局rowmax，最后再除以当前的safe softmax的分母 （反向过程还是看别的博客吧）\n简要分析 首先分析一下fa的FLOPs（只分析大块的矩阵乘法，其他小的操作就不计算了）：\n一开始的$Q_i K^T_j$矩阵相乘，其中$Q_i$的形状为$[B_r, d]$，$K_j^t$的形状为$[d, B_c]$，此时FLOPs=$2d \\times B_r \\times B_c$ 后面计算O的时候有一个$\\widetilde{P}{ij} V_i$矩阵相乘，其中$\\widetilde{P}{ij}$的形状为$[B_r, B_c]$，$V_i$的形状为$[B_c, d]$，此时FLOPs=$2B_c \\times B_r \\times d$一共进行了$\\frac{N}{B_r} \\times \\frac{N}{B_c}$次上面的循环，所以FLOPs=$4N^2d$，如果d远小于N，则计算复杂度就变成了$O(N^2)$，计算复杂度相比于standard attention没有变化 然后再分析一下显存占用（显存占用说的是HBM上的显存占用，假设计算精度为$w$ Bytes）\nHBM上需要维护一个全局的rowmax和expsum，占用显存为$w\\times N$ 然后还要存储一个最后的输出$O$，占用显存为$wNd$，但是这个部分是必须的 因此，显存占用的复杂度为$O(Nd)$（或者$O(N)$，如果不考虑$O$的话）。standard attention需要保存中间的$S, P$，显存占用复杂度为$O(N^2)$ fa相对于standard attention一个优势，在于减小了计算过程中的访存量，最后来分析一下访存次数：\nstandard attention 从HBM中读取Q，K（形状都是$[N, d]$），访存量=$wNd$，计算$S=QK^T$，然后向HBM中写回S（形状为$[N, N]$），访存量=$wN^2$ 从HBM中读取S，访存量=$w N^2$，计算$P=softmax(S)$，向HBM中写回P，访存量=$w N^2$ 从HBM中读取P（形状为$[N, N]$）、V（形状为$[N, d]$），访存量=$w N^2 + wNd$，计算$O=PV$，向HBM中写回O（形状为$[N, d]$），访存量=$wNd$ 总的访存量=$w(3Nd+4N^2)$，如果d远小于N，则访存量的复杂度变成了$O(N^2)$ flash attention（分析时将inner loop作为一个整体进行分析，就像上面示意图画的那样） 从HBM中读取分块$Q_i, i=0, \u0026hellip;, T_r -1$，读取分块$K_j$，访存量=$w(Nd+B_c d)$；后面$S_{ij}, \\widetilde{P}_{ij}$不需要写回HBM；$m, l$只是一个向量，数据量很少，忽略；再后面读取和写入分块$O_i, i = 0, \u0026hellip;,T_r =1$，访存量=$w(2\\times Nd)$ outer loop共有$\\frac{N}{B_c}=T_c$次，总的访存量=$w\\times \\frac{N}{B_c} \\times (Nd + B_cd + 2Nd)=w(Nd+\\frac{3N^2d}{B_c})=w(T_c+1)Nd$ 比如N=1024，d=64，B=64，standard_attention访存量-flash_attention访存量=$w(3Nd+4N^2-Nd-\\frac{3N^2d}{B_c})=w(2Nd+(4-\\frac{3d}{B_c})N^2)=w(2Nd+N^2)$，可以看出少了很多访存 实际使用 接口返回值 flash-attention开源代码中，针对不同qkv、是否是varlen、是否需要kv_cache等不同需求封装了不同的接口，这里说一下返回值。这些接口的返回值都相同，除了返回输出的$O$之外，如果设置了return_attn_probs=True，还会返回softmax_lse和S_dmask：\nsoftmax_lse（形状$[nheads, seqlen]$）：在计算$S=\\frac{QK^T}{scale}$之后，会得到形状为$[bs, seqlen, seqlen]$的方阵S，在计算softmax的过程中，需要按行求和，得到一个列向量，然后再取log，写成表达式即为：$softmax_lse=log[\\sum_je^{S_{ij}}]$，注意不是$softmax_lse=log[\\sum_je^{S_{ij}-rowmax(S_{ij})}]$，参考issue：What\u0026rsquo;s the exactly formula of softmax_lse? #404 S_dmask（形状$[bs, nheads, seqlen, seqlen]$）：就是返回$P=softmax(\\frac{QK^T}{scale}+mask)$的这个P矩阵 varlen attention 特别的，这里再说一下flash_attn_varlen_func等一些支持varlen的接口，其函数形参中还有cu_seqlens_q、cu_seqlens_k、max_seqlen_q、max_seqlen_k等特有的参数。这里介绍一些varlen是什么。\nvarlen即变长序列，产生的背景是”数据拼接“，即LLM使用的训练数据集中，长度较短的序列占大多数，这些短序列为了能够符合Transformer固定长度的输入，就要进行padding，序列越短，padding越多，而我们不太想要padding，padding只是无奈之举。此时，我们可以使用varlen特性，简单来说就是将多个短序列拼接成一个长序列，但是还是每个短序列自己内部计算注意力，短序列之间是隔离的，这样减少了padding，节省计算量和显存。\n这里举个例子（参考），比如一些短序列长度分别是：70，300，180， \u0026hellip;，260，120，1200，\u0026hellip;等，attention固定输入长度是4096，此时我们将这些短序列拼接起来，使用varlen_attn后，就像右图所示，每个短序列自己内部计算attention，短序列之间不计算attention（否则就像左图这样，白白多了很多浪费的计算）\n为了实现varlen特性，需要对接口有一些调整。比如不使用varlen的flash_attn接口中，传入的Q、K、V的形状一般为$[bs, seqlen, nheads, head_dim]$（K和V的nheads可以少于Q的nheads，此时就是GQA/MQA）。在使用varlen的flash_attn接口中，主要有两点变化：\nQ、K、V的形状一般为$[total_seq, nheads, head_dim]$，这里将多个batch拼接起来，拼起来的长度为$total_seq$ 多了cu_seqlens_q、cu_seqlens_k、max_seqlen_q、max_seqlen_k等特有的参数 cu_seqlens_q是对每个短序列的Q的长度的exclusive_scan，作用就是找到原来每个batch的起始点（offset），比如上面的例子，此时cu_seqlens_q=[0, 70, 370, 550, ... ]，如果cu_seqlens_q的形状为$[batch_size+1]$，则需要在最后拼接上序列Q的总长度 max_seqlen_q好理解，就是短序列的Q的最长长度 在具体实现中，对每个序列的每个head分别launch kernel，来实现并行计算，这个过程中要通过cu_seqlens_q来确定对应Q的start_idx和end_idx。\n参考：\nFlash attention变长batching API使用\nHow did flash-attn compute attention for cu_seqlens #850\n参考 图解大模型计算加速系列：FlashAttention V1，从硬件到计算逻辑\n优质好文：\n[Attention优化][2w字]🔥原理\u0026amp;图解: 从Online-Softmax到FlashAttention V1/V2/V3\n","permalink":"https://qinganzhang.github.io/posts/flash_attention%E7%AE%80%E8%A6%81%E7%AC%94%E8%AE%B0/","summary":"本文中有较多Latex数学公式，博客上有一些数学公式格式渲染不正确，可以查看flash_attention简要笔记 优化效果 原来，attent","title":"flash_attention简要笔记"},{"content":"Abstract Transformer模型架构在自然语言处理、计算机视觉、强化学习等领域表现出了强大的能力，已经成为当前深度学习很多模型的核心，当前发展迅速的大模型更加凸显出这一点。由于Transformer较高的复杂度，限制了其在很多场景中的应用。因此，为了提高模型的高效性，针对Transformer的改进层出不穷。本文从模型算法的角度出发，关注于模型推理的场景，从不同层次梳理当前提高模型效率的方法，包括设计复杂度更低的注意力机制、提出更加高效的网络设计、进行模型压缩和优化的方法，并针对每一种方法进一步做了分类和总结，并选取具有代表性的方法进行说明。本文最后探讨了Transformer未来可能的发展方向。\n1. Introduction 近年来，深度学习发展迅速，尤其是以Transformer为核心的结构，构成了当前深度学习架构的核心，在计算机视觉、自然语言处理等领域，SOTA的模型均以Transformer架构为核心，而且当前诸如ChatGPT等大模型，核心同样是基于RLHF的Transformer，显示出了Transformer强大的能力。\n但是，受限于Transformer相对于序列长度平方的计算复杂度，在图片、视频等需要长序列的场景下，相对于传统的CNN架构，Transformer仍不够有效，无法得到有效的应用。Transformer的平方复杂度来源于注意力机制，因此，许多研究关注于改进注意力机制，降低注意力机制的复杂度，提出新的注意力机制。除此之外，不同的Transformer架构被提出，这些架构在Vanilla Transformer架构上做出改进来提高计算和访存效率，这可以归结为efficient attention或efficient Transformer网络架构的设计。\n除此之外，为了进一步降低Transformer模型的复杂度，提高模型的推理速度，efficient Transformer的网络架构还可以使用一些模型压缩的方法，比如剪枝、量化、蒸馏、神经架构搜索（NAS）等，这些方法可以在基本保持模型效果的同时，降低模型复杂度，减小模型大小，进一步加速模型的推理。\n需要说明的是，efficiency是一个比较宽泛的用词，包括data-efficiency, model-efficiency（efficient architecture），training-efficiency，inference-efficiency。其中data-efficiency一般指充分利用、挖掘数据，从小规模数据中进行学习；model-efficiency侧重于降低模型的复杂度或是参数量；training-efficiency指使用更少的资源（或提高资源利用效率）、使用更少的时间来进行训练；inference-efficiency通常也被成为模型推理加速，它针对训练好的模型，尽可能提高模型的推理速度、吞吐量等。本综述中只涉及到model-efficiency，并介绍一些针对Transformer的模型压缩方法。\nBlog: Efficient Deep Learning 高效深度学习\n2. Model Efficiency Model efficiency主要侧重于提出新的架构，或者改善现有架构，从而降低模型复杂度或参数量。不同于训练场景只关注于模型的参数量，在推理场景中，模型在访存、计算等方面同样需要高效，2.1节说明了在推理场景中模型所关注的几种不同的efficiency。为了能够量化的来比较模型在推理时的efficiency，2.2节总结了一些评估模型推理性能的指标。\n2.1 Kinds of Efficiency 模型的高效是一个相对的概念，但是有几个发展方向是确定的，比如高效的模型一般具有一下几个特征：模型中存在较多的计算密集型算子而非访存密集型算子（有助于充分发挥硬件性能），模型计算复杂度尽量低（可以应用于更加广泛的场景），模型参数量尽量少（可以减少存储空间和内存的占用），受限于模型的结构、应用的场景，在应用中需要先对这几个方向进行分析，然后才能够做进一步的分析和优化。\n2.1.1 Memory Efficiency 访问内存的开销是影响模型推理速度的一个关键因素。Transformer中许多操作，比如频繁的reshape，element-wise相加，归一化等操作，这些操作或算子是访存密集型的，即大部分时间花费在访存上，而计算耗时占比很小，此时模型推理速度主要受到内存带宽限制。减少模型推理过程在访存上的时间开销，就是提高memory efficiency。\nBlog: 深度学习模型大小与模型推理速度的探讨\n2.1.2. Computation Efficiency 模型的computation efficiency往往指的是模型的算法复杂度低。特别的，针对Transformer而言，当序列长度序列较小时，此时模型的计算开销主要集中在FFN模块，计算复杂度近似地线性于序列长度。但是在很多使用Transformer的场景中，比如图片、视频等场景中，输入序列长度较大。此时，模型的计算开销会集中于自注意力层，产生相对于序列长度平方的复杂度，限制了Transformer在很多场景中的应用。\nBlog: Efficient Transformers\nPaper: Attention is all you need 中FFN与Attention复杂度对比\n2.1.3 Parameter Efficiency Parameter Efficiency主要指的是模型的轻量化和较少的参数量。使用参数量较少的模型，可以减少模型在磁盘上存储的空间和模型加载后内存的占用。需要注意的是，随着大模型的发展，受限于大模型训练的成本，大模型的微调技术PEFT（Parameter-efficient fine-tuning）发展迅速。PEFT旨在最小化微调参数的数量和计算复杂度，以减少大模型微调的成本，来提高模型在新任务上的性能。这里所说的Parameter Efficiency更加类似于模型轻量化的概念。\n2.2 Metrics 设计神经网络架构的主要考虑因素之一就是效果和成本的权衡。一般情况下，一个模型的参数量越多，计算量越大，模型的容量越大，该模型的效果就越好。但是，不同模型在不同硬件平台上的推理效果往往无法直接比较。因此，在比较模型推理性能时，经常会使用一些指标，从不同角度对模型的推理性能进行比较。\n2.2.1 计算量 计算量是评价模型efficiency最常用的指标，包括很多文献进行对比时，常常会将计算量和参数量作为最重要的比较依据。计算量是模型所需的计算次数，模型的整体计算量等于模型中每个算子的计算量之和。衡量计算量主要有两个指标：\nFLOPs（Floating Point Operations，浮点计算次数）：计算量一般用OPs（Operations，计算次数）来表示，由于最常用的格式为float32，因此也常被写作为FLOPs。\nMACs（Multiply-Accumulate Operations，乘加累计操作数）：1个MACs包括一个乘法操作与一个加法操作，大约相当于2FLOPs。在很多硬件上，Multiply-Accumulate可以使用单独一个指令完成，而且很多对tensor的操作也是Multiply-Accumulate操作。FLOPs通常用于模型的理论上计算量的分析，MACs更加贴近真实的计算量。\nMultiply–accumulate_operation from wiki\n2.2.2 参数量 参数量是模型中参数的总和，直接反应了模型在磁盘中存储的大小。虽然参数量并不直接影响推理性能，但是参数量一方面会影响内存占用，另一方面会影响程序初始化时间。而且，在某些场景下，参数量是很重要的指标。比如在嵌入式或移动端场景下，磁盘空间极其有限，此时往往会对模型的参数量有比较严格的限制。在这种情况下，除了在设计时减少参数量，还可以通过压缩模型权重的方式进一步降低打包后模型的大小，但是这样会带来解压缩开销，会在一定程度上增加程序初始化的时间。\n2.2.3 访存量 访存量往往是最容易被忽略的指标，但它对推理性能有着极大的影响。访存量是指模型推理时所需访问内存的数据量，反应了模型对存储带宽的要求。访存量有时也称作MAC（Memory Access Cost）或者MOPs（Memory Operations），一般用Bytes（或KM/MB/GB）来表示，即模型需要读取/写入多少Bytes的内存数据。和计算量一样，模型整体访存量等于模型各个算子的访存量之和。\n2.2.4 运行速度 运行速度是衡量模型efficiency最有效的指标，但是需要基于相同的硬件平台进行对比，而且，即使使用相同的硬件平台，使用不同的软件环境、使用流水线的效率等因素也对最终的推理速度有极大的影响，所以往往在实践中难以直接进行比较。运行速度主要有两种形式进行反应：\n吞吐量（Throughput）：在单位时间内处理的样本个数，相当于可以并行处理的任务量，充分利用流水线可以极大提高模型推理的吞吐量。 延迟（Latency）：通常指单个样本或单个batch处理完成的时间，相当于串行处理一个任务所需要的时间。相对于吞吐量，流水线无法减少延迟。因此，对于需要实时推理的模型而言，需要考虑延迟而非提高吞吐量。 [Paper: THE EFFICIENCY MISNOMER]\n需要注意的是，使用单个指标对模型进行评估往往会导致不全面的结论，甚至评价指标无法真实地比较模型在硬件上的推理速度。比如在下图中，相较于其他网络，在保持类似精确度的情况下，EfficientNet具有相对较小的计算量（GFLOPs）和参数量（Million Parameters），但是模型的推理速度并没有相对于其他模型很明显的提升，甚至有时其他模型推理速度更快一些。虽然如此，但是固定某些指标进行比较，仍是一个相对公平的方法。而且通过分析模型的推理瓶颈，可以针对性的提升模型的某些指标，从而加速推理。\nPaper: THE EFFICIENCY MISNOMER Figure5\n2.3 Find the Bottleneck 不同的模型具有不同的特征，即使同一个模型的不同部分也有不同的特征，比如某些部分是计算密集性的，有些部分是访存密集型的，这里选取Bert和GPT-2两个典型的模型进行分析。\n为了综合衡量计算密集型与访存密集型，通常使用算数强度（arithmetic intensity，也称计算密度，计算强度，计算访存比等）来表示。算数强度表示从内存加载的每个字节可以进行的浮点运算的数量，反映了程序相对于访存而言计算的密集程度，可以通过计算量FLOPs除以访存量来计算得到。RoofLine模型是基于算数强度，来评估程序在硬件上能达到性能上界的模型，即给定一个硬件资源的限制（算力、内存带宽），模型在该硬件上可以达到的最大计算速度。\n当模型的计算密度较小时，访存相对较多，计算相对较少，模型性能主要受到内存带宽限制，此时模型是访存密集型的。反之如果模型的计算密度较大，访存相对较少，计算相对较多，模型性能主要受到硬件算力的限制，此时模型是计算密集型的。一般而言，模型的计算密度越大，越有可能提升硬件的计算效率，充分发挥硬件性能。对于访存密集型算子，推理时间跟访存量呈线性关系，而对于计算密集型算子，推理时间跟计算量呈线性关系。\nBlog: 深度学习模型大小与模型推理速度的探讨\n[Paper: Roofline: An Insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures]\nBERT是Encoder-only的模型，而GPT-2是Decoder-only的模型，如图a所示，这个区别导致两类模型的计算密度差异很大，而两种不同大小的BERT模型的计算密度差异反而不是很大。究其原因，是由于Decoder模型中，每次都是逐个token输入并解码，导致实际矩阵乘法退化为矩阵与向量的乘法，数据重用有限，使其更容易受到内存带宽的限制。因此，如图b所示，当使用高算力的硬件进行推理性能测试时，以BERT-Base的推理时间为基准，尽管相对于BERT-Base，GPT-2具有更少的计算量，但是由于访存量的激增，导致计算密度变低，最终在实际推理时，推理延时远远慢于BERT-Base。因此，针对模型进行优化时，需要综合不同的指标，分析模型的特点，找到模型的瓶颈，从而进行针对性的优化，才能对最终的推理性能有较大提升。\nBlog: LLM Inference CookBook\n[Paper: Full Stack Optimization of Transformer Inference: a Survey] Figure 6 9\n3. Efficient Transformer 虽然当前很多SOTA模型都是基于Transformer，而且很多大模型也都是以Transformer为基础，但是由于Transformer相对于输入序列的平方的复杂度，使得在很多需要长序列的场景中，比如处理图片、视频时受到很大的限制，因此很多方法被提出来改善模型的复杂度，比如降低模型的时间复杂度，减少模型的参数量，设计更适合于硬件的模型来减少访存等。本章节从三个不同角度来讨论使得模型在设计上更加高效的方法。\n3.1 Efficient Attention 注意力机制作为Transformer的核心，它使得模型可以捕捉全局信息，进行长距离建模。但是注意力机制最核心的操作是进行矩阵相乘，由于词向量维数一般固定且不是很大，可以认为是常数，因此时间复杂度可以认为是输入序列长度的平方。本节讨论一些方法，侧重于改善注意力机制的时间复杂度，并根据核心思想进行分类和总结。\nBlog: Transformers大家族——Efficient Transformers: A Survey\nBlog: 「ArXiv2020」【Efficient Transformers: A Survey】论文笔记（更新中）\nBlog: Efficient Transformers: A Survey\nBlog: 进击的Transformer \u0026mdash; 一文介绍Efficient Transformers\nFixed Patterns\n将注意力机制从全局变为局部，限制注意力机制的范围，从而降低复杂度。根据限制的范围和形式，可以分为blockwise pattern， strided pattern，compressed pattern。\nBlockwise pattern将输入序列切成多个block，只在每个block内部进行注意力机制的计算，显著降低了计算复杂度，比如Blockwise Attention、Local Attention等。但是这样简单的切割会导致序列不连贯，缺乏block之间的信息交互，注意力机制能力有限。虽然很简单，但是确实后续很多改进的基础。\nStrided pattern采用滑动窗口的形式，每个token与周围相邻的几个token计算注意力，即按固定间隔进行注意力机制的计算。比如，Sparse Transformer使用类似strided形式的滑动窗口，LongFormer使用类似dilated形式的滑动窗口。相较于Blockwise pattern，考虑到自然语言很多情况下都是局部相关性较高，因此在一个窗口范围内计算注意力可能不会丢失太多信息。\nCompressed pattern则是先通过卷积、池化等CNN操作进行下采样，从而有效减小序列长度，将输入序列转换到固定的模式，降低计算注意力机制的复杂度。\nBlockwise attn: Blockwise Self-Attention for Long Document Understanding\nLocal attn: Image Transformer\nSparse Trans: Generating Long Sequences with Sparse Transformers\nLongFormer: Longformer: The Long-Document Transformer\nCombination of Patterns\n对于输入的token，可以在不同维度、不同区域上组合使用不同的注意力机制，从而学习到更好的特征。比如，Sparse Transformer将一半的注意力头使用strided pattern，另一半注意力头使用local pattern。类似的，在Axial Tranformer中不是像多数注意力模块一样先将多维输入展平，而是每次沿着特征图的单个维度计算自注意力，然后组合多个维度的特征图以得到覆盖全局感受野的特征图。\nAxial Trans: Axial Attention in Multidimensional Transformers\nLearnable Patterns\nLearnable pattern是对fixed pattern的拓展，fixed pattern是提前规定好一些区域，在这些区域中进行注意力，而learnable pattern则是引入可学习参数，让模型自己找到计算注意力的区域，即以数据驱动的方式指导模型的学习过程。比如Reformer引入基于哈希的相似度度量方法来将输入进行切割，Routing Transformer对token向量进行k-means聚类，从而将整体序列分割为多个子序列。因此，从最后注意力计算的角度看，Learnable pattern与fixed pattern是一致的，都是通过将整体序列进行切分，只在子序列中计算注意力，不同的只是子序列的划分方式是提前确定的还是模型学习得到的。\nReformer: Reformer: The Efficient Transformer\nRouting Trans: Efficient Content-Based Sparse Attention with Routing Transformers\nNeural Memory\nNeural memory类似于compressed pattern中先压缩再计算注意力的想法，Set Transformer中第一次使用了这种方法。具体而言，就是初始化k个untrainable向量（k\u0026laquo;n），n个token embedding和这k个trainable向量计算注意力，压缩得到k个向量，然后k个向量再和n个向量计算注意力还原得到n个向量，达到抽取输入序列特征的目的。这k个untrainable向量就可以理解为memory，用于处理临时上下文信息。\nSet Trans: Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks\nLow-Rank\nLow-rank通过矩阵压缩或矩阵近似来降低计算注意力的复杂度。假设$N$是序列长度，$d$是向量维度，$k$是矩阵压缩的超参数。在Linformer中观察到，经过softmax计算之后得到的$N \\times N$的attention score矩阵是不满秩的，这意味着不需要一个完整的attention score矩阵，可以使用一个$N \\times k$的矩阵来近似$N \\times N$的attention score矩阵，同时需要将$N \\times d$的key和value向量映射到$k \\times d$维空间，由于$k$是固定的超参数，因此将注意力机制的复杂度降低到了线性级别。\nLinformer: Linformer: Self-Attention with Linear Complexity\nKernels\nBlog: 线性Attention的探索：Attention必须有个Softmax吗？\nLinear Trans: Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention\n之前的一些研究中提到制约注意力机制性能的关键因素是其中的softmax操作，Scaled-Dot Attention其实就是对value做加权平均，未来得到attention score，就必须先对query和key进行运算。但是，以核函数变换的形式可以得到一个更加通用的注意力机制的数学表达，通过将相似性度量拆分，可以实现注意力机制线性的复杂度（原来的相似度计算中，指数操作的存在使得query，key，value的矩阵操作无法使用结合律）。由于通过kernel方法计算得到的是注意力矩阵的一种近似形式，因此核方法也可以认为是一种特殊的low-rank方法。\nRecurrence\nRecurrence实际上也是fixed pattern中blockwise的一种延申，本质上仍是对输入序列进行区域划分， 只是它进一步对划分后的block做了一层训练连接，通过这样的层级关系就可以把一个长序列的输出得到更好的表征。Transformer-XL使用segment-level recurrence，将上一个segment的状态缓存下来，然后再计算当前segment的时候重复使用上一个的隐藏状态，虽然加快了推理速度，但是由于需要进行缓存，是一种空间换时间的方案。\nTransformer-XL: Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context\n3.2 Efficient Architecture Design 除了改善Transformer中注意力机制的复杂度，修改Transformer中其他部分可能同样有效。实际上，比如针对Bert-Base而言，从参数量的角度看，模型总的参数量约为104MB，其中多头注意力机制部分的参数量大约为27MB；从计算量和访存量的角度看，即使针对较长的序列而言，多头注意力机制部分也只是占了整个模型计算量/访存量的一半左右。因此，设计更加高效的网络架构，同样可以提高模型运行时的性能。同样，本节根据不同模型架构的设计思路和特点进行分类总结。\nBlog: Hydra Attention: Efficient Attention with Many Heads翻译\nBlog: 一文懂“NLP Bert-base” 模型参数量计算\n[Paper: Full Stack Optimization of Transformer Inference: a Survey] Table 3\n增加感受野\n通过增加感受野，模型可以处理更加高分辨率的图像，但同时需要尽量降低额外带来的计算量。Efficient-ViT使用MobileNetV2中的MBConv作为基本块，使用线性注意力机制替代传统注意力机制，并且在前馈神经网络中使用可变形卷积。EdgeNeXt与之相似，它使用分裂的深度转置注意力模块（Split Depth-wise Transpose Attention， SDTA）来替代传统的多头注意力机制，SDTA将输入通道分成多个通道组，利用深度可分离卷积和跨通道的自注意力来有效增加模型的感受野。\n[Paper: EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation]\n[Paper: EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications]\n[Paper: MobileNetV2: Inverted Residuals and Linear Bottlenecks]\n使用池化层\n通常在注意力机制之后使用池化层，来减少推理延迟。NextViT交替使用卷积块和注意力块，其中卷积块由多头卷积注意力和MLP构成，卷积块主要使用了多头自注意力机制，但是注意力机制中key和value都先经过了一个池化层。PoolFormer总结了一种成为MetaFormer的通用架构，通过使用不同的Token-Mixer可以获得不同的具体架构，当Token-Mixer被修改为一个简单的池化层时，PoolFormer以极少的参数同样获得了与其他模型相似的准确度。\n[Paper: Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios]\n[Paper: MetaFormer Is Actually What You Need for Vision]\n使用局部特征\nLeViT再次将充分使用CNN的局部特征，尤其是首先通过卷积来得到低分辨率的特征图，然后通过修改注意力模块进行特征图的下采样。MobileViT网络主要使用MobileViT块和MBConv块堆叠而成，其中MobileViT块负责进行全局信息与局部信息的交互，其中将特征图通过卷积层进行局部建模得到局部信息，然后将局部信息的特征图基于注意力机制进行全局建模，最后进行残差连接。\n[Paper: LeViT: a Vision Transformer in ConvNet’s Clothing for Faster Inference]\n[Paper: MobileViT: Light-Weight, General-Purpose, and Mobile-Friendly Vision Transformer]\n保持维度一致性\n相对于多头注意力机制角度的计算量对于推理延迟的影响，特征维度一致性对推理延迟同样甚至有更大的影响，比如网络中存在大量低效的reshape操作，反复调整特征的维度，会极大影响推理的速度。EfficientFormer提出了一种维度一致性的设计，将网络分成一个特征图为四维的部分和一个特征图为三维的部分，网络从patch embedding开始，首先进入四维特征图部分，最后进入三维特征图部分。在四维特征图部分，主要通过卷积结构为主；在三维特征图部分，此时网络结构中加入注意力机制和MLP结构。最终四维和三维分区的长度是通过网络架构搜索得到的。\n[Paper: EfficientFormer: Vision Transformers at MobileNet Speed]\n并行网络\n一些模型可以并行的执行特定的层，从而加快推理速度。比如Mobile-Former的两个并行分支分别提取局部和全局信息，通过双向桥接进行信息的双向融合。MixFormer基于并行分支设计，将局部自注意力和通道分离卷积两个分支进行交互，并且根据不同分支上操作共享参数的维度不同，使用双向交互模块融合不同维度的信息，针对每个分支提供互补的信息来进一步学习到更好的特征。\n[Paper: Mobile-Former: Bridging MobileNet and Transformer]\n[Paper: MixFormer: Mixing Features across Windows and Dimensions]\n3.3 Efficient Efforts 除了针对注意力机制和Transformer的架构进行改进，通用的模型压缩同样可以提高Transformer的推理性能，同时保持模型精度或将模型精度的下降控制在一个合理范围内。模型压缩主要包括剪枝、蒸馏、量化等。其中，剪枝和蒸馏可以减少模型参数量，量化可以提高模型的访存效率，而且不同的方法可以是正交的，即可以先进行模型的剪枝，再进行模型的量化。许多研究提出了不同的方法来进行Transformer模型的压缩，本节简单进行介绍。由于在自然语言处理领域和计算机视觉领域中，模型压缩的方法可能略有不同，本节更加侧重于视觉方面的模型压缩方法。\n此外，由于Transformer的广泛应用，为了提高模型的推理性能，在设计模型架构时有时需要将硬件也纳入考虑，比如考虑到硬件限制的网络架构搜索，软硬件协同设计等，虽然本综述不涉及硬件的描述，但是本节最后介绍一种针对GPU的新型注意力机制FlashAttention，通过优化注意力机制算法的访存过程，来显著提高模型的运行速度、降低所需内存，同时保持对结果不变和对用户的透明。\n3.3.1 Pruning 剪枝方法基于lottery ticket假设，即模型中只有小部分参数起到了核心作用，其他的大部分参数都是无效参数或是不重要的参数，可以去除掉，在减小模型参数量的同时，保持模型原有的精度。剪枝可以分为结构化剪枝与非结构化剪枝。非结构化剪枝允许修建任何参数，定位参数中接近于0的参数，将这些参数归零，使得权重矩阵稀疏化。虽然非结构化剪枝可以极大减少模型参数，但是由于硬件的限制，很多场景中无法完全发挥非结构化剪枝的效果。结构化剪枝是粒度较大的剪枝，修剪模型中结构化的部分，比如权重的整行，多头注意力中不需要的注意力头，多层Transformer中不需要的若干层等。由于存在一定限制，结构化剪枝的模型压缩率较小，但是更加适合于硬件运行。\n考虑到Transformer中大部分的计算量是在多头注意力（MSA）和前馈神经网络（FFN）部分，为了简Transformer的结构，Vision Transformer Pruning（VTP）是第一个专门用于Vision Tranormer的剪枝方法。VTP首先使用L1稀疏正则化进行训练，VTP获取每一个Transformer block中Dimension的重要性分数，然后对分数较低的Dimension进行裁剪，这样大量的不重要的Dimension将会被裁剪，最后进行微调。不同于VTP主要关注于通道维度的冗余，PS-ViT方法关注于patch层面的冗余，通过计算patch对于最终分类特征的重要性得分来判断每个patch的有效性，同时保证信息一致性，显著降低了计算量并保持了原始模型的精度。NViT在剪枝时将模型的推理时间纳入考虑，通过重分配使用的参数，进行全局结构性剪枝。后续模型分别针对剪枝范围和粒度、剪枝方法、剪枝过程等做出改进，进一步提高模型的推理性能。\n[Paper: THE LOTTERY TICKET HYPOTHESIS: FINDING SPARSE, TRAINABLE NEURAL NETWORKS]\n[Paper: Vision Transformer Pruning]\n[Paper: Vision Transformer with Progressive Sampling]\n[Paper: NViT: Vision Transformer Compression and Parameter Redistribution]\n3.3.2 Distillation 蒸馏是指用教师模型来指导学生模型训练，通过蒸馏的方式让学生模型学习到教师模型的知识。在模型压缩中，教师模型是一个提前训练好的复杂模型，而学生模型则是一个规模较小的模型。由训练好的教师模型，在相同的数据下，通过将教师网络对该样本的预测值作为学生模型的预测目标指导学生模型学习。通过教师模型的指导，让学生模型学习教师模型的泛化能力，以达到或媲美教师模型的准确度。\n在计算机视觉领域，DeiT在ViT的基础上，提出了一种专门针对Transformer的蒸馏方法，将distillation token与原始的class token同时加入网络，同时对损失函数进行相应的变化，显著减小了模型训练时间和训练所需的数据量。Mainfold Distiallation方法考虑了视觉Transformer的特点，在模型中间层引入了patch层级的细粒度监督信号，它是一种基于内积计算特征空间的流形结构表示，通过约束学生模型与教师模型的特征空间具有相似的流形结构，可以更好的将教师模型的知识迁移到学生模型中。TaT中进一步考虑到，由于教师模型和学生模型在结构上的异构型，直接对比像素级别的特征图可能导致不对齐的问题，因此使用注意力机制来隐式对齐语义，并提出一种近似的方法来改善方法的复杂度。\n[Training data-efficient image transformers \u0026amp; distillation through attention]\n[Learning Efficient Vision Transformers via Fine-Grained Manifold Distillation]\n[Knowledge Distillation via the Target-aware Transformer]\n3.3.3 Quantization 量化的基本思想即使用低精度、低比特的数据类型来代替原本的浮点数据类型，可以量化参数权重，也可以量化激活值，不但显著减小了模型的体积，更为重要的意义是优化了模型在运行时的访存，相较于单个指令的计算，访存耗时要远高于计算，因此可以显著加速模型推理。量化最核心的挑战在于使用更低精度的权重的同时保持模型精度尽可能少的降低。量化主要分为两大类，训练后量化（Post-Training Quantization，PTQ）和量化感知训练（Quantization-Aware Training，QAT）。训练后量化是将训练好的模型中的参数或激活值量化为低精度类型的数值类型，虽然使用简单，但是模型精度精度下降一般要高于量化感知训练。量化感知训练在训练过程中模拟量化过程，进而在更新参数时考虑量化产生的误差，虽然量化感知训练得到的量化模型精度下降较低，但是因为需要重新训练，所以开销较大，在实际使用中需要进行权衡使用。\n虽然在卷积神经网络中可以相对简单的使用量化，但是将量化应用于Transformer存在一些挑战。Transformer激活值范围较大，很难使用低精度数据类型表示。传统的卷积神经网络会将异常的离群值截断，但是在Transformer中，这样的离群值有助于深层网络中形成特定的注意力模式，直接截断会改变网络的特性和精度，如果不截断会导致数值分辨率降低，而且注意力机制中存在一些难以量化的算子，进一步导致Transformer模型难以量化。PTQ4ViT提出了使用孪生均匀量化方法来解决激活值范围大的问题，同时为了获得最优的量化参数（而非局部最优），使用Hessian引导度量来评估不同的标定因子，从而以较小的成本提高校准准确率，最终达到了近乎无损的量化效果。针对部分算子难以量化的问题，FQ-ViT中使用Power-of-Two Factor（PTF）来量化LayerNorm，使用Log-Int-Softmax（LIS）来量化softmax，并使用4位量化和BitShift来进行简化，这也是第一个实现Transformer无损全量化的工作。\n[Understanding and Overcoming the Challenges of Efficient Transformer Quantization]\n[PTQ4ViT: Post-Training Quantization Framework for Vision Transformers with Twin Uniform Quantization]\n[FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer]\n3.3.4 FlashAttention FlashAttention是一种对标准注意力机制进行加速的算法，减少了对HBM（High Bandwidth Memory，通常用于GPU显存）的访问，而且它的训练和推理过程的结果和标准注意力机制完全相同，对用户透明，并且显著减小了标准注意力机制的运行时间和所需内存。\nFlashAttention主要从两个方面减少注意力机制的HBM的访问。首先在计算softmax时，FlashAttention可以在不访问整个输入的情况下计算softmax reduction，将输入分割成块，在输入块上多次传递，从而以增量的方式计算softmax reduction。其次，在传统注意力机制中，需要将$QK^T$的计算结果$S$和$softmax(S)$后的计算结果$P$分别存储到显存中，FlashAttention对此做出改进，在反向传播中不存储中间注意力矩阵，避免从显存中读取和写入中间结果矩阵。通过分块写入到HBM中去，存储前向传递的 softmax 归一化因子，在后向传播中快速重新计算片上注意力，这比从HBM中读取中间注意力矩阵的标准方法更快。即使由于重新计算导致 FLOPS 增加，但因为减少了HBM访问，导致运行速度更快并且使用更少的显存（序列长度线性）。\n此外，最新的研究SCFA进一步进行拓展，使得FlashAttention可以计算稀疏注意力，特别是针对Hash-based Attention和Query/Key-Dropping Based Attention，都得到了显著的推理加速。\nBlog: 论文分享：新型注意力算法FlashAttention\n[Paper: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness]\n[Paper: Faster Causal Attention Over Large Sequences Through Sparse Flash Attention]\n4. Discussion on Future Research Transformer虽然有很强的建模能力，但是由于其中注意力机制具有序列长度平方的复杂度，限制了Transformer在很多场景中的使用。在未来的工作中，仍然可能会有很多工作对efficient attention、efficient transformer、模型压缩的不同方面进行改进。除此之外，本文观察到另外两个方向未来可能有进一步的发展。\n4.1 Early Exit 虽然当前很多研究关注于大模型在大量数据上的有效训练，但是经过训练的模型在实际使用中仍然速度较慢，特别是大模型作为基础设施时，越来越多的关注集中于提高模型的推理速度上。从模型来分析，很多大语言模型都是自回归模型，需要根据前面的单词递推的预测下一个单词，这个过程不能并行化，而且考虑到大模型庞大的参数量，整个推理过程需要大量的计算与较高的延迟。\n在推理时，有些单词的预测比较轻松，可能在比较浅层的网络中就可以预测出正确的结果，不用计算到最后一层就可以正确预测，即提前退出（early exit），有的单词就需要较多的计算才能预测，但是很多模型在推理时针对这两种情况使用了相同的计算量。有一些工作已经初步在这方面进行了尝试，比如CALM，不是等待所有解码器层完成，而是尝试在某个中间层之后更早地预测下一个单词。 为了决定是进行某个预测还是将预测推迟到后面的层，测量模型对其中间预测的置信度。 只有当模型有足够的信心预测不会改变时，才会跳过其余的计算。\n[Paper: Confident Adaptive Language Modeling]\nBlog: 基于动态提前退出的预训练模型推理加速简介\n4.2 Alternatives to Attention 虽然注意力机制对于Transformer而言至关重要，但是由于其较高的复杂度，一些研究开始寻找注意力机制的替代而非单纯改进注意力机制。在AFT模型中，同样有类似于标准的点积注意力算法，同样由查询向量Q，被查向量K，内容向量V相互作用而成。但不同的是，AFT中的K和V首先与一组学习得到的位置偏差（position bias）结合，然后再进行同位元素对应相乘（element-wise multiplication）。这一新操作的内存复杂度、文本规模、特征维度都是线性的。当前一个较新的尝试是Hyena。Hyena将时域卷积和频域卷积作为一个组合，通过递归进行多次来增大表达能力，其全局卷积网络达到了超越Transformer建模的效果。\n[Paper: An Attention Free Transformer]\n[Paper: Hyena Hierarchy: Towards Larger Convolutional Language Models]\n5. Conclusion 在本综述中，从推理的角度出发，对efficient transformer进行了粗粒度的调研、分析与总结，并且相对侧重于计算机视觉方面的研究。首先介绍模型不同角度的efficiency和评价efficiency的量化指标。然后从模型算法的角度，从不同层次分析了当前提高模型效率的方法，比如设计复杂度更低的注意力机制，更加高效的网络设计，模型压缩和优化等方法，并针对每种方法进一步做了分类和总结，选取代表性的方法进行具体说明。最后，简单讨论了一些efficient transformer未来可能的发展方向，比如早退机制、注意力机制的替代品等。\n6. More Reading Large Transformer Model Inference Optimization\nThe Transformer Family Version 2.0\nEfficient transformers: Survey of recent work\nBert/Transformer模型压缩与优化加速\n","permalink":"https://qinganzhang.github.io/posts/a_survey_of_efficient_transformer_on_inference/","summary":"Abstract Transformer模型架构在自然语言处理、计算机视觉、强化学习等领域表现出了强大的能力，已经成为当前深度学习很多模型的核心，当前发展迅","title":"A survey of Efficient Transformer on Inference"},{"content":"1. tmux简单介绍 xshell等工具SSH远程登录服务器时，终端窗口（显示界面）和会话（用户与服务器的交互命令）是绑定的，关闭窗口会话也随之结束。tmux可以将窗口和会话分离，关闭窗口后，会话不终止，下次重新打开窗口可以继续绑定上次的会话。\n界面说明：\n左下角，方括号中为会话编号或名称，后面是窗口编号和名字，星号*表示当前所处窗口\n2. 常用命令 2.1 会话管理 新建会话\n1 2 tmux # 会话编号自动从0开始 tmux new -s \u0026lt;session-name\u0026gt; # 自定义会话名称 将会话与窗口分离：Ctrl+b d或者tmux detach\n查看会话：tmux ls\n接入会话： tmux attach -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;\n杀死会话：tmux kill-session -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;\n退出会话：Ctrl+b d\n切换会话：tmux switch -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;或者Ctrl+b s\n重命名会话：tmux rename-session -t \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt;或者Ctrl+b $\n2.2 窗口（window）管理 新建窗口：tmux new-window -n \u0026lt;window-name\u0026gt;或者Ctrl+b c 切换窗口： tmux select-window -t \u0026lt;window-name\u0026gt;/\u0026lt;window-id\u0026gt; Ctrl+b p/n切换上一个/下一个窗口 Ctrl+b l：在两个窗口之间来回切换。 Ctrl+b \u0026lt;window-id\u0026gt;切换指定窗口 Ctrl+b w从列表中选择窗口 当前重命名窗口：tmux rename-window \u0026lt;new-name\u0026gt;或者Ctrl+b , 关闭当前窗口：Ctrl+b \u0026amp; 2.3 窗格（pane）管理 划分窗格：\n左右划分Ctrl+b % 上下划分Ctrl+b \u0026quot; 切换选中窗格：\nCtrl+b \u0026lt;方向键\u0026gt; 切换到下一个窗格Ctrl+b o 切换到上一个窗格Ctrl+b ;\n交换窗格：\n与上一个窗格交换位置Ctrl+b { 与下一个窗格交换位置Ctrl+b }\n关闭窗格：\nCtrl+b x\n调整窗格：\nCtrl+b Ctrl+\u0026lt;方向键\u0026gt;：按方向调整窗格大小\nCtrl+b z：当前窗格全屏显示（临时），再用一次复原\nCtrl+b !：将当前窗格拆分为独立的窗口\n其他：\nCtrl+b q：显示窗格编号\nCtrl+b [：进入翻屏模式，实现上下翻页\n2.4 其他 Ctrl+b ?：帮助命令 tmux list-keys列出所有快捷键和对应的tmux命令 3. 参考资料 Tmux 使用教程-阮一峰\nLinux 终端复用神器 Tmux 使用详解，看完可以回家躺平了～\n","permalink":"https://qinganzhang.github.io/posts/tmux%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","summary":"1. tmux简单介绍 xshell等工具SSH远程登录服务器时，终端窗口（显示界面）和会话（用户与服务器的交互命令）是绑定的，关闭窗口会话也随之","title":"Tmux简单使用"},{"content":"1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从energy看 访存消耗energy远多于计算（200倍） 浮点数运算消耗energy多于int8类型（十几倍），因此量化有助于keep efficient 2. 数值类型（浮点数） FP32：1+8+23 FP16：1+5+10，通常使用在混合精度训练中 BF16：1+8+7，直接将FP32进行截断，方便直接进行转换 TF32：1+8+19，保留了FP32的范围（8位范围）与FP16的精度（10位精度），用于TensorCore中 FP24： 3. 量化基础 K-Means-based Quantization\n原理：权重进行kmeans聚类（每个类别cluster视为一个模式），每个cluster对应一个浮点数，构成一个codebook（lookup table），权重矩阵中保存的是codebook中的索引 微调过程：给定权重矩阵对应的梯度矩阵，将梯度矩阵按照模式进行分组（对应不同的cluster），每组梯度进行求和，再更新codebook中对应cluster的浮点数 效果： 从pruning ratio看：剪枝+量化同时使用，可以获得更小的pruning ratio（量化后再微调一下，有助于恢复精度） 从准确率看：剪枝+量化准确率与只进行量化差不多 优化：霍夫曼编码 将更频繁的权重使用更短的编码表示（但是这样会导致权重矩阵中各个元素大小不一❓） 特点：量化后存储的是低比特，但是计算仍然是浮点数（只是节省了存储，但是访存翻倍❓） Linear Quantization\n原理：直接进行映射，相当于线性的codebook，权重矩阵中存储的是量化值，运算时先反量化到浮点数范围、再使用不同的量化参数量化到int8 $$ 量化：\u0026amp;uint \u0026amp;=\u0026amp; round( \\frac{float}{scale} + offset) \\ 反量化：\u0026amp;float \u0026amp;=\u0026amp; (uint - offset) * scale $$\ntricks：\n公式中的很多部分可以pre-compute\nscale的浮点乘法可以转换为定点小数的位移\n详见Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference 第2.2章\n神经网络量化入门\u0026ndash;基本原理\n量化推理是如何把scale转换为定点运算的\n分类\n对称量化 非对称量化（由于补码负数比正数多一个，因此区分两种模式，构造成左右对称的形式，不同框架可能使用不同的mode） full range mode：正数128加进来 restricted range mode：负数-128去掉 特点：量化后存储的是int8，计算中也是int8\n4. 量化种类 4.1 Post-Training Quantization(PTQ) 权重量化Weight Quantization：减小模型大小\nPer-tensor vs Per-channel\nWeight Equalization\n背景：\nPer-tensor量化简单，但是由于channel之间range差异较大，导致效果很差 Per-channel量化效果较好，但是需要特殊硬件支持❓ 目标：make weight ranges similar (or equalize the weight range), so that per-tensor quantization can be applied（既想要per-tensor的简单，又想要per-channel的效果） 原理：positive scaling equivariance伸缩等价性\n对于conv、fc和relu，满足：\n$$f(s x) = s f(x), where \\quad s \\gt 0 $$\n方法：对于连续的两个卷积层，第一个卷积层乘上一个scale，第二个卷积核对应通道除以一个scale，这样与原来是等价的，但是调整了第一个卷积核的range；然后逐渐连续地调整\n后量化训练-Data free quantization\nAdaptive Rounding\n背景：\n看似符合直觉的round-to-nearest其实精度并不是最优的\n因为并非每个单独的weight的量化损失越小越好，weight之间存在相互影响\n方法：Adaptive地决定weight量化时将浮点数转到最近右定点还是最近左定点❓\nAdaRound解读\n激活值量化Activation Quantization：减小内存占用\n目标：由于激活值无法提前确定，因此要找到激活值的$r_{min}, r_{max}$\nDuring Training\nEMA\n在训练时使用exponential moving averages (EMA)来得到$r_{min}, r_{max}$ $$ \u0026amp;\\hat{r} ^ {(t)} _ {max, min} = \\alpha r ^ {(t)} _ {max, min} + (1 - \\alpha) \\hat{r} ^ {(t-1)} _ {max, min} \\ \u0026amp;其中 \\hat{r} ^ {(t)} _ {max, min} 是EMA激活值范围， \\ \u0026amp;r ^ {(t)} _ {max, min} 是 epoch=t时的激活值范围 $$\nQuantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference 3.1段\nUse calibration after training\n统计calibration中每个sample的$r_{min}, r_{max}$，然后取平均\nACIQ\n基本思想：最小化激活值X与量化值Q（X）的MSE，具体假设原始激活值的分布，展开求导 $$ \\mathop{min}\\limits_{|r|_{max}} \\mathbb{E} \\left[ (X - Q(X))^2 \\right] $$\nCNN后量化方法：ACIQ\nPost training 4-bit quantization of convolutional networks for rapid-deployment\n缺点：需要假设原始的激活值浮点分布（因为需要密度函数）\nKL-divergence based\n基本思想：使用KL散度来衡量量化的信息损失（原始激活值的分布与量化后的分布）\nTensorRT INT8量化原理与实现（非常详细） 第七部分\n偏置量化Bias Quantization\n背景：权重量化之后，权重分布会产生一个shift。一方面希望量化误差尽量小，另一方面希望量化误差的期望为0（但并非如此）\n后训练量化——Data free quantization 中Bias Correction，可以看到蓝色的量化误差明显左偏\n方法：\n如果当前有数据：全精度和量化模型分别跑一遍，bias减去这个量化误差，注意对于每一个卷积层或全连接层都要跑一遍 如果当前没有数据： 4.2 Quantization Aware Training(QAT) K-means-based Quantization 微调\nSTE方法：\n想法：权重信息经过伪量化操作，来模拟产生量化误差，反向传播的梯度信息跳过伪量化节点直接更新原始权重，相当于更新权重信息考虑到了量化误差、梯度下降进行优化\n过程：\n拿到训练好的模型\n在权重、激活值、输入输出等（对应权重量化与激活值量化）前面插入伪量化节点（将浮点权重量化再反量化，模拟推理时的量化）\n一开始伪量化节点中量化参数是怎么来的？\n在微调的forward过程中，顺便计算出量化参数：\n如果是针对权重的量化：直接统计权重中的最小值、最大值，从而计算量化参数 如果是针对激活值的量化：使用指数移动平均EMA来更新量化参数 前向推理，模拟量化的过程\n反向传播：正常更新权重（权重是浮点类型），相当于梯度信息跳过了伪量化节点\n神经网络量化入门\u0026ndash;量化感知训练\n量化感知训练（Quantization-aware-training）探索-从原理到实践\n再读《神经网络量化白皮书》- 0x04 训练时量化(QAT)\nLSQ方法：在反向传播时可以更新量化参数\n量化训练之可微量化参数—LSQ\n5. 低比特量化 Binary Quantization Ternary Quantization Mixed-Percision Quantization 参考：\nMIT 6.S965 韩松课程 05 闲话模型压缩之量化（Quantization）篇 ","permalink":"https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/","summary":"1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener","title":"量化基础"},{"content":"Java编译技术分析 ​ Java程序在运行时首先需要进行前端编译，传统的方法是将Java字节码进行解释执行。为了提高性能，JIT编译通过分层编译热点代码，结合诸多优化方法，在很多场景中性能得到显著的提高。在云原生的场景中，JIT方法面临冷启动的局限，因此AOT受到越来越多的关注。Java AOT是近几年较新的一个Java编译方法，GraalVM Native Image是当前一个主流的实现方法，它将Java字节码编译为平台相关的二进制代码，将Java的动态编译转变为静态编译，以适应云原生等场景。在文章最后将JIT与AOT进行了简单的对比。\n1. 传统Java编译和运行 1.1 Java编译 ​ 编译一般是指将高级程序设计语言转换为计算机硬件能识别的机器语言，以便计算机进行处理和实现人类的易读性，而解释是指将源代码逐条转换为目标代码并逐条运行的过程。针对Java语言而言，Java程序运行的过程中同时包括编译与运行，第一个阶段是在编译阶段，将Java代码编译成Java字节码，这个过程通常叫做前端编译，比如使用Oracle的javac编译器进行编译；第二个阶段是在运行时，通过JVM将Java字节码逐条运行。Java编译主要在第二个阶段有不同的类型，比如JIT和AOT，这两种方法会在后续进行介绍。第一个阶段的转换过程大体与其他编程语言类似，下面简单进行介绍。\n​ 前端编译主要是将源代码转换为中间代码的过程，大体分为以下几个过程。首先通过词法分析分析出句子中各个单词的词性或者词类，将程序划分为词法单元（即Token）。接下来通过语法分析从上面输出的Token流中识别出各类短语，并构造语法分析树。然后进行语义分析，手机标识符的属性信息，同时进行语义检查，最后生成中间代码。各种编程语言的前端编译大体类似。\n1.2 Java运行 ​ 经过传统的Java编译后，得到了Java字节码，即Class文件，Java字节码由操作码和操作数组成，Java通过Java字节码实现了平台无关性，一次编写，到处运行。当使用java命令运行Class文件时，相当于启动了一个JVM进程，JVM中的执行引擎（中的解释器）将平台无关的字节码转换为机器码。JVM采用基于栈的结构，同样分为堆和栈。比如我们现在运行到了 main 方法，就会给它分配一个栈帧。当退出方法体时，会弹出相应的栈帧。\n2 Java即时编译（JIT） 2.1 JIT运行过程 ​ 传统的Java运行过程是JVM解释器逐条代码翻译运行Java字节码，所以在性能上Java通常不如C++这类编译型语言。为了优化Java的性能，根据“二八定律”（少部分代码占据了程序的大部分运行时间），JVM在解释器之外引入了即时（Just In Time）编译器：当程序运行时，解释器首先发挥作用，代码可以直接执行。随着时间推移，即时编译器逐渐发挥作用，把越来越多的代码编译优化成本地代码，来获取更高的执行效率。解释器这时可以作为编译运行的降级手段，在一些不可靠的编译优化出现问题时，再切换回解释执行，保证程序可以正常运行。\n​ 使用JIT后，Java代码的执行过程分为两个部分。第一步同样是进行前端编译，转换成Java字节码。第二部分中，在程序解释运行的过程中，部分代码在一定时间内调用或循环次数超过一定的阈值后，该段代码被认为是热点代码，JIT会编译热点代码并存入codeCache中。当下次要执行该段代码时，直接从codeCache中读取执行，以此来提升运行的性能。简单说，JIT就是将代码经过预热之后，将热点代码进行编译，整体的执行过程大致如 图 1 JIT编译过程 所示。\n图一 JIT编译过程 2.2 分层编译 ​ JIT大体分为两个部分或两种模式：C1编译模式与C2编译模式，分别对应了两种不同的编译器：Client Compiler和Server Compiler。Client Compiler（或C1编译器）注重启动速度和局部的优化，Server Compiler更关注全局的优化，性能更好但是编译时间也更久。\n​ 具体来说，C1编译器会对字节码进行以下的优化：进行局部简单可靠的优化（比如方法内联、常量传播等），将字节码构造成高级中间表示（HIR，HIR与平台无关，通常采用图结构），将HIR转换为低级中间表示（LIR）、C2编译器会进行一些全局性的、更激进的优化（比如循环变换等）。从JDK9开始，C2编译模式除了Server Compiler，还可以选择Graal编译器，该编译器会进行分支预测、虚函数内联等优化，相对Server Compiler优化更加激进，峰值性能更好。\n​ C1编译器和C2编译器和解释器可以相互进行组合，即分层编译。Java7开始引入了分层编译的概念，对于需要快速启动的，或者一些不会长期运行的服务，可以采用编译效率较高的C1；长期运行的服务，或者对峰值性能有要求的后台服务，可以采用峰值性能更好的C2。分层编译将JVM的执行状态分为了五个层次（如 图二 常见编译路径 中横向阶段）：\n​ 0层：解释执行\n​ 1层：执行不带profiling的C1代码\n​ 2层：执行仅带方法调用次数和循环回边执行次数profiling的C1代码\n​ 3层：执行带所有profiling的C1代码\n​ 4层：执行C2代码\n​ 其中profiling就是收集能够反映程序执行状态的数据。其中最基本的统计数据就是方法的调用次数，以及循环回边的执行次数\n根据实际中不同层次进行组合的情况，常用的有五种路径或组合方式（如 图二 常见编译路径 中纵向路径）：\n​ 路径①：编译的一般情况，热点方法从解释执行到被3层的C1编译，最后被4层的C2编译。\n​ 路径②：如果方法比较小（比如Java服务中常见的getter/setter方法），3层的profiling没有收集到有价值的数据，JVM就会断定该方法对于C1代码和C2代码的执行效率相同，在这种情况下，JVM会在3层编译之后，放弃进入C2编译，直接选择用1层的C1编译运行。\n​ 路径③：如果C1编译器忙碌，就在解释执行过程中对程序进行profiling ，根据信息直接由第4层的C2编译。\n图二 常见编译路径 ​ 路径④：如果C2编译器忙碌，因为C1阶段运行速度快，这时方法会被2层的C1编译，然后再被3层的C1编译，以减少方法在3层C2的执行时间。\n​ 路径⑤：如果编译器做了一些比较激进的优化，比如分支预测，在实际运行时发现预测出错，这时就会进行反优化，重新进入解释执行\n​ 总的来说，C1的编译速度更快，C2的编译质量更高，分层编译的不同编译路径，也就是JVM根据当前服务的运行情况来寻找当前服务的最佳平衡点的一个过程。从JDK 8开始，JVM默认开启分层编译。\n2.3 编译优化 ​ JIT会对正在运行的服务进行一系列的优化，包括字节码解析过程中的分析，根据编译过程中代码的一些中间形式来做局部优化，还会根据程序依赖图进行全局优化，最后才会生成机器码。下面简要介绍一些常用的优化方法。\n2.3.1 方法内联 ​ 方法内联，是指在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。JIT大部分的优化都是在内联的基础上进行的，方法内联是即时编译器中非常重要的一环。\n​ Java服务中存在大量getter/setter方法，如果没有方法内联，在调用getter/setter时，程序执行时需要保存当前方法的执行位置，创建并压入用于getter/setter的栈帧、访问字段、弹出栈帧，最后再恢复当前方法的执行。内联了对 getter/setter的方法调用后，能将对getter、setter的访问优化成单一内存访问。\n​ 内联是JIT提升性能的主要手段，但是虚函数使得内联是很难的，因为在内联阶段并不知道他们会调用哪个方法。C2编译器会优化单个实现方法的虚函数调用，但是无法优化多个实现方法的虚函数调用。\n2.3.2 逃逸分析 ​ 逃逸分析是一种确定指针动态范围的静态分析，它可以分析在程序的哪些地方可以访问到指针。JIT会对新建的对象进行逃逸分析，判断对象是否逃逸出线程或者方法。根据逃逸分析的结果进行诸如锁消除、栈上分配以及标量替换的优化。\n​ 锁消除即如果JIT能够证明锁对象不逃逸，那么对该锁对象的加锁、解锁操作没就有意义，可以进行锁消除。\n​ 栈上分配是如果逃逸分析能够证明某些新建的对象不逃逸，那么JVM完全可以将其分配至栈上，并且在new语句所在的方法退出时，通过弹出当前方法的栈桢来自动回收所分配的内存空间。这样一来，我们便无须借助垃圾回收器来处理不再被引用的对象。在Hotspot虚拟机中，并没有进行实际的栈上分配，而是使用了标量替换这一技术，编译器会在方法内将未逃逸的聚合量分解成多个标量，以此来减少堆上分配。\n3 Java提前编译（AOT） ​ JIT会对正在运行的服务进行一系列的优化，包括字节码解析过程中的分析，根据编译过程中代码的一些中间形式来做局部优化，还会根据程序依赖图进行全局优化，最后才会生成机器码。下面简要介绍一些常用的优化方法。\n3.1 背景 ​ JIT编译经过不断的发展，在某些情况下性能甚至可以编译型语言相比，但是冷启动开销较大（即需要经过虚拟机初始化后才能达到可用状态，再经过程序预热才能达到最佳性能）的问题是JIT难以解决的一个问题，这个问题在某些情形下显得尤为重要。比如云原生场景下，Serverless 服务本身执行时间短，Serverless 应用强调微服务架构，服务的粒度小，耗时短。与短暂的应用执行时间相比，冷启动的开销耗时所占比重增大，甚至可能比程序执行时间还要长，因此冷启动对应用的影响也到了不可忽视的程度。\n3.2 运行过程与分析 ​ Java AOT与C++的编译过程比较类似，它首先仍需要将Java程序进行前端编译，转换为Java字节码。然后使用静态编译器将字节码编译为平台相关的二进制可执行代码，最后执行。\n​ 相较于JIT，Java AOT（Ahead Of Time）是一个近年来较新的解决方案，GraalVM Native Image是Oracle官方首推的AOT解决方案，它摈弃了JVM，将Java像C++一样编译成机器代码来执行。GraalVM是Oracle在2019年推出的新一代UVM（通用虚拟机），它在HotSpotVM的基础上进行了大量的优化和改进，主要提供了两大特性：多语言支持（可以在GraalVM中无缝运行多种语言）与高性能（提供了一个高性能的JIT引擎和SubstrateVM）。下面简单介绍一下这个特定的Java AOT方案。\n​ Native Image 是一种将 Java 代码提前编译为独立可执行文件（称为Native executable）的技术，即Native Image是基于GraalVM的AOT。Native Image的输入是整个应用的所有组件，包括应用本身的代码、各种依赖的库、JDK库、以及Substrate VM（Substrate VM是一个包含内存管理、线程调度等的运行时系统），然后会进行三个步骤（如 图三 Native executable构建过程 所示）：\n图三 Native executable构建过程 3.3 动态特性 ​ Substrate VM除了实现内存管理、线程映射等底层能力之外，还需要以静态的方式实现Java的动态特性，以保持JDK接口层面的兼容性和功能的等价性。例如反射是Java中使用非常广泛的动态特性，Substrate VM通过预执行、编译时和运行时三个阶段的配合对其实现了有条件的静态化支持。\n​ 静态分析无法得到反射的目标，所以静态分析得到的可达代码中缺少了反射的目标类、函数和域。Substrate VM需要用户在编译时额外提供关于反射的信息——被称为元数据配置，以帮助Substrate VM编译出正确的程序。元数据配置可以由用户手动编辑，但是考虑到在实际项目中手工编辑是不现实的，所以Substrate VM提供了native-image-agent，可以在挂载在应用程序上，将运行过程中遇到的所有反射都记录下来自动生成静态编译需要的配置文件。将通过agent得到配置的过程称为预执行，预执行时不但记录了反射信息，还记录了序列化、动态类加载和动态代理等动态特性的数据。\n​ 解析出来这个配置文件以后，就可以知道反射什么东西了，将反射的东西注册上去，也就是将可达性的范围进行了扩张，也就扩大了编译的范围。有了配置提供的反射数据，编译时一方面将反射目标注册为可达，扩大了代码可达范围；另一方面将反射调用替换为直接调用，使得在运行时可以在原本用反射调用的位置实现了直接调用。\n3 不同编译方法的对比和应用 ​ 传统的单纯解释方法已经逐渐淘汰，现在主流的方法是基于JIT的编译方法，因此下面主要讲JIT与AOT进行对比。\n​ JIT吞吐量高，有运行时性能加成，程序运行更快，并可以做到动态生成代码等，但是相对启动速度较慢，并需要一定时间和调用频率才能触发 JIT 的分层机制。AOT内存占用低，启动速度快，可以无需 runtime 运行，直接将 runtime 静态链接至最终的程序中，但是无运行时性能加成，不能根据程序运行情况做进一步的优化，而且对动态特性的支持是有限的，部分Java的机制不再适用，且与平台相关。\n​ 总的来说，JIT与AOT是面向于不同场景下的编译方法。在传统服务器部署的场景中，应用执行时间足够长，冷启动问题就被淡化了，而且还可以提前将服务预热准备好，以最好的状态迎接用户的服务请求，因此可以充分发挥JIT的性能。而Serverless 服务本身执行时间短。Serverless 应用强调微服务架构，服务的粒度小，耗时短。与短暂的应用执行时间相比，冷启动的开销耗时所占比重增大，甚至可能比程序执行时间还要长，因此冷启动对应用的影响也到了不可忽视的程度，此时使用AOT更合适。\n","permalink":"https://qinganzhang.github.io/posts/java%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/","summary":"Java编译技术分析 ​ Java程序在运行时首先需要进行前端编译，传统的方法是将Java字节码进行解释执行。为了提高性能，JIT编译通过分层编","title":"Java编译技术分析"},{"content":"编程模型 线程组织层次 grid 网格\n由一个内核函数启动所产生的所有线程统称为一个网格(grid)\ngrid size和block size都是三维结构，dim3类型\n数据类型dim3是基于uint3定义的：\n比如在主机端配置核函数grid size和block size时，数据类型为dim3类型，此时变量可以进行修改 比如核函数在运行时，在设备端查询grid size和block size时，此时数据类型为uint3，此时变量已经固定无法修改 三维网格grid_size(gridDim.x, gridDim.y, gridDim.z) 三维线程块block_size(blockDim.x, blockDim.y, blockDim.z) thread block 线程块\n一个grid可以分为很多个thread block，由blockIdx定位 线程块大小（block size，每个block中线程数量）为1024 warp（thread）\n一个thread block中包含很多thread，每相邻的32个（warpSize）thread组成一个warp 每个thread可以由线程块idblockIdx和线程idthreadIdx唯一确定，同样也是三维结构 函数 核函数 核函数配置：\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, shared_memory_size, stream\u0026gt;\u0026gt;\u0026gt;\n核函数的启动都是异步的，host只是启动（或launch）核函数\n可以使用cudaDeviceSynchronize进行显式同步，或者进行隐式同步 核函数的语法相关：\n返回类型必须是 void 必须使用限定符 __glolbal__，也可以加上 c++ 限定符（比如static）； 核函数支持 c++ 的重载机制； 核函数不支持可变数量的参数列表，即参数个数必须确定； 一般情况下，传给核函数的数组（指针）必须指向设备内存（“统一内存编程机制”除外）； 核函数不可成为一个类的成员（一般以包装函数调用核函数，将包装函数定义为类成员）； 在计算能力3.5之前，核函数之间不能相互调用；之后，通过“动态并行”机制可以调用； 有时启动的线程数量多于数组元素个数，因此通常使用if语句进行控制\n设备函数 核函数可以调用不带执行配置的自定义函数，即设备函数。\n函数执行空间标识符（函数类型限定符）：确定一个函数在哪里被调用，在哪里被运行：\n区分变量类型限定符：__device__全局内存，__shared__共享内存，__constant__常量内存，__managed__统一内存\n__global__修饰的函数称为核函数，一般由主机调用、在设备中执行； __device__修饰的函数称为设备函数，只能被核函数或其他设备函数调用、在设备中执行； __host__修饰主机端的普通 c++ 函数，在主机中被调用、在主机中执行，一般可以省略； 相关语法：\n设备函数可以有返回值 不能同时用 __global__ 和 __device__ 修饰函数（即一个函数不能同时是核函数和设备函数） 不能同时用 __global__ 和 __host__ 修饰函数（即一个函数不能同时是核函数和主机函数） 可以同时用 __host__ 和 __device__ 修饰函数，从而减少代码冗余，此时编译器将分别在主机和设备上编译该函数，生成两份不同的机器码 可以通过 __noinline__ 建议编译器不要将一个设备函数当作内联函数； 可以通过 __forceinline__ 建议编译器将一个设备函数当作内联函数。 内存模型 执行模型 并行方式 指令级并行：如果某个warp中两条指令相互独立，则可以依次发射，进行指令级并行 线程并行方式：SIMT SIMD：比如向量运算指令 一个线程可以同时处理多个数据，但是当前只使用一个ALU。比如使用ARM指令拓展NEON中的向量加指令，可以同时进行四个int的相加 多个数据使用使用相同的指令一起执行 SIMT 从硬件上看，所有的core有各自的执行单元（与SIMD共用一个ALU不同） 从软件上看，每个线程都有自己的指令计数器、寄存器，因此每个线程可以有自己独立的执行路径 尽管一个warp中的所有线程在相同的程序地址上同时开始执行，但是单独的线程仍然可能有不同的行为 warp并行方式：SM上同一个线程块的多个warp，通过大量的core实现并行，通过调度和流水线实现并发和并行 执行模型 host启动核函数，GPU异步执行\nGPU根据运行配置，GPU将启动的核函数作为一个grid，并划分为线程块\n一个线程块分配到一个SM执行，多个线程块可以分配到同一个SM执行，但是一个线程块无法分配到多个SM 线程块划分为warp\n由于资源和硬件限制，并非所有的warp都可以同时执行，因此warp可以分类：\n资源和硬件限制：\n限制了运行的warp的最大数量\nSM限制：每个SM、每个block的最大共享内存大小\n寄存器限制：每个SM、每个block、每个thread的最大寄存器数量\n每个SM中resident block、resident warps、resident threads的最大数量\n寄存器和共享内存都是以256个或字节为单元进行分配的\n限制了每个时钟周期发射的warp的数量：比如一个warp scheduler如果只有一个issue slot，则只能从warp slots中发生一个warp\nactive warp：进入到warp slots中的warp（另一种说法是，当寄存器和共享内存分配给线程块，该线程块内的warp处于活跃状态） stalled warp：阻塞的warp 造成阻塞的情况：正在取指，依赖内存指令的访存结果，依赖于之前指令的执行结果，pipeline正在忙，同步barrier eligible warp：符合条件的warp（32个cuda core可用于执行，数据已经就绪），可以运行的warp selected warp：选定的warp，当前正在运行的warp inactivate warp 由于计算资源是在warp之间分配的，且warp的整个生命周期都在片上（上下文常驻SM），所以warp的上下文切换是非常快速的\n而CPU中寄存器数量很有限，进行需要保护和切换上下文 参考\nwarp scheduler 隐藏延迟：如果warp scheduler在指令周期的每个时钟周期都有一些可以发射的指令，则最大化硬件利用率。通过流水线，来隐藏延迟\n同一个线程中的指令使用流水线来进行指令级并行 两类指令： 算数指令：使用ALU，延迟小（大约10~20个时钟周期） 算数指令隐藏延迟的目的是使用全部的计算资源\n算数运算的并行可以表示为：隐藏算数指令延迟所需要的操作数量\n所需的指令数量=延迟 $\\times$ 吞吐量/32 吞吐量是每个SM每个时钟周期的操作数量，由于SIMT，一个指令对应32个线程的操作，因此指令的吞吐量=（操作数量）吞吐量/32 理论上所需active的warp数量=延迟 $\\times$ 吞吐量/32，还是延迟$\\times$ warp_scheduler数量，不是很清楚\n比如有4个warp scheduler，一个算数指令的耗时或延迟是8个周期，则为了完全隐藏延迟，最少需要32个active的warp；如果warp表现出指令并行性，则需要的active的warp数量更少\n内存指令：使用LD/ST，延迟较大（大约400~800个时钟周期） 内存指令隐藏延迟的目的是使用全部的带宽 内存操作的并行可以表示为：每个周期内隐藏内存延迟所需的字节数 $$所需active的warp数量=\\frac{\\frac{访存延迟(周期)}{内存频率(周期/s)} \\times 带宽(GB/s)}{每个线程访问的数据量(B) \\times 32} $$ 辨析： 传统CPU流水线：每个硬件部件（译码单元，ALU等）当前运行的，属于不同的指令，隐藏的是整个指令从取指到写回的整个过程。独立的算数指令的流水线也与此类似。 CPU通过cache来隐藏延迟，而GPU通过计算来隐藏延迟 算数指令的流水线：在一个SM中，warp之间运行的是不同的指令，因为GPU指令相对CPU而言较慢，所以隐藏的是GPU指令的运行时间 内存指令的流水线：若干个SM中的所有core，使用流水线，从而隐藏访存延迟 内存延迟的时候，计算资源core正在被别的warp使用，这两种延迟使用的是不同的硬件资源，但是遵循相同的原理 一方面，隐藏延迟需要足够多的活跃的warp，数量越多，隐藏越好；另一方面，warp的数量又受到资源和硬件的限制，不能过多 warp占用率：CUDA Occupancy Calculator\nwarp占用率=$\\frac{SM中活跃的warp的数量}{SM最大支持warp数量}$ nvcc编译时，添加编译选项--ptxas-options=-v，可以统计共享内存和寄存器的使用量 高占用率不一定有高性能，但是低占用率不利于隐藏延迟 占用率限制因素： 资源限制：共享内存和寄存器限制 硬件设计限制：每个SM的最多block数、warp数、thread数 权衡 如果每个线程块中线程太少，线程块数量变多，容易受到每个SM中最多block数的限制，导致占用率低 如果每个线程块中线程太多，每个线程块中warp数量变多，线程块数量减少，容易受到每个线程寄存器/共享内存的限制，剩余的一些warp没法组成一个线程块，导致占用率变低 参考 https://blog.csdn.net/weixin_44444450/article/details/118058031 一个占用率计算例子：https://blog.csdn.net/wd1603926823/article/details/108871290 https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P2/ 避免分支 一个warp中的if语句如果在运行时判断产生分支，会导致一个warp中对应的线程依次执行相应路径，其他线程等待（或是假运行），相当于每个代码块都跑了一遍，分支数量越多，性能越差\n如果if中没有产生分支，则不用考虑 比如for循环中包含了if判断，则很可能 可以将分支粒度调整为warp大小的倍数，使得一个warp中执行同一个路径，不同warp间可以执行不同路径，比如(tid/warpSize)%2进行奇偶交错 独立线程调度机制中，每个线程有自己的程序计数器和寄存器，此时SIMT如何运行？不是很清楚\nmetric：不是很清楚\nBranch Efficiency is a measure of how many branches diverged. 100% means no branches diverged. When a branch diverges the warp thread active mask is reduce to be less than 32 so the execution is not as efficient. In addition the branch may have to be executed multiple times based upon the number of ways the branch diverged. Control Flow Efficiency is a measure of how many threads in a warp were active for each instruction. Unless you launch a non-multiple of 32 threads this will be 32 threads or 100%. This number will be less than 100% if the code diverges. 参考\nWhat does a high branch efficiency and low control flow efficiency indicate 循环展开 循环展开：在一次循环中，完成多次循环的任务，从而减少循环的迭代次数\n减少了循环判断次数（减少指令消耗） 循环内部可以有更多独立的操作，有利于流水线 例子：reduce中循环展开\n首先一个线程累加多个数据：shrink 收益：线程数量减半（指数减少） 代价：多了一次（或若干次）访存，但是可以使用流水线隐藏延迟 然后折半reduce的过程 要求此时数组长度必须为2的幂次，因此可以写成模板、在编译期判断 最后是一个warp中的reduce过程：此时计算的线程数量\u0026lt;=32， 不仅没有了循环判断，而且读写过程可以充分使用流水线 动态并行 优点：\n让复杂的kernel变得有层次，比如实现递归核函数 可以等到执行的时候再创建执行配置，利用GPU硬件调度器和加载平衡器动态的调整以适应数据驱动或工作的负载 缺点：\n运行效率更低 过程\n子grid被父thread启动，必须在对应的父thread，父thread block，父grid结束之前结束。所有的子grid结束后，父thread，父thread block，父grid才能结束 如果父thread调用子grid时没有显式同步，则运行时保证，父thread与子grid隐式同步 需要仔细考虑内存竞争的问题 编译时需要加上-lcudadevrt --relocatable-device-code true\n--relocatable-device-code true表示生成可重新定位的代码 参考 # CUDA编程第三章: CUDA执行模型 ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%92%8C%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B/","summary":"编程模型 线程组织层次 grid 网格 由一个内核函数启动所产生的所有线程统称为一个网格(grid) grid size和block size都是三维结构，dim3类","title":"[cuda-learning-notes] 硬件抽象和执行模型"},{"content":"内存模型 全局内存 对全局内存变量的理解：\n从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局内存变量 一个经常会发生的错误就是混用设备和主机的内存地址：主机代码不能直接访问设备变量，设备也不能直接访问主机变量 对全局内存的读写\n如果是读操作，有三种部分的访问方式： L1缓存，L2缓存，DRAM （禁用L1缓存）L2缓存，DRAM Fermi之后都是默认禁用L1 禁用L1缓存的原因是，L1缓存被用作缓冲从寄存器中溢出的数据 只读缓存，L2缓存，DRAM 如果是写操作，则无法被缓存，只经过device层次的L2缓存，没有命中再访问DRAM ==不是很清楚== 编程模型 动态全局内存： 1 2 3 4 5 double *d_x; cudaMalloc((void**)(\u0026amp;d_x), 100*sizeof(double)); // d_x改变为指向设备全局内存的指针 double *h_x; h_x = (double*)malloc(100*sizeof(double)); // h_x是指向主机内存的指针 cudaMemcpy(d_x, h_x, 100*sizeof(double), cudaMemcpyHostToDevice); 静态全局内存： 如果静态全局变量是一个变量（而非数组类型）：此时主机中不可以直接给静态全局内存变量赋值，可以通过 cudaMemcpyToSymbol() 和 cudaMemcpyFromSymbol() 拷贝。 （一个例外：固定内存） 1 2 3 4 5 6 7 8 9 __device__ double d; // 从设备端来看，d直接就是设备全局内存上的变量；从主机端来看，d是一个指针，但是不知道其指向哪里 double h = 0.0; cudaMemcpyToSymbol(d, \u0026amp;h, sizeof(double)); // H2D cudaMemcpyFromSymbol(\u0026amp;h, d, sizeof(double)); // D2H // 因为使用cudaMemcpy需要得到d的地址，而主机端无法直接操作设备端的变量。如果非要使用cudaMemcpy: double *dptr; cudaGetSymbolAddress((void**)(\u0026amp;dptr), d); // 因为主机无法对全局内存变量d取地址，只能使用函数间接得到其地址dptr cudaMemcpy(dptr, h, 100*sizeof(double), cudaMemcpyToDevice); 如果静态全局变量是一个数组，可以使用cudaMemcpy： 1 2 3 __device__ double d_x[100]; // d_x[]直接就是设备全局内存上的数组，d_x是其地址 double h_x[100]; cudaMemcpy(d_x, h_x, 100*sizeof(double), cudaMemcpyHostToDevice); 优化 全局内存访问速度慢，往往是一个 CUDA 程序的性能瓶颈。 优化目标：\n对齐合并的内存访问，减少带宽浪费 足够的并发内存操作，隐藏内存延迟 全局内存的对齐合并访问 访问粒度：\nL1的缓存粒度为128字节（可以禁用L1缓存，只使用L2缓存） L2的缓存粒度为32字节 只读缓存也可以缓存全局内存中的数据，缓存粒度为32字节 使用__ldg()函数将全局内存缓存到只读缓存中 如果编译器能够判断一个全局内存变量在整个核函数的范围内都可读，则自动使用__ldg()函数进行缓存，但是对于全局的写入，没有相应的函数 可以使用__restrict__修饰指针，表示该指针专门用来访问特定的数组（该指针不是别名），nvcc使用只读缓存进行加载 内存对齐：\n一次数据传输中，从全局内存转移到 L2 缓存的一片内存的首地址一定是 32 的整数倍。 使用cuda runtime api（比如cudaMalloc）分配的内存的首地址至少是256字节的整数倍 内存事务：从核函数发起请求，到硬件相应返回数据这个过程\n内存事务可以分为1段，2段，4段 比如全局内存写入时，经过L2缓存，缓存粒度为32字节，此时一次内存事务可以写入1段32字节，2段64字节，4段128字节，其他字节数量只能组合得到 全局内存的访问模式：\n对齐的：内存事务的首地址是缓存粒度的整数倍 合并的（coalesced）：一个warp对全局内存的访问都在一个缓存粒度中（一个warp对全局内存的访问导致最少数量的数据传输），或者可以理解为缓存利用率 合并度=$\\frac{warp请求的字节数}{由该请求导致的所有数据传输的字节数}$ 几种常见的内存访问模式：（以一维的grid和一维的block为例）\n理想的内存访问：顺序的合并访问，合并度=100% 1 2 3 4 5 void __global__ add(float *x, float *y, float *z){ int n = threadIdx.x + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); 乱序的合并访问：访问是交叉的，但仍是合并的，合并度=100% 1 2 3 4 5 6 7 void __global__ add_permuted(float *x, float *y, float *z){ int tid_permuted = threadIdx.x ^ 0x1; // 交换两个相邻的数 // 比如：threadIdx.x=0, tid_permuted=1; threadIdx.x=1;tid_permuted=0; int n = tid_permuted + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add_permuted\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); 不对齐的非合并访问（地址错位） 如果使用L1 cache，访问粒度为128字节，速度快，但是带宽利用率更低 如果不使用L1 cache，访问粒度为32字节，速度慢，但是带宽利用率更高，从而可以提高总线的整体利用率 1 2 3 4 5 6 7 8 void __global__ add_offset(float *x, float *y, float *z){ int n = threadIdx.x + 1 + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add_offset\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); // 对于某个thread block，有32个线程 // 假设数组x，y，z首地址都是256字节的倍数，而一次访存至少32字节 // 由于地址错位，需要进行五次访存，合并度=128/(5*32)=80% 跨越式非合并访问 如果使用L1 cache，访问粒度为128字节，合并度很低（而且出现频繁的缓存失效和替换） 如果不使用L1 cache，访问粒度为32字节，合并度稍微提升 1 2 3 4 5 6 7 8 void __global__ add_stride(float *x, float *y, float *z){ int n = blockIdx.x + threadIdx.x * gridDim.x; z[n] = x[n] + y[n]; } add_stride\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); // 对于0号线程块(blockIdx.x=0)，将访问：0， 128， 256， 384 ... 等位置 // 即stride=gridDim.x=128 // 合并度=128/(32*32)=12.5%，触发32次访存，每次访存32字节 广播式非合并访问 1 2 3 4 5 6 7 void __global__ add_broadcast(float *x, float *y, float *z){ int n = threadIdx.x + blockIdx.x * blockDim.x; z[n] = x[0] + y[n]; } // 合并度=4/32=12.5% // 虽然合并度低，但是整个过程只进行了一次访存 // 其实更适合使用常量内存 定量衡量核函数的有效带宽 带宽：\n理论带宽：硬件限制 有效带宽：核函数实际达到的带宽，$有效带宽=\\frac{(读字节数+写字节数)\\times 10^{-9}}{运行时间}$ 吞吐量：单位时间内操作的执行速度，比如说FPS或（流水线）每个周期完成都少个指令，不仅取决于有效带宽，而且与带宽的利用率、是否命中缓存有关 比如数据经常命中缓存，此时吞吐量就可能超过有效带宽 例子：使用全局内存进行方阵转置，\n准备工作：测量有效带宽的上限和下限 测量有效带宽的上限：对A按行合并读取，对B按行合并写入 1 B[nx + ny * N] = A[nx + ny * N]; 测量有效带宽的下限：对A按列交叉读取，对B按列交叉写入 1 B[ny + nx * N] = A[ny + nx * N]; 测试：code部分如果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const int TILE_DIM = 32; const int N = 100; typedef double real; __global__ void copy(const read *A, real *B, const int N){ const int nx = threadIdx.x + blockIdx.x * TILE_DIM; const int ny = threadIdx.y + blockIdx.y * TILE_DIM; /* code */ } const dim3 block_size(TILE_DIM, TILE_DIM); // 每个thread block中TILE_DIM*TILE_DIM个线程，每个元素对应一个线程 // 此时一个线程块中32*32个线程，少于1024的限制 const dim3 grid_size((N + TILE_DIM - 1) / TILE_DIM, (N + TILE_DIM - 1) / TILE_DIM); // grid的维度 copy\u0026lt;\u0026lt;\u0026lt;grid_size, block_size\u0026gt;\u0026gt;\u0026gt;(A, B, N); 将A的一行转成B的一列：\n1 2 if(nx \u0026lt; N \u0026amp;\u0026amp; ny \u0026lt; N) B[ny + nx * N] = A[nx + ny * N]; 对于A的读取是顺序的，对于B的写入是非顺序的 将A的一列转成B的一行：更快\n1 2 if(nx \u0026lt; N \u0026amp;\u0026amp; ny \u0026lt; N) B[nx + ny * N] = A[ny + nx * N]; 对于A的读取不是顺序的，对于B的写入是顺序的 分析：\n如果对A按行读取（将A的一行转成B的一列），对A按行读取是合并的，写入过程（交叉写入）不缓存\n如果对B按行写入（将A的一列转成B的一行），对A按列读取是交叉的，写入过程（合并写入）不缓存，应该更慢\n但是实际上第二种方式更快，原因在于L1缓存命中率 对A按行读取，每个warp读取$32\\times4B=128B$，正好是一次L1缓存的访问粒度，相当于每次访问，L1缓存命中率都为0，数据从全局内存拿到L1缓存后，后续这些数据又不再使用。因此，总体来看L1缓存命中率=0 对A按列访问，第0个warp中每个线程此时都L1缓存没有命中，此时会有32次128B的访存，然后数据拿到L1缓存中，后面第1~31个warp中线程都可以命中L1缓存。因此，总体来看缓存命中率=$\\frac{31}{32}$=0.96875 可能是对A按列访问由于L1缓存命中率高，隐藏延迟更好，总体耗时更短，==不是很清楚== 若不能满足读取和写入都是合并的，一般应该尽量做到合并写入\n结构体数组和数据结构体 结构体数组（Structure of Array，SoA）：一个结构体，其中成员是数组\n1 2 3 4 5 struct SoA{ int a[N]; int b[N]; }; struct SoA myStruct; 数组结构体（Array of Structure, AoS）：一个数组，每个元素都是一个结构体\n1 2 3 4 typedef struct element { int a, b; } Aos; Aos array[N]; CUDA中普遍倾向于SoA（结构体数组）因为这种内存访问可以有效地合并 其他 增加每个线程中执行独立内存操作的数量，减少核函数发射的数量\n对于IO密集型的核函数，每个线程多处理一点数据（而非原来只处理一个数据） 比如reduce中，每个线程可以先累加多个数据，然后再进行两两数据的折叠相加 对核函数的运行配置进行调整，提升SM占用率\n提升SM占用率会更好隐藏访存延迟吗？==不是很清楚== 参考：Better Performance at Lower Occupancy 参考\nhttps://mp.weixin.qq.com/s/t4T7u4SqajH8db0Essedog 常量内存 常量内存属于全局内存，只有64KB 核函数的参数通过常量内存传递，且限定4KB 常量内存通过Read-Only Data Cache进行缓存，而且读取到的数据可以广播给warp中的其他线程 因为是只读的，因此常量内存必须在全局空间内、所有核函数之外进行声明，且必须在kernel启动前由host进行初始化（比如使用cudaMemcpyToSymbol来进行初始化） 纹理和表面内存 纹理内存专门为那些存在大量空间局部性的内存访问模式设计，可以充分利用空间局部性（比如插值、滤波等操作） 纹理内存驻留在全局内存中，经过只读纹理缓存进行缓存 寄存器 一个寄存器有32bit（4B）的大小，一些常用内建变量存放在寄存器中 核函数中定义的不加任何限定符的变量一般就存放在寄存器中，不加任何限定符的数组可能存放在寄存器中，或者放在局部内存中（即寄存器溢出，会对性能造成很大影响） 核函数前显式说明来帮助编译优化：__launch_bounds_(maxThreadaPerBlock, minBlocksPerMulitprocessor) maxThreadaPerBlock：线程块内包含的最大线程数 minBlocksPerMulitprocessor：可选参数，每个SM中预期的最小的常驻线程块数量 寄存器只能被一个线程可见，因此每个线程都有一个变量的副本，而且该变量的副本可以值不同 局部内存 将寄存器放不下的变量、索引值不能再编译时就确定的数组，都存放在局部内存中（编译器进行判断） 局部内存是全局内存的一部分，因此使用时延迟较高 对于计算能力2.0以上的设备，局部内存可能会存储在L1缓存或L2缓存上 共享内存 主要作用： 减少核函数中对全局内存的访问次数，实现高效的线程块内部的通信 优化对全局内存的访问模式，尤其是针对全局内存的跨越式非合并访问，提高带宽利用率 共享内存一般和L1缓存共享64KB片上内存，可以进行配置 按设备进行配置 1 2 3 4 5 6 7 cudaDeviceSetCacheConfig(cudaFuncCache cacheConfig); /* 参数 cudaFuncCachePreferNone: no preference(default) cudaFuncCachePreferShared: prefer 48KB shared memory and 16 KB L1 cache cudaFuncCachePreferL1: prefer 48KB L1 cache and 16 KB shared memory cudaFuncCachePreferEqual: prefer 32KB L1 cache and 32 KB shared memory */ 不同核函数自动配置 1 cudaFuncSetCacheConfig(const void* func, enum cudaFuncCache cacheConfig); // 配置核函数func对应的共享内存大小 编程模型 静态分配：__shared__ float mat[5][5]; 动态分配： 函数内声明方式：extern __shared__ double arr[]; 动态共享内存只支持一维数组 核函数的执行配置中，第三个参数为每个线程块中动态共享内存的字节数：\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, sizeof(float) * block_size\u0026gt;\u0026gt;\u0026gt; 同步：__syncthreads进行线程块的同步 优化 缓存 L1和L2缓存：缓存局部内存和全局内存的数据\n每个SM都有自己的L1缓存，但是L2缓存是所有SM共用的 可以配置是否使用L1缓存 CPU的L1缓存考虑了时间局部性（LRU算法）和空间局部性，GPU的L1缓存只有空间局部性，没有时间局部性（频繁访问一个一级缓存的内存位置不会增加数据留在缓存中的概率） CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有 与CPU读写都缓存不同，GPU只会针对读过程进行缓存，写过程不缓存 每个SM都有一个只读常量缓存\n使用__ldg()函数显示将数据通过只读数据缓存进行加载 GPU不是很强调缓存（not dependent on large caches for performance），因为当指令或数据miss时，由于warp切换速度快，所以旧切换warp；即用计算而非cache来隐藏延迟\n内存管理 常规数据传输函数 cudaMalloc函数：cudaError_t cudaMalloc(void **address, size_t size);\n示例： 1 2 double *d_x; cudaMalloc((void**)\u0026amp;d_x, 100); // \u0026amp;d_x的类型为double** 参数说明： address是在分配设备内存的指针 注意事项： ==一个经常会发生的错误就是混用设备和主机的内存地址==：主机代码不能直接访问设备变量，设备也不能直接访问主机变量 因为该函数的功能是改变指针d_x的值（即改变d_x指向的位置，将一个指向内存地址的指针赋值给d_x），而非改变d_x所指内容的值，因此只能传入指针d_x的地址，即指针的指针 原来d_x是主机上的一个指针，cudaMalloc之后改变为指向设备全局内存的指针，本质上是GPU地址在内存中的虚拟映射地址 cudaMemset函数：cudaError_t cudaMemset(void * devPtr,int value,size_t count)\ncudaFree函数：cudaError_t cudaFree(void* address)\n设备内存的分配和释放非常影响性能，尽量重用 CUDA允许在核函数内部使用malloc/free 分配/释放全局内存，但是一般会导致较差的性能 cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind)\n主机端的内存默认是可分页的，如果进行数据拷贝，此时CUDA分配不可分页的固定内存，将可分页内存中的数据复制其中，然后再从固定内存中拷贝数据到显存 如果主机端的内存是可分页的，使用虚拟内存，当该页面被换出到交换区时，设备此时无法访问或者进行控制 cudaMemcpyToSymbol函数和cudaMemcpyFromSymbol函数\nsymbol是一个驻留在全局或常量内存空间中的变量 cudaMemcpy 的异步版本 cudaMemcpyAsync\ncudaError_t cudaMemcpyAsync(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind, cudaStream_t stream) 使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（使用cudaMallocHost或cudaHostAlloc），从而防止在程序执行期间物理地址被修改 如果将可分页内存传递给cudaMemcpyAsync，则会导致同步传输 固定内存：\ncudaError_t cudaMallocHost(void **devPtr, size_t count); cudaError_t cudaFreeHost(void *ptr); 固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。 固定内存有更高的读写带宽，但是分配过多的固定内存可能会降低主机系统的性能，同时固定内存分配和释放的代价更高。通常, 当传输数据量\u0026gt;=10M时, 使用固定内存是更好的选择 零拷贝内存\n在零拷贝内存中，主机和设备可以直接访问对方的变量，原理是将host内存直接映射到设备内存空间上，使得设备可以通过DMA的方式访问host的锁页内存 cudaError_t cudaHostAlloc(void **pHost, size_t size, unsigned int flags) cudaHostAllocDefault：与cudaMallocHost函数行为一致 cudaHostAllocPortable：返回能被所有CUDA上下文使用的固定内存，而不仅是执行内存分配的那一个，分配portable memory，适用于主机多线程，让控制不同GPU的主机端线程操作同一块portable memory，实现GPU线程间通信 cudaHostAllocMapped：分配mapped memory，可以在kernel中直接访问mapped memory中的数据，不必再内存和显存之间进行数据拷贝，即zero-copy功能 cudaHostAllocWriteCombined：分配write-combined memory，提高从CPU向GPU单向传输数据的速度，不使用CPU的L1、L2 cache，将cache资源留给其他程序使用，在PCI-E总线传输期间不会被来自CPU的监视打断 将多次写操作写到固定内存的buffer中，将多次写合并；但实际上性能会比普通的write-back更糟糕, 主要是由于其没有使用cache, 而是直接写回内存 零拷贝内存虽然不需要显式的将主机的数据复制到设备上，但是设备也不能直接访问主机端的数据，需要通过cudaHostGetDevicePointer函数主机上的地址，然后才能通过pDevice访问主机上的零拷贝内存 cudaHostGetDevicePointer(void **pDevice, void *pHost, unsigned int flags); flags设置为0 如果使用统一内存，则无须使用cudaHostGetDevicePointer 使用零拷贝内存需要注意同步主机和设备之间的内存访问 零拷贝内存适合用于少量的数据传输 统一内存 发展：\n统一寻址（Unified Address）：Fermi架构中提出了统一的地址空间，将全局内存、局部内存、共享内存放在一个地址空间中 统一虚拟地址(UVA)：CUDA 4（开普勒架构，麦克斯韦架构）引入，将CPU和GPU的内存映射到统一的虚拟地址上，可以使用指针访问对方的地址 统一内存(UM)：CUDA 6（帕斯卡架构之后）引入，实现了一个CPU和GPU之间的内存池 对于第一代统一内存，主机与设备不能并发访问统一内存。因此，在主机调用核函数之后，必须加上一个同步函数（比如cudaDeviceSynchornize），确保核函数对统一内存的访问已经结束，然后才能主机访问统一内存变量 对于第二代统一内存，主机与设备可以并发访问统一内存 语法相关：\n统一内存在device中当作全局内存来使用，必须由主机来定义或分配内存，不能在设备端（核函数或__device_函数中）进行。因此，在核函数中由malloc分配的堆内存不属于同一内存，因而如果CPU需要访问，需要手工进行移动 同一个程序中可以同时使用统一内存和非统一内存 统一内存的分配\n动态分配：cudaError_t cudaMallocManaged(void **devPtr, size_t size, unsigned flags = 0); 参数flags默认为cudaMemAttachGlobal，表示分配的全局内存可以由任何设备通过任何CUDA流访问 静态分配：__device__ __managed__修饰，而且只能是全局变量 超量分配：\n编译选项：-DUNIFIED cudaMallocManaged申请内存只是表示预定了一段空间，统一内存的实际分配发生在第一次访问预留的内存时 优化使用统一内存的程序\n可以手动给编译期一些提示，避免数据缺页、内存抖动，保持数据局部性等，可以使用cudaMemAdvice和cudaMemPrefetchAsync cudaError_t cudaMemPrefetchAsync(const void *devPtr, size_t count, int dstDevice, cudaStream_t stream) 在CUDA流中将统一内存缓冲区devPtr内count字节的内存迁移到设备dstDevice（cudaCpuDeviceId表示主机的设备号）中的内存区域，从而防止或减少缺页异常，提高数据局部性 尽可能多的使用cudaMemPrefetchAsync 优势：\n简化编程 编程更简单：比如之前多GPU，针对某一个数据使用零拷贝内存，每个设备都需要有对应的一个指针，容易混乱（针对零拷贝的改进） 方便代码移植 支持更完整的C++语言要素：比如核函数参数可以使用引用，可以直接使用拷贝构造函数而不用手工进行拷贝或进行很多重载 可能会提供比手工移动数据更好的性能，比如可能会将某部分数据放置到离某个存储器更近的位置 可以进行超量分配，超出GPU显存的部分可以放在主机内存中（但是反过来不行） ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","summary":"内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局","title":"[cuda-learning-notes] 内存模型"},{"content":"CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start, 0)); // 将事件start关联到指定的流0 cudaEventQuery(start); // 强制刷新 cuda 执行流，因为WDDM模式下，CUDA流中的操作显式提交到一个软件队列中（TCC模式不用） // 此处不能使用CHECK，因为它可能返回cudaErrorNotReady，但是又不代表程序出错 // run code. CHECK(cudaEventRecord(stop, 0)); CHECK(cudaEventSynchronize(stop)); // 强制同步，让主机等待cuda事件执行完毕。 float elapsed_time = 0; CHECK(cudaEventElapsedTime(\u0026amp;elapsed_time, start, stop)); // 计算 start 和stop间的时间差（ms）。 CHEKC(cudaEventDestroy(start)); CHEKC(cudaEventDestroy(stop)); CUDA流 CUDA流：由主机发出的、在一个设备中执行的CUDA操作序列\nkernal_func\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, 0, stream\u0026gt;\u0026gt;\u0026gt;(params); 一个CUDA流中各个操作的次序是由主机控制的，但是来自于两个不同CUDA流中的操作顺序无法确定 任何CUDA操作都存在于某个CUDA流中，要么是默认流（也成为空流），要么明确指定的流 相关函数\ncudaError_t cudaStreamCreate(cudaStream_t *stream); cudaError_t cudaStreamDestory(cudaStream_t stream); cudaError_t cudaStreamSynchronize(cudaStream_t stream); 同步等待一个流中的所有操作完成 cudaError_t cudaStreamQuery(cudaStream_t stream); 查询一个流中的操作是否全部完成，不会阻塞；若是，则返回 cudaSuccess; 否则，返回 cudaErrorNotReady。 Stream对并行性的影响 调度队列的个数： 单调度队列：虽然Fermi架构支持最多16个流，但是实际调度过程中，所有的流被塞进同一个调度队列，当选中一个操作执行时，runtime会查看操作之间的依赖关系，如果当操作依赖于前面的操作，而且由于只有一个调度队列，因此调度队列阻塞（后面所有操作都等待，即使这些操作来自不同的流） Hyper-Q：最多32个调度队列和32个流 多个流的操作的发射顺序 左边将多个流以DFS方式发射，右边将多个流以BFS方式发射 以DFS方式发射时，流的发射顺序对并行性有影响 每种资源都有一个队列 每个流内部很可能有依赖关系 比如先发射Stream1，后发射Stream2： 比如先发射Stream2，后发射Stream1： 每个操作操作具体占用的资源大小差异对并行性也有影响 使用流隐藏延迟 在默认流中重叠主机和设备计算 一些cuda runtime api具有隐式同步的效果（比如cudaMemcpy函数），会导致主机阻塞等待 核函数的调用是非阻塞的 用多个流重叠多个核函数的执行 制约加速比的因素：（假设每个CUDA流都执行相同规模的计算） GPU的计算资源（SM数量，每个SM最多允许的线程数量） 当CUDA流较少时，增加CUDA流的数量，总耗时只是略微增加，加速比线性增加，此时加速比没有饱和 当CUDA流的个数到达瓶颈，继续增加CUDA流的数量时，总耗时线性增加，加速比饱和 单个GPU中能够并发运行的核函数个数的上限 比如此时能够并发运行的核函数上限为32，Tesla K40有15个SM，每个SM最多允许2048个线程 比如此时一个核函数开1024线程，理论上最多并发运行的核函数$=\\min{ \\frac{15\\times2048}{1024}, 32}=30$，此时限制因素为GPU的计算资源 比如此时一个核函数开128线程，理论上最多并发运行的核函数$=\\min { \\frac{15 \\times 2048}{128}, 32 }=32$，此时限制因素为并发运行核函数的上限 参考 《CUDA编程：基础与实践》 用多个流重叠核函数的执行与数据传递 将数据与相应操作分成若干份，每个流中依次进行操作，形成流水线 理论上最大加速比为3（假设H2D,KER,D2H运行时间相同） 同步 核函数（或grid）之间的同步 背景：连续发射两个核函数，其调度行为未知 使用cuda graph显示指定核函数调度顺序（？不确定） 相关函数 cudaDeviceSynchronize：阻塞host端，直到所有的kernel调用完毕 原理是device设置了cudaDeviceScheduleBlockingSync标志，将host线程阻塞 在device中使用 cudaDeviceSynchronize已经被逐渐废弃 cudaStreamSynchornize：阻塞host端，直到流中的kernel调用完毕 cudaSetDeviceFlags：记录标志，作为活动的host线程执行device代码时使用的标志 cudaLaunchKernel：在CPU端使用\u0026lt;\u0026lt;\u0026lt;\u0026gt;\u0026gt;\u0026gt;launch核函数时，实际上调用的是该函数，launch核函数到GPU上执行 线程块（或Block）内部的同步 barrier：__syncthreads()同步Block内所有线程 注意死锁问题：__syncthreads必须能被块内所有线程访问到，即不要将__syncthreads放到if-else语句中 __syncthreads的变种：syncthreads_xxx(int predicate) 与__syncthreads相同，但是有一个额外的功能： predicate是一个条件表达式，该变种函数对所有线程评估predicate： __syncthreads_or：如果有任意一个线程的predicate值非零，返回非零 __syncthreads_and：如果对所有线程的predicate值非零，返回非零 __syncthreads_count：统计所有线程中predicate值非零的线程数量 应用：last-block guard确定最后一个线程块（编号最后的线程块未必是最后运行结束的） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 __device__ int counter = 0; __device__ bool lastBlock(int* counter){ // 方法一： __shared__ int last; // 表示当前已经调度发射了多少个线程块 __threadfence(); // 确保之前计算的结果已经写入内存，对所有线程块可见 if(threadIdx.x == 0) // 每个块中第一个线程维护last的值 last = atomicAdd(counter, 1); // 原子更新全局内存中的变量，将更新后的值返回到共享内存中 __syncthreads(); // 块内所有线程同步，有必要。如果没有线程块内同步，则一个线程块内对last的访问有的是新值，有的是旧值，但是又必须要求一个线程块内部的last值都相同。注意没有保证不同的线程块之间是同步的 return last == gridDim.x-1; } __device__ bool lastBlock(int* counter){ // 方法二： __threadfence(); int last = 0; // 寄存器变量 if(threadIdx.x == 0) last = atomicAdd(counter, 1); // 块内线程不需要完全同步 return __syncthreads_or(last == gridDim.x-1); // 仍需要使用__syncthreads_or，因为一个线程块内部，只有0号线程的last是用来维护计数的。因此只要0号线程计算完即可确定当前线程块是否为最后一个 } 线程块（或Block）之间的同步 全局锁+原子操作 线程块内选一个代表，通过维护锁变量，代表先进行同步，从而线程块同步\n1 2 3 4 5 6 7 8 9 __device__ volatile int g_mutex; // 全局锁变量 __deviec__ void __gpu_sync(int goalVal){ int tid_in_block = threadIdx.x * blockDim.y + threadIdx.y; if(tid_in_block == 0){ // 每个线程块中的0号线程 作为线程块的代表 atomicAdd((int*)\u0026amp;g_mutex, 1); while(g_mutex != goalVal){ /* Do nothing */} // 死循环，直到g_mutex到达goalVal的值 // 这里，goalVal个线程块之间达成同步 } } 无锁方法 将块间同步转换为块内同步 为每个线程块分配一个同步变量，形成一个数组Arrayin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 __device__ void __gpu_sync(int goalVal, volatile int* Arrayin, volatile int* Arrayout){ int tid_in_block = threadIdx.x * blockDim.y + threadIdx.y; // 线程在block中的id int nBlockNum = gridDim.x * gridDim.y; // block数量 int bid = blockIdx.x * gridDim.y + blockIdx.y; // 线程块id if(tid_in_block == 0) // 每个线程块的0号线程，基于自己线程块的索引，更新Arrayin数组 Arrayin[bid] = goalVal; // 0号线程块进行控制 if(bid == 0){ // 将块间同步转换为线程块0号内部的块内同步 if(tid_in_block \u0026lt; nBlockNum) { // 0号线程块中，每个线程控制一个线程块 while(Arrayin[tid_in_block] != goalVal) { /* Do nothing */} } __syncthreads(); // 0号线程块内进行同步。 // 0号线程块执行到这里，表示所有线程块已经完成初始化Arrayin数组 if(tid_in_block \u0026lt; nBlockNum) Arrayout[tid_in_block] = goalVal; } if(tid_in_block == 0){ // 每个线程块的0号线程 while(Arrayout[bid] != goalVal) { /* Do nothing */} } __syncthreads(); // 同步所有块内线程 } 内存fence 背景：CUDA 编程模型假定了一种弱顺序(weakly-ordered)一致性的内存模型 内存一致性（memory consistency）：访存操作在全局中生效（或观察到的）顺序问题， 是指令集所规范的，是软硬件接口的一部分 缓存一致性（cache coherence）：同一个地址在不同的缓存中一致性问题，是完全的硬件实现策略，程序员无关，是集成电路设计者考虑的东西。 内存fence：读写操作可能进行重排or优化，添加fence之后，fence之前的op一定比fence之后的op先执行。即抑制编译器重排、抑制乱序。 内存fence：The CUDA programming model assumes a device with a weakly-ordered memory model. Memory fence functions can be used to enforce a sequentially-consistent ordering on memory accesses. volatile：声明一个变量，防止编译器优化，防止这个变量存入缓存，如果恰好此时被其他线程改写，那就会造成内存缓存不一致的错误，所以volatile声明的变量始终在全局内存中。 内存fence只会影响自己线程中内存操作的顺序，保证自己的数据fence后能够被其他线程安全的访问，并不能像__syncthreads那样保证内存操作对于同block中的其他线程可见 相关函数 __threadfence_block()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对block内所有线程可见。 __threadfence()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对grid内所有线程可见。 __threadfence_system()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对system（CPU+GPU）内所有线程可见。 参考： CUDA内存栅栏（Memory Fence）理解 warp同步 warp内（inter-warp）同步 barrier：__syncwarps()同步一个warp中的线程\n线程束内函数都有 _sync 后缀，表示这些函数都具有隐式的同步功能。\n线程束表决函数（warp vote functions） unsigned __ballot_sync(unsigned mask, int predicate)：如果线程束内第n个线程参与计算（旧掩码）且predicate值非零，则返回的无符号整型数（新掩码）的第n个二进制位为1，否则为0 int __all_sync(unsigned mask, int predicate)：线程束内所有参与线程的predicate值均非零，则返回1，否则返回0 int __any_sync(unsigned mask, int predicate)：线程束内所有参与线程的predicate值存在非零，则返回1， 否则返回0 线程束匹配函数（warp match functions） 线程束洗牌函数（warp shuffle functions）：最后一个参数表示逻辑上的warp大小 T __shfl_sync(unsigned mask, T v, int srcLane, int w = warpSize)：参与线程返回标号为 srcLane 的线程中变量 v 的值。该函数将一个线程中的数据广播到所有线程。 T __shfl_up_sync(unsigned mask, T v, unsigned d, int w=warpSize)：标号为t的参与线程返回标号为 t-d 的线程中变量v的值，t-d\u0026lt;0的线程返回t线程的变量v。该函数是一种将数据向上平移的操作，即将低线程号的值平移到高线程号。 例如当w=8、d=2时，2-7号线程将返回 0-5号线程中变量v的值；0-1号线程返回自己的 v。 T __shfl_down_sync(unsigned mask, T v, unsigned d, int w=warpSize)：标号为t的参与线程返回标号为 t+d 的线程中变量v的值，t+d\u0026gt;w的线程返回t线程的变量v。该函数是一种将数据向下平移的操作，即将高线程号的值平移到低线程号。 例如当w=8、d=2时，0-5号线程将返回2-7号线程中变量v的值，6-7号线程将返回自己的 v。 T __shfl__xor_sync(unsigned mask, T v, int laneMask, int w=warpSize)：标号为t的参与线程返回标号为 t^laneMask 的线程中变量 v 的值。该函数让线程束内的线程两两交换数据。 线程束矩阵函数（warp matrix functions） 例子：使用warp shuffle函数进行规约：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void __global__ reduce_shfl(const real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; // tid从0到blockDim.x const int bid = blockIdx.x; const int n = tid + bid * blockDim.x; extern __shared__ real s[]; // 比如大小128 s[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; const unsigned FULL_MASK = 0xffffffff; __syncthreads(); // 线程块同步函数 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt;= 32; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s[tid] += s[tid + offset]; __syncthreads(); } real y = s[tid]; for(int offset = 16; offset \u0026gt; 0; offset \u0026gt;\u0026gt;= 1) y += __shfl_down_sync(FULL_MASK, y, offset); // 线程tid返回线程tid+offset中寄存器变量y的值 if(tid == 0) atomicAdd(d_y, y); } 协作组 协作组（cooperative groups）:提供了线程块以上级别的同步\nthread_group\n协作组编程模型中最基本的类型，是线程块级别的协作组 成员函数： void sync()，同步组内所有线程；（相当于__syncthreads函数） unsigned size()，返回组内总的线程数目，即组的大小； unsigned thread_rank()，返回当前调用该函数的线程在组内的标号（从0计数） bool is_valid()，如果定义的组违反了任何cuda限制，返回 false，否则true thread_block继承于thread_group_base\u0026lt;T\u0026gt;，thread_group_base\u0026lt;T\u0026gt;继承于thread_group\ndim3 group_index()，返回当前调用该函数的线程的线程块指标，等价于 blockIdx； dim3 thread_index()，返回当前调用该函数的线程的线程指标，等价于 threadIdx； this_thread_block()：初始化一个thread_block对象 tiled_partition() ：将一个thread_block划分为若干片（tile），每片构成一个thread_group 1 2 3 4 5 6 7 #include \u0026lt;cooperative_groups.h\u0026gt; using namespace cooperative_groups; // 相关变量和函数定义在该命名空间下 // namespace cg = cooperative_groups; // 取别名 thread_block g = this_thread_block(); // g相当于一个之前的线程块，这里将其包装为一个类型 thread_group myWarp = tiled_partition(g, 32); // 将thread_block划分为thread_group thread_group g4 = tiled_partition(myWarp, 4); // 可以将thread_group进一步细分 thread_block_tile\n使用模板，在编译期划分 线程块片（thread block tile） 1 2 thread_block_tile\u0026lt;32\u0026gt; g32 = tiled_partition\u0026lt;32\u0026gt;(this_thread_block()); thread_block_tile\u0026lt;32\u0026gt; g4 = tiled_partition\u0026lt;4\u0026gt;(this_thread_block()); 线程块片具有额外的函数（类似线程束内函数）：\nunsigned ballot(int predicate); int all(int predicate); int any(int predicate); T shfl(T v, int srcLane); T shfl_up(T v, unsigned d); T shfl_down(T v, unsigned d); T shfl_xor(T v, unsigned d); 与一般的线程束不同，线程组内的所有线程都要参与代码运行计算；同时，线程组内函数不需要指定宽度，因为该宽度就是线程块片的大小。 例子：使用协作组进行规约：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void __global__ reduce_cp(const real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; // tid从0到blockDim.x const int bid = blockIdx.x; const int n = tid + bid * blockDim.x; extern __shared__ real s[]; // 比如大小128 s[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; __syncthreads(); // 线程块同步函数 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt;= 32; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s[tid] += s[tid + offset]; __syncthreads(); } real y = s[tid]; thread_block_tile\u0026lt;32\u0026gt; g = tiled_patition\u0026lt;32\u0026gt;(this_thread_block()); for(int i = g.size() \u0026gt;\u0026gt; 1; i \u0026gt; 0; i \u0026gt;\u0026gt;= 1) y += g.shfl_down(y, i); // 使用协作组的成员函数与使用warp shuffle函数具有等价的执行效率 if(tid == 0) atomicAdd(d_y, y); } more\nhttps://www.zhihu.com/question/586453330/answer/3232856921 原子操作 两类原子函数： atomicAdd_system：将原子函数的作用范围拓展到所有节点（host和device） atomicAdd_block：将原子函数的作用范围缩小至一个线程块 一个特殊的原子函数：atomicCAS，所有其他原子函数都可以使用它来实现 相关语法： 原子函数的返回值都是原来的旧值 原子函数都是__device__函数，只能在核函数中使用 原子函数操作的地址可以位于全局内存，也可以位于共享内存 原子操作开销与是否存在竞争相关，且参与竞争者越少，开销越小 例子：使用原子函数进行规约 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void __global__ reduce_shared(real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; const int bid = blockIdx.x; const int n = blockIdx.x * blockDim.x + threadIdx.x; extern __shared__ real s_y[]; // 动态共享内存 s_y[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; // 将全局内存中的数据拷贝到线程块对应的共享内存中 __syncthreads(); // 保证一个线程块中的同步，但是不能保证不同线程块之间的同步 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt; 0; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s_y[tid] += s_y[tid + offset]; __syncthreads(); } if(tid == 0) atomicAdd(\u0026amp;d_y[0], s_y[0]); // 使用原子操作，将结果累加到d_y[0] } ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/","summary":"CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start, 0)); //","title":"[cuda-learning-notes] 流和同步"},{"content":"工具 nvidia-smi -L：显示设备名称，精简信息\n-q -i 0：显示0号设备详细状态信息\n-q -i 0 -d MEMORY：从详细状态信息中提取某类信息（比如MEMORY、COMPUTE、UTILIZATION等）\n部分字段含义：\nGPU-util：For a given time period, it reports what percentage of time one or more GPU kernel(s) was active (i.e. running). nvidia-smi Volatile GPU-Utilization explanation? Nsight System(nsys) nsys profile ./hello_world\n--trace cuda\n--gpu-metrics-device 0\n--stats true\n如何检测achieved_occupancy活跃线程束比例， gld_throughput内存利用率\nhttps://face2ai.com/CUDA-F-3-3-%E5%B9%B6%E8%A1%8C%E6%80%A7%E8%A1%A8%E7%8E%B0/\nhttps://zhuanlan.zhihu.com/p/589120507\nnvprof是旧的分析工具，不支持8.0以上的GPU，其功能拆分给nsys和ncu\nnsys nvprof：统计cuda api和cuda kernel的耗时和相关配置 ncu --metrics：统计得到metrics Nsight Compute(ncu) 几种常规用法：很可能需要sudo权限 分析某几个指标：ncu --metrics ncu --query-metrics可以列出分析的指标 得到profile的全部信息：ncu --set full --import-source yes --target-processes all -o profile_file --set full：profile全部信息 ncu --list-sets可以查看支持的section，每个section是一些metric的集合 --import-source yes：在服务器端跑出profile，然后copy到本地gui中进行查看 -o \u0026lt;output_file_name\u0026gt; metrics metrics：performance counter，性能统计的指标\nmetrics structure\npeak rete：每个counter都有两类peak rete burst rate：the maximum rate reportable in a single clock cycle sustained rate：the maximum rate achievable over an infinitely long measurement period metrics entities counter：直接从GPU而来的统计量 每个counter都有四个sub-metrics，叫做roll-ups sum，avg，min，max 有一些可以从counter roll-ups计算而来的sub-metrics 比如.peak_sustained ratio：有三个sub-metrics pct，ratio，max_rate throughputs：标识一个portion接近peak rate的程度，有四个sub-metrics 比如.pct_of_peak_sustained_active ncu的metrics与nvprof的metrics不相同，存在一定的对应关系。常用的对应关系 nvprof ncu 说明 achieved_occupancy sm__warps_active.avg.pct_of_peak_sustained_active gld_throughput l1tex__t_bytes_pipe_lsu_mem_global_op_ld.sum.per_second gst_throughput l1tex__t_bytes_pipe_lsu_mem_global_op_st.sum.per_second gld_efficiency smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct gst_efficiency smsp__sass_average_data_bytes_per_sector_mem_global_op_st.pct gld_transactions l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum gst_transactions l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum gld_transactions_per_request l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_ld.ratio gst_transactions_per_request l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_st.ratio shared_efficiency smsp__sass_average_data_bytes_per_wavefront_mem_shared.pct shared_load_throughput l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.per_second shared_load_transactions l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum shared_store_throughput l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second shared_store_transactions l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second inst_per_warp smsp__average_inst_executed_per_warp.ratio 比如if分支优化之后，分支减少，inst_per_warp会减少很多 metrics命名规则和对应实体\n其他\n常见报错：Error: ERR_NVGPUCTRPERM - The user does not have permission to access NVIDIA GPU Performance Counters on the target device. 官方解决方法：# NVIDIA Development Tools Solutions - ERR_NVGPUCTRPERM: Permission issue with Performance Counters 自己在/etc/modprobe.d下touch nvidia-restrict-profiling.conf并写入options nvidia NVreg_RestrictProfilingToAdminUsers=0，然后重启 参考\nnvprof的metric与ncu的metric的对应关系 ncu的metric中命名规则和说明 nvprof的metric的说明 nvprof的metric的说明（中文博客） cuda-memcheck CUDA 提供了 CUDA-MEMCHECK 的工具集，包括 memcheck, racecheck, initcheck, synccheck.\ncuda-memcheck --tool memcheck [options] app-name [options] 对于 memcheck 工具，可以简化为：\ncuda-memcheck [options] app-name [options] 实战 二维矩阵相加进行profile：https://face2ai.com/CUDA-F-3-3-%E5%B9%B6%E8%A1%8C%E6%80%A7%E8%A1%A8%E7%8E%B0/\nreduce使用全局内存进行profile逐步优化：https://face2ai.com/CUDA-F-3-5-%E5%B1%95%E5%BC%80%E5%BE%AA%E7%8E%AF/\n","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E5%92%8Cprofile/","summary":"工具 nvidia-smi -L：显示设备名称，精简信息 -q -i 0：显示0号设备详细状态信息 -q -i 0 -d MEMORY：从详细状态信息中提取某类信息（比如MEMORY、CO","title":"[cuda-learning-notes] 工具使用和profile"},{"content":"CUDA编译链和兼容性 兼容性 CPU与GPU的区别\nCPU只有少量的计算核心，有更多晶体管用于数据缓存和流程控制， GPU有大量计算能力较弱的计算核心，用于控制和缓存的晶体管较少 GPU系列：\nTesla系列：使用ECC内存，用于科学计算。后来也叫Data Center GPUs。 Quadro系列：专业级，用于OpenGL、CAD等需要高精度计算的场景。后来也叫Workstation GPUs。 GeForce系列：消费级，用于游戏和计算，但是没有ECC Tegra系列：移动处理器 Jetson系列：嵌入式 GPU架构、计算能力与对应系列\n计算能力（Compute Capability）决定了GPU硬件支持的功能，反映了设备支持的指令集及其他规范，也称SM version，注意GPU计算能力不等价于计算性能 架构 计算能力Compute Capability 发布时间 Tesla系列 Quadro系列 GeForce系列 Jetson系列 Tesla X = 1 2006 Fermi X = 2 2010 Kepler X = 3 2012 Kepler K系列 Quadro K系列 GeForce 600/700系列 Tegra K1 Maxwell X = 5 2014 Maxwell M系列 Quadro M系列 GeForce 900系列 Tegra X1 Pascal X = 6 2016 Pascal P系列 Quadro P系列 GeForce 10系列 Tegra X2 Volta X = 7 2017 Tesla V系列 - TITAN V AGX Xavier Turing X.Y = 7.5 2018 Tesla T系列 Quadro RTX系列 GeForce 16系列，GeForce 20系列 AGX Xavier Ampere X = 8 2020 Tesla A系列 RTX A系列 GeForce 30系列 Ada Lovelace X.Y = 8.9 2022 L4、L40 RTX Ada系列 GeForce 40系列 Hopper X = 9 2022 H100 - CUDA开发平台 CUDA 提供两个编程接口 CUDA driver API：low-level CUDA (driver) library由NVIDIA driver安装，比如常用的共享库libcuda.so，对应头文件为cuda.h，里面提供的API称为CUDA driver API 同时可以看到NVIDIA driver的版本：find / -name libcuda.* NVIDIA driver同时包含了nvidia-smi命令，可以看到NVIDIA driver的版本，以及当前NVIDIA driver支持的最高CUDA版本（向下兼容） 或者使用函数cudaDriverGetVersion(int* driverVersion) CUDA runtime API：high-level CUDA Runtime library由CUDA Toolkit安装，比如常用的共享库libcudart.so，对应头文件为cuda_runtime.h，里面提供的API称为CUDA runtime API cuda_runtime_api.h是纯C版本，cuda_runtime.h是C++版本 离线安装的CUDA工具包会默认携带与之匹配特定的驱动程序 CUDA Toolkit中同时包含了一些工具比如编译器nvcc，nvcc -V显示的CUDA版本是runtime API版本 cuda driver API版本（即驱动支持的最高cuda版本）应该高于cuda runtime API版本（即当前安装的cuda toolkit版本） 或者使用函数cudaRuntimeGetVersion(int *runtimeVersion) 注意不要将GPU计算能力与CUDA (driver/runtime)版本混淆 参考 # CUDA Driver VS CUDA Runtime # cuda 的driver API 和 runtime API 编译相关 编译过程 编译过程 编译device code 首先将预处理之后的C++ code经过CICC compiler编译成PTX code PTX可以视为虚架构的汇编，虚架构体现了应用程序对GPU计算能力的要求，版本尽量低，因此可以适用于更加广泛的GPU架构 再使用ptxas (PTX optimizing assembler)，根据实架构，将PTX code编译成cubin二进制机器码 .cubin：CUDA device code binary file (CUBIN) for a single GPU architecture 将PTX code和cubin放到fatbin.c文件中 .fatbin：CUDA fat binary file that may contain multiple PTX and CUBIN files 编译host code 将预处理之后的C++ code，使用cudafe++将host和device部分分离 分离后的host代码，结合device code部分得到的fatbin.c文件，进行编译 在host code看来，device code其实就是一段数据。 对每一个.cu文件都执行单独的host code和device code编译 链接： 使用nvlink将所有.o目标文件中的device code重新链接到一个cubin文件中，并通过fatbinary转换为.fatbin.c文件 将.fatbin.c文件，结合一些其他的文件，编译得到device code最终对应的目标文件 将host code的目标文件和device code最终的目标文件链接起来，得到最终的可执行文件 使用\n需要选项 -arch=compute_XY 指定一个PTX虚拟架构的计算能力，虚架构版本：Virtual Architecture Feature List\nArchitecture 虚架构 实架构 Maxwell compute_50，compute_52，compute_53 sm_50，sm_52，sm_53 Pascal compute_60，compute_61，compute_62 sm_60，sm_61，sm_62 Volta compute_70，compute_72 sm_70，sm_72 Turing compute_75 sm_75 Ampere compute_80，compute_86，compute_87 sm_80，sm_86，sm_87 Ada Lovelace compute_89 sm_89 Hopper compute_90，compute_90a sm_90，sm_90a 需要选项 -code=sm_ZW 指定一个真实架构的计算能力，实架构版本：GPU Feature List\nCUDA二进制兼容性只能保证局限在相同大版本计算能力的架构中 实架构的计算能力必须大于等于虚架构的计算能力 如果希望编译出来的文件能在更多的GPU上运行，可以使用-gencode同时指定多组计算能力，生成多个PTX版本代码，例如：\n1 2 3 -gencode arch=compute_35, code=sm_35 -gencode arch=compute_50, code=sm_50 -gencode arch=compute_60, code=sm_60 此时，编译出来的可执行文件将包含3个二进制版本，在不同架构的GPU中运行时会自动选择对应的二进制版本 -code=可以指定虚架构，此时将进行即时编译，只会包含PTX代码 如果在运行期间找不到当前架构的二进制版本代码，则使用即时编译\n即时编译推迟cubin的生成，将PTX代码在runtime内编译成cubin然后执行，因为runtime时已经知道当前运行在哪种GPU架构中，因此可以直接生成 缺点是增加了程序的启动延迟，但是可以使用编译缓存来缓解 默认cuda以whole program compilation mode来编译\nreference and more reading\n# Matching CUDA arch and CUDA gencode for various NVIDIA architectures # CUDA 编译与 NVVM IR 笔记 # 银河系CUDA编程指南(2.5)——NVCC与PTX # NVCC编译流程+中间文件+GDB调试cuda程序初探 nvcc文档 # CUDA编译过程 nvcc编译选项 -g：在host端生成调试信息 -G：在device端生成调试信息。如果-dopt未指定，则关闭编译优化。 -lineinfo：为device端生成行号，同时将source information嵌入到可执行文件中 -dopt：如果-G没有指定，则-dopt=on，允许device端代码编译优化。如果-G指定，enables limited debug information generation for optimized device code 常用编译命令：\nnvcc -lineinfo -arch=compute_86 -code=sm_86 或者alias mynvcc='nvcc -lineinfo -arch=compute_86 -code=sm_86' 架构发展 Overview Tesla G80 SP（Streaming Processor）：scalar ALU for a single CUDA thread ALU执行是流水线化的，即一项操作会被分为X个步骤由X个组件去处理，每个步骤都耗费1周期。虽然一条指令要X周期才能执行完，但对于每个组件只要1周期就执行完了，所以每个周期都能送入一份数据进ALU。 SP的频率是调度单元（以及外部纹理单元等）的2倍，所以在调度单元看来，是需要2周期去消化1条指令。 SM（Streaming Mulitprocessor）：每个线程块分配到一个SM上 SM的频率是GPU频率的两倍 scoreboarding 作用：在指令发射阶段，检查待发射的指令是否与正在执行但尚未写回寄存器的指令之间存在数据相关。三种数据相关： 大致原理：scoreboard为每个warp寄存器分配一个bit来记录相应寄存器的写完成状态，\n如果后序指令不存在数据相关，则进入流水线 如果存在数据相关，通过检查标识位，后续指令就会stall而无法发射，此时可以切换其他warp的指令进行调度 参考\n# ILP——指令级并行2：记分牌（Scoreboard）技术 通用图形处理器设计3.5 Fermi 以GF100为例，架构： 特点 第三代流式多处理器（SM） 每个SM有32个CUDA核心，比GT200多4倍 双精度浮点峰值性能比GT200提高8倍 两个warp调度器，可以同时调度和分发指令给两个独立的warp 64KB RAM，可供共享内存和L1缓存配置化划分使用 第二代并行线程执行ISA（Instruction Set Architecture指令集架构） 统一地址空间，完全支持C++（比如虚函数、new/delete等） 针对OpenCL和DirectCompute进行了优化 完全支持IEEE 754-2008 32位和64位精度 具有64位扩展的完整32位整数路径 内存访问指令支持向64位寻址的过渡 通过预测提高性能 Predication enables short conditional code segments to execute efficiently with no branch instruction overhead 改进的内存子系统 具有可配置L1和统一L2高速缓存的NVIDIA Parallel DataCacheTM层次结构 之前Tesla架构没有L1、L2 cache 支持ECC内存的第一款GPU 大大提高原子内存操作性能 NVIDIA GigaThread引擎 应用程序上下文切换速度提高了10倍 并发内核执行 无序线程块执行 双向可重叠的内存传输引擎 SM SM架构：有4个执行端口 core 每个CUDA处理器都有完全流水线化的整数算术逻辑单元（ALU）和浮点单位（FPU） LD/ST单元 每个SM有16个Load/Store单元，允许16个线程每个时钟周期计算源和目的地址，支持将每个地址的数据读取和存储到缓存或DRAM中 SFU dual warp scheduler 每个SM有两个warp scheduler和两个instruction dispatch unit，每个周期可以同时issue和execute两个warp warp scheduler：选择warp Instruction Dispatch Unit：将指令发送到对应的端口（16个core、或16个LD/ST、或4个SFU中） 由于SP（或者core）的频率是调度单元的2倍，因此调度单元一个周期选择一个warp，一个周期内2倍频率的core连续两次在half-warp上执行 由于SFU只有4个，因此一个warp在SFU中计算需要消耗8个周期，但是此时它不阻塞调度 由于warp之间独立运行，因此warp scheduler不需要检查指令流中的依赖关系 大多数指令可以这样同时dual issue，两个整数指令、两个浮点指令或混合发出整数、浮点、加载、存储和 SFU 指令；但是双精度指令不支持dual dispatch with any other operation G80/GT200/Fermi对比 ISA Fermi是第一个支持PTX2.0的架构 PTX2.0统一了各种内存空间的寻址 GigaThread 两级thread scheduler thread scheduler：将线程块调度和分配到SM，GigaThread warp scheduler：将warp调度和分配到执行单元 特点： 应用程序上下文切换速度更快 concurrent(并发) kernel执行：（感觉下面的图画得有些confused？） 同一应用程序上下文的不同kernel可以并行在GPU上执行 不同应用程序上下文的kernel可以顺序执行 Kepler GK110/210是Kepler架构中高端型号，用于科学计算，因此主要以这两种型号为基础来介绍kepler架构。总体架构：15个SMX SMX 架构 SMX中的core的频率与主GPU频率相同，以增大面积为代价，降低功耗 warp scheduler 4个warp scheduler和8个instruction dispatch unit warp scheduler中调度的warp，对应的2个instruction dispatch unit可以在一个周期分配给该warp两个独立的指令 两个指令中允许双精度指令与其他指令dual dispatch kepler架构针对warp scheduler在降低功耗方面的优化：从硬件的动态调度转向编译器辅助的静态调度 Fermi用硬件scoreboard来记录寄存器的使用信息，从而确定指令之间的依赖关系 硬件scoreboard就是记录各个组件（寄存器、执行单元）当下的情况，并自动根据指令涉及的操作数、ALU去匹配。 到了Kepler架构，因为指令的执行周期是可以预计的，所以调度信息其实在编译期就能确定了。于是ISA就做了更改，每7条指令为一组，附加一段调度信息（Control Code），把因为数据依赖需要等待的cycle数记录进去。硬件上许多动态调度的模块被砍掉了，节省了功耗。 访存指令的延迟依旧是没法预计的，因为不知道有没有cache miss，所以遇到访存指令势必需要一个等待数据就绪的同步过程，可以借助软件scoreboard来完成。 软件scoreboard可以看作是预分配几个信条量，有依赖关系的指令会显式声明对哪几个信号量做操作，这样一来要记录维护的信息变少了，逻辑也简单了。同时软件scoreboard没有dependency check，一方面可以将这部分卸载到编译器，另一方面考虑到dependency不多 cache\nKepler的L1 Cache是用来为reg spill或者stack data服务的，即访存数据其实并不会缓存在L1里。 对于那些readonly的global memory，允许借用Tex Cache shuffle指令：warp可以读取来自warp内其他线程中任意排列的值，因此节省了共享内存\nDynamic Parallelism Hyper-Q 之前架构中只有一个CPU与GPU的工作分配器（CWD）之间的硬件工作队列，多个流复用一个队列，可能造成虚假的依赖性 现在有32个硬件工作队列 Grid Management Unit 为了支持动态并行，需要改变对grid的管理 NVIDIA GPUDirect 可以实现 GPU 与其他设备（例如网络接口卡 (NIC) 和存储设备）之间的直接通信和数据传输，但是中间数据不经过CPU Maxwell 以GM204为例，4个GPC，每个GPC有4个SMM 特点 更高效的SM（Maxwell SM，也称SMM）：core数量减少但是效率增加 指令调度提升 所有核心的SMM功能单元都分配给特定的调度器，没有共享单元。 每个分区中的core数量是32，warp scheduler方便调度 支持双发射（两个独立的指令，比如一个计算一个访存），也支持单发射（此时正好调度到一个warp） 现有代码的占用率增加：每个SM上active的block数量翻倍 减少算数指令延迟 更大的专用共享内存： 每个SMM有64KB的共享内存，4个processing block共享；但是每个线程块只能用48KB L1缓存专职服务于texture，L2缓存大小激增 快速的共享内存原子操作 支持动态并行：Kepler只在高端GPU中支持，Maxwell在低功率芯片中也支持 SMM Pascal 以GP100为例，6个GPC，每个GPC有5个TPC，每个TPC有2个Pascal SM（但是P100有56个SM） 架构 SMP 每个SM有64个core 每个SM中寄存器数量保持不变，因为SM数量更多，所以总的寄存器数量也变多 每个SM中共享内存从GM200的96KB下降到64KB，但是因为SM数量更多，因此共享内存总量更大 每个SM中有32个双精度FP64 CUDA core 支持FP16 有专用的共享内存（64KB/SM），L2 cache进一步增大 Unified Memory Compute preemption 计算抢占：允许在GPU上运行的计算任务在指令级别粒度上被中断 在Pascal架构之前： 仅仅在线程块粒度可以被中断 如果GPU上同时运行计算任务和显示任务，则长时间的计算可能会使得显示任务变得不响应和非交互 Pascal中 支持计算抢占，因此显示任务会保持流畅运行 同时，计算抢占允许在单个GPU上交互式调试kernel 硬件结构 内存从原来的GDDR5更换到HBM NVLink：可以GPU之间连接，也可以CPU和GPU之间连接 通过NVLink连接的GPU，程序可以直接访问另一个GPU的显存 Volta 以V100为例，有6个GPC，每个GPC有7个TPC，每个TPC有2个SM\nSM和Tensor Core core的变化：允许FP32和INT32操作同时执行\n原来SM是core（ALU+FPU）+DPU的结构，因此FP32与INT32无法同时运行 由于ALU都是流水线化、分阶段的，因此虽然ALU和FPU可以同时运行，但是可能处于不同阶段 现在SM是FP32+FP64+INT的结构，分离了ALU和FPU 因此FP32与INT32可以同时运行 而且FP32和INT32可以满吞吐运行 对于1个warp共32个线程，交给16个单元去执行的话，要像G80等架构提到的那样占用连续的两个周期来完成issue。不过在第二个周期，dispatch unit可以继续发射指令到其他单元，比如INT32。两者交错起来，就正好能达到满吞吐。 虽然增加了1周期的延迟，但是Volta大多数指令延迟都从6个周期降低到4个周期，总体还是快 意义：很多程序具有执行指针算术（整数内存地址计算）与浮点计算相结合的内部循环，流水线循环的每次迭代都可以更新地址（INT32指针算术）并为下一次迭代加载数据，同时在FP32中处理当前迭代。 Tensor Core\n每个tensor core在每个时钟周期内，可以执行64个浮点FMA操作（4*4*4的GEMM） 每个tensor core执行浮点FMA操作：D=A*B+C enhanced L1 data cache and shared memory\nInstruction Cache 原来SM中有一个Instruction Cache，每个processing block中有一个Instruction Buffer 现在SM中有一个L1 Instruction Cache，每个processing block中有一个L0 Instruction Cache 提高了L1 data cache的带宽，降低了其延迟 共享内存 将共享内存和L1 data cache整合起来，一共128KB，其中共享内存可以分配到96KB 纹理内存、全局内存都会经过L1 data cache 之前的GPU只有load caching，GV100中引入了write caching Independent Thread Scheduling 之前的SIMT模型\n一个warp使用一个共享的程序计数器，作用于32个线程，使用一个活动掩码，masked thread就是inactive的thread。各个分支依次执行，最后reconverge（同步） 由于divergence处理成顺序的执行，因此，来自不同区域或不同执行状态的 Warp 中的线程不能相互发送信号或交换数据，同时需要由锁或互斥锁保护的细粒度数据共享的算法很容易导致死锁 例子：比如0~3号线程在执行完A之后，需要使用到X的计算结果，此时无法实现 Volta的SIMT模型：引入独立线程调度，每个线程都有自己的程序计数器和调用堆栈 Volta的独立线程调度允许GPU放弃任何线程的执行，以便更好地利用执行资源或允许一个线程等待另一个线程生成数据，现在线程可以按照子warp粒度进行分支和重新汇聚，同时Volta中的收敛优化器仍会将执行相同代码的线程组合在一起、并行运行以达到最大效率。 可以使用CUDA 9的warp同步函数__syncwarp()来强制warp重新汇聚，因此假设了warp同步的代码不再安全 void __syncwarp(unsigned mask = 0xffffffff) 二进制位1表示对应的线程参与同步 虽然一个SM中拆分为了4个processing block，每个processing block16个FP32/INT32，而且每个线程都有自己的PC和stack，看起来half-warp在1个周期内可以直接调度和dispatch到一个processing block；但是每次调度仍然是一个warp（32个线程），消耗2个周期（1个周期调度到1个processing block，2个周期将完整的warp调度完毕）。 前面的方法会增加调度硬件的复杂性，而且这种运行时的动态信息会改变各个组件的可用情况，也可能会破坏编译器静态调度的预设状态。 例子1：可以实现warp内部细粒度的同步 例子2：分支间交错执行，可以掩盖stall 独立线程调度使得假设了warp同步的代码不再安全，比如此时在执行Z的时候，一个warp中的32个线程没有reconverge（同步），而是保持原来的branch执行 这是因为调度程序必须保守地假设Z可能会产生其他分叉执行分支所需的数据，如果是这种情况，自动强制重新汇聚将不安全。 此时需要使用__syncwarp()强制汇聚，可以提高SIMT效率 因此，从CUDA 9开始，原来的warp shuffle指令__shfl都变成了deprecated，推荐使用__shfl_sync，里面加入了mask参数 例子3：无饥饿算法，多线程环境下双向链表插入节点 Volta的独立线程调度确保即使线程T0当前持有节点A的锁，同一warp中的另一个线程T1也可以成功等待锁变得可用，而不会妨碍线程T0的进展。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 __device__ void insert_after(Node *a, Node *b) { Node *c; lock(a); lock(a-\u0026gt;next); c = a-\u0026gt;next; a-\u0026gt;next = b; b-\u0026gt;prev = a; b-\u0026gt;next = c; c-\u0026gt;prev = b; unlock(c); unlock(a); } 缺点：增加了寄存器负担，单个线程的程序计数器一般要占用两个寄存器 参考 https://www.zhihu.com/question/290660113 https://developer.nvidia.com/blog/inside-volta/ https://zhuanlan.zhihu.com/p/186192189 Multi-Process Service(MPS) MPS：实现多个计算应用程序共享GPU时的性能提升和隔离\n特点\n保证服务质量：限制每个应用程序只使用GPU资源的一部分，从而降低或消除排队阻塞 独立地址空间：不同应用程序进行地址隔离 发展\nVolta之前都是通过软件方法，使用时间片的方式Time-slice scheduling 从Kepler GK110 GPU开始，NVIDIA引入了基于软件的Multi-Process Service（MPS）和MPS Server，MPS Server允许将多个不同的CPU进程（应用程序上下文）组合成单个应用程序上下文并运行在GPU上，从而实现更高的GPU资源利用率。 对于Pascal，CUDA Multi-Process Service是一个CPU进程，它代表已经请求和其他GPU应用程序同时共享执行资源的GPU应用程序。该进程充当中介，将工作提交到GPU内部的工作队列中以进行并发内核执行。 Volta MPS： Server CUDA Context管理GPU硬件资源，多个MPS Clients会将它们的任务通过MPS Server传入GPU Volta MPS对MPS server的关键部分使用硬件加速，使得MPS客户端能够直接将工作提交到GPU内部的工作队列中，同时将MPS客户端的最大数量从Pascal上的16增加到Volta上的48 Volta MPS旨在将GPU共享在单个用户的应用程序之间，并不适用于多用户或多租户用例 如果其中一个运行出错，则可能导致运行的任务都失败，即Volta MPS不提供客户端之间的致命故障隔离。 应用：\nNo Batching的推理场景中，允许许多单独的单个推理任务同时提交到GPU，提升GPU利用率 支持linux下的统一内存， 在GPU执行时，之前的MPS client都是运行在一个单独的地址空间，与访问独立CPU进程内存不兼容 Hyper-Q与MPS\nHyper-Q：多流优化，同一个应用程序下多个stream中，没有依赖的操作可以并行执行 MPS：同时并行运行多个应用程序，多个应用程序共享同一个GPU context more reading and reference\nMULTI-PROCESS SERVICE # 教你如何继续压榨GPU的算力 https://asphelzhn.github.io/2019/04/14/tensor_09_MPS/ https://blog.csdn.net/cleanarea/article/details/112691820 Cooperative Groups(CG) 协作组是CUDA 9引入的新特性，允许自定义线程通信的粒度 # CUDA 编程模型之协作组（Cooperative Groups） # CUDA协作组详解\nTuring 以TU102为例，有6个GPC，每个GPC有6个TPC，每个TPC有2个SM SM 添加了独立的integer datapath，可以与浮点数指令同时运行 Uniform Register：将共享内存、texture cache、memory load cache（L1 data cache？）重新设计，统一到一起 第二代Tensor Core 添加了INT8和INT4精度模式，增强了推理性能 支持DLSS（Deep Learning Super Sampling） 实时光线追踪、渲染管线、RT Core、DLSS等图像相关 Ampere 以GA100为例，有8 GPCs, 8 TPCs/GPC, 2 SMs/TPC\nSM 第三代Tensor Core Tensor Core Sparsity利用2:4的细粒度结构化稀疏性，使得吞吐量翻倍 稀疏矩阵定义：2:4稀疏矩阵，即每个四元组中有两个非零值 过程：使用稠密权重进行训练，然后进行细粒度结构化剪枝，最后通过额外的训练步骤对剩余的非零权重进行微调。 具体而言，A100使用Sparse MMA(Matrix Multiply-Accumulate)指令，跳过对带零值的输入进行计算，从而使 Tensor Core 的计算吞吐量翻倍 支持所有数据类型：FP16、BF16、TF32、FP64、INT8、INT4 和 INT1，且比V100有进一步的加速效果 如果不使用Tensor Core，默认使用FP32；如果使用Tensor Core，则默认使用TF32 支持FP16/FP32、BF16/FP32混合精度，且两种混合精度速度一样快 TF32一方面保持了FP16的精度，另一方面保持了FP32的范围，因此很适合训练 memory方面的改进 Data sharing improvements： 数据可以在一个warp中32个线程共享，原来Volta只能在8个线程之间共享 因此节省了寄存器和带宽 同时，A100 Tensor Core将矩阵乘法指令的k维变为原来的4倍 表格中的数据怎么来的？Nvidia tensorCore 计算过程 Data Fetch improvement 新的异步拷贝指令可以直接将数据从全局内存（通常是DRAM和L2缓存）中加载到共享内存中，绕过L1缓存和寄存器 原来Volta中，数据先经过L1缓存读取到寄存器，然后再写到共享内存中 异步拷贝指令与异步barrier搭配使用：异步拷贝完成后，通过异步barrier通知程序拷贝完成 Compute Data Compression Combined L1 cache and shared memory L1 data cache和共享内存整合到一起，一共192KB FP32和INT32可以同时运行、且满吞吐运行（与Volta与Turing架构相同） L2 cache improvement\n设计改进 Residency Control：ping-pong buffer（或称double buffer） ping-pong buffer常驻于L2缓存上，减少对内存的写回，保持L2中数据重用 比如推理场景中，权重分段轮流装载到L2缓存上，让计算与权重装载并行。此时，多batch可以共用更多的权重 总结 Multi-Instance GPU(MIG) 背景：Volta MPS虽然支持多个应用程序同时运行，但是可能一个应用程序占用太多内存带宽或是L2缓存，对其他应用程序造成影响\nMIG MIG可以将每个A100 划分为最多7个GPU Instance，每个instance可以为client（虚拟机、容器、进程等）提供定义的服务质量和故障隔离 每个instance由若干个GPU slices组成，GPU slices的结构 Sys Pipe：GigaThread Engine的一部分 一个GPC（7个TPC，14个SM） 一个L2 slice group（包括10个L2 cache slices） 对一部分frame buffer memory的访问 每个instance内部可以再细分为compute instance compute instance可以自行配置和封装计算资源，默认每个instance创建一个compute instance，因此该compute instance使用该instance的全部资源 每个compute instance包括一个Sys Pipe和若干个GPC，所有共享一个compute instance的应用程序共享一个Sys Pipe，每个compute instance都可以单独进行上下文切换 每个compute instance都支持MPS，MPS client的最大数量与compute instance大小成正比 应用场景：\nMulti-Tenant Single Tenant, Single User：一个用户运行多个GPU应用程序 Single Tenant, Multi-User：比如对外部提供AI服务 CUDA Advances Task Graph Acceleration\n背景：对于深度学习等应用场景，有iterative structure（即same workflow is executed repeatedly） 以前只能在每个iteration中，CPU重新提交任务到GPU。尤其是很多小的kernel在整个运行过程中，launch、init等开销占了相当一部分时间。 现在定义一个task graph（若干个操作、相应依赖关系和一些内存操作），可以define-once/run-repeatedly，即先将多个kernel预先构建为一个task graph，然后CPU一次性launch，减少了launch、init的时间 kernel的执行流程可以分为三个步骤：launch，grid initialization，kernel execution 加速原理： launch optimization：submit multiple work items to the GPU in a single operation execution dependency optimization：可以优化复杂的graph（比如workflow fork and re-join，在一个fork分支中可以有多个dependency） 异步数据拷贝和异步barrier：memcpy_asnyc\n异步数据拷贝： memcpy_asnyc：从global memory到shared memory的异步数据拷贝 cudaMemcpyAsync：从CPU memory到GPU global memory的异步数据拷贝 异步barrier：arrival和wait是分开的 arrival：最快线程到达barrier wait：等待其他线程（或者最慢的线程）到达barrier 普通的barrier由于各线程快慢不一，中间有idle；异步barrier中间原来idle的部分现在进行其他independent work Controlling Data Movement to Boost Performance on the NVIDIA Ampere Architecture：两阶段的pipeline，将计算与拷贝重叠 L2 cache residency control\n两种数据： persisting data：数据重复使用，比如深度学习场景，或生产者-消费者场景 streaming data：数据只使用一次 L2 cache中专门留出一部分给persisting data使用，persistent access优先访问这部分，具体见Device Memory L2 Access Management 参考\n# NVIDIA GPU A100 Ampere(安培) 架构深度解析 # CUDA效率优化之：CUDA Graph # NV Ampere GPU架构学习与思考 Ada Lovelace cuda core数量增加 第四代Tensor Core Hopper FP8 Transformer Engine Hopper white paper\n参考 https://mp.weixin.qq.com/s/qakvAfNV4KkmNa3P56i-dQ 江南泣相关（翻译）博客和对应white paper NVIDIA GPU的一些解析（一）的相关解读 ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/gpu%E6%9E%B6%E6%9E%84%E5%8F%91%E5%B1%95%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%BC%96%E8%AF%91/","summary":"CUDA编译链和兼容性 兼容性 CPU与GPU的区别 CPU只有少量的计算核心，有更多晶体管用于数据缓存和流程控制， GPU有大量计算能力较弱的计算","title":"[cuda-learning-notes] GPU架构发展、兼容性和编译"},{"content":"1. 查看 1.1 移动光标 w/W, b/B移动到下一单词、上一单词的开头，e/E移动到下一单词的结尾，大写空格分割，小写非字母分割 $, ^行尾 行首，0行间第一个字符 Ctrl+f/b翻页，Ctrl+d/u翻半页，Ctrl+e/y上下滚动一行 数字+方向键移动多次（数字+cmd执行多次cmd） gg, G文件首尾 50%移动到文件50%的位置，:50移动到第50行，.表示当前行号，$表示最后一行的行号 /pattern正则匹配查找，n/N上下跳转 光标移动到括号上时，使用%进行括号配对 1.2 文件编码 :set fileencoding查看当前文件编码 :e ++enc=utf-8使用utf-8重新打开文件 1.3 显示 :set nu, :set nonu显示/不显示行号，在~/.vimrc中设置set nu持久化设置 Ctrl+G显示当前状态 1.4 分屏 打开 vim -O file1 file2 打开多个文本（-O垂直分屏，-o水平分屏） :vs file在当前vim中打开file的垂直分屏，:sp file在当前vim中打开file的水平分屏 Ctrl+w v/s复制当前屏为相同垂直分屏或水平分屏 :new newfile在vim中创建新文本并创建分屏 切换 Ctrl+w+w切换下一个 Ctrl+w+h/j/k/l，hl左右，jk上下 改变位置 Ctrl+w Shift+h/j/k/l，当前屏左上下右移动 改变大小 Ctrl+w Shift+|水平加宽，Ctrl+w Shift+_垂直加宽，Ctrl+w =重置大小 Ctrl+w n +增加高度n，Ctrl+w n -减少高度n，Ctrl+w n Shift+\u0026lt;界线左移n，Ctrl+w n Shift+\u0026gt;界线右移n 关闭 Ctrl+w c关闭当前分屏 Ctrl+w o只保留当前分屏 2. 编辑 2.1 进入编辑模式 i光标处插入，a光标右边插入，o,O下面、上面另起一行，I,A行首尾插入 2.2 简单编辑 2.2.1 选中：v v, V, Ctrl+v字符、行、块选中 可以结合w/W, b/B, e/E 结合text object 2.2.2 text object 包括范围和文本对象，可以结合各种操作使用 范围：i：inner,a：around 文本对象：w：word，s：sentence，各种括号引号 2.2.3 删除和剪切：d 删除将内容复制到匿名寄存器中（即剪切），可以使用黑洞寄存器\u0026quot;_避免剪切内容\n不剪切的删除（将删除内容复制到黑洞寄存器中，相当于不保存）：\u0026quot;_cmd，其中cmd是删除相关的命令，eg：\u0026quot;_x\n使用键盘映射实现更简便的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;在~/.vimrc中,将删除映射为不剪切的删除，剪切映射为删除命令前加前缀\u0026#34; let mapleader = \u0026#34;,\u0026#34; nnoremap x \u0026#34;_x nnoremap X \u0026#34;_X nnoremap d \u0026#34;_d nnoremap dd \u0026#34;_dd nnoremap D \u0026#34;_D vnoremap d \u0026#34;_d vnoremap dd \u0026#34;_dd \u0026#34;\u0026lt;leader\u0026gt;是前缀，通过mapleader设定\u0026#34; nnoremap \u0026lt;leader\u0026gt;x \u0026#34;\u0026#34;x nnoremap \u0026lt;leader\u0026gt;X \u0026#34;\u0026#34;X nnoremap \u0026lt;leader\u0026gt;d \u0026#34;\u0026#34;d nnoremap \u0026lt;leader\u0026gt;dd \u0026#34;\u0026#34;dd nnoremap \u0026lt;leader\u0026gt;D \u0026#34;\u0026#34;D vnoremap \u0026lt;leader\u0026gt;d \u0026#34;\u0026#34;d vnoremap \u0026lt;leader\u0026gt;dd \u0026#34;\u0026#34;dd 在~/.vimrc中输入:source ~/.vimrc使设定生效\n在vim中输入:map查看当前的键盘映射\nD, d$删除光标至行尾，dd删除当前行\nx删除当前字符，daw删除单词及后面的空格，diw删除单词，结合text object\n:m,nd删除m-n行\ns删除字符并插入，S清空行并插入\n先选中，然后x删除选中部分，D删除选中行\n2.2.4 复制：y yy复制当前行，:m,ny复制m-n行到剪贴板 结合text object 2.2.5 粘贴：p p，P粘贴到光标处/后 m,ncok复制m-n行到k行下一行 m,nmk移动m-n行到k行下一行 2.2.6 搜索 /pattern匹配，n, N下一个上一个匹配对象 *, #匹配下一个，上一个相同的单词 2.2.7 替换：c 结合text object r单字符替换，R字符串替换 [range]s/pattern/replace/[flags] [range]：%(全文)，.，m,n，m [flags]：g全局替换，c替换前询问，不写默认替换首个 2.2.8 撤销重做 u撤销 Ctrl+r重做 2.2.9 批量注释 方法一： 注释：Ctrl+v选择，Shift+i进入编辑模式，输入插入的字符比如#，再两次Esc 取消注释：Ctrl+v选择，x或d删除（就是选择然后删除） 方法二：正则替换 注释：:m,ns/^/#/g 取消注释：:m,ns/^#//g（替换成空白） 2.2.10 其他 J将当前行下面的行合并到当前行 3. 其他 3.1 优质Blog 完全用Vim工作 ","permalink":"https://qinganzhang.github.io/posts/%E5%B8%B8%E7%94%A8vim%E6%93%8D%E4%BD%9C/","summary":"1. 查看 1.1 移动光标 w/W, b/B移动到下一单词、上一单词的开头，e/E移动到下一单词的结尾，大写空格分割，小写非字母分割 $, ^行尾 行首，0行间第一个字","title":"常用vim操作"},{"content":"Git配置相关 （全局）配置：如果是局部配置，每个仓库都需要进行配置\n1 2 3 4 5 6 7 8 # 设置全局配置 # git config --global user.name \u0026#34;zhangqingan\u0026#34; # git config --global user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --global https.proxy http://127.0.0.1:7890 # git config --global https.proxy http://127.0.0.1:7890 # 清除全局配置 # git config --global unset user.name # git config --global unset user.email 如果是针对仓库的局部配置\n1 2 3 git config --local user.name \u0026#34;zhangqingan\u0026#34; git config --local user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --local --list 生成密钥对\n1 2 3 4 ssh-keygen -t rsa -C \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # 并且后续生成密钥的位置自定义，注意win上这里是一个目录，linux上是文件名 ssh-keygen -l -f key # 查看密钥的contents（SHA256+comments） 添加私钥\n1 2 3 4 # ssh-agent bash ssh-add private_key # 将私钥添加到本地 ssh-add -l # 查看当前添加的私钥 ssh agent详解\n修改配置文件：修改~/.ssh/config\n1 2 3 4 5 Host github(bupt) User QinganZhang HostName ssh.github.com IdentityFile /home/zqg/.ssh/github/bupt Port 443 # or 22 reference and more reading\nGit多用户配置 如何为Git设置代理 相关概念 顶层概念：\nWorkspace：工作区，本地的工作目录 Repository：包含.git目录的工作区，其中.git为版本库，其中保存了stage暂存区、第一个分支main、指向main的指针HEAD Index/Stage：暂存区 Remote：远程仓库 底层概念：from missing semester中的Git\n文件称为Blob对象（数据对象），目录称为tree，每个commit即为一个对文件和目录的快照的指针（保存了当前的整个仓库，或者说追踪最顶层的树）\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 文件就是一组数据 type blob = array\u0026lt;byte\u0026gt; // 一个包含文件和目录的目录 type tree = map\u0026lt;string, tree | blob\u0026gt; // 每个提交都包含一个父辈，元数据和顶层树 type commit = struct { parent: array\u0026lt;commit\u0026gt; // 一个commit可能有多个parent author: string message: string snapshot: tree // 追踪最顶层的树 } 对象可以是文件、目录或者commit，对象通过SHA-1哈希进行按名存取（文件和目录好说，但是commit就不好访问了，因此统一使用SHA-1哈希）\n1 2 type object = blog | tree | commit objects = map\u0026lt;string, object\u0026gt; 为了方便好记，使用引用来指向最近一次的commit，而不是来记一串哈希值。因此，分支就是可变的引用，而标签就是绑定到特定commit的引用，HEAD指向当前的commit\n1 references = map\u0026lt;string, string\u0026gt; 因此，Repository保存的就是对象和引用。\n前面说commit是一个对文件和目录的快照，是通过向暂存区进行若干次操作，确认保存操作的结果，即形成一个快照\n其他概念：\ntrack/untrack：文件或目录是否纳入到git的版本控制范围内 基础操作 常用操作 git init -b main：创建.git文件夹，将当前目录变成一个仓库，默认分支为main\ngit add：将文件添加到暂存区（stage），相当于创建了快照，否则文件就是untracked的\ngit diff：比较当前工作区和暂存区快照之间的差异，即修改之后还没有暂存起来的变化内容 git commit -m \u0026quot;comment\u0026quot;：将暂存区的修改提交到分支（多次add之后进行一次commit），commit就是一个快照\ngit diff --staged：比较暂存区快照和最近一次commit之间的差异 git commit -a -m \u0026quot;comment\u0026quot; ：将所有跟踪过的文件暂存起来一起提交，跳过了git add步骤 git status：查看当前文件夹中文件的状态\ngit rm --cached \u0026lt;file\u0026gt;：取消对file的跟踪\ngit diff：\ngit diff命令，官方文档 git diff输出结果解读 git diff输出中 \\ No newline at end of file的含义 git log：查看commit历史，最近的排在最上面\n-p (--path)：显示每次提交所引入的差异（按补丁的格式输出） 补丁：即两次文件的差异 --stat：显示每次提交的简略统计信息 --ptetty：设置输出模式，可以自定义输出格式 --decorate：查看各个分支当前所指向的对象 --graph： -n：限制输出长度 --since, --until --grep：搜索提交说明中的关键字 -S：pickaxe选项，接受一个字符串，搜索那些添加或删除了该字符串的提交 -- path：输出某些文件或目录的历史提交，注意这个参数是放在最后的（因此用两个短线隔开） 版本控制 版本回退\ngit reset --hard HEAD^：返回到最近一次commit HEAD指向最近一次的commit，HEAD^和HEAD^^分别表示上一个commit和上上个commit git reset --hard commitId：返回到特定的commit git log --pretty=oneline ：显示所有提交过的commit，不包括已经回退的commit记录 怎么才能看懂git log的线 git reflog：显示所有提交过的commit，包括回退的操作，比如回退之后又反悔了，需要使用reflog来找到新版本对应的commit id 撤销修改\n如果只是在本地工作区修改了，还没有git add：git restore \u0026lt;file\u0026gt;或者git checkout -- \u0026lt;file\u0026gt; 如果在本地工作区修改之后，已经git add：git restore --staged \u0026lt;file\u0026gt;或者git reset HEAD \u0026lt;file\u0026gt; 如果已经git commit，则进行版本回退 重新提交：如果上一次commit完成后，发现漏了些文件，此时先git add，然后使用git commit --ament，这样只会有一次提交，后一次的提交会覆盖前一次的提交\n远程库 对远程库的操作实际上都是对远程库中远程分支的操作，默认远程库为origin，远程分支为 与当前本地仓库分支 同名的远程分支\n远程库的几种使用场景：\n克隆别人的仓库：git clone默认只有main分支，使用git checkout -b dev origin/dev在本地创建dev分支，并且与远程的dev分支关联起来\n自己在GitHub上新建一个仓库，然后clone下来进行开发\n自己在本地目录下，先git init创建本地仓库，然后将本地仓库与远程仓库关联起来：git remote add \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt;\n\u0026lt;url\u0026gt;支持多种协议，\u0026lt;shortname\u0026gt;即代表了该url\n一般远程库的名字就叫origin\n可以关联多个远程库，比如本地仓库关联一个共有的和一个私有的仓库\n查看远程库信息：git remote -v\n远程库可能有多个 获取远程库的更新：\ngit fetch \u0026lt;remote\u0026gt;：只会将远程库的更新下载到本地仓库，不会自动进行合并 git pull：如果当前分支设置了跟踪远程分支，则git pull会拉取更新，并自动进行合并。如果有冲突，需要手动解决冲突。 详解git pull和git fetch的区别 将本地库的内容推送到远程库：git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt;\n默认remote是origin，默认将本地分支推送到远程的同名分支上 git push -u origin main：第一次push时，远程库是空的，此时不但会将本地库的内容推送到远程库，而且将本地的main分支和远程库的main分支关联起来 如果他人先于你push到远程，你的push会被拒绝，此时需要拉取更新，手动修改冲突的部分，合并之后才能再push 查看某个远程仓库：git remote show \u0026lt;remote\u0026gt;\n远程仓库重命名：git remote rename old-name new-name\n解除本地和远程库之间的关联关系：git remote rm origin\n分支管理 分支是指向commit的可变指针，默认名字为main，main分支在每次提交时都自动向前移动\nHEAD是一个指向当前所在的本地分支的指针（可以想象为当前分支的别名）\n基本操作 注意这些操作都是在本地仓库的\n创建分支：git branch dev\n--merged：查看哪些分支已经合并到当前分支 --no-merged：查看所有包含未合并工作的分支（即没有汇聚到当前分支的那些分支） 重命名当前分支：git branch -M newname\n切换分支：git checkout dev\n创建并切换分支：git checkout -b dev或者git switch -c dev\n合并指定分支到当前分支：git merge dev\n如果当前分支main和待合并分支dev存在冲突，此时进行了合并，但是没有创建一个新的commit，需要先解决冲突，再手动进行commit，解决冲突就是手动将git merge失败的文件手动进行编辑，可以使用git status查看unmerged的文件，然后使用git merge --continue继续合并过程。 Git官方文档-3.2分支的新建与合并 Git冲突详细处理步骤及案例 如何避免Git冲突 git解决冲突（超详细图文版及常用命令） 因此使用分支时应该在main分支中生成多个dev分支，最后选择合适的dev分支进行合并，而非直接在main分支上进行修改 默认合并分支时使用Fast forward模式，此时删除分支之后，会丢掉分支信息。如果禁用fast forward模式（--no-ff），git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息 fast forward模式的含义：比如dev是master的直接后继，即master之后没有分叉，此时将dev merge到master上时，直接移动master的指针即可 查看分支：git branch\n-vv：列出每一个分支正在跟踪的远程分支，以及ahead和behind信息 如果需要查看最新的信息，则需要更新远程的信息，git fetch --all; git branch -vv 删除分支：git branch -d dev\n如果当前分支还没有被合并，而且需要删除当前分支，需要使用git branch -D dev强行删除 远程分支 远程跟踪分支是远程分支状态的引用，相当于书签。比如远程仓库命名为origin，拉取该仓库的main分支，因此本地就将对应的commit叫做origin/main，在本地仓库同样有一个main分支，比如本地进行多个commit会ahead of origin/main。Git官方文档-3.5远程分支\n比如当拉取本地没有的、位于远程的新的分支b时，本地只会有一个不可修改的origin/b指针，本地不会自动生成一份可编辑的副本。因此，需要使用git merge origin/b将远程分支b合并到本地当前分支，或者git checkout -b b origin/b将远程分支拉取到本地的新分支b上（如果本地仓库没有分支b，而且远程分支只有一个叫做b的分支，则一个快捷方式为：git checkout b） 修改或设置跟踪的上游分支 ：git branch -u origin/b 删除远程分支：git push origin --delete b 这个操作只是从服务器上移除这个指针，实际物理删除需要等到过一段时间git服务器进行垃圾回收时，因此误删通常是容易恢复的 最佳实践-修复Bug 背景：比如main分支上有一个bug，但是当前在dev分支上，而且针对dev的工作还没有完成（即当前不能commit到dev分支，从而清空status） 大致流程为： 使用git stash将当前工作区保存起来，此时工作区恢复到最近一次commit时的状态 然后修复bug：先切换到main分支，创建修复bug的分支，修复bug，然后再合并到main分支，同时也需要将修复bug这个commit合并到其他dev分支，切换到dev分支，然后git cherry-pick git cherry-pick commit_id：复制一个特定的commit到当前分支（相当于在dev分支上将修复bug的操作重新进行commit，因此生成的commit id和在main分支上的commit id不同） 修复完bug再恢复当前工作区 查看暂存的工作区：git stash list 恢复暂存的工作区： git stash apply：恢复之前保存的工作区，但是保存的工作区内容还在stash中，需要使用git stash drop进行删除。可以恢复指定的工作区：git stash apply stash{0} git stash pop：恢复工作区的公式，也将保存在stash中的内容删除 Rebase 用来将一组commit按照顺序（即某一分支上的commit）合并到一个特定的commit后面（即另一个分支的最后）\n万能公式：git rebase --onto \u0026lt;base\u0026gt; \u0026lt;start\u0026gt; \u0026lt;end\u0026gt; 变基原则：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，则不要进行变基 参考 Git官方文档-3.6变基 万能公式来源：强烈推荐：git rebase有哪些用法？elpie-kay的回答 标签管理 标签就是指向commit的指针，但是分支可以移动，标签不能移动\n在关键commit节点，使用commit id不方便，因此标签绑定到该commit id\n打标签：git tag v1.0\n在某个特定的commit上打tag，并添加说明：git tag -a v1.0 -m \u0026quot;comments\u0026quot; commitId 这里说的标签指的是轻量标签（某个特定提交的引用），附注标签指的是上面添加的说明 查看所有标签：git tag\n标签不是按照时间顺序列出，而是按照字母排列列出 查看标签信息：git show v1.0 删除标签：git tag -d v0.9可以删除本地标签\n删除远程标签时，先从本地删除，然后使用从远程删除。从远程删除： 第一种方法：git push origin :refs/tags/v0.9（即将冒号前面的空值推送到远程） 第二种方法：git push origin --delete v0.9 推送标签到远程：git push origin v1.0\n默认情况下git push不会将标签推送到远程仓库上 一次性推送所有标签到远程：git push origin --tags 检出标签：git checkout \u0026lt;tag\u0026gt;，即将HEAD移动到指向某个标签，此时仓库处于detached HEAD状态\n自定义Git 忽略特殊文件.gitignore 一些.gitignore模板\n虽然某个文件可以匹配到gitignore的规则，但是需要强制添加：git add -f myfile\n或者某个文件应该可以添加但仍然被忽略了，说明gitignore规则有问题，找出对应的规则条目：git check-ignore -v myfile\n在线生成gitignore文件：Gitignore Online Generator\n配置别名 几个例子：\ngit config --global alias.st status\ngit config --global alias.unstage 'restore --stage'：将add到暂存区的修改撤销掉\ngit config --global alias.last 'log -1'：显示最后一次提交信息\ngit config --global alias.lg \u0026quot;log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset' --abbrev-commit\u0026quot;：自定义git log显示\n删除别名时，只需要在仓库的配置文件.git/config或是用户的配置文件.gitconfig的[alias]段落中，删除掉特定的行即可\n工作流 向一个项目贡献 提交准则 提交不应包含trailing whitespace。git apply应用补丁时会检测空白错误,默认情况下,尾部空白,包含空白的空行,初始tab缩进之后紧跟的空白字符会被认为是错误。参考\n在git apply patch时，应该先git diff --check，将会找到可能的whitespace errors并列出来 By default, trailing whitespaces (including lines that consist solely of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors.\n—— from git-diff\n让每个commit解决一个问题，不要多个问题混在一个commit中\n重视写commit message\n一个好的commit message模板 私有开发项目 Git文档中一个私有开发项目的例子\n私有管理团队 多个开发者在feature分支上工作，只有整合者才能将feature分支merge到master分支\nGit文档中一个私有管理团队的例子\n派生的公开项目 先fork公开项目，然后自己进行修改，最后通过Pull Request请求合并\nGit文档中一个派生的公开项目的例子\n通过邮件的公开项目 使用git format-patch生成mbox文件，它将每一个提交转换为一封电子邮件，其中保留了所有的提交信息。最后通过git send-email发送补丁。\n维护项目 在主题分支中工作 应用来自邮件的补丁 使用git apply应用补丁 补丁是通过git diff生成的，可以对补丁进行检查git apply --check git apply要么全部应用补丁，要么全部不应用，不会部分应用补丁 git apply之后，需要手动暂存并提交 使用git am应用补丁（推荐） 补丁是通过git format-patch生成的，此时补丁中包含了作者信息和commit message，因此更加推荐 git am是为了读取mbox文件而构建的，mbox是一种用来在单个文本文件中存储一个或多个电子邮件消息的简单纯文本格式 git am会自动创建一个新的提交，作者信息和提交消息来自于mbox文件，并自动应用mbox指向的补丁 如果发生冲突，则同样需要手动进行修改，然后暂存，再git am --resolved继续应用下一个补丁 git生成patch和打patch 检出远程分支 背景：别人fork了自己的仓库，并且在某个分支上进行了修改，想提交贡献，此时我得到了它的仓库的URL和对应的分支 如果想与他人建立长期的合作交流：将其仓库添加为远程仓库，fetch到本地并在本地checkout到该分支，进行测试 如果别人只是偶尔提供一个贡献 直接pull到本地（不会将该URL添加为远程仓库），然后切换分支并进行测试 或者使用电子邮件来接受patch（或者使用托管服务） 确定引入了哪些东西 检查main分支未包含的commit，比如检查某个分支contrib上引入的修改：git log contrib --not main\n如果想具体查看contrib分支上相对于原来main，到底有什么区别（即diff），使用git diff main...contrib，即对contrib分支的最新提交和两个分支的最近共同祖先进行比较（注意三个点）\n因为在进行contrib分支上的工作时，main分支可能同时继续向前，diff比较时的main分支应该为原来的位置，即为contrib和现在main分支的最近共同祖先 将贡献的工作整合进来 合并工作流：将主题分支合并到main分支，然后删除主题分支\n如果项目很重要，可以使用两阶段循环合并，即维护两个长期分支（main和develop分支），新代码首先合并到develop分支，打标签发布时才将main分支更新到稳定的develop分支 为了保持线性的提交历史，可以在 main分支上对贡献来的工作进行变基而不是直接合并。另一种类似效果的方式是，提取分支的补丁，然后应用到当前分支上\nRerere：重用已记录的冲突解决方案，是一种简化冲突解决的方法。当启用 rerere 时，Git 将会维护一些成功合并之前和之后的镜像，当 Git 发现之前已经修复过类似的冲突时， 便会使用之前的修复方案，而不需要你的干预。\n发布 为发布打标签 生成一个构建号 创建一个归档文件 制作提交简报 基于Github的工作流 常见问题 ssh -T git@github.com 连接超时 示例：\nssh -T git@github.com的含义：\n解决方法：\n如果使用ssh协议：修改HostName或者修改Port\n在.ssh文件夹下的config文件中修改：参考\n1 2 3 4 Host github.com HostName ssh.github.com User xxx IdentityFile xxx 如果使用https协议：参考\n","permalink":"https://qinganzhang.github.io/posts/git%E7%AC%94%E8%AE%B0/","summary":"Git配置相关 （全局）配置：如果是局部配置，每个仓库都需要进行配置 1 2 3 4 5 6 7 8 # 设置全局配置 # git config --global user.name \u0026#34;zhangqingan\u0026#34; # git config --global user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --global https.proxy http://127.0.0.1:7890 # git config --global","title":"Git笔记"},{"content":"[toc]\ntags：【双指针】，【前缀和】，【原地哈希】\n【好题】，【不会】，【重要】，【继续看】\n方法 双指针 前后定长双指针 前后快慢双指针 左右双向双指针 611.有效三角形的个数 方法一：二重循环a、b，对c进行二分查找（查找最后一个满足a+b\u0026lt;c的c） 方法二：遍历c，左右双指针表示a(nums[i])和b(nums[j])，参考 if(nums[i] + nums[j] \u0026gt; c) ，此时有j-i个三角形，j向左走（i向右走无用） if(nums[i] + nums[j] \u0026lt;= c) ，此时有0个三角形，i向右走（j向左走无用） 11.盛最多水的容器：盛水体积只取决于左右两隔板的高度（木桶理论） 区别于接雨水，雨水可能分布在不连续的凹陷处 两分支双指针 165.比较版本号 滑动窗口 904. 水果成篮\n基于双指针的滑动窗口 必须使用滑动窗口保证水果是连续的，如果只使用哈希表，则可能出现中间有中断的情况 76. 最小覆盖子串：代码\n对t统计词频，得到相同的两个ump：tump和tmp_ump 只移动右指针，找到s中第一个包含t的区间 移动右指针的过程中，逐步递减并erasetmp_ump中的元素，直到tmp_ump为空，此时就找到了s中第一个包含t的区间，同时维护区间的词频win_ump 窗口进行移动：将c=s[left++]从win_ump中减一，同时左指针向右移动了一位， 如果此时win_ump[c] \u0026gt;= tump[c]，说明c不在t中，或者c是t中是多余重复的，因此continue 如果此时win_ump[c] \u0026lt; tump[c]，说明c是t中的，需要右指针向右移动，再次找到c字符，因此得到了新的窗口 技巧：可以s+=' '，避免最后跳出循环还要移动左指针， 3.无重复字符的最长子串 【重要】\n同最长无重复子数组，都是用左右双指针作为滑动窗口，同时数组做哈希用于判断是否用过该元素 1004.最大连续1的个数Ⅲ\n两种思路 复杂的代码：维护窗口内0的数量，但同时也分情况讨论左右断点的情况 简洁的代码：找出一个最长的子数组，该子数组中最多有k个0，因此只需要维护窗口内0的数量即可 数组【二刷】 模拟题 498.对角线遍历：i+j==level\n48.旋转图像\n最重要的是找到原来(i,j)位置的元素，旋转之后在什么位置（(j,n-i-1)） 矩阵变换的方法也是从上面的对应关系来的 先转置(j,i)，再水平翻转(j,n-i-1) 或者先垂直翻转(n-i-1,j)，再转置(j,n-i-1) 54.螺旋矩阵 和 59. 螺旋矩阵 II\n按圈遍历，设定四个逐步减小的边界 每圈遍历中，判断新到达的位置是否超出边界，若是则改变方向 (二分)查找 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 假设v非递减 int find_first_ge(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回第一个\u0026gt;=target的元素的索引（lower_bound） int left = 0, right = v.size(), mid = -1; while(left \u0026lt; right){ mid = left + (right - left) / 2; if(v[mid] \u0026gt; target) right = mid; // target is in left part else if(v[mid] \u0026lt; target) left = mid + 1; // target is in right part else right = mid; // v[mid] == target, } return left; // now left == right } int find_first_gt(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回第一个\u0026gt;target的元素的索引（upper_bound） int left = 0, right = v.size(), mid = -1; while(left \u0026lt; right){ mid = left + (right - left) / 2; if(v[mid] \u0026gt; target) right = mid; else if(v[mid] \u0026lt; target) left = mid + 1; else left = mid + 1; // difference } return left; } int find_last_le(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回最后一个\u0026lt;=target的元素的索引 return find_first_gt(v, target) - 1; // 即第一个\u0026gt;target的元素的前一个位置 } int find_last_lt(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回最后一个\u0026lt;target的元素的索引 return find_first_ge(v, target) - 1; // 即第一个\u0026gt;=target的元素的前一个位置 } 240.搜索二维矩阵Ⅱ 方法一：从右上开始，按照搜索二叉树的逻辑查找 方法二：每行进行一次二分查找 162.寻找峰值 【继续看】 方法一：分治，类似归并排序，递归找最大值 方法二：类似二分查找，判断nums[mid]与nums[mid+1]的大小关系（即判断中点是上坡还是下坡），从而修改左右索引 原理是因为开始时left和right都是最小值，此后mid部分永远是高点 细节：在函数体中，left与right不相等，因此mid永远不会等于right，同时left与right是左闭右闭，代码 搜索旋转排序数组系列：是否有重复数字，如果有重复数组，首先移动左右端点，保证left和right指向的元素不同。多使用原语表示（比如find_first_gt、find_first_ge） 33.搜索旋转排序数组：首先二分找到分界点，然后在左边或者右边再次进行二分（此时范围是有序的） 81.搜索旋转排序数组Ⅱ：尝试将问题转换到33.搜索旋转排序数组，我的题解 154.寻找旋转排序数组中的最小值Ⅱ BM21旋转数组的最小数字 排序 快排：在partition时，如果选left作为pivot，则需要先移动右边的指针，原理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void qSort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int left, int right){ // [left, right] if(left \u0026gt;= right) return ; if(left+1 == right){ if(nums[left] \u0026lt;= nums[right]) return ; else {swap(nums[left], nums[right]); return ;} } // 左中右，取中间大小的值，放在最左边 int begin = left, end = right, mid = (left + right) / 2; int pivot = max(min(nums[left], nums[right]), nums[mid]); if(nums[right] == pivot) swap(nums[left], nums[right]); else if(nums[mid] == pivot) swap(nums[left], nums[mid]); // 注意元素是覆盖的 while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; nums[right] \u0026gt;= pivot) --right; nums[left] = nums[right]; while(left \u0026lt; right \u0026amp;\u0026amp; nums[left] \u0026lt;= pivot) ++left; nums[right] = nums[left]; } // now: left == right nums[left] = pivot; // 缩小中轴范围，尤其针对重复元素多的数组 while(left \u0026gt; begin \u0026amp;\u0026amp; nums[left] == nums[left-1]) --left; while(right \u0026lt; end \u0026amp;\u0026amp; nums[right] == nums[right+1]) ++right; qSort(nums, begin, left-1); qSort(nums, right+1, end); } 归并排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 归并排序需要辅助数组，因为前后两个有序数组是连着的， void mergeSort(vector\u0026lt;int\u0026gt;\u0026amp; out, int begin, int end, vector\u0026lt;int\u0026gt;\u0026amp; in){ // [begin, end) if(begin \u0026gt;= end || begin+1 == end) return ; int mid = (begin + end) / 2; mergeSort(out, begin, mid, in); // [begin, mid) mergeSort(out, mid, end, in); // [mid, end) // now left part and right part are all sorted, merge them into out int i = begin, j = mid, k = begin; while(i \u0026lt; mid \u0026amp;\u0026amp; j \u0026lt; end){ if(in[i] \u0026lt;= in[j]) out[k++] = in[i++]; // stable else out[k++] = in[j++]; } while(i \u0026lt; mid) out[k++] = in[i++]; while(j \u0026lt; end) out[k++] = in[j++]; // copy out back to in for(int s = begin; s \u0026lt; end; ++s) in[s] = out[s]; } BM20 数组中的逆序对： 归并方式，前后两段数据都是有序数组，比如前面一段数组中nums[a]大于后面一段数组中nums[b]，则前面数组中[a:mid)这一段元素都大于nums[b]，这些都是逆序对，只需在归并时统计这样的长度即可。代码 堆排序\n第一种方法：数组原地构建最大堆，数组原地进行排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void heapSort(vector\u0026lt;int\u0026gt;\u0026amp; nums){ buildMaxHeap(nums); int len = nums.size(); for(int i = len-1; i \u0026gt;0; --i){ swap(nums[0], nums[i]); // 将最大堆的首元素（最大元素）放在数组后面位置 adjust(nums, 0, --len); // 首元素变了，因此需要调整，同时堆的长度减一 } } void buildMaxHeap(vector\u0026lt;int\u0026gt;\u0026amp; nums){ int n = nums.size(); for(int i = n/2-1; i \u0026gt;= 0; --i){ // n/2-1是最后一个非叶节点，依次向上检测和调整每个非叶节点 adjust(nums, i, n); } } void adjust(vector\u0026lt;int\u0026gt;\u0026amp; nums, int idx, int len) { // 当前节点的索引为idx，在[0, len)范围内是最大堆 while(idx * 2 + 1 \u0026lt; len){ int leftSon = idx * 2 + 1; int rightSon = idx * 2 + 2; int largeIdx = idx; // largeIdx指向{根节点，左孩子，右孩子}中较大的值 if(leftSon \u0026lt; len \u0026amp;\u0026amp; nums[leftSon] \u0026gt; nums[idx]) largeIdx = leftSon; if(rightSon \u0026lt; len \u0026amp;\u0026amp; nums[rightSon] \u0026gt; nums[largeIdx]) largeIdx = rightSon; if(largeIdx != idx){ swap(nums[idx], nums[largeIdx]); idx = largeIdx; }else break; } } 第二种方法：数组构建最小堆，依次弹出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 手写堆 class minHeap{ private: vector\u0026lt;int\u0026gt; heap; int len = -1; public: minHeap(vector\u0026lt;int\u0026gt;\u0026amp; nums): heap(nums) { len = heap.size(); // build minHeap for(int i = n/2-1; i \u0026gt;= 0; --i) adjust(i); } void adjust(int idx){ while(idx * 2 + 1 \u0026lt; len){ int leftSon = idx * 2 + 1; int rightSon = idx * 2 + 2; int largeIdx = idx; // largeIdx指向{根节点，左孩子，右孩子}中较大的值 if(leftSon \u0026lt; len \u0026amp;\u0026amp; heap[leftSon] \u0026gt; heap[idx]) largeIdx = leftSon; if(rightSon \u0026lt; len \u0026amp;\u0026amp; heap[rightSon] \u0026gt; heap[largeIdx]) largeIdx = rightSon; if(largeIdx != idx){ swap(heap[idx], heap[largeIdx]); idx = largeIdx; }else break; } } int top() { return heap[0];} // return min value void pop() { swap(heap[0], heap[--len]); adjust(0); } }; // 或者调用优先队列 vector\u0026lt;int\u0026gt; heapSort(vector\u0026lt;int\u0026gt;\u0026amp; nums){ priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; for(int n: nums) pq.push(n); vector\u0026lt;int\u0026gt; ans; while(!pq.empty()) {ans.push_back(pq.top()); pq.pop();} return ans; } 179.最大数\n巧妙的自定义排序规则：a+b\u0026lt;b+a 215.数组中的第k个最大元素 【重要】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 int findKthLargest(vector\u0026lt;int\u0026gt;\u0026amp; nums, int begin, int end, int k){ // [begin, end), 快排逻辑 if(begin+1 == end) return nums[begin]; if(begin+2 == end){ if(k == begin) return max(nums[begin], nums[begin+1]); if(k == begin+1) return min(nums[begin], nums[begin+1]); } int left = begin, right = end-1; // [left, right] int pivot = nums[left]; while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; nums[right] \u0026lt;= pivot) --right; nums[left] = nums[right]; while(left \u0026lt; right \u0026amp;\u0026amp; nums[left] \u0026gt;= pivot) ++left; nums[right] = nums[left]; } int mid = left; // now left == right nums[mid] = pivot; if(k-1 == mid) return pivot; else if(k-1 \u0026lt; mid){ while(mid \u0026gt; k-1 \u0026amp;\u0026amp; nums[mid] == nums[mid-1]) --mid; return findKthLargest(nums, begin, mid+1, k); // 注意这里还是传入[begin, mid+1)而非[begin, mid)，因为经过while优化，此时mid可以退到和begin位置相同 } else{ // k-1 \u0026gt; mid while(mid \u0026lt; k-1 \u0026amp;\u0026amp; nums[mid] == nums[mid+1]) ++mid; return findKthLargest(nums, mid, end, k); // 注意这里还是传入[mid, end)而非[mid+1, end) } } 剑指40.最小k个数：快排逻辑\n套路题 14.最长公共前缀 按行比，按列比，都行 209.长度最小的子数组 方法一：贪心+双指针 方法二：前缀和+二分 细节较多：前缀和是inclusive的还是exculsive的（这里用的是exculsive的），二分找的是第一个大于val的位置 剑指21.调整数组顺序使奇数位于偶数前面 如果不需要保持奇数/偶数内部的相对顺序，左右双指针向内走 169.多数元素 投票法：维护一个元素值value和计数值cnt，数组元素等于value时累加cnt，不等于value时递减cnt，当cnt==0时更新value 可以保证最后众数的cnt至少为1 128.最长连续序列 哈希表unordered_map\u0026lt;int, bool\u0026gt;（bool表示是否使用过该数字），元素往前往后分别试探 31.下一个排列 ： 题解 与556.下一个更大元素Ⅲ相同 从后往前遍历，找到一个最长的后缀，这个后缀是逆序的（即该后缀从前往后看递减，从后往前看递增） 该最长后缀前面一个元素nums[idx]，是小于最长后缀的第一个元素的 在该最长后缀中，找到最后一个\u0026gt;nums[idx]的元素nums[pos]，然后交换（因此最长后缀又变长了一位） 最后reverse[idx+1, end)，因此数组前面部分不动，后面部分得到了下一个排列 综合 560.和为K的子数组：【前缀和】+【哈希表】 通过前缀和可以将区间和转换为两个点的查询 通过哈希表记录遍历过的位置的前缀和（value是特定前缀和的计数） 现在已知一个点和中间差值，通过哈希找到另一个点 区别209.长度最小的子数组 字符串 模拟 415.字符串相加 43.字符串相乘 443.压缩字符串 6.Z字形变换 468.验证IP地址：先判断有.还是:，然后根据.或者:分割之后，逐段判断 7.整数反转：用字符串表示数字 166.分数到小数：首先注意符号问题，然后注意能否整除，最后逐次*10模拟竖式除法 套路 翻转字符串的妙用：局部翻转后再整体反转（或反过来），达到子串位置颠倒的效果\n151. 反转字符串中的单词\nLCR 182. 动态口令\nKMP系列\n实现strStr 链表【二刷】 206. 反转链表\n注意递归写法\n1 2 3 4 5 6 7 ListNode* reverseList(ListNode* head) { // 递归，返回反转链表的头 if(head==nullptr || head-\u0026gt;next==nullptr) return head; // 当前是空节点，或者是最后一个节点 ListNode* newHead = reverseList(head-\u0026gt;next); // 已经将head-\u0026gt;next部分的链表处理完毕 head-\u0026gt;next-\u0026gt;next = head; head-\u0026gt;next = nullptr; return newHead; } 迭代写法1：遍历，修改相邻节点的指针指向\n迭代写法2：创建虚拟头节点，进行头插法（遍历链表，插入到虚拟头节点之后）\n142. 环形链表 II 【好题】\n快慢指针可以判断有环 如何找到这个环的入口 148.排序链表\n递归方法：（自顶向下的）归并排序，时间复杂度O(n logn)，空间复杂度O(logn) 迭代方法：自底向上的归并排序，时间复杂度O(n logn)，空间复杂度O(1) 143.重排链表 【好题】\n先快慢指针寻找中点，然后后半段链表原地反转，最后两个链表合并 23.合并K个升序链表\n最小堆：priority_queue\u0026lt;ListNode*, vector\u0026lt;ListNode*\u0026gt;, decltype(cmp)\u0026gt; pq;\n归并：\n1 2 3 4 5 6 7 8 9 10 11 12 ListNode* mergeKLists(vector\u0026lt;ListNode*\u0026gt;\u0026amp; lists){ return merge(lists, 0, lists.size()-1); } ListNode* merge(vector\u0026lt;listNode*\u0026gt; \u0026amp; lists, int l, int r){ //[left, right] if(l == r) return lists[l]; if(l \u0026gt; r) return nullptr; int mid = (l + r) / 2; return mergetTwoLists(merge(lists, l, mid), merge(lists, mid+1, r)); } ListNode* mergeTwoLists(ListNode* a, ListNode* b) {/*两个链表合并*/} 445.两数相加Ⅱ\n一种方法是反转链表，另一种是使用栈进行计算 LRU缓存 【好题】代码\n数据结构：双向链表维护最近更新的节点，unordered_map\u0026lt;int,Node*\u0026gt;实现从key到链表中节点的映射\n设置dummyHead与dummyTail，可以避免专门判断head与tail是否为空（因为是双向链表，所以要设置头尾两个dummyNode）\n在Node中需要同时包含key和value，因为当删除某个node时，需要知道其对应的key，从而删除哈希表中对应的表项\n在向链表插入节点或是从链表中删除节点时，不要忘记更新map\nLFU缓存 【好题】\n方法一：map记录key到Node的映射，使用平衡二叉树保存Node的结构 方法二：双哈希表 递归 递归写法代码量一般比较少，也比较优雅，尤其在没有头节点的情况下避免对头节点另外判断\n138.随机链表的复制 21.合并两个有序链表 单链表的排序：归并排序\n哈希表【二刷】 有时可以直接使用数组进行哈希，有时需要使用map（unordered_map）或set（unordered_set）进行哈希，注意如果键无法进行哈希，则无法使用unordered_map或unordered_set（比如vector容器就没有hash方法，不能作为unordered_map或unordered_set的键）\n202.快乐数：使用哈希表空间复杂度为O(n)，将其视为快慢指针此时空间复杂度为O(1)\nn数之和系列：给定n数之和\n给定一个数组，要求返回其中一个元组下标：哈希\n1. 两数之和 给定一个数组，要求返回所有元组下标：先排序，外层遍历，内层左右指针向中移动，根据当前三数之和确定左指针还是右指针移动，同时注意跳过相同的数字\n15. 三数之和\n18. 四数之和：注意四数之和可能超过int的范围\n给定多个数组，要求返回元组的个数：哈希\n454. 四数相加 II 【原地哈希】\n例题：LCR 120.寻找文件副本：可能有多个重复数字，返回任意其一\n调整数组为nums[i]==i，如果将i写入到nums[i]时发现原来已经nums[i]==i，说明i就是重复数字 方法：通过交换实现调整 442.数组中重复的数据：数字出现1或2次，返回所有出现两次的数字\n287.寻找重复数：只有一个重复数，返回之；但是不能修改原数组\nFloyd判圈 268.丢失的数字：只有一个缺失的数字，返回之\n41.缺失的第一个正数 ：首先要判断数字是否在[0,n]的范围内\n方法一：标记\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 int minNumberDisappeared(vector\u0026lt;int\u0026gt;\u0026amp; nums) { // write code here if(nums.size() == 0) return 1; nums.push_back(0); for(int\u0026amp; n: nums){ if(n \u0026lt; 0) n = INT_MAX-1; // 将数组中的元素都转换为正数 } for(int i = 0; i \u0026lt; nums.size(); ++i){ int j = abs(nums[i]); if(j \u0026lt; nums.size()){ // 如果位置j在数组内 nums[j] = -abs(nums[j]); // 将位置j的数值标记为负 } } for(int i = 1; i \u0026lt; nums.size(); ++i){ if(nums[i] \u0026gt; 0) return i; // 找一个没有标记过的位置 } return nums.size(); } 方法二：交换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int minNumberDisappeared(vector\u0026lt;int\u0026gt;\u0026amp; nums) { // write code here if(nums.size() == 0) return 1; nums.push_back(0); for(int i = 0; i \u0026lt; nums.size(); ++i){ while(nums[i] \u0026gt;= 0 \u0026amp;\u0026amp; nums[i] \u0026lt; nums.size() \u0026amp;\u0026amp; nums[i] != nums[nums[i]]) swap(nums[i], nums[nums[i]]); } for(int i = 1; i \u0026lt; nums.size(); ++i){ if(nums[i] != i) return i; } return nums.size(); } 总结：虽然原地哈希的核心部分都是判断当前位置j的元素j=nums[i]为索引时，是否已经写入j?=nums[j]，但是中间很多细节略微不同\n974.和可被K整除的子数组：前缀和+哈希表\n前缀和实际上是前缀和的取模，使用哈希表记录模和其计数 12.整数转罗马数字\n哈希表记录数字到字符串的映射，注意使用map\u0026lt;int, string, greater\u0026lt;int\u0026gt;\u0026gt;将key从大到小排列 栈与队列【二刷】 用栈模拟队列：一个输入栈，一个输出栈 用队列模拟栈：只需要一个队列，将元素进行循环弹入弹出 优先队列 注意优先队列如何自定义比较顺序 栈 基本计算器Ⅱ：遇到加减法入栈（即栈内都进行加法运算），有两种不太相同的写法：比如a+b*c\n方法一：暂存数字。比如解析+时，暂存的是数字a，此时可以入栈；比如解析*时，暂存的是数字b（运算符前面的数字），此时先不能入栈，需要继续向后解析完c之后，更新暂存的数字\n方法二：暂存数字前的运算符，更简洁。比如解析b时，当前暂存的运算符是+（数字前面的运算符），因此遇到新的运算符*时，根据需要出栈入栈\n技巧：将a+b*c处理成a+b*c+0，且开始时暂存的运算符是+ 但是当表达式中含有括号时，可以递归，但是此时不太好在递归函数传入的表达式参数后面+0，具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 int solve(string s) { return func(s, 0).first; } pair\u0026lt;int, int\u0026gt; func(string\u0026amp; s, int idx){ // s += \u0026#34;+0\u0026#34;; // 本来想在表达式末尾加上0，但是因为使用的使用，所以无法使用 stack\u0026lt;int\u0026gt; numSt; int num = 0; // 相当于在表达式前面加上 0+ char preSymbol = \u0026#39;+\u0026#39;; for(; idx \u0026lt; s.size(); ++idx){ // cout \u0026lt;\u0026lt; idx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; if(s[idx] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[idx] \u0026lt;= \u0026#39;9\u0026#39;) num = num * 10 + (s[idx] - \u0026#39;0\u0026#39;); else if(s[idx] == \u0026#39;(\u0026#39;){ pair\u0026lt;int, int\u0026gt; p = func(s, idx+1); num = p.first; idx = p.second; } else if(s[idx] == \u0026#39;)\u0026#39;) break; else{ // 此时这几个变量的顺序: numSt.top() preSymbol num s[idx] if(preSymbol == \u0026#39;+\u0026#39;) numSt.push(num); else if(preSymbol == \u0026#39;-\u0026#39;) numSt.push(-num); else if(preSymbol == \u0026#39;*\u0026#39;) { int tmp = numSt.top(); numSt.pop(); numSt.push(tmp * num); } preSymbol = s[idx]; num = 0; } } if(preSymbol == \u0026#39;+\u0026#39;) numSt.push(num); else if(preSymbol == \u0026#39;-\u0026#39;) numSt.push(-num); else if(preSymbol == \u0026#39;*\u0026#39;) { int tmp = numSt.top(); numSt.pop(); numSt.push(tmp * num); } int ans = 0; while(!numSt.empty()){ ans += numSt.top(); numSt.pop(); } return make_pair(ans, idx); } }; 394.字符串解码：【重要】\n方法一：【双栈】写法，数字栈与string栈 字符串出栈时，每个元素需要先reverse，连起来字符串之后要再次reverse（因为出栈是逆序的，每个元素内部有时顺序的） 数字栈使用stack\u0026lt;int\u0026gt;，string栈使用deque\u0026lt;string\u0026gt;进行模拟，方便最后进行出栈 方法二：递归写法 全局的索引idx，函数传参string和重复数量cnt 如果遇到[，则进入递归；如果遇到]，则退出递归 递归就是顺着累加字符串，不需要reverse 678.有效的括号字符串：\n方法一：【双栈】 括号一个栈st，星号一个栈star_st，栈内存放下标 括号按照传统方法出入栈，星号直接入星号栈 在遍历完成之后，括号栈依次出栈， 如果当前是(，需要保证star_st.top()大于(的下标 如果当前是)，需要保证star_st.top()小于)的下标（极其注意需要当前star_st.top()可能大于)的下标，需要while依次出栈，与上面逻辑不同） 方法二：贪心 维护未匹配的(的数量可能的最大值和最小值，遇到星号时，最小值减一，最大值加一 如果最大值\u0026lt;0，则字符串无效 遍历完成后，只有最小值=0时，字符串才可能有效 最小栈 参考\n方法一：【双栈】 一个普通栈，一个最小栈（用来记录最小值） 如果当前元素==minStack.top()，也要push/pop最小栈 方法二：使用一个栈，并维护当前最小值minVal 入栈：如果当前元素\u0026lt;=minVal，则先将minVal入栈，然后再将当前元素入栈，同时更新minVal的值；否则直接入栈 技巧：minVal初始值设定为最大值 方法三：使用一个栈 每次入栈元素为当前元素-minVal -\u0026gt; st.top()，如果结果是负数，说明minVal需要更新minVal=当前元素 每次出栈或top，如果栈顶元素是正数，则原来的元素=minVal+st.top()；如果栈顶元素是负数，则说明当前minVal经过更新变得更小，原来的元素=minVal，复原原来的minVal=原来的元素(即旧的minVal)-st.top() 单调队列 239. 滑动窗口最大值\n方法一：大根堆，维护一个大根堆，里面存放数组索引，但是比较方法是按照对应元素大小进行比较，出队列时肯定是当前最大元素，而且可以判断该元素是否在窗口范围内\n最坏情况如果是一个递增序列，每次push都是log(i)的复杂度，总的复杂度为sum(log(i))=O(n log(n)) 方法二：单调队列，维护一个递减的deque，里面存放数组索引，从后面pop_back可以比较当前元素与队尾元素，保持队列递增；从前面pop_front可以保持元素位于窗口范围内\n最坏情况是O(n) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 vector\u0026lt;int\u0026gt; maxInWindows(vector\u0026lt;int\u0026gt;\u0026amp; num, int size) { // write code here int len = num.size(); vector\u0026lt;int\u0026gt; v; if(size \u0026gt; len || size == 0) return v; if(size == 1) return num; deque\u0026lt;int\u0026gt; dq; // 滑动窗口，里面存放数组下标，对应的数组元素递减（队首元素对应数组元素最大） for(int idx = 0; idx \u0026lt; size - 1; ++idx){ // 注意遍历到滑动窗口大小-1的位置 while(!dq.empty() \u0026amp;\u0026amp; num[dq.back()] \u0026lt;= num[idx]) dq.pop_back(); dq.push_back(idx); } // 每次遍历idx，对应的都是滑动窗口的末尾 for(int left = 0, idx = size-1; idx \u0026lt; len; ++idx, ++left){ while(!dq.empty() \u0026amp;\u0026amp; dq.front() \u0026lt; left) dq.pop_front(); // dq前面元素不在滑窗内了 while(!dq.empty() \u0026amp;\u0026amp; num[dq.back()] \u0026lt;= num[idx]) dq.pop_back(); // dq后面新加的元素更大 dq.push_back(idx); v.push_back(num[dq.front()]); } return v; } 单调栈 739. 每日温度：从左往右，找到第一个比当前元素大的元素\n单调递增栈（从栈顶到栈底递增，栈顶元素为已经遍历过部分的最小值），如果当前元素nums[i]大于栈顶元素nums[top]，则从左往右nums[top]第一个比它大的元素是nums[i]\n496. 下一个更大元素 I：单调栈+哈希表\n503. 下一个更大元素 II：朴素想法是将循环数组展开，但是可以相同的单调栈代码跑两遍（第二遍继续使用第一遍剩下的单调栈）\n42. 接雨水 【重要】\n方法一：单调栈，从栈顶到栈底递增（反映到柱子上就是往下的台阶）\n横着接水：如果当前元素height[i]高于栈顶的柱子H=height[st.top()]，则栈顶的柱子H为最低高度，pop之后的栈顶为左边比H更高的位置，当前位置i为右边比H更高的位置，横着按层累加\n时间复杂度O(n)，空间复杂度O(n)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int trap(vector\u0026lt;int\u0026gt;\u0026amp; height) { if(height.size() \u0026lt;= 2) return 0; stack\u0026lt;int\u0026gt; st; int ans = 0; for(int i = 0; i \u0026lt; height.size(); ++i){ while(!st.empty() \u0026amp;\u0026amp; height[st.top()] \u0026lt; height[i]) { int mid = height[st.top()]; st.pop(); if(!st.empty()){ ans += ( min(height[st.top()], height[i]) - mid) * (i - st.top() - 1); } } st.push(i); } return ans; } 方法二：双指针\n竖着接水：维护左右边历史最高柱子，往中间移动的过程中：\n如果右边低，当前水位最高只能按照低的来，ans += rightHeight - height[right--] 左边同理 时间复杂度O(n)，空间复杂度O(1)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int trap(vector\u0026lt;int\u0026gt;\u0026amp; height) { if(height.size() \u0026lt;= 2) return 0; int left = 0, right = height.size() - 1, ans = 0; int leftHeight = height[left], rightHeight = height[right]; while(left \u0026lt; right){ leftHeight = max(leftHeight, height[left]); rightHeight = max(rightHeight, height[right]); if(leftHeight \u0026lt;= rightHeight) { // 左边低 ans += leftHeight - height[left++]; } else{ ans += rightHeight - height[right--]; } } return ans; } 方法三：两个数组，分别从左向右和从右向左记录当前最高水位，也是竖着接水\n类似题目：盛水最多的容器\n这个题目使用双指针的方式 84. 柱状图中最大的矩形 【重要】\n单调栈，从栈顶到栈底递减（反应到柱子上就是往上的台阶）\n找每个柱子左右两边第一个低于该柱子的位置：如果当前元素height[i]低于栈顶的柱子H=height[st.top()]，有： i-1位置的柱子一定不低于H pop之后的栈顶位置+1一定不低于H（注意与接雨水的细微区别） 因此可以算面积 时间复杂度O(n)，空间复杂度O(n)\n技巧：在原来height数组开头height.insert(heights.begin(), 0)，在结尾height.push_back(0)，可以保证最后栈中无元素\n85.最大矩形\n每行统计高度，因此每行跑一个84. 柱状图中最大的矩形 时间/空间复杂度均为O(mn) 402. 移掉 K 位数字\n单调栈：从栈底到栈顶递增，同时维护栈的顺序和k\u0026gt;0 优先队列 347.前K个高频元素：小根堆，遍历过程中逐步弹出堆顶，剩下的就是高频元素\n注意优先队列的写法：\n1 2 auto cmp = [](pair\u0026lt;int, int\u0026gt;\u0026amp; p1, pair\u0026lt;int, int\u0026gt;\u0026amp; p2){return p1.second \u0026gt; p2.second;}; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, decltype(cmp)\u0026gt; pq(cmp); 手写堆\n最小的k个元素/最小的第k个元素：维护一个最大堆，堆顶是当前最大元素（k个最小的元素中最大的一个）；如果新来的数比堆顶元素小，则弹出堆顶，新元素入堆\n数据流中的中位数：两个优先队列，前一半数组用最大堆，后一半数组用最小堆\n但是注意，为了保证后一半数组都大于前一半数组，新来的数需要先push到前面的最大堆中，然后再取top，放到后面的最小堆中 同时需要保证前面最大堆的大小\u0026gt;=后面最小堆的大小 二叉树【二刷】 遍历 DFS 递归写法：\n确定递归函数的参数和返回值 确定终止条件 确定单层递归的逻辑 迭代写法：\n道理：当前arrive（或access）的节点，未必就是要add进数组的节点\n前序：第一次arrive的节点，就是add进数组的节点 中序：第二次arrive的节点，就是add进数组的节点 前序：空节点不入栈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; v; stack\u0026lt;TreeNode*\u0026gt; st; if(root == nullptr) return v; st.push(root); while(!st.empty()){ TreeNode* now = st.top(); st.pop(); v.push_back(now-\u0026gt;val); if(now-\u0026gt;right) st.push(now-\u0026gt;right); if(now-\u0026gt;left) st.push(now-\u0026gt;left); } return v; } 中序：使用now指向当前arrive的节点，now指向可以为空，此时出栈一个元素，now指向其右节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 vector\u0026lt;int\u0026gt; inorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; v; stack\u0026lt;TreeNode*\u0026gt; st; TreeNode* now = root; while(now != nullptr || !st.empty()){ // 比如中间-\u0026gt;可能now指向空指针，此时stack不能为空 // -\u0026gt;可能stack为空，但是now指向右节点 // 最后now指向某个节点的右空树，且stack都出栈已经为空，此时就是结束 if(now == nullptr){ now = st.top(); st.pop(); // st.top()是第二次访问，可以add进数组 v.push_back(now-\u0026gt;val); now = now-\u0026gt;right; } else{ // now != nullptr st.push(now); now = now-\u0026gt;left; } } return v; } 后序：可以按照【根右左】的顺序遍历，然后reverse（即左右根）\nBFS 迭代写法：注意是否要分层；如果不用分层，则不用计算每层的size，更简单一些\n递归写法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; levelOrder(TreeNode* root) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; vv; bfs(root, vv, 0); return vv; } void bfs(TreeNode* root, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; vv, int depth){ if(root == nullptr) return ; if(vv.size() == depth) vv.push_back(vector\u0026lt;int\u0026gt;()); vv[depth].push_back(root-\u0026gt;val); if(root-\u0026gt;left) bfs(root-\u0026gt;left, vv, depth+1); if(root-\u0026gt;right) bfs(root-\u0026gt;right, vv, depth+1); } 199.二叉树的右视图：注意递归的写法，将深度和当前数组的size比较 二叉树 222.完全二叉树的节点个数 【好题】\n如何判断满二叉树？向左递归深度==向右递归深度 完全二叉树中，某个节点左子树和右子树中，至少有一个是满二叉树，参考 复杂度分析： 每次递归需要计算当前节点的高度，O(log n) 最多需要调用“树的高度”次，O(log n) 相乘，O(log n) * O(log n) 110.平衡二叉树\n注意二叉树节点【深度】和【高度】的差异 高度：该节点到叶子节点的最长，求高度适合用前序遍历 深度：根节点到该节点的路径，求深度适合用后序遍历 112.路径总和\n注意分辨递归什么时候有返回值 不用完整搜索整棵二叉树，找到其中一条路径即可，需要返回值（比如本题），比如if判断当前节点后直接返回。或者说遍历的思维 需要完整搜索整棵二叉树，或者说二叉树与回溯的结合 需要返回值（比如递归求深度） 不需要返回值 124.二叉树中的最大路径和 【好题】\n递归写法 236.二叉树的最近公共祖先 【好题】\n递归方法： 后序遍历：分别在左右子树中找p和q的最近公共祖先，然后根据找到的情况进行处理 如果子树递归返回nullptr，说明子树不包含p或者q 如果子树递归返回非nullptr，说明子树包含p、或q、或pq 理解返回值：返回值是以root为根的子树中，p或q的最近公共祖先，如果该子树不包含p或者q，则返回nullptr 如果root==p || root==q，则当前root至少为一个节点祖先，另一个节点可能在这个子树上，也可能不在这个子树上，但至少返回root 如果当前root为根的子树，没有p或者q（左右子树都是nullptr），只能返回nullptr 如果当前root为根的子树，左右子树分别有p和q，则root为最近公共祖先，返回root 如果当前root为根的左子树或右子树其中一个，同时有p和q，则只能将其最近公共祖先向上返回 迭代方法：使用map记录子节点到父节点的映射，再使用一个map记录p到root的路径，最后q向上回到root过程中找到最近同时访问的节点 543.二叉树的直径\n维护一个计算每个节点最大深度的递归函数deepest 在计算节点左右子树的过程中，更新树的直径 662.二叉树最大宽度：中间nullptr也算\npair\u0026lt;TreeNode*, unsigned long long\u0026gt;保存节点和其id，×2得到其左节点id，×2+1得到其右节点id，最后id相减 116.填充每个节点的下一个右侧节点指针\n常规方法：使用队列进行迭代 递归方法：递归函数中传入两个节点指针 671.二叉树中第二小的节点：root是最小的，遍历一遍，比root大的其中最小的\n区分572.另一棵树的子树 和 LCR 143.子结构判断(这个题目关于空节点本身没有说清楚)\n863.二叉树中所有距离为K的结点\n遍历一遍得到子节点到父节点的map，从而变树为图，然后dfs 297.二叉树的序列化与反序列化 【好题】\n第一种方法：使用括号表示编码（BNF编码）进行序列化，使用递归函数进行反序列化，代码 BNF编码：比如postOrder BNF编码(左)(右)(根) 反序列化时，递归函数中需要使用栈，从而确定左右子树在字符串中的范围 第二种方法：使用逗号表示编码按照层序遍历进行序列化，使用迭代方法进行反序列化，代码 序列化方式与leetcode样例给出方式相同，不需要特殊表示换层 反序列化同样使用队列，字符串遍历的过程中入栈出栈 第三种方法：使用逗号表示编码进行序列化，使用递归函数进行反序列化，代码 序列化表示形式与第二种方法相同，但是好像只能使用前序遍历 如果使用中序/后序，字符串中第一个元素解码后是nullptr，在反序列化的递归函数中第一个元素就直接返回，不会处理后面的字符串了 如果使用前序，字符串中第一个元素肯定不为nullptr，可以递归下去 反序列化过程需要维护一个全局的索引，从而在不同的递归函数之间确定当前处理的元素的位置 652.寻找重复的子树\n使用基于后序遍历的二叉树序列化，模板类似297.二叉树的序列化与反序列化中第一种方法，但是序列化格式可以简化 在后序遍历进行序列化的过程中，同时维护unordered_map\u0026lt;string, pair\u0026lt;TreeNode*, int\u0026gt;\u0026gt;的映射 二叉搜索树 98.验证二叉搜索树 530.二叉搜索树中的最小绝对差 501.二叉搜索树中的众数\n原理：二叉搜索树中序遍历是有序的 可以是递归写法：维护一个全局变量，记录上一个节点的指针pre 可以是迭代写法：中序迭代写法 98.验证二叉搜索树极易想成简单左右子树判断，但此时根节点和右子树的左孩子的关系是无法判断的，只能中序遍历判断有序 450.删除二叉搜索树中的节点 【好题】\n对比递归方法与迭代方法：都是五种情况 迭代方法：小心删除根节点时的特判 递归方法：使用root-\u0026gt;left或root-\u0026gt;right接受返回值，避免记录pre节点（同时也避免了删除根节点时pre==nullptr的判断） LCR 174.二叉搜索树的第k大节点\n中序倒序，维护全局变量的计数器 426.将二叉搜索树转换为有序的双向链表\n递归函数返回有序双向链表的头 LCR 152.验证二叉搜索树的后序遍历序列\n注意是二叉搜索树，因此可以确定根与左右子树，从而递归判断 第二种方法：单调栈+后序逆序，代码，参考，不太会 比如当前是根节点（栈顶） 如果下一个节点大于栈顶元素，则在右侧，因此入栈 如果下一个节点小于栈顶元素，则出栈（该节点在其祖先节点的右边），找到其祖先节点，后序节点应该都在该祖先节点的左边 假设有一个极大的虚拟根节点，整棵树都在其左边 99.恢复二叉搜索树\n遍历过程中，记录这两个节点，参考 综合 437.路径总和Ⅲ 【好题】，【二叉树】+【前缀和】+【回溯】\n递归方法：以每个节点为root（O(n)），再计算包含root时的路径数量（O(n)），复杂度O(n^2)\n前缀和：在前序遍历的过程中，记录当前节点的前缀和，并遍历过的节点的前缀和保存到map中（value是特定前缀和的个数）\n根据当前前缀和和root-\u0026gt;val，可以得到当前分支上符合要求的路径的个数 当当前root返回时，当前的前缀和也需要从map中复原 回溯 回溯\n思路：二叉树/多叉树的递归遍历\n视为二叉树的话，每个元素选择或不选，每个dfs中有两条路径 视为多叉树的话，在每个for循环中进行选择，注意选择之后的回溯复原就表示没有选择当前元素，然后可以选择后面的元素 写法：数组直接作为全局变量，进行多叉树的遍历时使用一个startIdx来表示当前搜索数组的位置\n细节问题：\n使用startIdx还是从0开始 能否对数组排序？ 能，如果需要去重，维护一个全局的used数组 used数组的索引，表示nums的下标（一般是这个，比如有重复元素时，使用str[i]==str[i-1 \u0026amp;\u0026amp; isVisit[i-1]来判断），还是nums元素的值 不能，如果需要去重，则每一层应该维护一个局部的set 组合问题：从N个数中选k个数，有几种选法\n77.组合：模板题 216.组合总数Ⅲ：直接在for循环中进行剪枝 17.电话号码的字母组合：使用字符串数组（或者二维数组）来进行数字到字符串的对应 39.组合总和： 40.组合总和Ⅱ：使用used数组进行去重，初始化used=false： 当数组中相邻两个元素相等且used=true时，表示这两个元素在同一个树枝上（在一个分支上），此时不用去重（即组合内部使用了相同的元素） 当数组中相邻两个元素相等且user=false时，表示这两个元素在递归的同一层（同一树层上），此时表示后面会有相同的组合出现，因此需要去重（continue） 切割问题：一个字符串不同切割方式，有几种方式\n131.分割回文串：逐个分割每个元素进行判断，同样是递归的树形结构 93.复原IP地址：感觉写成三叉树的递归方式，而非是for循环的递归方式更直观和易于理解 三叉树方式：从当前位置开始的子串，分别作为一个字符、两个字符、三个字符进行匹配 子集问题：N个数中相关子集的个数\n78.子集：递归的树形结构的所有节点 90.子集Ⅱ：理解“树枝去重”与“树层去重”的逻辑，对于相同的数字，前面的可以选或不选，后面的必须不能选 491.递增子序列：同样需要去重，但不能使用全局的used数组来去重 90.子集Ⅱ中数组是有序的，可以保证相同的数字都是挨着的， 491.递增子序列中数组无序，如果按上面的方式，只能保证相同的连着的数字是去重的，相同的不挨着的数字会重复，因此只能每一层维护一个局部的used数组，动态判断该数字之前是否出现过 排列问题：N个数的不同排列方式\n46.全排列：\n方法一：使用used数组记录该数字是否使用过，仔细考虑for循环和回溯（回退）的过程 方法二：使用swap和startIdx，每次减小排列的规模 47.全排列Ⅱ：对比491.递增子序列\n332.重新安排行程：\n错误理解和写法：每个机场只到一次（因此使用一个数组记录该节点是否到过） 正确理解：所有路径都走且只走一次（可能比如北京到上海有好几张票，都要使用，因此使用unordered_map\u0026lt;string, map\u0026lt;string, int\u0026gt;\u0026gt;来进行建图，然后dfs,回溯更新int的值） 棋盘问题：\n51.N皇后：画出搜索的树形结构，dfs中逐层放置皇后 37.解数独： 二维的递归，注意最外层for循环的是数组/棋盘，而不是各种可能性或组合（即选或不选） 判断合法性时，只是判断当前元素是否行、列、方格重复 贪心 区间贪心 55. 跳跃游戏：维护一个当前可以跳跃到的最右边界 45.跳跃游戏Ⅱ 435.无重叠区域 当有重叠区域时，更新右端点right = min(right, v[1]);的含义：如果重叠，使得右端点最小 如果旧的right更小，则移除掉新来的区间 如果新来的区间v[1]更小，则移除原来的区间 452.用最少数量的箭引爆气球 对比435.无重叠区域 按照每个点的start进行排序，当前重叠范围为[start, right]，start递增，维护逐渐缩小的重叠区间right = min(right, points[i][1]) 主持人调度（二）：排序+最小堆 按开始时间、结束时间先排序区间 使用最小堆保存当前正在进行的所有活动的结束时间，堆顶是最早的结束时间 因此，如果新来的某次活动，开始时间小于堆顶的最早结束时间，则这个活动可以连起来 两个维度贪心 406.根据身高重建队列：先从高到低排队，再插队，复杂度O(n^2) 上下坡 376.摆动序列 方法一：贪心，也就是统计一共有几次变化 方法二：带空间优化的动规，up[i], down[i]为以nums[i]为结尾（最后一个是上升或下降）的摆动序列长度 135.分发糖果：正着统计上坡，反着统计上坡 122.买卖股票的最佳时机Ⅱ：直接累加上坡的差值 134.加油站：找剩余油量的前缀和中最小的位置 动态规划 总结 动规五部曲：\n确定dp数组的含义和下标的含义 确定递推公式 确定dp数组的初始化 确定遍历顺序 举个例子 单纯动规 直接寻找/使用最优子结构 97.交错字符串\n91.解码方法\n最优子结构好找（相当于递推），只是中间判断有点多 139.单词拆分\n322.零钱兑换\n343.整数拆分\n221.最大正方形\n子结构需要从三个方向考虑 使用滚动数组优化，注意有斜向上的依赖，需要使用一个变量记录 576.出界的路径数：题目一般，就像递推\n931.下降路径最小和\n120.三角形最小路径和\n剑指 Offer 47. 礼物的最大价值 同 64.最小路径和\n剑指Ⅱ 091.粉刷房子\n174.地下城游戏\n从右下到左上的动规 823.带因子的二叉树\n01背包 494.目标和：要装满背包，有几种方法 注意，0可以特殊处理，也可以不用特殊处理 416.分割等和子集： 给定背包容量，能不能装满这个背包 方法一：dp[j]就表示背包容量为j时，能否将背包装满 方法二：视为标准01背包，物品价值和重量相等，最后看容量为j的背包里最大价值 1049.最后一块石头的重量Ⅱ 1049.最后一块石头的重量Ⅱ： 首先转换成标准01背包：分成两堆石头，一堆小，一堆大，让小的那堆尽量接近一半 474.一和零：给定背包容量，装满背包最多有多少个物品 注意背包是二维的（长对应0的数量，宽对应1的数量） 排列数与组合数 377.组合总和Ⅳ：算组合数 22.爬楼梯：进阶版爬楼梯（每次可以爬[1 - m]个台阶）其实是一个完全背包下计算组合数的问题 参考 打家劫舍系列 198.打家劫舍： 不要硬套01背包，01背包只是动规中很套路的一个模板；除了直接题目可以直接套模板，剩下的还是要具体分析出来递推公式 213.打家劫舍Ⅱ 拆环为链，拆分成两种情况，各跑一遍 337.打家劫舍Ⅲ：树形DP 每个节点有一个状态数组 在后序遍历中，得到左右子树的状态，更新当前节点的状态 买卖股票的最佳时机系列 121.买卖股票的最佳时机\ndp数组表示持有/不持有股票，第0天持有即买入 划分状态 首先为什么标准01背包不需要针对每个背包的容量分成两种状态的数组？ 动规原理是最优子结构，标准01背包中物品之间是相互独立的，不存在某件放入a物品后必须放入b物品这样的关联 其次为什么打家劫舍问题也不需要针对每一间房屋分成两种状态的数组？ 首先可以分，而且公式写出来也很清晰，在比如树形DP中还必须要分 但是打家劫舍中，只是相邻两个房屋之间有关联，公式中可以直接将关联表示出来 买卖股票中为什么必须要分成两种状态的数组？ 因为买卖股票的两天之间的关联不是固定的 买卖股票中还需要注意两种状态的定义：是持有/不持有，而非买入/卖出 什么是状态？ 第i天进行第j笔交易，是持有还是不持有 注意如何保证只买入一次？区别122.买卖股票的最佳时机Ⅱ 加上手续费相同714.买卖股票的最佳时机含手续费 122.买卖股票的最佳时机Ⅱ\n123.买卖股票的最佳时机Ⅲ\n每天有多种状态：第i天进行第j笔交易，是持有还是不持有\n有一个技巧可以将空间复杂度降到O(1)，参考\n188.买卖股票的最佳时机Ⅳ 同理\n309.最佳买卖股票时机含冷冻期\n细化状态（比如不持有股票可以细分为今天卖出还是维持原来不持有的状态） 画出状态转移图 序列问题 递增序列/数组 300.最长递增子序列 LIS\n674.最长连续递增序列是连续的递增序列（或称为递增数组），是否连续决定是否内部要使用一个for循环找到比当前元素小的位置\n可以使用贪心+二分实现更低的复杂度\n贪心：d[len]表示：长度为len的LIS的最后一个元素值，该元素值越小越好\n二分：d[]数组单调递增，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 int d[N]; // 长度为len的LIS中的最后一个元素的值 int lengthOfLIS(vector\u0026lt;int\u0026gt;\u0026amp; nums) { if(nums.size() == 1) return 1; d[0] = -1000000; d[1] = nums[0]; int len = 1; // 当前最长LIS的长度 for(int i = 1; i \u0026lt; nums.size(); ++i){ if(nums[i] \u0026gt; d[len]) // 如果当前最长LIS后面可以继续添加一个元素 d[++len] = nums[i]; else{ // nums[i] \u0026lt;= d[len] // // 固定nums[i]为结尾，找前面尽可能长的一个LIS，同时该LIS的最大值\u0026lt;nums[i] // // 即：长度j尽可能大，同时d[j] \u0026lt; nums[i] // int j = find_last_lt(d, 0, len+1, nums[i]); // d[j+1] = min(d[j+1], nums[i]); // 另一种等价的写法：找到d中第一个\u0026gt;nums[i]的位置j // 说明j-1长度的LIS的最大元素小于nums[i]，j长度的LIS最大元素又\u0026gt;nums[i] // 说明为j长度的LIS找到了更小的一个末尾元素 int j = find_first_ge(d, 0, len+1, nums[i]); d[j] = nums[i]; } } return len; } 参考\n673.最长递增子序列的个数\n使用贪心+树状数组实现O(nlogn)的复杂度，参考 354.俄罗斯套娃信封问题\n先排序，w正排，h倒排（保证相同w时，大h不能包含小h） 通过排序将二维LIS转换为一维的LIS 368.最大整除子集\n与LIS方法差不多 重复数组、公共序列、子数组/序列问题 718.最长重复子数组\n使用滚动数组进行优化：代码 内层逆序：之所以逆序，一是因为不将物品重复放入，二是因为可能依赖是斜向上的，逆序可以直接访问未更新之前的数值 也可以使用顺序，不过要将原来未更新之间的数值记录下来 其实是这个题目对遍历顺序没有要求，因为if中dp依赖左上旧值，else中dp直接是0 其他题目中，else中可能需要用到刚才更新过的值，因此只能从前向后遍历 1143.最长公共子序列 和 1035.不相交的线\n使用滚动数组进行优化：使用两个数组来回调替，或者直接记录依赖的旧值 极其注意如果使用一维数组优化，同时使用pre来记录斜上角的值时，此时tmp=dp[j]还是tmp=dp[j+1]，tmp保存的是当前dp要被覆盖的值 53.最大子数组和\n遇到数组和第一直觉总是前缀和，但是这个题目使用动规很简单 392.判断子序列\n可以使用双指针 使用动规：状态转移方程很类似 dp可以表示相同序列的长度 dp也可以是bool数组，表示s[0, i]是否为t[0, j]的子序列 使用滚动数组优化二维数组时，注意将初始化方式从原来的二维情况下转换到一维情况下，比如当i=0时容易记起初始化，但是i=1,2,3\u0026hellip;之后，dp[0]或者dp数组开头几个数字就容易忘记初始化，代码 115.不同的子序列\n代码模板是392.判断子序列，只是递推公式需要多考虑一下 字符串操作 583.两个字符串的删除操作 动规方式1：先求出最长公共子序列，再相减 动规方式2：dp直接表示删除的最小步数，逻辑相同 注意原来使用二维数组时，有一定初始化方式；使用一维数组进行优化时，dp[0]很容易忘记初始化，代码 712.两个字符串的最小ASCII删除和 72.编辑距离 当word1[i]与word2[j]不相同时，如果进行插入和删除，只需要考虑将word1[i]当前字符插入或删除 牛客NC35 编辑距离二 有O(nlogn)的算法吗？？？ 回文相关 647.回文子串：【好题】，分析\ni倒着遍历，j顺着遍历 有时dp数组的含义并不是直接求什么，定义什么 如果$dp[i][j]$表示$s[i:j]$内的回文子串的数量，当s[i]==s[j]时，此时无法判断$s[i+1:j-1]$是否为回文串，由此无法确定递推公式中是否要+1，错误代码 $dp[i][j]$表示$s[i:j]$是否为回文串，在递推公式之后根据true or false进行累加，正确代码 5.最长回文子串\n516.最长回文子序列\n注意看是子序列（不必连续）还是子串（必须连续） 这个回文动规中，dp的含义，就是求什么定义什么 1312.让字符串成为回文串的最少插入次数\n其他 152.乘积最大子数组：【好题】，也是分状态，但是其中另一个状态隐含在题目中，需要分析，很巧 第一次几乎完全不会 32.最长有效括号 动规+单调队列 1696.跳跃游戏： 模板题 14253带限制的子序列和：【好题】 比1696在动规上多了一点 图论 DFS与BFS 797.所有可能的路径：DFS+回溯\n200.岛屿数量：DFS，BFS模板题\n1020.飞地的数量：第一阶段原地修改原来的二维数组标记，第二阶段再次遍历\n130.被围绕的区域：原地修改二维数组标记\n827.最大人工岛：保存中间计算结果（岛屿面积），避免重复计算\n首先遍历，每个岛屿进行编号，同时使用map记录id到岛屿面积的映射 对于水块，上下左右累加岛屿面积 127.单词接龙：\n单词个数n，单词长度m\n方法一：BFS内部，对单词进行遍历，找到相邻的单词，最坏情况复杂度O(nnm) 方法二：BSF内部，对当前单词逐字母进行替换，判断替换后的单词是否在词表中，复杂度O(26*n) BM61 矩阵最长递增路径 DFS+动规\nDFS的模板，动规的公式：\n1 2 3 4 5 // 从(x,y)到(xx,yy)递增 if(inBound(xx,yy) \u0026amp;\u0026amp; mat[x][y] \u0026lt; mat[xx][yy]){ dfs(mat, xx, yy); // DFS计算dp[xx][yy]的值 dp[x][y] = max(dp[x][y], dp[xx][yy]+1); } 并查集 并查集：一个用数组表示的森林\n当存在u-\u0026gt;v的有向边时，添加到并查集：father[v] = u; // v的father是u 1971.寻找图中是否存在路径：模板题\n数学 模拟 9.回文数： 空间复杂度O(1)的方法：原来数字取模除十的过程中，与反转后的数组比较大小 172.阶乘后的零：实际上就是找因子5的个数 位运算 常用技巧：对于int n\n获取n的最低位的1：n \u0026amp; (-n) 将n的最低位1变为0：n \u0026amp; (n-1) 191.位1的个数：\n循环检查二进制位：if(n \u0026amp; (1 \u0026lt;\u0026lt; i)) ++cnt lsb翻转：n \u0026amp; (n-1)结果为将n的二进制lsb变为0，因此：while(n) {n \u0026amp;= (n-1); ++cnt;} 136.只出现一次的数字：数组异或，原理是异或具有交换律\n137.只出现一次的数字Ⅱ：\n对于32位int，统计每一个bit中1的个数cnt，如果cnt无法整除3，则只出现一次的数字在当前bit为1，ans |= (1 \u0026lt;\u0026lt; i) 260.只出现一次的数字Ⅲ：分组异或\nxorsum一定不为0，否则所有数字都出现两次，假设两个出现一次的数字为a和b\nxorsum的最低有效位lsb，则一定是a的lsb=1，b的lsb=0（或反过来）\n为什么要取最低有效位？为了实现分组，a和b在最低有效位不同， 出现两次的数字，其lsb一定相同；因此根据这个lsb可以将所有数字分成两类，分别进行异或\n1 2 3 4 5 6 7 8 9 10 11 12 13 vector\u0026lt;int\u0026gt; FindNumsAppearOnce(vector\u0026lt;int\u0026gt;\u0026amp; nums) { // write code here int xorsum = 0; for(int n: nums) xorsum ^= n; int lsb = xorsum == INT_MIN ? xorsum : xorsum \u0026amp; (-xorsum); int a = 0, b = 0; for(int n: nums){ if(n \u0026amp; lsb) a ^= n; else b ^= n; } return vector\u0026lt;int\u0026gt;{min(a,b), max(a,b)}; } 其他 快速幂 470.用Rand7()实现Rand10()：拒绝采样 注意不能直接使用rand7() * rand7()，因为其中元素概率不完全相同，比如14的概率是2/49，1的概率是1/49，6的概率是4/49 视为行列索引：row=rand7(); col=rand7(); c = (row-1)*7 + col;，这样每个元素等概率 设计 705.设计哈希集合：基于vector\u0026lt;list\u0026lt;int\u0026gt;\u0026gt;的链地址法 706.设计哈希映射：基于vector\u0026lt;list\u0026lt;pair\u0026lt;int,int\u0026gt;\u0026gt;\u0026gt;的链地址法 380.O(1)时间插入、删除和获取随机元素： 一个vector用来获取随机元素 一个unordered_map\u0026lt;int, int\u0026gt;用来记录val到idx的映射 208.实现Trie（前缀树） 类似二叉树，Trie本身就是一个node，里面有vector\u0026lt;Trie*\u0026gt; children(26, nullptr)表示26叉树 Trie节点中包含一个属性isEnd，如果当前节点表示字符串的最后一个字符，则当前节点的下一个节点的isEnd=true 包含一个辅助函数Trie* searchPrefix(string prefix)，返回prefix字符串结尾的下一个节点 继续刷 437.路径总和Ⅲ\n4.寻找两个正序数组的中位数\n85.最大矩形\n28.找出字符串中第一个匹配项的下标：KMP模板\n附录一：ACM输入输出模板 A+B问题\n1 2 3 4 5 6 7 8 int main(){ int a, b; while(scanf(\u0026#34;%d %d\u0026#34;, \u0026amp;a, \u0026amp;b) != EOF) { } // while(cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b) {} // 或者cin输入 return 0; } 注意scanf输入中的换行，对于输入int不影响，但是对于输入char会影响，比如可能会将换行吃掉\n平均绩点\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;cstdio\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; int main(){ string s; while (getline(cin, s)) { // 接受一整行字符串 } return 0; } 附录二：刷题列表 牛客面试笔刷TOP101\n","permalink":"https://qinganzhang.github.io/posts/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/","summary":"[toc] tags：【双指针】，【前缀和】，【原地哈希】 【好题】，【不会】，【重要】，【继续看】 方法 双指针 前后定长双指针 前后快慢双指针 左右双向双指针","title":"Leetcode刷题记录"},{"content":"指令集架构 指令集 说明了操作种类、指令格式（操作码和地址码，地址码个数，操作码定长与拓展）、寻址方式、地址空间大小和寄存器个数等。简单可以理解为汇编指令用01表示。\nCPU位数=CPU中寄存器的位数=数据总线宽度\n硬件厂商开发某种指令集的CPU，需要该指令集专利持有者进行授权\n比如ARM公司自己的研发指令集叫ARM指令集，对外授权（同时ARM公司还进行微架构的授权）\n一些大型公司都获得ARM公司针对ARM指令集的授权，开发兼容ARM指令集的不同的微架构\n比如Intel授权AMD可以生产兼容x86指令集的CPU 编译：高级语言翻译成特定ISA的机器码\n参考\n关于CPU、指令集、架构、芯片的一些科普 复杂指令集CISC x86：在1978年的Intel 8086 CPU（16位）指令集基础上，发展而来的一些列指令集的泛称\n桌面级CPU一般都是x86的，兼容8086指令集 IA-32(x86,i386)：Intel将16位的x86拓展为32位的IA-32，但是由于IA-32的统治地位，x86也一般指IA-32的CPU\nIntel 80386是第一款i386 CPU（第一款IA-32架构的CPU） i386，i486：即Intel 80386， Intel 80486 Pentium（i586）：Intel 80586 Pentium Pro（Pentium Ⅱ，i686）：Intel 80686 此后，x86成为一些列架构的泛称，不限于16位，32位，64位 IA-64：1994年Intel推出的与x86完全无关的新架构（也不兼容之），基于显式并行指令运算（EPIC）的64位指令集架构\n2001年发布第一款基于IA-64的CPU，叫Itanium安腾，IA-64也称为Intel Itanium 但是由于软件环境的缺乏和AMD的竞争，导致市场不好 x86-64(x64)：1999年，AMD推出x86-64架构（简称x64），是对IA-32(x86)的兼容和拓展\n2003年AMD发布的一款基于x86-64的CPU，x86-64也称为AMD64\n后来Intel也用AMD64架构，称为IA-32e(IA-32 extension)，后来又叫Intel64\nx86-64, x64, AMD64, Intel64, IA-32e(IA-32 extension)基本是一个东西\n苹果公司和 RPM 包管理员以 x86-64 或 x86_64 称呼此 64 位架构。甲骨文公司及 Microsoft 称之为x64。BSD 家族及其他 Linux 发行版则使用 amd64，32 位版本则称为i386（或 i486/586/686），Arch Linux 用x86_64 称呼此 64 位架构。\nx86,x64,x86-64,amd64,arm指令集架构之间的关系中x86 架构发展\n参考\ni386、i486、i586、 i686、 x86、x86_64、x64、amd_64详解【写的很好】 精简指令集RISC ARM ARMv3~ARMv7都是32位 ARMv8：向前兼容32位指令，同时 AArch64：64位执行状态，使用全新的ARM 64位指令集 AArch32：32位执行状态 RISC-V：伯克利发明的一种基于RISC的开源指令集架构 一文看懂RISC-V MIPS PowerPC 微架构 微架构：硬件电路（或CPU单个核心core）的结构和实现 CPU研发能力一般指的是独立的微架构研发能力，是否使用自行研发的指令集关系不大 研发兼容的指令集可以没有获得授权，指令集的研发不是很难，但是之后获得授权后才能合法销售 微架构的设计细节是保密且复杂的 SoC（System on Chip）封装相对简单 商业模式 之前在PC时代，CPU研发厂商自己的微架构只有自己用 后来在智能设备时代，ARM公司将自己的微架构出售，其他厂商可以拿来组装，比如Cortex系列核心 由于ARM公司的成功，ARM公司针对PC领域发布了ARM v8 64位指令集 以前ARM适合低功耗的场景，随着技术进步，指令集对微架构的影响越来越小 指令集的选择：倾向于选择软件生态良好的指令集 以前获得指令集的授权很困难，主要通过技术交换的形式（指令集多授权一家，就多一个对手） 后来ARM对指令集授权略微放松 参考： 指令集、微架构、手机芯片(Soc)及ARM的介绍(偏硬件科普) 计算机架构 冯.诺伊曼架构：程序和指令存储在一起 哈佛架构：程序和指令分开存储 比如单片机（51单片机，STM32单片机），Cortex-M系列 现代处理器架构一般指令和数据共享存储，但是CPU内部缓存分开 特别介绍：ARM ARM商业发展 由于商业需要，1985年，Acorn公司基于RISC，自研CPU（包括指令集和微架构），称为ARM（Acorn RISC Machine），型号命名为ARM1（对标80286）\n后来，Acorn公司和苹果公司联合成立了一家叫ARM（Advanced RISC Machines）的公司，开启新的产品策略：授权\n传统商业模式：\nIDM(Integrated Design and Manufacture)：从设计，到制造、封装测试以及投向消费市场一条龙全包，比如Intel 无工厂模式Fabless：自己设计，制造交给代工厂，比如AMD，NVIDIA Foundry：只做代工 使用层级授权（处理器授权）：只能买来已经封装好的CPU，不能更改原来设计，可以配置的地方不多 内核层级授权（POP授权）：以一个内核（或IP核）为基础然后在加上自己的外设 架构层级授权：授权使用ARM指令集，可以修改指令集，但是比较贵 比如华为基于ARMv8，自研达芬奇架构 后来ARM公司越来越成功，苹果公司逐渐卖掉其股份，开发ipod（基于ARM指令集）。\n2007年，苹果公司发布iphone，基于ARM指令集 2008年，谷歌发布Android系统，也是基于ARM指令集 2016年，ARM公司被软银集团收购\n参考\n如何看待观点「华为没有核心技术，因为芯片用的是ARM（安谋）架构，一旦被停止授权，就会做不出芯片」？ 【推荐】到底什么是Cortex、ARMv8、arm架构、ARM指令集、soc？一文帮你梳理基础概念【科普】 ARM处理器 一般处理器就是指CPU\n但是ARM处理器指的是单个核（或IP核，或内核），因为厂商可以在IP核上进一步封装，最终CPU不尽相同\nIP核，全称知识产权核（英语：intellectual property core），是在集成电路的可重用设计方法学中，指某一方提供的、形式为逻辑单元、芯片设计的可重用模组。IP核通常已经通过了设计验证，设计人员以IP核为基础进行设计，可以缩短设计所需的周期。\n参考：\narmv7-A系列0 - arm 处理器架构发展史中的处理器到底指的是什么 到底什么是Cortex、ARMv8、arm架构、ARM指令集、soc？一文帮你梳理基础概念【科普】中的ARM内核与架构 指令集、微架构、手机芯片(Soc)及ARM的介绍(偏硬件科普) 指令集架构：\nARMv1~ARMv9（可以有一定的变种比如ARMv8-A） ARMv8是首款64位的ARM指令集 处理器架构\nARMv3~ARMv6： ARM6, ARM7, ARM9, ARM11系列 ARMv7及以后 Cortex-A：大型嵌入式系统（手机） Cortex-R：实时处理器 Cortex-M：单片机 参考：\nARM基础教程 | ARM命名规则\nARM 命名规则——指令架构、CPU的历史回顾\n参考：\nARM体系架构概述\nAndroid 简介 Android是一个开源的，基于Linux的移动设备操作系统，主要使用于移动设备\n谷歌在2007年发布了第一个测试版本的 Android 软件开发工具包（SDK），第一个商业版本的 Android 1.0，则发布于2008年9月。\nAndroid 应用程序一般使用 Android 软件开发工具包，采用 Java 语言来开发。\n版本 Android版本（版本代号）\n每个Android 版本对应一个Android SDK，可以类比JDK Android API版本：有利于设置和解决兼容性问题\nAndroid API级别官方说明\nAndroid版本和 Android API level的对应关系\nAndroid NKD\n工具链 背景：\n使用GCC编译，很多时候需要手动链接（只有标准库才默认链接） 当需要链接的文件很多时，一来每次在命令行中写一遍繁琐容易出错，二来无法使用增量编译 Makefile 背景：make命令根据编译规则进行编译，而且可以进行增量编译，makefile用于写编译规则\n简要语法：\n阮一峰make教程 简明make教程 GNU make/Makefile 简明实用教程 语法笔记\nmake：即制作出某个指定的文件（默认makefile中第一个文件）\n越是接近目标文件的命令，就越是要写在前面。因为程序是按照递归的方式进行依赖文件查找的，看到第一行有一个没见过的依赖文件，就往下一行进行查找，以此类推。 核心概念：目标target，前置条件prerequisite，命令command\n伪目标的使用\n伪目标是一个命令，且没有前置条件：比如clean，显式使用内置目标名指定为伪目标，主要用于执行命令\n伪目标是一个文件，但是前置条件有多个，且没有命令：比如生成多个文件\nCMake 背景： 当工程很大的时候，手写Makefile也不简单 Makefile与平台相关，无法实现跨平台 cmake：跨平台的项目管理工具，自动生成makefile文件，然后make构建 手写CMakeLists.txt文件，cmake生成Makefile，然后再make构建 cmake简要语法 指令大小写无关，变量大小写相关\n可以使用双引号将文件名或目录名包含其中\nadd_executable：将源文件编译成可执行文件\nadd_library：将源文件编译为库文件\n在构建时，静态库和动态库重名会导致后面的构建失败，参考 SET_TARGET_PROPERTIES：同时构建同名的静态库和动态库 aux_source_directory(\u0026lt;dir\u0026gt; \u0026lt;variable\u0026gt;)：将dir目录下所有源文件的文件名存放到variable变量中\nadd_subdirectory：包含一个子目录，该子目录中也有一个CMakeLists.txt文件和代码文件，它们也会被处理，同时可以指定编译输出（包含编译中间结果）的路径\nlink_directories：添加共享库搜索目录\nCMAKE_LIBRARY_PATH：设置库文件搜索目录，这不是cmake变量（需要在bash中设置），通过FIND_LIBRARY找到相应库文件 target_link_libraries(\u0026lt;target\u0026gt; \u0026lt;items\u0026gt;)：为库或可执行文件加入库链接\ninclude_directories：添加头文件搜索目录\nCMAKE_INCLUDE_PATH：设置头文件搜索目录，这不是cmake变量（需要在bash中设置），通过find_path找到相应头文件 target_include_directories：在编译目标文件时指定头文件\nfind_系列\nfind_package：加载外部库到项目中 configure_file：默认定义了一些编译选项的值\noption：添加编译选项（更准确是代码中的宏定义）\n变量\n创建变量：set()，获取变量的值：${variable}，调用环境变量：$ENV{} 追加变量的值：set(SRC_LIST ${SRC_LIST} test.cpp) PROJECT_NAME PROJECT_BINARY_DIR、CMAKE_BINARY_DIR：编译路径，当前工程的二进制路径（即编译产物会存放到该路径，一般为build所在路径） PROJECT_SOURCE_DIR、CMAKE_SOURCE_DIR：工程根目录，即顶层CMakeLists.txt文件的路径 EXECUTABLE_OUTPUT_PATH：编译生成的可执行文件的路径 LIBRARY_OUTPUT_PATH：编译生成的共享库文件的路径 最佳实践 项目配置 在源文件同级目录下建立目录build，在build中 cmake ..：将cmake得到的中间文件保存在build文件夹中，需要重新构建直接删除文件夹 make：构建，可以使用make clean清除中间文件，重新构建 ","permalink":"https://qinganzhang.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84%E7%A7%91%E6%99%AE%E5%92%8C%E6%A2%B3%E7%90%86/","summary":"指令集架构 指令集 说明了操作种类、指令格式（操作码和地址码，地址码个数，操作码定长与拓展）、寻址方式、地址空间大小和寄存器个数等。简单可以理解","title":"计算机架构科普和梳理"},{"content":"本地搭建博客 本地环境：windows10\n使用主题：PaperModX\n安装过程 安装Go并配置环境\n下载prebuilt版本的hugo\n注意hugo有普通版本和extended版本，最好使用extended版本，因为在使用PaperModX主题时，需要使用到extended版本（但是PaperMod主题使用普通版本就可以） 新建站点：hugo new site myblog\n下载主题：在myblog/themes/下git clone git@github.com:reorx/hugo-PaperModX.git\n也可以使用git submodule的方式添加主题，此时方便进行版本控制和管理 本地配置 myblog/下的配置文件参考sulvblog\u0026rsquo;s config.yaml和PaperModX example\u0026rsquo;s config.yaml进行配置，自己慢慢调吧（papermodx在papermod的基础上添加了一些特性，比如侧边目录）\n个人主要进行的修改有：\n在archetypes/posts.md中设定默认的meta内容 修改为posts、archive、search、tags、categories、about六个menu，其中posts、categories、tags在content下为目录，archive、search、about在content下为md文件 在文件夹下创建_index.md文件可以在里面添加Front Matter，用来设置当前文件夹下的meta信息 在配置时留意是posts还是post，是archive还是archives 加入数学公式的支持 但是当使用带有/begin{} /end{}的多行公式，或者多行公式中含有若干下划线时，此时可能无法正确渲染，我的解决办法是将没有正确渲染的多行数学公式放在\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;标签对中，这样在网页博客和本地typora中都可以正常显示。考虑到平时不怎么写复杂的多行数学公式，因此手动修改也不多。 在Hugo中优雅地使用数学公式中，博主的方法三自己编译一份加入了goldmark数学插件的hugo版本，但是注意编译过程中gcc版本不宜过高（我的gcc原来是8.1.0，编译不过，后来改到5.1.0，编译通过）。但是最终使用好像针对原生latex的多行公式支持不足（？不确定，可能是自己后面配置不正确？），最后没有使用这个方案 调整了主页中Welcome部分的高度，在themes/hugo-PaperModX/assets/css/common/main.css的.first-entry中min-height修改为80px 调整了页面中内容的宽度（原来侧边留空感觉有点多，可以适当减小），themes/hugo-PaperModX/assets/css/common/main.css的.main.post中添加right: 60px; 在themes/hugo-PaperModX/assets/css/common/post-single.css中调整h1~h6标题的高度 内容管理 写文章：hugo new posts/文章名称.md，注意写对md文件的路径\n本地预览：hugo server -D在localhost:1313上进行预览\n-D表示draft: true的内容在预览时展示 有时将draft改为false，使用hugo server进行预览时，对应文章没有出现，此时关掉PowerShell重开一个，重新运行一下命令 构建：hugo会将构建的网站内容保存到public文件夹中，默认只会向public中添加内容，而不会删除外部不存在但是public中还存在的文件\nhugo -F --cleanDestinationDir表示每次生成的public都是全新的，会覆盖原来的 --theme指定主题，--baseURL=\u0026quot;xxx\u0026quot;指定url 将内容发布到GitHub Pages上 将public文件夹转换为git库：\n进入到public文件夹，git init -b main 生成的默认主分支名字为main 将git库关联到远程库：\ngit remote add origin git@github.com:QinganZhang/QinganZhang.github.io.git 检查是否关联成功：cat .git/config 如果[remote \u0026quot;origin\u0026quot;]信息正常显示，说明本地git库已经成功关联到远程库 将修改commit到本地库\n1 2 3 git status # 查看当前修改状态 git add . # 添加所有修改过的文件，也可以只添加某个文件 git commit -m \u0026#34;add a new post\u0026#34; # 将修改push到远程库\ngit push -u origin main --force 报错： error: src refspec main does not match any 本地的branch为master，但是远程库默认branch是main，先将本地branch的名字修改为main git branch -m master main 报错： ! [rejected] main -\u0026gt; main (fetch first) 提交冲突，远程库和本地库不一致。通常出现在初始化仓库有readme而本地没有等情况。参考 git pull --rebase origin main 查看是否部署成功\n网页样式（css）丢失，但是内容还在，浏览器F12控制台报错：Failed to find a vlid digest in the 'integrity' attribute for source 'xxx.css' with computed SHA-256 integrity '***'. The resource has been blocked. （关键词：”integrity“）\n尝试方法一：解决 hugo 中关于 integrity 的错误，仍然出现原来的错误\n尝试方法二：解决Hugo无法加载css文件，仍然出现原来的错误，而且第一遍文章会覆盖在h1标题Posts上，\n最终方法：在themes/hugo-PaperModX/layouts/partial/head.html中，将\n1 2 3 4 5 6 {{- if not site.Params.assets.disableFingerprinting }} {{- $stylesheet := $stylesheet | fingerprint }} \u0026lt;link crossorigin=\u0026#34;anonymous\u0026#34; href=\u0026#34;{{ $stylesheet.RelPermalink }}\u0026#34; integrity=\u0026#34;{{ $stylesheet.Data.Integrity }}\u0026#34; rel=\u0026#34;preload stylesheet\u0026#34; as=\u0026#34;style\u0026#34;\u0026gt; {{- else }} \u0026lt;link crossorigin=\u0026#34;anonymous\u0026#34; href=\u0026#34;{{ $stylesheet.RelPermalink }}\u0026#34; rel=\u0026#34;preload stylesheet\u0026#34; as=\u0026#34;style\u0026#34;\u0026gt; {{- end }} 注释掉，只保留\u0026lt;link crossorigin=\u0026quot;anonymous\u0026quot; href=\u0026quot;{{ $stylesheet.RelPermalink }}\u0026quot; rel=\u0026quot;preload stylesheet\u0026quot; as=\u0026quot;style\u0026quot;\u0026gt;这一行。猜想可能是与使用的主题相关，但是暂时没有找到使用相同主题类似错误的信息。\n更多参考：Hugo - Failed to find a valid digest in the \u0026lsquo;integrity\u0026rsquo; attribute for resource - The resource has been blocked - Host on Github\n使用GitHub Actions自动构建博客 使用上面的方式（手动构建），在本地写好博客之后，然后使用hugo在本地构建好静态博客，生成public目录，最终是将public目录push到GitHub仓库，构建静态博客。\n还有一种方式，看起来更加高级，那就是基于GitHub Action自动构建博客。大致流程为：在本地写好博客之后，直接push到远程GitHub仓库，在远端而非本地构建博客。这个方式只是节省了自己使用hugo手动进行构建的这一步，但是如果当自己手工进行操作的步骤比较繁琐且固定时，使用GitHub Action自动化就很方便了。\n在实际配置过程中，这里使用了两个仓库。一个是private的myblog仓库，本地写好博客后就push到这个myblog仓库；另一个仓库是public的、作为GitHub Pages的仓库，myblog仓库使用GitHub Action自动进行构建，将最终得到的public文件就放到这个仓库中。下面简要介绍基于Github Action自动构建博客的过程，着重介绍与上面手动构架不同的地方。\n具体过程：\n在Github远程新建一个仓库，比如命名为myblog\n在本地使用hugo新建站点时（比如hugo new site myblog），在本地myblog目录下git init -b main，并且使用git remote add将本地的myblog目录关联到远程myblog仓库\n注意之前手动构建的方式中，是在public目录下git init，并关联到远程仓库的，而且该远程仓库即为Github Pages 在下载主题时，可以直接git clone源码，也可以使用git submodule的方式将主题作为子项目添加进来\n注意git submodule的子模块和原来的主模块是两个单独的项目，所以进入到子模块和主模块中进行git操作，是针对不同仓库的。Git Submodules介绍 但是这里想将主题添加进来，自己进行一些修改，因此使用了另一种方法将主题添加进来：git subtree，这样可以直接将子项目作为主仓库的一个目录添加进来 git subtree的使用 在myblog根目录下，创建.github/workflows/deploy.yaml，个人的deploy.yaml配置文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 name: deploy on: # 表示GitHub Action的触发条件（即push） push: branches: - main # 设定触发的分支为main workflow_dispatch: # 可以在Github项目仓库的Action工具栏手动调用 # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write jobs: # 表示GitHub Action的任务，这里定义了一个build的任务 build: runs-on: ubuntu-latest # 指定GitHub Action的运行环境 env: HUGO_VERSION: 0.122.0 steps: # 其中run表示执行的命令，uses时GitHub Action中的一个插件 - name: Checkout # 使用actions/checkout插件检出GitHub仓库 uses: actions/checkout@v2 # with: # submodules: false # 同时检出子模块 # fetch-depth: 0 # 完整检出所有历史记录 - name: Setup Hugo # 使用peaceiris/actions-hugo插件来安装Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.122.0\u0026#34; # 0.122.0 extended: true - name: Build Web # 运行hugo命令生成博客的静态文件 env: HUGO_ENVIRONMENT: production HUGO_ENV: production run: hugo --gc --minify # --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v2 with: path: ./public - name: Deploy Web # 使用peaceiris/actions-gh-pages插件将静态网页部署到GitHub Pages上 uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_BLOG_TOKEN }} # 个人访问令牌 EXTERNAL_REPOSITORY: QinganZhang/QinganZhang.github.io # 部署到的GitHub Pages仓库 PUBLISH_BRANCH: main # Github Pages分支 PUBLISH_DIR: ./public # hugo静态文件的目录 commit_message: ${{ github.event.head_commit.message }} # 提交更改时使用的提交消息 # cname: ${{ secrets.DOMAIN }} # 自定义域名，默认使用github pages域名 # reference1: https://blog.csdn.net/m0_51993913/article/details/132657065 # reference2: https://blog.csdn.net/freeking101/article/details/135515958使用Github Actions自动化部署部分 # reference3: https://github.com/reorx/hugo-PaperModX/blob/master/.github/workflows/gh-pages.yml 然后生成Token，参考\n因为需要从myblog仓库推送public目录到Github Pages仓库，所以需要向myblog仓库添加身份验证凭据 最后将本地博客push到myblog远程仓库，然后myblog远程仓库下使用GitHub Actions将public目录推送到Github Pages仓库中\n其他问题：\n如何将obsidian双链转换为HTML的\u0026lt;a\u0026gt;\u0026lt;/a\u0026gt;标签对？ 目前发现的一个方案是jekyll-wililinks，但是这个方案需要使用jeklly搭建静态博客 ","permalink":"https://qinganzhang.github.io/posts/hugo+github_pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","summary":"本地搭建博客 本地环境：windows10 使用主题：PaperModX 安装过程 安装Go并配置环境 下载prebuilt版本的hugo 注意hugo","title":"Hugo+Github Pages搭建个人博客"},{"content":"第十八章 用于大型程序的工具 18.1 异常处理 18.2 命名空间 命名空间定义 语法相关： 只要能出现在全局作用域的声明就能置于命名空间中 命名空间不能定义在函数或类内部 每个命名空间是一个作用域。 命名空间可以不连续，即同一命名空间可以定义为几个不同的部分，在多处出现 在头文件中声明命名空间中的成员，在源文件中定义命名空间中的成员 通常不将#include放在命名空间中，否则会将该头文件中的所有名字定义为该命名空间中的成员 几种命名空间 全局命名空间：使用::显式指明 嵌套命名空间 内联命名空间：无需使用该命名空间的前缀，通过外层命名空间就可以直接访问。 inline必须出现在命名空间第一次定义的地方，后续打开命名空间时可以不加inline 程序代码更新版本时经常使用内联空间，当前版本放在内联空间中，历史版本放在非内联空间中， 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* 文件名：FifthEd.h */ inline namespace FifthEd{ //定义第五版命名空间，是内联，使用时不需显式指定该空间的名字 class Query_base{/* 类的定义 */}; } /* 文件名：FourthEd.h */ namespace FourthEd{ //定义第四版命名空间 class Query_base{/* 类的定义 */}; } /* 文件名：cplusplus_primer.h */ namespace cplusplus_primer{ //将上面两个命名空间嵌套进外层空间 #include\u0026#34;FifthEd.h\u0026#34; //引入头文件中的所有名字 #include\u0026#34;FourthEd.h\u0026#34; } /* 文件名：main.cc */ #include\u0026#34;cplusplus_primer.h\u0026#34; using cplusplus_primer::Query_base; //默认使用第五版中的成员 using cplusplus_primer::FourthEd::Query_base; //手动指定第四版中的成员 未命名的命名空间 未命名的命名空间可以在一个文件内不连续（是同一个命名空间），但是不可跨越文件（否则是两个无关的命名空间） 未命名的命名空间中定义的变量拥有静态的声明周期：在第一次使用前创建，直到程序结束才销毁。 如果头文件中定义了未命名的命名空间，则不同源文件中包含了该头文件后，该空间中的名字对应不同实体 未命名的命名空间中的名字可以跨越到上一次作用域，因此定义在未命名的命名空间中的名字可以直接使用，不能对未命名的命名空间的成员使用作用域算符 应用：未命名的命名空间取代文件中的静态声明 原来将全局变量声明为static以转变为内部变量（C方式） 现在将全局变量放在未命名的命名空间中（C++方式，原因见上述语法），但是此时全局变量仍然是外部的， 使用命名空间成员 命名空间的别名：namespace new_name = old_name1::old_name2; 一个命名空间可以有多个别名，但不能在未定义命名空间之前就声明别名 using声明：using my_namespace::mem; 一次只能引入命名空间的一个成员 声明的名字的作用域与using语句本身的作用域一致 在类作用域中using声明只能声明基类成员 using指示：using nemespace my_namespace; 引入命名空间中所有名字 using指示将命名空间注入到外层作用域，即将命名空间中所有名字出现在最近的外层作用域中（相当于using声明的外层作用域） 不可出现在类作用域 命名空间污染： 使用了多个命名空间的using指示后，外层作用域中来自不同命名空间的名字可能发生冲突，这种冲突允许存在，但是使用时需要使用::明确指定版本 在头文件中，不要在全局作用域中使用using声明/指示，最多在函数、命名空间中使用 using指示引发的二义性错误只有在使用冲突名字的地方才会被发现，难以定位bug 尽量使用using声明而非using指示 类、命名空间与作用域 名字查找的例外：给函数传递类类型对象/引用/指针时，先在常规的作用域中查找函数名，随后还会在实参类（及其基类）所属的命名空间中查找函数名。 这个规则使得概念上作为接口一部分的非成员函数不需单独using声明就可被程序使用 例子：std::cin\u0026gt;\u0026gt;str;表达式中，作用域中没有声明operator\u0026gt;\u0026gt;()函数，但是仍可以使用，这是因为在istream（实参std::cin所属类）和string（实参str所属类）所在的命名空间中进行了查找。否则需要显式声明：using std::operator\u0026gt;\u0026gt;，使用operator\u0026gt;\u0026gt;(std::cin, str); 友元相关： 当类声明友元时，还需要在类外给出友元的正式声明 一个未声明的类/函数若第一次出现在友元声明中，则认为它是最近的外层命名空间的成员。 1 2 3 4 5 6 7 8 9 10 11 namespace A{ class C{ //这2个友元声明时还没有正式声明，认为它是最近的外层空间的成员，即隐式声明为空间A的成员 friend void f2(); //没有形参 friend void f(const C \u0026amp;); //接受C类型对象作为实参 }; } int main(){ A::C cobj; f(cobj); //对，f被隐式声明为A的成员，且实参决定会在A中查找函数f f2(); //错，虽然f2被隐式声明为A的成员，但未显式指明 } 重载与命名空间 using声明 using声明语句声明的是一个名字，而非特定的函数，也就是包括该函数的所有版本，都被引入到当前作用域中。 using声明引入的函数将重载该声明语句所属作用域中已有的同名函数。 using指示 若命名空间中函数名与外层作用域中函数同名，即使函数同名同参也不会报错，只需要使用时指明版本 18.3 多重继承与虚继承 多重继承 可以从多个基类中继承构造函数，但是这些构造函数必须形参列表不同 如果相同，则派生类必须为这种形参列表的构造函数定义自己的版本 类型转换与多个基类 在派生类向基类的转换中，如果有多个基类，编译器不会进行比较，转换到任何基类一样好 对象的指针/引用的静态类型决定了哪些成员可见 多重继承下的类作用域 在派生类中使用了某个名字，则程序并行的在多个基类中查找名字 派生类继承多个基类的同名成员合法，只是使用时需要::指明版本 派生类只是引入潜在的二义性，如果不调用该重名的对象，则不会报错 只有使用该重名对象时，才会产生二义性报错 该名字在多个基类中是形参列表不同的函数 该名字在一个基类中是private，而在另一个基类中是public/protected 该名字在一个基类中直接找到，而在另一个基类的间接基类中找到 避免这种二义性的方法是在派生类中再定义一次这个名字，覆盖基类名字，避免在基类中查找 当一个类拥有多个基类时，有可能出现派生类从两个或更多基类中继承了同名成员的情况。此时，不加前缀限定符直接使用该名字将引发二义性。 虚继承 背景：菱形继承中，间接基类应该只有一个，如果不使用虚继承，则间接基类在派生类对象中有两个部分 虚继承：令某个类做出声明，承诺愿意共享它的基类。被共享的基类子对象称为虚基类，不论虚基类在继承体系中出现了多少次，在派生类中都只包含唯一一个共享的虚基类子对象。 经常并不知道一个类是否会被继承多次，因此不知道由它而来的派生是否应该是虚派生 实际编程中，位于中间层次的类将其继承基类的方式声明为虚继承并不会出问题。虚派生只影响从虚基类的派生类中进一步派生出的类，它不影响虚基类的派生类。 语法相关： 在派生列表中添加virtual，表示后续的派生类共享虚基类的同一份实例 菱形继承：类B定义了成员x，D1和D2由B虚继承得到，D继承自D1和D2，则在D的作用域中，x通过两个基类都可见。若通过D的对象使用x，有几种可能： 若D1和D2中都未定义x，则x被解析为B的成员，不存在二义性。因为只在虚基类中有定义 若D1或D2其中之一定义了x，则x被解析为D1或D2的成员，不存在二义性。因为D1和D2是派生类，位于内层作用域，优先级更高 若D1和D2中都定义了x，则直接访问x时是二义性。因为D1和D2的优先级相同 解决二义性最好的方法就是在派生类中为成员自定义新的实例 构造函数与虚继承 在虚派生中，虚基类由最终的派生类在其构造函数初值列表中初始化（越过了继承链），而非由其直接派生类初始化，否则被重复初始化 只要创建了虚基类的派生类对象，该派生类的构造函数就会越过继承链初始化虚基类 含有虚基类的对象的构造顺序： 首先使用提供给最终派生类构造函数的初值来初始化虚基类（否则虚基类默认初始化） 一个类可有多个虚基类，这些虚基类的初始化顺序是它们在派生列表中的顺序 然后按照直接基类在派生列表中的顺序初始化非虚基类 构造派生类时，编译器按照直接基类的声明顺序对其依次检查，若基类中含有虚基类，则先构造虚基类，然后按照声明顺序逐一构造其他非虚基类 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch19-%E7%89%B9%E6%AE%8A%E5%B7%A5%E5%85%B7%E4%B8%8E%E6%8A%80%E6%9C%AF/","summary":"第十八章 用于大型程序的工具 18.1 异常处理 18.2 命名空间 命名空间定义 语法相关： 只要能出现在全局作用域的声明就能置于命名空间中 命名空间不能定义在函数或类","title":"Ch19 特殊工具与技术"},{"content":"第十八章 用于大型程序的工具 18.1 异常处理 18.2 命名空间 命名空间定义 语法相关： 只要能出现在全局作用域的声明就能置于命名空间中 命名空间不能定义在函数或类内部 每个命名空间是一个作用域。 命名空间可以不连续，即同一命名空间可以定义为几个不同的部分，在多处出现 在头文件中声明命名空间中的成员，在源文件中定义命名空间中的成员 通常不将#include放在命名空间中，否则会将该头文件中的所有名字定义为该命名空间中的成员 几种命名空间 全局命名空间：使用::显式指明 嵌套命名空间 内联命名空间：无需使用该命名空间的前缀，通过外层命名空间就可以直接访问。 inline必须出现在命名空间第一次定义的地方，后续打开命名空间时可以不加inline 程序代码更新版本时经常使用内联空间，当前版本放在内联空间中，历史版本放在非内联空间中， 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* 文件名：FifthEd.h */ inline namespace FifthEd{ //定义第五版命名空间，是内联，使用时不需显式指定该空间的名字 class Query_base{/* 类的定义 */}; } /* 文件名：FourthEd.h */ namespace FourthEd{ //定义第四版命名空间 class Query_base{/* 类的定义 */}; } /* 文件名：cplusplus_primer.h */ namespace cplusplus_primer{ //将上面两个命名空间嵌套进外层空间 #include\u0026#34;FifthEd.h\u0026#34; //引入头文件中的所有名字 #include\u0026#34;FourthEd.h\u0026#34; } /* 文件名：main.cc */ #include\u0026#34;cplusplus_primer.h\u0026#34; using cplusplus_primer::Query_base; //默认使用第五版中的成员 using cplusplus_primer::FourthEd::Query_base; //手动指定第四版中的成员 未命名的命名空间 未命名的命名空间可以在一个文件内不连续（是同一个命名空间），但是不可跨越文件（否则是两个无关的命名空间） 未命名的命名空间中定义的变量拥有静态的声明周期：在第一次使用前创建，直到程序结束才销毁。 如果头文件中定义了未命名的命名空间，则不同源文件中包含了该头文件后，该空间中的名字对应不同实体 未命名的命名空间中的名字可以跨越到上一次作用域，因此定义在未命名的命名空间中的名字可以直接使用，不能对未命名的命名空间的成员使用作用域算符 应用：未命名的命名空间取代文件中的静态声明 原来将全局变量声明为static以转变为内部变量（C方式） 现在将全局变量放在未命名的命名空间中（C++方式，原因见上述语法），但是此时全局变量仍然是外部的， 使用命名空间成员 命名空间的别名：namespace new_name = old_name1::old_name2; 一个命名空间可以有多个别名，但不能在未定义命名空间之前就声明别名 using声明：using my_namespace::mem; 一次只能引入命名空间的一个成员 声明的名字的作用域与using语句本身的作用域一致 在类作用域中using声明只能声明基类成员 using指示：using nemespace my_namespace; 引入命名空间中所有名字 using指示将命名空间注入到外层作用域，即将命名空间中所有名字出现在最近的外层作用域中（相当于using声明的外层作用域） 不可出现在类作用域 命名空间污染： 使用了多个命名空间的using指示后，外层作用域中来自不同命名空间的名字可能发生冲突，这种冲突允许存在，但是使用时需要使用::明确指定版本 在头文件中，不要在全局作用域中使用using声明/指示，最多在函数、命名空间中使用 using指示引发的二义性错误只有在使用冲突名字的地方才会被发现，难以定位bug 尽量使用using声明而非using指示 类、命名空间与作用域 名字查找的例外：给函数传递类类型对象/引用/指针时，先在常规的作用域中查找函数名，随后还会在实参类（及其基类）所属的命名空间中查找函数名。 这个规则使得概念上作为接口一部分的非成员函数不需单独using声明就可被程序使用 例子：std::cin\u0026gt;\u0026gt;str;表达式中，作用域中没有声明operator\u0026gt;\u0026gt;()函数，但是仍可以使用，这是因为在istream（实参std::cin所属类）和string（实参str所属类）所在的命名空间中进行了查找。否则需要显式声明：using std::operator\u0026gt;\u0026gt;，使用operator\u0026gt;\u0026gt;(std::cin, str); 友元相关： 当类声明友元时，还需要在类外给出友元的正式声明 一个未声明的类/函数若第一次出现在友元声明中，则认为它是最近的外层命名空间的成员。 1 2 3 4 5 6 7 8 9 10 11 namespace A{ class C{ //这2个友元声明时还没有正式声明，认为它是最近的外层空间的成员，即隐式声明为空间A的成员 friend void f2(); //没有形参 friend void f(const C \u0026amp;); //接受C类型对象作为实参 }; } int main(){ A::C cobj; f(cobj); //对，f被隐式声明为A的成员，且实参决定会在A中查找函数f f2(); //错，虽然f2被隐式声明为A的成员，但未显式指明 } 重载与命名空间 using声明 using声明语句声明的是一个名字，而非特定的函数，也就是包括该函数的所有版本，都被引入到当前作用域中。 using声明引入的函数将重载该声明语句所属作用域中已有的同名函数。 using指示 若命名空间中函数名与外层作用域中函数同名，即使函数同名同参也不会报错，只需要使用时指明版本 18.3 多重继承与虚继承 多重继承 可以从多个基类中继承构造函数，但是这些构造函数必须形参列表不同 如果相同，则派生类必须为这种形参列表的构造函数定义自己的版本 类型转换与多个基类 在派生类向基类的转换中，如果有多个基类，编译器不会进行比较，转换到任何基类一样好 对象的指针/引用的静态类型决定了哪些成员可见 多重继承下的类作用域 在派生类中使用了某个名字，则程序并行的在多个基类中查找名字 派生类继承多个基类的同名成员合法，只是使用时需要::指明版本 派生类只是引入潜在的二义性，如果不调用该重名的对象，则不会报错 只有使用该重名对象时，才会产生二义性报错 该名字在多个基类中是形参列表不同的函数 该名字在一个基类中是private，而在另一个基类中是public/protected 该名字在一个基类中直接找到，而在另一个基类的间接基类中找到 避免这种二义性的方法是在派生类中再定义一次这个名字，覆盖基类名字，避免在基类中查找 当一个类拥有多个基类时，有可能出现派生类从两个或更多基类中继承了同名成员的情况。此时，不加前缀限定符直接使用该名字将引发二义性。 虚继承 背景：菱形继承中，间接基类应该只有一个，如果不使用虚继承，则间接基类在派生类对象中有两个部分 虚继承：令某个类做出声明，承诺愿意共享它的基类。被共享的基类子对象称为虚基类，不论虚基类在继承体系中出现了多少次，在派生类中都只包含唯一一个共享的虚基类子对象。 经常并不知道一个类是否会被继承多次，因此不知道由它而来的派生是否应该是虚派生 实际编程中，位于中间层次的类将其继承基类的方式声明为虚继承并不会出问题。虚派生只影响从虚基类的派生类中进一步派生出的类，它不影响虚基类的派生类。 语法相关： 在派生列表中添加virtual，表示后续的派生类共享虚基类的同一份实例 菱形继承：类B定义了成员x，D1和D2由B虚继承得到，D继承自D1和D2，则在D的作用域中，x通过两个基类都可见。若通过D的对象使用x，有几种可能： 若D1和D2中都未定义x，则x被解析为B的成员，不存在二义性。因为只在虚基类中有定义 若D1或D2其中之一定义了x，则x被解析为D1或D2的成员，不存在二义性。因为D1和D2是派生类，位于内层作用域，优先级更高 若D1和D2中都定义了x，则直接访问x时是二义性。因为D1和D2的优先级相同 解决二义性最好的方法就是在派生类中为成员自定义新的实例 构造函数与虚继承 在虚派生中，虚基类由最终的派生类在其构造函数初值列表中初始化（越过了继承链），而非由其直接派生类初始化，否则被重复初始化 只要创建了虚基类的派生类对象，该派生类的构造函数就会越过继承链初始化虚基类 含有虚基类的对象的构造顺序： 首先使用提供给最终派生类构造函数的初值来初始化虚基类（否则虚基类默认初始化） 一个类可有多个虚基类，这些虚基类的初始化顺序是它们在派生列表中的顺序 然后按照直接基类在派生列表中的顺序初始化非虚基类 构造派生类时，编译器按照直接基类的声明顺序对其依次检查，若基类中含有虚基类，则先构造虚基类，然后按照声明顺序逐一构造其他非虚基类 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch18-%E7%94%A8%E4%BA%8E%E5%A4%A7%E5%9E%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%B7%A5%E5%85%B7/","summary":"第十八章 用于大型程序的工具 18.1 异常处理 18.2 命名空间 命名空间定义 语法相关： 只要能出现在全局作用域的声明就能置于命名空间中 命名空间不能定义在函数或类","title":"Ch18 用于大型程序的工具"},{"content":"第十六章 模板和泛型编程 16.1 定义模板 模板参数列表：\u0026lt;\u0026gt; 模板参数（也称(模板)类型参数）：T typename或class（作用相同），用来表示模板参数 模板非类型参数：模板参数列表中表示一个值而非一个类型 函数模板 模板实例化时，可以使用[[ch16-模板和泛型编程#函数模板显式实参|显式实参]]，根据实参[[ch16-模板和泛型编程#类型转换与模板类型参数|隐式推断模板参数类型]] 模板非类型参数： 可以是一个整型、指针或左值引用 实例化时，整型实参必须是常量表达式，指针/引用指向的对象必须有静态的生存周期（即对象不能是非static局部变量或动态对象），这样做可以使编译器在编译时实例化模板 使用场景：比如数组类型作为模板参数时大小固定，但是使用模板非类型参数就不必固定 1 2 3 4 template \u0026lt;typename T, unsigned N, unsigned M\u0026gt; inline T compare(const char (\u0026amp;r1)[N], const char (\u0026amp;r2)[M]) { return strcmp(r1, r2); } inline或constexpr的函数模板：模板参数列表之后，返回类型之前 模板编译 只有模板实例化时，编译器才生成代码 通常将类定义和函数声明放在头文件中，其实现放在源文件中；但是，函数模板和类模板成员函数的实现通常也放在头文件中。因为编译器知道模板的完整定义后才能进行实例化 大多数模板的编译错误在实例化期间才报告 类模板 使用类模板必须提供显式模板参数列表，编译器不能推断模板参数类型 一个类模板的成员函数只有当程序用到它时，才进行实例化 使用类模板类型时必须提供模板参数，只有在类模板作用域内部才可以只使用模板名而不提供实参 友元相关，例子 如果一个类模板包含一个非模板友元，则友元可以访问该类模板的所有实例 如果一个类模板包含一个模板友元，则类可以授权给所有友元模板实例，也可以只授权给特定实例 一对一友好关系：友好关系被限定在相同类型的友元和类本身之间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 template\u0026lt;typename\u0026gt; class Fri; template\u0026lt;typename\u0026gt; class MyClass; template\u0026lt;typename T\u0026gt; bool operator== (const MyClass\u0026lt;T\u0026gt;\u0026amp;, const MyClass\u0026lt;T\u0026gt;\u0026amp;); template\u0026lt;typename T\u0026gt; class MyClass{ friend class Fri\u0026lt;T\u0026gt;; // 比如Fri\u0026lt;int\u0026gt;实例可以访问MyClass\u0026lt;int\u0026gt;实例 friend bool operator==(const MyClass\u0026lt;T\u0026gt;, const MyClass\u0026lt;T\u0026gt;); // 友元函数，重载== public: MyClass() {}; MyClass(const MyClass\u0026amp; m): v(m.v) {} void push_back(T val) { v.push_back(val); } MyClass clone(); // 处于类模板作用域中，编译器会将MyClass当作是MyClass\u0026lt;T\u0026gt; private: vector\u0026lt;T\u0026gt; v; }; template\u0026lt;typename T\u0026gt; MyClass\u0026lt;T\u0026gt; MyClass\u0026lt;T\u0026gt;::clone() { return MyClass(*this); } template\u0026lt;typename T\u0026gt; class Fri{ public: // 一对一友好关系，Fri\u0026lt;T\u0026gt;是MyClass\u0026lt;T\u0026gt;的友元 void size(MyClass\u0026lt;T\u0026gt; m) { cout\u0026lt;\u0026lt;m.v.size()\u0026lt;\u0026lt;endl; } // 但是Fri\u0026lt;T\u0026gt;就不是MyClass\u0026lt;K\u0026gt;的友元(T!=K) void func(MyClass\u0026lt;int\u0026gt; m) { cout\u0026lt;\u0026lt;m.v.size()\u0026lt;\u0026lt;endl; } }; int main(){ MyClass\u0026lt;char\u0026gt; char_class; MyClass\u0026lt;int\u0026gt; int_class; Fri\u0026lt;char\u0026gt; fri; fri.size(char_class); // fri.func(int_class); } 通用和特定的模板友好关系：一个类可以将另一个模板的每个实例都声明为为自己的友元，或者限定特定的实例为友元 1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T\u0026gt; class Fri; class Common{ // 普通类 template\u0026lt;typename K\u0026gt; friend class Pal; // 【Pal的所有实例】都是类Common的友元，此时Fri可以不用提前声明 }; template\u0026lt;typename T\u0026gt; class MyClass{ // 模板类 friend class Fri\u0026lt;T\u0026gt;; // 一对一友元 template\u0026lt;typename K\u0026gt; friend class MyFri; // 【MyPal的所有实例】都是MyClass每个实例的友元，此时MyPal可以不用提前声明，且声明中使用了不同的模板参数 friend class Commom_fri; // 普通类作为模板类的友元，此时不需要提前声明 }; 虽然友元通常是类或函数，但是允许将模板类型参数T作为友元，因此类型T的对象可以访问类模板的private成员。例子。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; using namespace std; template\u0026lt;typename T\u0026gt; class MyClass{ friend T; // 类型T是MyClass的友元 private: void private_func() { cout\u0026lt;\u0026lt;\u0026#34;private func of MyClass \u0026#34;\u0026lt;\u0026lt;endl; } }; class Test{ public: void func(){ test.private_func(); } private: MyClass\u0026lt;Test\u0026gt; test; // 类型Test是MyClass的友元，Test类型的对象可以访问【类模板MyClass基于Test类型的实例】的private成员 }; int main(){ Test t; t.func(); } 模板类型别名 为类模板的实例创建别名：typedef MyClass\u0026lt;int\u0026gt; MC; 为类模板定义别名： 1 2 3 template\u0026lt;typename K, typename V\u0026gt; using p = std::pair\u0026lt;K, V\u0026gt;; template\u0026lt;typename K\u0026gt; using p = std::pair\u0026lt;K, std::string\u0026gt;; // 固定一个类型 template\u0026lt;typename T\u0026gt; using p = std::pair\u0026lt;T, T\u0026gt;; 类模板的static成员 相同类型类模板的实例的static成员是共享的，不同类型之间类模板的实例的static成员是不同的 模板参数 模板内不能重用模板参数名，且同一个模板参数名T在同一个模板参数列表中只能出现一次 声明中的模板参数不必与定义中的模板参数相同，且模板声明通常一起放在文件开始位置（使用模板的代码之前） 使用T::mem，无法判断mem是类型T的static成员还是类型T的类型成员 普通类中编译器已知类的定义因此可以判断 默认T::mem访问的是static成员 使用typename显式说明访问的是类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Person{ public: using age = std::size_t; // 类型成员 static std::string name; // static成员 }; std::string Person::name = \u0026#34;zhang\u0026#34;; template\u0026lt;typename T\u0026gt; class MyClass{ public: typename T::age func(){ // 显式说明T::age是一个类型而非static成员 std::cout\u0026lt;\u0026lt;T::name\u0026lt;\u0026lt;std::endl; // 默认T::name是static成员 typename T::age myAge = 10; return myAge; } }; 默认模板实参：默认模板实参都在最右侧，对函数模板和类模板都可以提供默认模板实参 成员模板 成员模板：普通类或模板类的成员函数是模板函数，成员模板不能是虚函数 普通类的成员模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; using namespace std; class MyClass{ // 普通类中包含成员模板 public: template\u0026lt;typename T\u0026gt; void func(T); }; // 普通类中的成员模板 template\u0026lt;typename T\u0026gt; void MyClass::func(T t){ cout\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } template\u0026lt;typename T\u0026gt; class Test{ public: void func(T); }; // 对比模板类中的普通成员函数 template\u0026lt;typename T\u0026gt; void Test\u0026lt;T\u0026gt;::func(T t){ cout\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } int main(){ MyClass myClass; myClass.func\u0026lt;int\u0026gt;(1); // 普通类中的成员模板 Test\u0026lt;int\u0026gt; test; test.func(2); // 模板类中的普通函数 } 类模板的成员模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; template\u0026lt;typename T\u0026gt; class MyClass{ public: MyClass() {} template\u0026lt;typename K\u0026gt; MyClass(K k) {cout\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; typeid(K).name()\u0026lt;\u0026lt;endl;} template\u0026lt;typename H\u0026gt; void func(H); }; template\u0026lt;typename T\u0026gt; // 类模板的模板参数列表 template\u0026lt;typename H\u0026gt; // 类模板的成员模板的模板参数列表 void MyClass\u0026lt;T\u0026gt;::func(H h){ cout\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; typeid(H).name()\u0026lt;\u0026lt;endl; } int main(){ MyClass\u0026lt;int\u0026gt; myClass(\u0026#39;k\u0026#39;); // 显式提供T=int, 隐式推断K=char myClass.func(3.14); // 隐式推断H=double myClass.func\u0026lt;string\u0026gt;(\u0026#34;str\u0026#34;); // 显式提供H=string } 显式实例化 背景：模板只有使用时才被实例化，因此相同的实例可能出现在多个文件中，造成额外开销 显式实例化 当编译器遇到extern模板声明时，不会在本文件中生成模板的实例化代码，表示使用其他位置的实例化代码 extern声明必须出现在使用此实例化版本的代码之前，否则编译器进行实例化，起不到外部定义的效果 显式实例化定义会实例化所有成员 1 2 3 4 5 6 7 // 在a.cpp中 extern template class MyClass\u0026lt;int\u0026gt;; // 实例化声明 extern template int compare\u0026lt;const int\u0026amp;, const int\u0026amp;\u0026gt;; // 在b.cpp中 template class MyClass\u0026lt;int\u0026gt;; // 实例化定义 template int compare(const int\u0026amp;, const int\u0026amp;); 效率与灵活性 shared_ptr在运行时绑定删除器，因此删除器保存为一个指针而不是一个成员，因此删除器的类型直到运行时才直到，而且可以随时改变删除器的类型 需要间接调用删除器，但是用户重载删除器的操作更加便捷（只需要传入一个可调用对象） unique_ptr在编译期绑定删除器，删除器的类型是类类型的一部分（因此删除器类型在编译器是已知的），从而删除器可以直接保存在成员中 避免了间接调用删除器的运行时开销 16.2 函数模板实参推断 可以[[ch16-模板和泛型编程#类型转换与模板类型参数|基于实参推导模板参数类型]]，也可以[[ch16-模板和泛型编程#函数指针和实参推断|函数指针指向函数模板推导模板参数类型]] 有时比如返回值类型无法推导出来，可以指定[[ch16-模板和泛型编程#函数模板显式实参|模板显式实参]]，也可以使用[[ch16-模板和泛型编程#尾置返回类型与类型转换|尾置返回类型]]（同时可以[[ch16-模板和泛型编程#尾置返回类型后进行类型转换|去除引用]]） 当模板类型T为引用时，需要依据实参是左值/右值来判断T的引用类型，而且可以使用完美转发保持实参的类型不变 类型转换与模板类型参数 模板实参推断：根据实参类型推断出模板参数T的类型 一般T就是实参类型 编译器会对以下几种实参进行类型转换，得到的T并不完全是实参类型 顶层const会被忽略 可以将非const对象的指针或引用传递给一个const的指针或引用形参 如果形参不是引用类型，数组名/函数名转换为指针类型 template\u0026lt;typename T\u0026gt; void func(T a, T b);中，a和b推断的类型必须相同 函数模板显式实参 背景：类型T只出现在返回值/函数体，不在形参列表中时，编译器无法推断出模板实参的类型： 函数模板显式实参从左到右进行对应，如果模板参数可以推导出来，放在模板参数列表右侧，实例化时可以进行推导 当显式指定实参时，对实参可以使用正常的类型转换 1 2 3 4 5 6 7 template \u0026lt;typename T1, typename T2, typename T3\u0026gt; T1 sum(T2, T3); // T1在返回值中 int a = 1; double = 2.0; auto result = sum\u0026lt;long long\u0026gt;(a, b); // T1类型是long long, T2、T3类型可以推导出来，放在右侧 auto test = sum\u0026lt;long long, long long\u0026gt;(a, b); // T2类型显式指定为long long，因此将a转换为long long型 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); int cmp = compare\u0026lt;long long\u0026gt;(a, b); // 使用显式模板实参，a、b都转换为long long类型 尾置返回类型与类型转换 尾置返回类型 背景：有时函数模板的返回值类型不能由实参推导而来，比如[[ch16-模板和泛型编程#函数模板显式实参|函数模板显式实参]]的背景 可以使用函数模板显式实参进行指定，也可以使用尾置返回类型自动推导 1 2 3 4 template \u0026lt;typename Iter\u0026gt; auto func(Iter beg, Iter end) -\u0026gt; decltype(*beg){ // 从局部变量中推导出返回类型 return *beg; } 尾置返回类型后进行类型转换 背景：通过模板显式实参可以指定返回值类型，但是通过尾置返回类型推导得到的类型可能不是想要的，比如有时不希望得到引用类型 标准库的类型转换模板 定义在头文件type_traits中，常用于模板元程序设计 Mod是一个类模板，将类型T转换为类型type；如果无法转化，则类型type 1 2 3 4 template \u0026lt;typename Iter\u0026gt; auto func(Iter beg, Iter end) -\u0026gt; typename remove_reference\u0026lt;decltype(*beg)\u0026gt;::type{ // 表明type是一个类型而非一个static成员 return *beg; } Mod T Mod\u0026lt;T\u0026gt;::type remove_reference X\u0026amp;或X\u0026amp;\u0026amp; X 否则 T add_const X\u0026amp;或const X或函数 T 否则 const T add_lvalue_reference X\u0026amp; T X\u0026amp;\u0026amp; X\u0026amp; 否则 T\u0026amp; add_rvalue_reference X\u0026amp;或X\u0026amp;\u0026amp; T 否则 T\u0026amp;\u0026amp; remove_pointer X* X 否则 T add_pointer X\u0026amp;或X\u0026amp;\u0026amp; X* 否则 T* make_signed unsigned X X 否则 T make_unsigned 带符号类型 unsigned X 否则 T remove_extent X[n] X 否则 T remove_all_extents X[n1][n2]... X 否则 T 函数指针和实参推断 将函数模板赋值给函数指针： 函数指针指向函数模板的一个实例 使用函数指针的类型来推断模板实参 1 2 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); int (*f)(const int\u0026amp;, const int\u0026amp;) = compare; // T是int，f指向函数模板的实例compare(const int\u0026amp;, const int\u0026amp;) 如果函数func的形参是函数指针，实参可以传入函数模板，这样函数指针指向一个模板实例且进行了参数推断 但是当func有多个重载的版本时（接受不同类型的函数指针），传入函数模板可能产生歧义，此时可以指定【显式模板实参】 1 2 3 4 5 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); void func(int(*fp)(const int\u0026amp;, const int\u0026amp;)); void func(int(*fp)(const std::string\u0026amp;, const std::string\u0026amp;)); // 重载 // func(compare); // 歧义：函数模板compare实例化为哪一种函数指针？ func(compare\u0026lt;int\u0026gt;); 模板实参推断和引用 模板参数T\u0026amp;的类型推断 模板类型参数 实参要求 例子 T\u0026amp; 必须传递一个左值 实参为int，T为int;实参为const int，T为const int const T\u0026amp; 可以传递左值或右值 实参为int, const int, const int\u0026amp;\u0026amp;，T都为int T\u0026amp;\u0026amp; 必须传递一个右值 实参为int\u0026amp;\u0026amp;， T为int T\u0026amp;\u0026amp; 例外：传递一个类型为type的左值，推导T为type\u0026amp;类型 实参为int\u0026amp;,T为int\u0026amp; 引用折叠 背景：基于上面这个例外，创造出了引用的引用，或者通过类型别名也可以创造出引用的引用，可以将多个引用折叠为一个引用 引用折叠规则： type\u0026amp; \u0026amp;、 type\u0026amp; \u0026amp;\u0026amp;、 type\u0026amp;\u0026amp; \u0026amp;折叠为type \u0026amp; type\u0026amp;\u0026amp; \u0026amp;\u0026amp;折叠为T\u0026amp;\u0026amp; 使用： 若函数形参是T\u0026amp;\u0026amp;，则可以传递一个左值（实参的const属性可以保持，因为是底层const） 如果传入的是左值type\u0026amp;，推导出T=type\u0026amp; 万能引用（或称为模板类型参数右值引用）：函数形参为T\u0026amp;\u0026amp;时，传递左值/右值均可 使用万能引用导致只有在运行时才能确定形参是左值还是右值，使得模板的编写变得困难 通常在两种情况中使用万能引用：模板转发实参，模板重载 使用万能引用的形参通常重载为两个版本： 拷贝版本：template\u0026lt;typename T\u0026gt; void f(const T\u0026amp;) 绑定到左值和const右值 移动版本：template\u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp;) 绑定到非const右值 std::move [[ch13-拷贝控制#^d3a2a0|std::move函数]]的定义： 1 2 3 4 template \u0026lt;typename T\u0026gt; typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp; move(T\u0026amp;\u0026amp; t) { return static_cast\u0026lt;typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp;\u0026gt;(t); } 可以使用static_cast显式地将左值转换为右值引用 转发 背景：比如函数f内部调用函数g时，可能需要将f的实参传递给g，而且同时要求保持实参性质不变（比如const属性，左值/右值属性） 即希望达到这样的效果：将实参传递给f，再传递给g，与实参直接传递给g，的效果等价 例子一：f形参类型是非引用，g形参类型是左值引用，传入一个左值引用，则此时f转发参数给g时会使用自己的拷贝而非原来的引用 例子二：f形参类型是万能引用T\u0026amp;\u0026amp;，g形参类型是右值引用，f可以接受右值（或左值），此时f转发参数给g时，使用的右值引用本身是一个左值，不能传参给g的右值引用 比较：都是定义在utility中的函数模板，最好显式指明是std::中的 std::forward：可指定模板参数，并且可以对返回值使用引用折叠来保留左右值属性 std::move：返回值一定是右值引用 使用：完美转发 通过万能引用在传入外层f时保留实参的全部属性 通过std::forward在传入内层函数g时再次保留实参的全部属性 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(T \u0026amp;\u0026amp;arg){ // 万能引用 g(std::forward\u0026lt;T\u0026gt;(arg)); // std::forward\u0026lt;T\u0026gt;的返回类型是T\u0026amp;\u0026amp; }; 如果实参是左值，推导出T=type\u0026amp;，std::forward\u0026lt;T\u0026gt;的返回类型T\u0026amp;\u0026amp;折叠为type\u0026amp; 如果实参是右值，推导出T=type，std::forward\u0026lt;T\u0026gt;的返回类型即为type\u0026amp;\u0026amp; 例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; using namespace std; template\u0026lt;typename F, typename T, typename K\u0026gt; void flip(F f, T \u0026amp;\u0026amp;t, K \u0026amp;\u0026amp;k){ f( std::forward\u0026lt;K\u0026gt;(k), std::forward\u0026lt;T\u0026gt;(t) ); } template\u0026lt;typename K, typename T\u0026gt; void g(K\u0026amp;\u0026amp; k, T\u0026amp;\u0026amp; t) { cout\u0026lt;\u0026lt;typeid(K).name()\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;k\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } void f(int \u0026amp;\u0026amp;k, int \u0026amp;t) { cout\u0026lt;\u0026lt;k\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } int main(){ int t = 2; flip(f, t, 3); // F=void(*)(int\u0026amp;\u0026amp;, int\u0026amp;), T=int\u0026amp;, K=int flip(g\u0026lt;int, int\u0026amp;\u0026gt;, t, 3); // F=void(*)(int\u0026amp;\u0026amp;, int\u0026amp;), T=int\u0026amp;, K=int } 16.3 重载与模板 函数模板可以被另一个函数模板或普通函数重载 [[ch06-函数#6.6 函数匹配|函数的重载与匹配]]：有一些重载的函数，根据实参情况，调用时用哪个函数？ 函数模板的重载与匹配：有一些重载的函数模板和普通函数，根据实参情况（函数模板进行函数模板实参推断），实例化并调用哪个函数模板 到函数模板的函数匹配规则（[[ch06-函数#6.6 函数匹配|普通函数匹配的拓展]]） 确定候选函数：同名的函数，包括实参推断成功的函数模板实例 确定可行函数：参数类型和数量都匹配， 候选的函数模板实例都是可行的，因为实参推断会排除掉不可行的模板 按照类型转换进行排序，寻找最佳匹配（普通函数和函数模板实例都可能发生类型转换，只是应用于函数模板的[[ch16-模板和泛型编程#类型转换与模板类型参数|类型转换]]十分有限） 若恰有一个函数提供比其他函数都好的匹配，则选择它 如果多个函数都提供相同级别的匹配 非模板和模板重载：如果只有一个是非模板函数，选择非模板函数 多个可行模板：如果没有非模板函数（有多个函数模板），选择最特例化的函数模板（特例化：比如T\u0026amp;可以匹配任意类型，T*只能匹配指针类型） 调用有歧义，失败 最佳实践：在定义重载函数之前，应该先声明所有重载的版本，否则可能重载一个模板函数进行实例化（因为没有找到想使用的版本，使用函数模板进行实例化），编译期不会报错，但是运行期会调用不期望使用的版本 16.4 可变参数模板 可变参数模板就是一个接受可变数目参数的模板函数或模板类，可变数目的参数被称为参数包 模板参数包：表示零个或多个模板参数（模板类型参数或模板非类型参数） typename后跟...表示模板类型参数包 类型名后跟...表示模板非类型参数包 函数参数包：表示零个或多个函数参数。 sizeof...运算符：返回参数包中的元素数量，且不会对其实参求值（类似于sizeof） 1 2 3 4 template\u0026lt;typename T, typename... Args\u0026gt; // 模板参数包：Args是模板类型参数包 void func(const T \u0026amp;t, const Args\u0026amp; ... rest){ // 函数参数包：rest是函数参数包（其类型是模板参数包Args） cout\u0026lt;\u0026lt;sizeof...(Args)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;sizeof...(rest)\u0026lt;\u0026lt;endl; } 编写可变参数函数模板 [[ch06-函数#可变形参|可变形参]]initializer_list可以接受可变数目实参，但是需要是相同类型的 可变参数函数通常是递归的 第一步调用处理参数包中的第一个实参，然后用剩余实参调用自身 还需要定义一个非可变参数的函数（因为函数匹配时会使用这个更加特例化的版本，而不是使用0个参数的可变参数模板的实例），来处理参数包中最后一个实参 1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;typename T\u0026gt; ostream \u0026amp;print(ostream \u0026amp;os, const T \u0026amp;t) // 打印最后一个元素，用来终止递归，必须在可变参数版本的print定义之前声明 { return os \u0026lt;\u0026lt; t; } template \u0026lt;typename T, typename... Args\u0026gt; ostream \u0026amp;print(ostream \u0026amp;os, const T \u0026amp;t, const Args\u0026amp;... rest) { os \u0026lt;\u0026lt; t \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; return print(os, rest...); // 递归调用，实参是将除了第一个，剩余的参数 } 包扩展 扩展...：将参数包分解为单个元素，每个元素应用模式，得到拓展后的列表 常用情况： const Args\u0026amp; ...：将模板参数包Args中所有类型T都扩展为const T\u0026amp; args...：将函数参数包args扩展为参数列表 f(args)...：对函数参数包args中每个元素调用函数f 1 2 3 4 template\u0026lt;typename... Args\u0026gt; ostream\u0026amp; msg(ostream\u0026amp; os, const Args\u0026amp;... rest){ // 扩展模板参数包 return print(os, debug_reg(rest)...); // 扩展函数参数包 } 转发参数包 组合使用可变参数模板和forward机制，实现将可变参数的完美转发，例子：emplace_back 如果同时存在模板参数包和函数参数包，则同时拓展： f\u0026lt;Args\u0026gt;(args)...等价于f\u0026lt;Args1\u0026gt;(args1), f\u0026lt;Args2\u0026gt;(args2), ... 1 2 3 4 template\u0026lt;typename... Args\u0026gt; void func(Args\u0026amp;\u0026amp;... args){ work(std::forward\u0026lt;Args\u0026gt;(args)...); }; 16.5 模板特例化（Specializations） 背景和例子：对于某个类型，不想用（对特定类型可以做优化）或者不能用（对特定类型的使用并非预期）模板 定义函数模板特例化 必须为原模板中每个模板参数都提供实参（全特例化） 关键字template后面跟一个空尖括号对（\u0026lt;\u0026gt;），表示所有模板参数都已被指定 特例化版本的参数类型必须与一个先前声明的模板中对应的类型相匹配。 1 2 3 4 5 template \u0026lt;typename T\u0026gt; bool compare(const T\u0026amp;, const T\u0026amp;) {} template \u0026lt;\u0026gt; bool compare(const char* const \u0026amp;, const char* const \u0026amp;); // T为const char* 函数重载与模板特例化 特例化的本质是实例化一个模板，而不是重载它。因此特例化不影响[[ch16-模板和泛型编程#16.3 重载与模板|函数的匹配规则]]，即非模板函数先，再是特例化版本的函数（模板的实例化），最后是函数模板的实例 最佳实践：模板及其特例化版本应该声明在同一个头文件中。所有同名模板的声明应该放在前面，然后是特例化版本。 1 2 3 4 5 6 7 template \u0026lt;typename T\u0026gt; void compare(const T\u0026amp; l, const T\u0026amp; r); template \u0026lt;\u0026gt; void compare(const char* const \u0026amp;l, const char* const \u0026amp;r); // 特例化版本，T为const char* void compare(const char* const \u0026amp;l, const char* const \u0026amp;r); // 普通函数 类模板特例化 必须在原模板定义所在的命名空间中进行类模板特例化 类模板可以进行部分特例化（偏特例化），得到的是模板；也可以全部特例化（全特例化），得到的是实例 类模板的部分特例化 未完全确定类型的模板参数仍放在\u0026lt;\u0026gt;中，即偏特化的模板参数列表非空。使用时也需提供模板实参，这些实参与原始模板中的参数按位置对应 部分特例化的模板参数列表是原始模板参数列表的一个子集或者特例化版本 例子：标准库remove_reference类型是通过一系列的特例化版本来完成其功能的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 //原始的、最通用的版本，可用于任意类型实例化 template\u0026lt;typename T\u0026gt; struct remove_reference { typedef T type; }; //部分特例化版本 template\u0026lt;typename T\u0026gt; struct remove_reference\u0026lt;T\u0026amp;\u0026gt; { //针对于左值引用的 typedef T type; }; template\u0026lt;typename T\u0026gt; struct remove_reference\u0026lt;T\u0026amp;\u0026amp;\u0026gt; { //针对于右值引用的 typedef T type; }; int i; //调用原始模板 remove_reference\u0026lt;decltype(42)\u0026gt;::type a; //decltype(i)==int\u0026amp;，调用第一个（T\u0026amp;）部分特例化版本 remove_reference\u0026lt;decltype(i)\u0026gt;::type b; //decltype(std::move(i))==int\u0026amp;\u0026amp;，调用第二个（T\u0026amp;\u0026amp;）部分特例化版本 remove_reference\u0026lt;decltype(std::move(i))\u0026gt;::type c; //a、b、c均为int 特例化成员函数而不是整个类 使用模板的实例调用成员时，若该实例的模板实参与特化该成员时的参数一致，则调用特化版本的成员 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 template\u0026lt;typename T\u0026gt; struct Foo { Foo(const T \u0026amp;t = T()) :mem(t) {} void Bar() {std::cout\u0026lt;\u0026lt;1\u0026lt;\u0026lt;std::endl;} //通用的Bar()函数 T mem; }; //特例化Foo\u0026lt;int\u0026gt;版本的的成员Bar template\u0026lt;\u0026gt; void Foo\u0026lt;int\u0026gt;::Bar() {std::cout\u0026lt;\u0026lt;2\u0026lt;\u0026lt;std::endl;} int main(){ Foo\u0026lt;std::string\u0026gt; fs; fs.Bar(); //使用Foo\u0026lt;string\u0026gt;的通用的Bar() Foo\u0026lt;int\u0026gt; fi; fi.Bar(); //使用Foo\u0026lt;int\u0026gt;的特例化的Bar() } ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch17-%E6%A0%87%E5%87%86%E5%BA%93%E7%89%B9%E6%AE%8A%E8%AE%BE%E6%96%BD/","summary":"第十六章 模板和泛型编程 16.1 定义模板 模板参数列表：\u0026lt;\u0026gt; 模板参数（也称(模板)类型参数）：T typename或class（作用相同），","title":"Ch17 标准库特殊设施"},{"content":"第十六章 模板和泛型编程 16.1 定义模板 模板参数列表：\u0026lt;\u0026gt; 模板参数（也称(模板)类型参数）：T typename或class（作用相同），用来表示模板参数 模板非类型参数：模板参数列表中表示一个值而非一个类型 函数模板 模板实例化时，可以使用[[ch16-模板和泛型编程#函数模板显式实参|显式实参]]，根据实参[[ch16-模板和泛型编程#类型转换与模板类型参数|隐式推断模板参数类型]] 模板非类型参数： 可以是一个整型、指针或左值引用 实例化时，整型实参必须是常量表达式，指针/引用指向的对象必须有静态的生存周期（即对象不能是非static局部变量或动态对象），这样做可以使编译器在编译时实例化模板 使用场景：比如数组类型作为模板参数时大小固定，但是使用模板非类型参数就不必固定 1 2 3 4 template \u0026lt;typename T, unsigned N, unsigned M\u0026gt; inline T compare(const char (\u0026amp;r1)[N], const char (\u0026amp;r2)[M]) { return strcmp(r1, r2); } inline或constexpr的函数模板：模板参数列表之后，返回类型之前 模板编译 只有模板实例化时，编译器才生成代码 通常将类定义和函数声明放在头文件中，其实现放在源文件中；但是，函数模板和类模板成员函数的实现通常也放在头文件中。因为编译器知道模板的完整定义后才能进行实例化 大多数模板的编译错误在实例化期间才报告 类模板 使用类模板必须提供显式模板参数列表，编译器不能推断模板参数类型 一个类模板的成员函数只有当程序用到它时，才进行实例化 使用类模板类型时必须提供模板参数，只有在类模板作用域内部才可以只使用模板名而不提供实参 友元相关，例子 如果一个类模板包含一个非模板友元，则友元可以访问该类模板的所有实例 如果一个类模板包含一个模板友元，则类可以授权给所有友元模板实例，也可以只授权给特定实例 一对一友好关系：友好关系被限定在相同类型的友元和类本身之间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 template\u0026lt;typename\u0026gt; class Fri; template\u0026lt;typename\u0026gt; class MyClass; template\u0026lt;typename T\u0026gt; bool operator== (const MyClass\u0026lt;T\u0026gt;\u0026amp;, const MyClass\u0026lt;T\u0026gt;\u0026amp;); template\u0026lt;typename T\u0026gt; class MyClass{ friend class Fri\u0026lt;T\u0026gt;; // 比如Fri\u0026lt;int\u0026gt;实例可以访问MyClass\u0026lt;int\u0026gt;实例 friend bool operator==(const MyClass\u0026lt;T\u0026gt;, const MyClass\u0026lt;T\u0026gt;); // 友元函数，重载== public: MyClass() {}; MyClass(const MyClass\u0026amp; m): v(m.v) {} void push_back(T val) { v.push_back(val); } MyClass clone(); // 处于类模板作用域中，编译器会将MyClass当作是MyClass\u0026lt;T\u0026gt; private: vector\u0026lt;T\u0026gt; v; }; template\u0026lt;typename T\u0026gt; MyClass\u0026lt;T\u0026gt; MyClass\u0026lt;T\u0026gt;::clone() { return MyClass(*this); } template\u0026lt;typename T\u0026gt; class Fri{ public: // 一对一友好关系，Fri\u0026lt;T\u0026gt;是MyClass\u0026lt;T\u0026gt;的友元 void size(MyClass\u0026lt;T\u0026gt; m) { cout\u0026lt;\u0026lt;m.v.size()\u0026lt;\u0026lt;endl; } // 但是Fri\u0026lt;T\u0026gt;就不是MyClass\u0026lt;K\u0026gt;的友元(T!=K) void func(MyClass\u0026lt;int\u0026gt; m) { cout\u0026lt;\u0026lt;m.v.size()\u0026lt;\u0026lt;endl; } }; int main(){ MyClass\u0026lt;char\u0026gt; char_class; MyClass\u0026lt;int\u0026gt; int_class; Fri\u0026lt;char\u0026gt; fri; fri.size(char_class); // fri.func(int_class); } 通用和特定的模板友好关系：一个类可以将另一个模板的每个实例都声明为为自己的友元，或者限定特定的实例为友元 1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T\u0026gt; class Fri; class Common{ // 普通类 template\u0026lt;typename K\u0026gt; friend class Pal; // 【Pal的所有实例】都是类Common的友元，此时Fri可以不用提前声明 }; template\u0026lt;typename T\u0026gt; class MyClass{ // 模板类 friend class Fri\u0026lt;T\u0026gt;; // 一对一友元 template\u0026lt;typename K\u0026gt; friend class MyFri; // 【MyPal的所有实例】都是MyClass每个实例的友元，此时MyPal可以不用提前声明，且声明中使用了不同的模板参数 friend class Commom_fri; // 普通类作为模板类的友元，此时不需要提前声明 }; 虽然友元通常是类或函数，但是允许将模板类型参数T作为友元，因此类型T的对象可以访问类模板的private成员。例子。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; using namespace std; template\u0026lt;typename T\u0026gt; class MyClass{ friend T; // 类型T是MyClass的友元 private: void private_func() { cout\u0026lt;\u0026lt;\u0026#34;private func of MyClass \u0026#34;\u0026lt;\u0026lt;endl; } }; class Test{ public: void func(){ test.private_func(); } private: MyClass\u0026lt;Test\u0026gt; test; // 类型Test是MyClass的友元，Test类型的对象可以访问【类模板MyClass基于Test类型的实例】的private成员 }; int main(){ Test t; t.func(); } 模板类型别名 为类模板的实例创建别名：typedef MyClass\u0026lt;int\u0026gt; MC; 为类模板定义别名： 1 2 3 template\u0026lt;typename K, typename V\u0026gt; using p = std::pair\u0026lt;K, V\u0026gt;; template\u0026lt;typename K\u0026gt; using p = std::pair\u0026lt;K, std::string\u0026gt;; // 固定一个类型 template\u0026lt;typename T\u0026gt; using p = std::pair\u0026lt;T, T\u0026gt;; 类模板的static成员 相同类型类模板的实例的static成员是共享的，不同类型之间类模板的实例的static成员是不同的 模板参数 模板内不能重用模板参数名，且同一个模板参数名T在同一个模板参数列表中只能出现一次 声明中的模板参数不必与定义中的模板参数相同，且模板声明通常一起放在文件开始位置（使用模板的代码之前） 使用T::mem，无法判断mem是类型T的static成员还是类型T的类型成员 普通类中编译器已知类的定义因此可以判断 默认T::mem访问的是static成员 使用typename显式说明访问的是类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Person{ public: using age = std::size_t; // 类型成员 static std::string name; // static成员 }; std::string Person::name = \u0026#34;zhang\u0026#34;; template\u0026lt;typename T\u0026gt; class MyClass{ public: typename T::age func(){ // 显式说明T::age是一个类型而非static成员 std::cout\u0026lt;\u0026lt;T::name\u0026lt;\u0026lt;std::endl; // 默认T::name是static成员 typename T::age myAge = 10; return myAge; } }; 默认模板实参：默认模板实参都在最右侧，对函数模板和类模板都可以提供默认模板实参 成员模板 成员模板：普通类或模板类的成员函数是模板函数，成员模板不能是虚函数 普通类的成员模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; using namespace std; class MyClass{ // 普通类中包含成员模板 public: template\u0026lt;typename T\u0026gt; void func(T); }; // 普通类中的成员模板 template\u0026lt;typename T\u0026gt; void MyClass::func(T t){ cout\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } template\u0026lt;typename T\u0026gt; class Test{ public: void func(T); }; // 对比模板类中的普通成员函数 template\u0026lt;typename T\u0026gt; void Test\u0026lt;T\u0026gt;::func(T t){ cout\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } int main(){ MyClass myClass; myClass.func\u0026lt;int\u0026gt;(1); // 普通类中的成员模板 Test\u0026lt;int\u0026gt; test; test.func(2); // 模板类中的普通函数 } 类模板的成员模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; template\u0026lt;typename T\u0026gt; class MyClass{ public: MyClass() {} template\u0026lt;typename K\u0026gt; MyClass(K k) {cout\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; typeid(K).name()\u0026lt;\u0026lt;endl;} template\u0026lt;typename H\u0026gt; void func(H); }; template\u0026lt;typename T\u0026gt; // 类模板的模板参数列表 template\u0026lt;typename H\u0026gt; // 类模板的成员模板的模板参数列表 void MyClass\u0026lt;T\u0026gt;::func(H h){ cout\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; typeid(H).name()\u0026lt;\u0026lt;endl; } int main(){ MyClass\u0026lt;int\u0026gt; myClass(\u0026#39;k\u0026#39;); // 显式提供T=int, 隐式推断K=char myClass.func(3.14); // 隐式推断H=double myClass.func\u0026lt;string\u0026gt;(\u0026#34;str\u0026#34;); // 显式提供H=string } 显式实例化 背景：模板只有使用时才被实例化，因此相同的实例可能出现在多个文件中，造成额外开销 显式实例化 当编译器遇到extern模板声明时，不会在本文件中生成模板的实例化代码，表示使用其他位置的实例化代码 extern声明必须出现在使用此实例化版本的代码之前，否则编译器进行实例化，起不到外部定义的效果 显式实例化定义会实例化所有成员 1 2 3 4 5 6 7 // 在a.cpp中 extern template class MyClass\u0026lt;int\u0026gt;; // 实例化声明 extern template int compare\u0026lt;const int\u0026amp;, const int\u0026amp;\u0026gt;; // 在b.cpp中 template class MyClass\u0026lt;int\u0026gt;; // 实例化定义 template int compare(const int\u0026amp;, const int\u0026amp;); 效率与灵活性 shared_ptr在运行时绑定删除器，因此删除器保存为一个指针而不是一个成员，因此删除器的类型直到运行时才直到，而且可以随时改变删除器的类型 需要间接调用删除器，但是用户重载删除器的操作更加便捷（只需要传入一个可调用对象） unique_ptr在编译期绑定删除器，删除器的类型是类类型的一部分（因此删除器类型在编译器是已知的），从而删除器可以直接保存在成员中 避免了间接调用删除器的运行时开销 16.2 函数模板实参推断 可以[[ch16-模板和泛型编程#类型转换与模板类型参数|基于实参推导模板参数类型]]，也可以[[ch16-模板和泛型编程#函数指针和实参推断|函数指针指向函数模板推导模板参数类型]] 有时比如返回值类型无法推导出来，可以指定[[ch16-模板和泛型编程#函数模板显式实参|模板显式实参]]，也可以使用[[ch16-模板和泛型编程#尾置返回类型与类型转换|尾置返回类型]]（同时可以[[ch16-模板和泛型编程#尾置返回类型后进行类型转换|去除引用]]） 当模板类型T为引用时，需要依据实参是左值/右值来判断T的引用类型，而且可以使用完美转发保持实参的类型不变 类型转换与模板类型参数 模板实参推断：根据实参类型推断出模板参数T的类型 一般T就是实参类型 编译器会对以下几种实参进行类型转换，得到的T并不完全是实参类型 顶层const会被忽略 可以将非const对象的指针或引用传递给一个const的指针或引用形参 如果形参不是引用类型，数组名/函数名转换为指针类型 template\u0026lt;typename T\u0026gt; void func(T a, T b);中，a和b推断的类型必须相同 函数模板显式实参 背景：类型T只出现在返回值/函数体，不在形参列表中时，编译器无法推断出模板实参的类型： 函数模板显式实参从左到右进行对应，如果模板参数可以推导出来，放在模板参数列表右侧，实例化时可以进行推导 当显式指定实参时，对实参可以使用正常的类型转换 1 2 3 4 5 6 7 template \u0026lt;typename T1, typename T2, typename T3\u0026gt; T1 sum(T2, T3); // T1在返回值中 int a = 1; double = 2.0; auto result = sum\u0026lt;long long\u0026gt;(a, b); // T1类型是long long, T2、T3类型可以推导出来，放在右侧 auto test = sum\u0026lt;long long, long long\u0026gt;(a, b); // T2类型显式指定为long long，因此将a转换为long long型 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); int cmp = compare\u0026lt;long long\u0026gt;(a, b); // 使用显式模板实参，a、b都转换为long long类型 尾置返回类型与类型转换 尾置返回类型 背景：有时函数模板的返回值类型不能由实参推导而来，比如[[ch16-模板和泛型编程#函数模板显式实参|函数模板显式实参]]的背景 可以使用函数模板显式实参进行指定，也可以使用尾置返回类型自动推导 1 2 3 4 template \u0026lt;typename Iter\u0026gt; auto func(Iter beg, Iter end) -\u0026gt; decltype(*beg){ // 从局部变量中推导出返回类型 return *beg; } 尾置返回类型后进行类型转换 背景：通过模板显式实参可以指定返回值类型，但是通过尾置返回类型推导得到的类型可能不是想要的，比如有时不希望得到引用类型 标准库的类型转换模板 定义在头文件type_traits中，常用于模板元程序设计 Mod是一个类模板，将类型T转换为类型type；如果无法转化，则类型type 1 2 3 4 template \u0026lt;typename Iter\u0026gt; auto func(Iter beg, Iter end) -\u0026gt; typename remove_reference\u0026lt;decltype(*beg)\u0026gt;::type{ // 表明type是一个类型而非一个static成员 return *beg; } Mod T Mod\u0026lt;T\u0026gt;::type remove_reference X\u0026amp;或X\u0026amp;\u0026amp; X 否则 T add_const X\u0026amp;或const X或函数 T 否则 const T add_lvalue_reference X\u0026amp; T X\u0026amp;\u0026amp; X\u0026amp; 否则 T\u0026amp; add_rvalue_reference X\u0026amp;或X\u0026amp;\u0026amp; T 否则 T\u0026amp;\u0026amp; remove_pointer X* X 否则 T add_pointer X\u0026amp;或X\u0026amp;\u0026amp; X* 否则 T* make_signed unsigned X X 否则 T make_unsigned 带符号类型 unsigned X 否则 T remove_extent X[n] X 否则 T remove_all_extents X[n1][n2]... X 否则 T 函数指针和实参推断 将函数模板赋值给函数指针： 函数指针指向函数模板的一个实例 使用函数指针的类型来推断模板实参 1 2 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); int (*f)(const int\u0026amp;, const int\u0026amp;) = compare; // T是int，f指向函数模板的实例compare(const int\u0026amp;, const int\u0026amp;) 如果函数func的形参是函数指针，实参可以传入函数模板，这样函数指针指向一个模板实例且进行了参数推断 但是当func有多个重载的版本时（接受不同类型的函数指针），传入函数模板可能产生歧义，此时可以指定【显式模板实参】 1 2 3 4 5 template \u0026lt;typename T\u0026gt; int compare(const T\u0026amp;, const T\u0026amp;); void func(int(*fp)(const int\u0026amp;, const int\u0026amp;)); void func(int(*fp)(const std::string\u0026amp;, const std::string\u0026amp;)); // 重载 // func(compare); // 歧义：函数模板compare实例化为哪一种函数指针？ func(compare\u0026lt;int\u0026gt;); 模板实参推断和引用 模板参数T\u0026amp;的类型推断 模板类型参数 实参要求 例子 T\u0026amp; 必须传递一个左值 实参为int，T为int;实参为const int，T为const int const T\u0026amp; 可以传递左值或右值 实参为int, const int, const int\u0026amp;\u0026amp;，T都为int T\u0026amp;\u0026amp; 必须传递一个右值 实参为int\u0026amp;\u0026amp;， T为int T\u0026amp;\u0026amp; 例外：传递一个类型为type的左值，推导T为type\u0026amp;类型 实参为int\u0026amp;,T为int\u0026amp; 引用折叠 背景：基于上面这个例外，创造出了引用的引用，或者通过类型别名也可以创造出引用的引用，可以将多个引用折叠为一个引用 引用折叠规则： type\u0026amp; \u0026amp;、 type\u0026amp; \u0026amp;\u0026amp;、 type\u0026amp;\u0026amp; \u0026amp;折叠为type \u0026amp; type\u0026amp;\u0026amp; \u0026amp;\u0026amp;折叠为T\u0026amp;\u0026amp; 使用： 若函数形参是T\u0026amp;\u0026amp;，则可以传递一个左值（实参的const属性可以保持，因为是底层const） 如果传入的是左值type\u0026amp;，推导出T=type\u0026amp; 万能引用（或称为模板类型参数右值引用）：函数形参为T\u0026amp;\u0026amp;时，传递左值/右值均可 使用万能引用导致只有在运行时才能确定形参是左值还是右值，使得模板的编写变得困难 通常在两种情况中使用万能引用：模板转发实参，模板重载 使用万能引用的形参通常重载为两个版本： 拷贝版本：template\u0026lt;typename T\u0026gt; void f(const T\u0026amp;) 绑定到左值和const右值 移动版本：template\u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp;) 绑定到非const右值 std::move [[ch13-拷贝控制#^d3a2a0|std::move函数]]的定义： 1 2 3 4 template \u0026lt;typename T\u0026gt; typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp; move(T\u0026amp;\u0026amp; t) { return static_cast\u0026lt;typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp;\u0026gt;(t); } 可以使用static_cast显式地将左值转换为右值引用 转发 背景：比如函数f内部调用函数g时，可能需要将f的实参传递给g，而且同时要求保持实参性质不变（比如const属性，左值/右值属性） 即希望达到这样的效果：将实参传递给f，再传递给g，与实参直接传递给g，的效果等价 例子一：f形参类型是非引用，g形参类型是左值引用，传入一个左值引用，则此时f转发参数给g时会使用自己的拷贝而非原来的引用 例子二：f形参类型是万能引用T\u0026amp;\u0026amp;，g形参类型是右值引用，f可以接受右值（或左值），此时f转发参数给g时，使用的右值引用本身是一个左值，不能传参给g的右值引用 比较：都是定义在utility中的函数模板，最好显式指明是std::中的 std::forward：可指定模板参数，并且可以对返回值使用引用折叠来保留左右值属性 std::move：返回值一定是右值引用 使用：完美转发 通过万能引用在传入外层f时保留实参的全部属性 通过std::forward在传入内层函数g时再次保留实参的全部属性 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(T \u0026amp;\u0026amp;arg){ // 万能引用 g(std::forward\u0026lt;T\u0026gt;(arg)); // std::forward\u0026lt;T\u0026gt;的返回类型是T\u0026amp;\u0026amp; }; 如果实参是左值，推导出T=type\u0026amp;，std::forward\u0026lt;T\u0026gt;的返回类型T\u0026amp;\u0026amp;折叠为type\u0026amp; 如果实参是右值，推导出T=type，std::forward\u0026lt;T\u0026gt;的返回类型即为type\u0026amp;\u0026amp; 例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; using namespace std; template\u0026lt;typename F, typename T, typename K\u0026gt; void flip(F f, T \u0026amp;\u0026amp;t, K \u0026amp;\u0026amp;k){ f( std::forward\u0026lt;K\u0026gt;(k), std::forward\u0026lt;T\u0026gt;(t) ); } template\u0026lt;typename K, typename T\u0026gt; void g(K\u0026amp;\u0026amp; k, T\u0026amp;\u0026amp; t) { cout\u0026lt;\u0026lt;typeid(K).name()\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;typeid(T).name()\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;k\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } void f(int \u0026amp;\u0026amp;k, int \u0026amp;t) { cout\u0026lt;\u0026lt;k\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;t\u0026lt;\u0026lt;endl; } int main(){ int t = 2; flip(f, t, 3); // F=void(*)(int\u0026amp;\u0026amp;, int\u0026amp;), T=int\u0026amp;, K=int flip(g\u0026lt;int, int\u0026amp;\u0026gt;, t, 3); // F=void(*)(int\u0026amp;\u0026amp;, int\u0026amp;), T=int\u0026amp;, K=int } 16.3 重载与模板 函数模板可以被另一个函数模板或普通函数重载 [[ch06-函数#6.6 函数匹配|函数的重载与匹配]]：有一些重载的函数，根据实参情况，调用时用哪个函数？ 函数模板的重载与匹配：有一些重载的函数模板和普通函数，根据实参情况（函数模板进行函数模板实参推断），实例化并调用哪个函数模板 到函数模板的函数匹配规则（[[ch06-函数#6.6 函数匹配|普通函数匹配的拓展]]） 确定候选函数：同名的函数，包括实参推断成功的函数模板实例 确定可行函数：参数类型和数量都匹配， 候选的函数模板实例都是可行的，因为实参推断会排除掉不可行的模板 按照类型转换进行排序，寻找最佳匹配（普通函数和函数模板实例都可能发生类型转换，只是应用于函数模板的[[ch16-模板和泛型编程#类型转换与模板类型参数|类型转换]]十分有限） 若恰有一个函数提供比其他函数都好的匹配，则选择它 如果多个函数都提供相同级别的匹配 非模板和模板重载：如果只有一个是非模板函数，选择非模板函数 多个可行模板：如果没有非模板函数（有多个函数模板），选择最特例化的函数模板（特例化：比如T\u0026amp;可以匹配任意类型，T*只能匹配指针类型） 调用有歧义，失败 最佳实践：在定义重载函数之前，应该先声明所有重载的版本，否则可能重载一个模板函数进行实例化（因为没有找到想使用的版本，使用函数模板进行实例化），编译期不会报错，但是运行期会调用不期望使用的版本 16.4 可变参数模板 可变参数模板就是一个接受可变数目参数的模板函数或模板类，可变数目的参数被称为参数包 模板参数包：表示零个或多个模板参数（模板类型参数或模板非类型参数） typename后跟...表示模板类型参数包 类型名后跟...表示模板非类型参数包 函数参数包：表示零个或多个函数参数。 sizeof...运算符：返回参数包中的元素数量，且不会对其实参求值（类似于sizeof） 1 2 3 4 template\u0026lt;typename T, typename... Args\u0026gt; // 模板参数包：Args是模板类型参数包 void func(const T \u0026amp;t, const Args\u0026amp; ... rest){ // 函数参数包：rest是函数参数包（其类型是模板参数包Args） cout\u0026lt;\u0026lt;sizeof...(Args)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;sizeof...(rest)\u0026lt;\u0026lt;endl; } 编写可变参数函数模板 [[ch06-函数#可变形参|可变形参]]initializer_list可以接受可变数目实参，但是需要是相同类型的 可变参数函数通常是递归的 第一步调用处理参数包中的第一个实参，然后用剩余实参调用自身 还需要定义一个非可变参数的函数（因为函数匹配时会使用这个更加特例化的版本，而不是使用0个参数的可变参数模板的实例），来处理参数包中最后一个实参 1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;typename T\u0026gt; ostream \u0026amp;print(ostream \u0026amp;os, const T \u0026amp;t) // 打印最后一个元素，用来终止递归，必须在可变参数版本的print定义之前声明 { return os \u0026lt;\u0026lt; t; } template \u0026lt;typename T, typename... Args\u0026gt; ostream \u0026amp;print(ostream \u0026amp;os, const T \u0026amp;t, const Args\u0026amp;... rest) { os \u0026lt;\u0026lt; t \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; return print(os, rest...); // 递归调用，实参是将除了第一个，剩余的参数 } 包扩展 扩展...：将参数包分解为单个元素，每个元素应用模式，得到拓展后的列表 常用情况： const Args\u0026amp; ...：将模板参数包Args中所有类型T都扩展为const T\u0026amp; args...：将函数参数包args扩展为参数列表 f(args)...：对函数参数包args中每个元素调用函数f 1 2 3 4 template\u0026lt;typename... Args\u0026gt; ostream\u0026amp; msg(ostream\u0026amp; os, const Args\u0026amp;... rest){ // 扩展模板参数包 return print(os, debug_reg(rest)...); // 扩展函数参数包 } 转发参数包 组合使用可变参数模板和forward机制，实现将可变参数的完美转发，例子：emplace_back 如果同时存在模板参数包和函数参数包，则同时拓展： f\u0026lt;Args\u0026gt;(args)...等价于f\u0026lt;Args1\u0026gt;(args1), f\u0026lt;Args2\u0026gt;(args2), ... 1 2 3 4 template\u0026lt;typename... Args\u0026gt; void func(Args\u0026amp;\u0026amp;... args){ work(std::forward\u0026lt;Args\u0026gt;(args)...); }; 16.5 模板特例化（Specializations） 背景和例子：对于某个类型，不想用（对特定类型可以做优化）或者不能用（对特定类型的使用并非预期）模板 定义函数模板特例化 必须为原模板中每个模板参数都提供实参（全特例化） 关键字template后面跟一个空尖括号对（\u0026lt;\u0026gt;），表示所有模板参数都已被指定 特例化版本的参数类型必须与一个先前声明的模板中对应的类型相匹配。 1 2 3 4 5 template \u0026lt;typename T\u0026gt; bool compare(const T\u0026amp;, const T\u0026amp;) {} template \u0026lt;\u0026gt; bool compare(const char* const \u0026amp;, const char* const \u0026amp;); // T为const char* 函数重载与模板特例化 特例化的本质是实例化一个模板，而不是重载它。因此特例化不影响[[ch16-模板和泛型编程#16.3 重载与模板|函数的匹配规则]]，即非模板函数先，再是特例化版本的函数（模板的实例化），最后是函数模板的实例 最佳实践：模板及其特例化版本应该声明在同一个头文件中。所有同名模板的声明应该放在前面，然后是特例化版本。 1 2 3 4 5 6 7 template \u0026lt;typename T\u0026gt; void compare(const T\u0026amp; l, const T\u0026amp; r); template \u0026lt;\u0026gt; void compare(const char* const \u0026amp;l, const char* const \u0026amp;r); // 特例化版本，T为const char* void compare(const char* const \u0026amp;l, const char* const \u0026amp;r); // 普通函数 类模板特例化 必须在原模板定义所在的命名空间中进行类模板特例化 类模板可以进行部分特例化（偏特例化），得到的是模板；也可以全部特例化（全特例化），得到的是实例 类模板的部分特例化 未完全确定类型的模板参数仍放在\u0026lt;\u0026gt;中，即偏特化的模板参数列表非空。使用时也需提供模板实参，这些实参与原始模板中的参数按位置对应 部分特例化的模板参数列表是原始模板参数列表的一个子集或者特例化版本 例子：标准库remove_reference类型是通过一系列的特例化版本来完成其功能的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 //原始的、最通用的版本，可用于任意类型实例化 template\u0026lt;typename T\u0026gt; struct remove_reference { typedef T type; }; //部分特例化版本 template\u0026lt;typename T\u0026gt; struct remove_reference\u0026lt;T\u0026amp;\u0026gt; { //针对于左值引用的 typedef T type; }; template\u0026lt;typename T\u0026gt; struct remove_reference\u0026lt;T\u0026amp;\u0026amp;\u0026gt; { //针对于右值引用的 typedef T type; }; int i; //调用原始模板 remove_reference\u0026lt;decltype(42)\u0026gt;::type a; //decltype(i)==int\u0026amp;，调用第一个（T\u0026amp;）部分特例化版本 remove_reference\u0026lt;decltype(i)\u0026gt;::type b; //decltype(std::move(i))==int\u0026amp;\u0026amp;，调用第二个（T\u0026amp;\u0026amp;）部分特例化版本 remove_reference\u0026lt;decltype(std::move(i))\u0026gt;::type c; //a、b、c均为int 特例化成员函数而不是整个类 使用模板的实例调用成员时，若该实例的模板实参与特化该成员时的参数一致，则调用特化版本的成员 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 template\u0026lt;typename T\u0026gt; struct Foo { Foo(const T \u0026amp;t = T()) :mem(t) {} void Bar() {std::cout\u0026lt;\u0026lt;1\u0026lt;\u0026lt;std::endl;} //通用的Bar()函数 T mem; }; //特例化Foo\u0026lt;int\u0026gt;版本的的成员Bar template\u0026lt;\u0026gt; void Foo\u0026lt;int\u0026gt;::Bar() {std::cout\u0026lt;\u0026lt;2\u0026lt;\u0026lt;std::endl;} int main(){ Foo\u0026lt;std::string\u0026gt; fs; fs.Bar(); //使用Foo\u0026lt;string\u0026gt;的通用的Bar() Foo\u0026lt;int\u0026gt; fi; fi.Bar(); //使用Foo\u0026lt;int\u0026gt;的特例化的Bar() } ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch16-%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/","summary":"第十六章 模板和泛型编程 16.1 定义模板 模板参数列表：\u0026lt;\u0026gt; 模板参数（也称(模板)类型参数）：T typename或class（作用相同），","title":"Ch16 模板和泛型编程"},{"content":"第十五章 面向对象程序设计 OOP的核心思想是多态性（polymorphism）。\n多态即具有继承关系的多个类型 引用或指针的静态类型与动态类型不同是C++支持多态的根本 本章内容：\n基类与派生类语法及其类型转换 虚函数、纯虚函数、抽象基类 访问控制：成员访问控制、派生访问控制、using声明 继承过程中的函数解析和作用域 继承过程中的构造函数和（合成）拷贝控制成员 15.1 OOP：概述 基类，派生类、类派生列表 [[ch15-面向对象程序设计#15.3 虚函数|虚函数]]：基类将函数声明为虚函数，派生类定义适合自己的版本 动态绑定（dynamic binding，又称运行时绑定）： 使用基类的引用或指针调用一个虚函数时将发生动态绑定（即在运行时，根据传入参数的类型选择函数版本） 15.2 定义基类和派生类 定义基类 如果函数希望被派生类覆盖，则基类将其定义为虚函数；否则基类中的函数希望派生类直接继承而且不要改变 基类中的虚函数 ^ae3c55 基类通常都应该定义一个【虚析构函数】，即使该函数不执行任何实际操作。 除构造函数之外的任何非静态函数都可以定义为虚函数 如果基类把一个函数声明为虚函数，则该函数在派生类中隐式的也是虚函数 [[ch15-面向对象程序设计#^8deb68|访问控制]] 定义派生类 【类派生列表中的访问说明符】用于控制【派生类从基类继承而来的成员】是否【对派生类的对象】可见 派生类必须将继承而来的成员函数中需要覆盖的那些重新声明 如果一个派生是公有的，则基类的公有成员也是派生类接口的组成部分，因此可以将派生类类型的对象绑定到基类的指针或引用上 派生类中的虚函数 ^91e48b 如果派生类没有覆盖基类中的某个虚函数，则派生类会直接继承其在基类中的版本 派生类必须在其内部对所有重新定义的虚函数进行声明，virtual关键字可加可不加 派生类中覆盖虚函数时，形参类型和返回值类型必须相同 返回值不相同只有一个例外：虚函数返回类型是类本身的指针或引用，比如类Base派生出类Derived，则基类Base的虚函数返回值可以返回*Base，而派生类Derived中覆盖的虚函数可以返回*Derived C++11使用override显式指明重新定义虚函数（override放在引用限定符之后） 派生类到基类的类型转换 基类与派生类之间的[[#类型转换与继承]] [[ch15-面向对象程序设计#^ec492b|派生类向基类转换的可访问性]] 派生类构造函数：每个类控制自己的成员初始化过程 派生类必须使用【基类的构造函数】来初始化它的基类部分，【派生类的构造函数】通过【[[ch07-类#^742596|构造函数初始值列表]]】来将实参传递给【基类构造函数】，同时在【构造函数初始值列表】初始化自己的数据成员 遵循基类的接口，尽管从语法上可以在派生类中给基类的公有成员直接进行赋值 除非特别指出，否则派生类对象的基类部分会像数据成员一样执行默认初始化 顺序：先初始化基类部分，在按声明顺序依次初始化派生类的成员 静态成员 如果基类定义了一个静态成员，则在整个继承体系中只存在该成员的唯一实例。 静态成员遵循通用的访问控制规则 派生类的声明中不包含它的派生列表，派生列表必须于派生类的定义一起出现 如果想用某个类作为基类，该类必须已经定义而非仅仅声明 一个类不能派生它本身 直接基类与间接基类：派生类构造函数只初始化它的直接基类 防止继承：在类名后面跟一个关键字final。 final关键字除了防止继承，还可以防止函数被覆盖 类型转换与继承 可以将【指向基类的指针/引用】绑定到派生类对象上，因此【指向基类的指针/引用】的静态类型与动态类型可能不一致 静态类型：变量或表达式类型在编译时已知 动态类型：变量或表达式类型在运行时才可知，是指针指向的内存中对象的类型 编译器自动将【指向派生类的指针/引用】转换为【指向基类的指针/引用】 不存在【指向基类的指针/引用】隐式转换到【指向派生类的指针/引用】 除了使用强制类型转换：使用dynamic_cast，将【指向基类的指针/引用】安全的转换成【指向派生类的指针/引用】，将在运行期进行安全检查 如果已知某个基类到派生类的转换是安全的，可以使用static_cast强制覆盖掉编译器的检查工作 派生类向基类的自动类型转换只对指针或引用类型有效，对象之间不存在类型转换。 如果表达式不是引用/指针，则它的静态类型与动态类型永远一致 有时确实希望将派生类对象转换成基类类型，派生类的部分被切掉(sliced down)了 15.3 虚函数 [[ch15-面向对象程序设计#^ae3c55|基类中的虚函数]] [[ch15-面向对象程序设计#^91e48b|派生类中的虚函数]] virtual关键字只能出现在类内部的声明语句，而不能用于类外部的函数定义 必须为每一个虚函数提供定义，不管是否被用到（因为编译器也无法确定哪个虚函数会被使用） 默认实参 如果虚函数中有默认实参，则默认实参的值由本次调用的指针/引用的静态类型决定 因此可能使用的是基类中的默认实参，但是实际运行的是派生类的虚函数版本 最好基类和派生类中的默认实参一致 回避虚函数：对虚函数的调用不要进行动态绑定，而强迫执行虚函数的某个版本 使用作用域运算符（::）来回避虚函数 通常，只有成员函数（或友元）中才需要使用使用回避虚函数的机制，比如一个派生类的虚函数调用它覆盖的基类的虚函数版本（如果不使用回避机制，在运行时该调用将被解析为派生类版本自身的调用，导致无限循环递归） 例子：Derived* p = Derived(); p-\u0026gt;Base::func(); 15.4 抽象基类 纯虚函数：一个没有意义的虚函数 纯虚函数无需定义，或者也可以提供定义，但是函数体必须定义在类的外部 声明时末尾加上=0将函数声明为纯虚函数，且只能出现在类内部的函数声明中 抽象基类 含有（或未经覆盖直接继承）纯虚函数的类 如果派生类不覆盖抽象基类中的纯虚函数，则该派生类仍然是抽象基类 抽象基类负责定义接口，后续的其他类可以覆盖该接口 不能创建抽象基类的对象。 15.5 访问控制与继承 派生类中继承而来的成员的访问权限受到两个因素影响：基类中成员的访问控制（成员访问说明符）、类派生列表中的访问控制（派生访问说明符） 基类中成员的访问控制 ^8deb68 public：基类本身、派生类、友元、类对象都可以访问 protected ： 基类本身、派生类、友元可以访问，类对象无法访问 派生类和友元可以通过派生类对象访问基类的protected成员，但是不能直接通过基类对象来访问。例子。 private ： 基类本身、友元可以访问，其他都无法访问 类派生列表中的访问控制：基类中public/protected的成员，在派生类中的访问说明符 如果继承是public的，则成员遵循原来的访问说明符 如果继承是private的，则派生类中【从基类中继承而来的成员】是private的 如果继承是protected的，则派生类中【从基类中继承而来的成员】是protected的 派生类向基类转换的可访问性 ^ec492b 总体原则：对于继承树中的某个节点，如果基类的共有成员是可以访问的，则派生类可以向基类进行类型转换；反之则不行。示例说明。 只有当继承是public的时，派生类才能转换到基类（基类指针指向派生类对象） 不管D以什么方式继承B，【D的成员函数和友元函数】中【派生类D可以转换到直接基类B】 如果D继承B的方式是public的或protected的，则【D派生类的成员和友元】可以使用【D向B的类型转换】；反之如果是私有的，则不能使用 友元关系是单向的，不具有传递性，且不能继承 如果Pal是基类Base的友元，则Pal可以访问Base的对象的成员和派生类Derived中属于Base部分的成员 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Base{ friend class Pal; protected: int protected_val; // 每个类负责控制自己成员的访问权限，protected_val访问权限由Base控制（即使Base是内嵌在派生类对象中） }; class Derived: public Base{ friend class PPal; protected: int de_protected_val; }; class Pal{ // 基类的友元 public: int f(Derived d) {return d.protected_val;} // protected_val的访问控制权限由Baes控制，这种可访问性包括了Base对象内嵌在其派生类对象中的情况 int g(Derived d) {return d.de_protected_val;} // error: 基类的友元不能随便访问派生类的成员 }; class DPal: public Pal{ // 【基类友元】的派生类 public: int k(Derived d) {return d.protected_val;} // error：友元关系不能继承 }; class PPal{ // 派生类的友元 public: int h(Derived d) {return d.protected_val;} }; 改变派生类个别成员的可访问性：使用using。 ^f2ba1c 将基类的public/protected成员使用using进行标记，放在派生类public/protected/private的位置，就获得了相应的访问级别 派生类只能针对基类的public/protected成员使用using声明改变可访问性（因为派生类无法访问基类的private成员） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Base{ public: int pub_func(); int pub_func(int i); protected: int pro; private: int pri; } class Derived: private Base{ // Derived中从基类Base中继承而来的成员默认都是private的 public: using Base::pub_func; // 使用using声明，两个重载的pub_func现在都被添加，都是public的 protected: using Base::pro; // 使用using声明，pro现在是protected的 // 派生类无法访问到基类的private成员 } class与struct 默认使用clas定义的类成员是private的，使用struct定义的类成员是public的 默认使用class定义的派生类是私有继承的，使用struct定义的派生类是公有继承的。 除此之外再无不同 15.6 继承中的类作用域 派生类的作用域嵌套在其基类的作用域之内 函数调用的解析过程：p-\u0026gt;mem()或者obj.mem() 确定p或obj的静态类型 名字查找：在该静态类型对应的类中查找mem，如果找不到，则依次在直接继承中不断查找，直到继承链的顶端 类型检查：假如找到mem，进行常规的类型检查，以确认本次调用是否合法 假如合法，编译器根据调用的是否为虚函数产生不同的代码： mem是虚函数且通过指针或引用来调用：编译器产生的代码将在运行时确定到底是运行该虚函数的哪个版本，依据是对象的动态类型 mem不是虚函数或者通过对象进行调用：产生一个常规的函数调用 函数调用的解析过程导致的现象： 一个对象、引用或指针的静态类型决定了该对象的哪些成员是可见的 比如将基类指针绑定到派生类，基类指针静态类型是指向基类（因此无法调用派生类特有的成员），但是动态类型是指向派生类 派生类的成员将隐藏同名的基类成员，即使成员函数形参列表不同 可以使用域运算符::使用被隐藏的基类成员 除了覆盖继承而来的虚函数之外，派生类最好不要重用其他定义在基类中的名字 派生类中继承来的虚函数要保持相同的参数列表，否则派生类定义的是一个新函数，该新函数不是虚函数 虚函数解析过程： 在编译期，基类指针在静态类型中进行名字查找和类型检查 在运行期，根据动态类型决定运行虚函数的哪个版本 覆盖重载的函数： 派生类可以覆盖重载函数的0个或多个版本 如果派生类希望所有的重载版本对它来说都是可见的，那么就需要覆盖所有的版本，或者一个也不覆盖（因此到基类中寻找名字） 如果像重写一部分而非全部，可以使用using声明将同名的重载版本都添加到派生类作用域中，然后再重写 根本原因还是相应静态类型中查找到名字后但是类型不匹配，如果只覆盖一部分相当于重载版本变少了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; class Base{ public: void f() { cout\u0026lt;\u0026lt;\u0026#34;Base 1\u0026#34;\u0026lt;\u0026lt;endl; } void f(int a) { cout\u0026lt;\u0026lt;\u0026#34;Base 2\u0026#34;\u0026lt;\u0026lt;endl; } void f(int a, int b) { cout\u0026lt;\u0026lt;\u0026#34;Base 3\u0026#34;\u0026lt;\u0026lt;endl; } }; class D1: public Base{ public: void f() { cout\u0026lt;\u0026lt;\u0026#34;D1 \u0026#34;\u0026lt;\u0026lt;endl; } // 只覆盖一个 }; class D2: public Base{ public: // 一个都不覆盖 }; class D3: public Base{ public: using Base::f; void f(int a) { cout\u0026lt;\u0026lt;\u0026#34;D3 2\u0026#34;\u0026lt;\u0026lt;endl; } }; int main(){ D1 d1; D2 d2; D3 d3; // d1.f(1); // 报错：因为d1静态类型为D1，D1中有函数f，但是类型检查失败 d2.f(0); // Base 2 d3.f(0); // D3 2 // D1* p = \u0026amp;d1; // 这样定义就错，原因同上 Base *p = \u0026amp;d1; // p的静态类型为Base，Base中有函数f(int) p-\u0026gt;f(0); // Base 2 } 重载、重写（覆盖）与隐藏，参考 重载：同一作用域内的几个函数同名但是形参列表不同 隐藏：派生类中的函数屏蔽了与其同名的基类函数，不管参数列表是否相同 重写（覆盖）：虚函数重写 15.7 构造函数与拷贝控制 虚析构函数 基类通常应该定义一个虚析构函数，这样最终执行动态类型版本的析构函数 一般来说，如果一个类需要析构函数，那么它也需要拷贝和赋值操作，但是基类的析构函数不遵循该规则 虚析构函数将阻止使用合成的移动操作，即使使用=default显式声明 合成的拷贝控制与继承 派生类的合成拷贝控制成员，通过调用基类的合成拷贝控制成员，来对基类部分进行相应的拷贝、移动、销毁等操作 某些定义基类的方式可能导致部分派生类成员成为被删除的函数： 如果基类中的默认构造函数、拷贝构造函数、拷贝赋值运算符或析构函数是被删除的或者不可访问的函数，则派生类中对应的成员也会是被删除的。 如果基类的析构函数是被删除的或者不可访问的，则派生类中合成的默认和拷贝构造函数也会是被删除的。 如果基类的移动操作是删除的，则派生类中对应的函数也是删除的。 在实际编程中，如果基类没有默认、拷贝或移动构造函数，则一般情况下派生类也不会定义相应的操作。 移动操作与继承 大多数基类都会定义一个虚析构函数，因此基类通常没有合成的移动操作 如果需要移动操作，首先在基类中定义，之后派生类会自动合成移动操作 派生类的拷贝控制成员 当派生类定义了拷贝或移动操作时，该操作通过调用基类的对应成员，来拷贝或移动包括基类在内的整个对象。 与拷贝和移动操作不同，派生类的析构函数只负责销毁由派生类自己分配的资源，对象销毁的顺序与创建顺序相反 在构造函数和析构函数中尽量不要调用虚函数：例子。 比如在进行基类的初始化时，调用了派生类版本的虚函数，但是此时派生类还未进行初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Base{ public: Base() { func(); } // 构造函数中调用虚函数 Base(const Base\u0026amp;) =default; Base(Base\u0026amp;\u0026amp;) =default; Base\u0026amp; operator= (const Base\u0026amp;) =default; Base\u0026amp; operator= (Base\u0026amp;\u0026amp;) =default; virtual ~Base() =default; virtual void func() {cout\u0026lt;\u0026lt;\u0026#34;Base\u0026#34;\u0026lt;\u0026lt;endl;} }; class Derived: public Base{ public: Derived(): Base() { func(); } Derived(const Derived\u0026amp; d): Base(d) {} // 使用基类的构造函数初始化对象的基类部分 Derived(Derived\u0026amp;\u0026amp; d): Base(d) {} Derived\u0026amp; operator= (const Derived\u0026amp; d){ Base::operator=(d); // 使用基类的拷贝赋值运算符赋值对象的基类部分 /* do something*/ return *this; } ~Derived() { /*销毁派生类自己分配的资源*/ } virtual void func() { cout\u0026lt;\u0026lt;\u0026#34;Derived\u0026#34;\u0026lt;\u0026lt;endl; } }; Derived d; // 先构造基类部分，此时派生类部分还未创建，基类构造函数中使用的是Base::func() 继承的构造函数 背景 如果基类有多个不同的构造函数，那么派生类也需要相应实现多个构造函数，参考 派生类不能继承默认、拷贝、移动构造函数，派生类如果没有直接定义这些构造函数，编译器会为派生类合成 派生类可以使用using声明重用基类的构造函数，编译器在派生类中生成一个形参列表完全相同的构造函数，派生类自己的数据成员被默认初始化 和普通的using声明不一样（可以[[ch15-面向对象程序设计#^f2ba1c|改变派生类个别成员的可访问性]]），构造函数的using声明不会改变构造函数的访问声明符 如果基类构造函数是explict的或constexpr的，则重用的构造函数也拥有相同的属性 如果一个基类构造函数含有默认实参，这些实参并不会被直接继承，派生类会获得多个继承的构造函数，每个构造函数分别省略掉一个含有默认实参的形参。 基类有几个构造函数，派生类会重用所有的这些构造函数，除了两个例外： 派生类可以继承一部分构造函数，而为其他构造函数定义自己的版本：如果派生类定义的构造函数与重用基类的构造函数具有相同的参数列表，则派生类中的构造函数将替换重用的基类构造函数 默认、拷贝和移动构造函数不会被继承，这些构造函数按照正常规则被合成 15.8 容器与继承 当我们使用容器存放继承体系中的对象时，通常必须采用间接存储的方式，即在容器中放置（智能）指针而非对象，否则派生类对象的部分会被切掉 15.9 文本查询程序再探 使系统支持：单词查询、逻辑非查询、逻辑或查询、逻辑与查询。 面向对象的解决方案 将几种不同的查询建模成相互独立的类，这些类共享一个公共基类： WordQuery NotQuery OrQuery AndQuery 这些类包含两个操作： eval：接受一个TextQuery对象并返回一个QueryResult。 rep：返回基础查询的string表示形式。 继承和组合： 当我们令一个类公有地继承另一个类时，派生类应当反映与基类的“是一种（Is A）”的关系。 类型之间另一种常见的关系是“有一个（Has A）”的关系。 对于面向对象编程的新手来说，想要理解一个程序，最困难的部分往往是理解程序的设计思路。一旦掌握了设计思路，接下来的实现也就水到渠成了。 Query程序设计: 操作 解释 Query程序接口类和操作 TextQuery 该类读入给定的文件并构建一个查找图。包含一个query操作，它接受一个string实参，返回一个QueryResult对象；该QueryResult对象表示string出现的行。 QueryResult 该类保存一个query操作的结果。 Query 是一个接口类，指向Query_base派生类的对象。 Query q(s) 将Query对象q绑定到一个存放着string s的新WordQuery对象上。 q1 \u0026amp; q2 返回一个Query对象，该Query绑定到一个存放q1和q2的新AndQuery对象上。 `q1 q2` ~q 返回一个Query对象，该Query绑定到一个存放q的新NotQuery对象上。 Query程序实现类 Query_base 查询类的抽象基类 WordQuery Query_base的派生类，用于查找一个给定的单词 NotQuery Query_base的派生类，用于查找一个给定的单词 BinaryQuery Query_base的派生类，查询结果是Query运算对象没有出现的行的集合 OrQuery Query_base的派生类，返回它的两个运算对象分别出现的行的并集 AndQuery Query_base的派生类，返回它的两个运算对象分别出现的行的交集 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch15-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/","summary":"第十五章 面向对象程序设计 OOP的核心思想是多态性（polymorphism）。 多态即具有继承关系的多个类型 引用或指针的静态类型与动态类型不同","title":"Ch15 面向对象程序设计"},{"content":"第十四章 重载运算与类型转换 14.1 基本概念 语法相关： 重载的运算符必须是某个类的成员或至少拥有一个类类型的运算对象 重载运算符函数的参数数量和该运算符作用的运算对象数量一样多，左侧运算对象传递给第一个参数，右侧传递给第二个，除了重载函数调用符()，其他重载运算符不能有默认实参，调用方式：operator+(data1, data2) 如果一个重载的运算符是成员函数，this指向左侧运算对象，因此定义成员运算符时的参数数量比运算符的运算对象少一个，调用方式：data1.operator+=(data2) 重载运算符的优先级和结合律跟对应的内置运算符保持一致。 使用： 一些运算符通常一起进行重载，比如重载了==也应该重载!=，重载了\u0026lt;也应该重载其他关系操作，重载了算数运算符或位运算符，也应该重载对应的复合赋值运算符 考虑定义为成员函数还是普通函数 赋值（=）、下标（[]）、调用（()）和成员访问箭头（-\u0026gt;）运算符必须是成员。 递增、递减、解引用、复合赋值运算符一般是成员 具有对称性的运算符如算术、相等性、关系和位运算符等，通常是非成员函数。 IO运算符应该声明为类的友元 14.2 运算符重载 14.2.1 重载输出运算符\u0026lt;\u0026lt; ostream\u0026amp; operator\u0026lt;\u0026lt; (ostream \u0026amp;os, const T \u0026amp;t); 第一个形参通常是一个非常量的ostream对象的引用，第二个形参是要打印类型的常量引用 输出运算符应该尽量减少格式化操作（比如不应该打印换行符） 14.2.2 重载输入运算符\u0026gt;\u0026gt; istream\u0026amp; operator\u0026gt;\u0026gt; (istream\u0026amp; is, T \u0026amp;t); 第一个形参通常是运算符将要读取的流的引用，第二个形参是将要读取到的（非常量）对象的引用。 输入运算符必须处理输入可能失败的情况，而输出运算符不需要。 如果读取失败，输入运算符应该负责从错误中恢复，主要是将输入对象重置为合法状态，一般为未输入前的状态。 14.2.3 重载算数运算符+、-、*、/ 一般设置为非成员函数，形参一般为常量引用，返回值不为引用（因为返回值一般是局部变量的拷贝） 一般都是先定义复合赋值运算符（成员函数），在基于此实现算数运算符（普通函数） 14.2.4 相等运算符== 如果定义了operator==，则这个类也应该定义operator!=。 相等运算符和不等运算符的一个应该把工作委托给另一个 14.2.5 关系运算符\u0026lt; 如果两个对象是!=的，则一个对象应该\u0026lt;另一个对象 14.2.6 赋值运算符= 赋值运算符和复合赋值运算符应该返回左侧运算对象的引用。 14.2.7 下标运算符[] 一般会定义两个版本： 返回普通引用：T\u0026amp; operator[](); 是类的常量成员，并返回常量引用：const T\u0026amp; operator[] const; 14.2.8 递增和递减运算符++、-- 应该同时定义前置版本和后置版本，而且通常为类的成员。 前置运算符应该返回递增或递减后对象的引用：string\u0026amp; operator++(); 后置运算符应该返回递增或递减前对象的值，而不是引用：T operator++(int); 后置版本接受一个额外的、不被使用的int类型的形参，且无需命名，编译器提供一个值为0的实参。该形参唯一的作用就是区分前置和后置递增。 如果想通过函数调用的方式使用后置递增，需要为这个int形参传递一个值（比如0） 后置版本可以通过调用前置版本来实现。 14.2.9 成员访问运算符*、-\u0026gt; 箭头运算符必须是类的成员，解引用运算符通常也是类的成员，且通常为const的成员函数，而且箭头运算符一般通过调用解引用运算符来实现 14.2.10 函数调用运算符() 14.8 函数调用运算符 如果类定义了调用运算符，则该类的对象称作【函数对象】。 函数对象可以被调用，同时因为函数对象可以存储状态（即数据成员），所以与普通函数相比更加灵活，通常作为泛型算法的实参 C++中的【可调用对象】：函数、函数指针、lambda表达式、bind创建的对象、函数对象（或者说重载了调用运算符的类） 【可调用对象的类型】：lambda表达式有他自己唯一（未命名）的类类型，函数、函数指针的类型由返回值类型和实参类型决定 【调用形式】：指明了调用返回的类型和传递给调用的实参类型，比如int(int,int) 不同类型的可调用对象可以共享同一种调用形式，但它们并不是同一类型。例子。 lambda是函数对象 编译器将[[ch10-泛型算法#lambda表达式|lambda表达式]]转换成一个未命名类的未命名对象（即类中重载了函数调用运算符） 这个未命名类不包含默认构造函数、赋值运算符和默认析构函数，它是否包含默认的拷贝/移动构造函数，通常视捕获变量的类型而定 lambda默认不能改变它捕获的变量，此时未命名类中的函数调用运算符是一个const成员函数；如果lambda被声明为可变的，则调用运算符就不再是const成员函数 如果进行引用捕获，编译器直接使用该引用而无须在产生的类中相应存储为数据成员（由程序确保该引用绑定的对象确实存在） 如果进行值捕获，产生的类必须为捕获的变量建立对应的数据成员，并创建构造函数，用捕获变量的值来初始化相应的数据成员 标准库定义的函数对象 标准库函数对象 算术 关系 逻辑 plus\u0026lt;Type\u0026gt; equal_to\u0026lt;Type\u0026gt; logical_and\u0026lt;Type\u0026gt; minus\u0026lt;Type\u0026gt; not_equal_to\u0026lt;Type\u0026gt; logical_or\u0026lt;Type\u0026gt; multiplies\u0026lt;Type\u0026gt; greater\u0026lt;Type\u0026gt; logical_not\u0026lt;Type\u0026gt; divides\u0026lt;Type\u0026gt; greater_equal\u0026lt;Type\u0026gt; modulus\u0026lt;Type\u0026gt; less\u0026lt;Type\u0026gt; negate\u0026lt;Type\u0026gt; less_equal\u0026lt;Type\u0026gt; 一组表示算数运算符、关系运算符和逻辑运算符的模板类，每个类中重载了调用运算符来实现相应的命名操作 标准库函数对象经常用来替换算法中的默认运算符 如果想根据指针（或者说内存地址）进行排序，Type可以是指针类型，但是无法通过自定义的函数来进行内存地址的比较 可调用对象与function 调用形式相同的可调用对象，其类型不一定相同 function封装了相同调用形式、但是不同类型的可调用对象 1 2 3 4 5 6 7 8 int add(int i, int j) { return i + j; } auto mod = [](int i, int j) {return i % j;} function\u0026lt;int(int,int)\u0026gt; f1 = add; function\u0026lt;int(int,int)\u0026gt; f2 = mod; map\u0026lt;string, function\u0026lt;int(int,int)\u0026gt;\u0026gt; mp; mp.insert({\u0026#34;+\u0026#34;, add}); mp.insert({\u0026#34;%\u0026#34;, mod}); mp[\u0026#34;+\u0026#34;](1,2); // 将不同可调用类型的可调用对象存储在一起 不能直接将重载函数的名字存入function类型的对象中，因为会产生二义性，消除二义性的方法是使用lambda或者函数指针而非函数名字 1 2 3 4 5 6 7 8 int add(int i, int j) {return i + j} string add(string s, string t) {return s + t;} map\u0026lt;string, function\u0026lt;int(int, int)\u0026gt;\u0026gt; mp; mp.insert({\u0026#34;+\u0026#34;, add}); // error: which add? int (*fp)(int, int) = add; mp.insert({\u0026#34;+\u0026#34;, fp}); mp.insert({\u0026#34;+\u0026#34;, [](int a, int b) {return add(a,b);}; // 另一种写法 14.9 重载、类型转换、运算符 类类型转换（或者称用户定义的类型转换）：转换构造函数（从其他类型转换到类类型）+类型转换运算符（从类类型转换到其他类型）\n类型转换运算符 一般类型：operator type() const; 语法相关： 可以转换到任意类型（除了void），只要该类型能作为函数的返回类型 必须是类的成员函数，不能声明返回类型（但是函数返回一个对应类型的值），形参列表为空，一般为const成员函数 使用： 类型转换运算符不需要显式调用，在执行运算时会隐式的执行 尽量确保类型转换是有意义的，避免过度使用 尽管编译器一次只能执行一个【用户定义的类型转换】，但是隐式的【用户定义的类型转换】可以置于一个标准内置类型转换之前或之后 1 2 3 4 5 6 7 8 9 class smallInt{ public: smallInt(int i): val(i) {if(i\u0026lt;0 || i \u0026gt; 255) cout\u0026lt;\u0026lt;\u0026#34;bad value\u0026#34;\u0026lt;\u0026lt;endl;} operator int() const {return -val;} // 为了说明类型转换运算符的效果 private: size_t val; }; smallInt s = 2.1; // 先将double转换为int，再使用转换构造函数将int转换为smallInt cout\u0026lt;\u0026lt;s + 2.1\u0026lt;\u0026lt;endl; // 使用【类型转换运算符】将s隐式地转换为int，再转换为double相加 显式的类型转换运算符（C++11）：explicit operator type() const; 需要使用static_cast\u0026lt;type\u0026gt;进行显式的类型转换 例外：当表达式被用作条件时，显式的类型转换将被隐式的执行 向bool的类型转换通常用在条件部分，因此operator bool一般定义成explicit的。 避免有二义性的类型转换 必须确保在类类型和目标类型之间只存在唯一一种转换方式，否则很可能有二义性 两种情况会产生多重转换路径： 【用A的转换构造函数还是B的类型转换运算符】：A类定义了一个参数为B类的转换构造函数，B类定义了一个目标类型为A类的类型转换运算符，此时可以显式指定调用哪一种 无法使用强制类型转换来解决二义性问题，因为强制类型转换本身也面临二义性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 struct B; struct A{ A() =default; A(const \u0026amp;B); // 转换构造函数 }; struct B{ operator A() const; // 类型转换运算符 }; A f(const A\u0026amp;); // 定义一个函数 B b; A a = f(b); // 二义性：使用B的【类型转换运算符】，还是使用A的【转换构造函数】 A a1 = f(b.operator A()); // 使用B的类型转换运算符 A a2 = f(A(b)); // 使用A的转换构造函数 【有多个类型转换运算符，用哪个】：类定义了多个类型转换规则，转换目标为内置类型，且转换级别一致 标准类型转换的级别决定编译器如何选择最佳匹配，转换级别一致就会出现二义性 1 2 3 4 5 6 7 8 9 10 11 12 13 struct A{ A(int); A(double); operator int() const; operator double() const; }; void f(long double); A a; f(a); // 二义性错误：a转换成int还是转换成double，再提升为long double short s = 1; A a2(s); // 不会产生二义性错误，因为short类型提升为int优先于short类型提升为double 经验：尽量避免定义类型转换，且限制非显式构造函数 不要令两个类执行相同的类型转换 避免转换目标是内置算数类型的类型转换，特别是已经定义了一个转换成算数类型的类型转换 重载与函数匹配 [[ch06-函数#6.6 函数匹配|函数匹配]] 重载函数与转换构造函数 当调用重载函数时，如果两个或多个类型转换都提供了同一种可行匹配，则这些类型转换一样好 1 2 3 4 5 6 7 8 9 struct C{ C(int); }; struct D{ D(int); }; void func(const C\u0026amp;); void func(const D\u0026amp;); // 重载函数 func(10); // 二义性错误： 重载函数与用户定义的类型转换 重载运算符与函数匹配 如果既定义了类型转换运算符（转换到内置类型），又将运算符进行重载，会遇到二义性问题 如果a是一种类类型，则表达式a sym b可能是： a.operatorsym(b); 成员函数 operatorsym(a,b); 普通函数 1 2 3 4 5 6 7 8 9 10 class T{ friend T operator+ (const T\u0026amp;, const T\u0026amp;); public: T(int i); // 转换构造函数 operator int() const; // 类型转换运算符 private: int val; }; T t; int result = t + 1; // 二义性：可以将t转换成int进行内置加法，或者将1转换成类型T进行重载加法 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch14-%E9%87%8D%E8%BD%BD%E8%BF%90%E7%AE%97%E4%B8%8E%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/","summary":"第十四章 重载运算与类型转换 14.1 基本概念 语法相关： 重载的运算符必须是某个类的成员或至少拥有一个类类型的运算对象 重载运算符函数的参数数量和该运算符","title":"Ch14 重载运算与类型转换"},{"content":"第十三章 拷贝控制 一些术语 构造函数： （合成的）[[ch07-类#^15282e|默认构造函数]]：编译器创建或是使用=default修饰的构造函数 一般的构造函数 拷贝构造函数 转换构造函数（或称为[[ch07-类#隐式的类型转换|隐式的类型转换]]） 移动构造函数 [[ch07-类#委托构造函数 （delegating constructor）|委托构造函数]] 初始化类型： 默认初始化：int* a = new int; 值初始化：int *a = new int(); // 默认a=0 直接初始化：int *a = new int(1); 拷贝初始化：= 列表初始化：{} 拷贝控制操作（copy control）（或者称为拷贝控制成员）:一个类通过定义五种特殊的成员函数来控制对象的拷贝、移动、赋值、和销毁操作 拷贝构造函数（copy constructor） 拷贝赋值运算符（copy-assignment operator） 移动构造函数（move constructor） 移动赋值函数（move-assignement operator） 析构函数（destructor） 13.1 拷贝、赋值和销毁 拷贝构造函数 拷贝构造函数： 第一个参数是自身类型的引用（而且一般是const引用，否则导致无限递归，因为传递实参本身就是拷贝），且其他参数都有默认值 通常不会声明为explicit的 合成的拷贝构造函数： 编译器将参数的非static成员逐个拷贝到正在创建的对象中。 对于某些类，合成的拷贝构造函数使用=delete来禁止对该类型对象的拷贝 拷贝初始化： 通常使用拷贝构造函数完成，但也可能使用移动构造函数 出现场景： 用=定义变量时。 将一个对象作为实参传递给一个非引用类型的形参。 从一个返回类型为非引用类型的函数返回一个对象。 用花括号列表初始化一个数组中的元素或者一个聚合类中的成员。 拷贝赋值运算符 重载赋值运算符： 通常返回一个指向其左侧运算对象（即自身）的引用：return *this; 合成拷贝赋值运算符： 将右侧运算对象的每个非static成员赋予左侧运算对象的对应成员，之后返回左侧对象的引用 对于某些类，合成的拷贝赋值运算符使用=delete来禁止对该类型对象的赋值 析构函数 析构顺序： 先执行析构函数体：因为销毁指针并不会delete它所指的对象，因此需要手动释放空间 再执行析构部分，按初始化顺序的逆序销毁非static的数据成员 三/五法则 背景：一个类通常需要拷贝构造函数、拷贝赋值运算符、析构函数（和移动构造函数、移动赋值运算符），虽然通常不会全部自定义，但是有时需要将这些拷贝控制成员看作一个整体 三五法则： 一个需要自定义析构函数的类，一定也需要一个拷贝构造函数和拷贝赋值运算符（比如类中有一个指向动态内存的指针，使用合成版本的构造函数只会复制指针的值） 一个需要自定义拷贝构造函数的类，也一定需要一个拷贝赋值运算符，反之亦然；但是未必需要析构函数（比如每个类需要有一个唯一id） 显式合成=default 可以通过将拷贝控制成员定义为=default来显式地要求编译器生成合成的版本。 只能对具有合成版本的成员函数（即默认构造函数或拷贝控制成员）使用=default 在类内部使用=default修饰成员声明时，合成的函数是隐式内联的；如果不希望合成的是内联函数，应该只对成员的类外定义使用=default 阻止拷贝=delete 删除的函数=delete：虽然声明了该函数，但是不能使用它们 语法相关： =delete只能出现在函数第一次声明的地方（即告诉编译器不定义这些函数） 可以对任何函数（除了析构函数，否则动态分配了对象后无法释放）使用 如果一个类有数据成员不能默认构造、拷贝、复制或销毁，则对应的构造、拷贝、复制、析构函数被定义为删除的。原文。 如果类的某个数据成员的析构函数是删除的或不可访问的（如 private 的），则该类的合成析构函数、合成拷贝构造函数和默认构造函数被定义为删除的 如果类的某个数据成员的拷贝构造函数是删除的或不可访问的，则类的合成拷贝构造函数被定义为删除的。 如果类的某个数据成员的拷贝赋值运算符是删除的或不可访问的，则类的合成拷贝赋值运算符被定义为删除的。 如果类有一个 const 成员或引用成员，则类的合成拷贝赋值运算符被定义为删除的。（但是拷贝构造函数在初始化时执行） 如果类有一个没有类内初始化器且未显式定义默认构造函数的 const 成员或没有类内初始化器的引用成员，则该类的默认构造函数被定义为删除的 老版本的阻止拷贝 将拷贝控制成员设置为private，阻止普通用户拷贝对象（编译期报错） 将拷贝控制成员只声明不定义，友元和成员函数调用时报错（链接时报错） 13.2 拷贝控制和资源管理 通常管理类外资源的类必须定义拷贝控制成员 类的行为可以像一个值，也可以像一个指针，主要是依据拷贝指针成员的行为 不允许拷贝和赋值的类，行为既不像值，也不像指针 行为像值 对象有自己的状态，副本和原对象是完全独立的，需要定义一个拷贝构造函数、一个析构函数、一个拷贝赋值运算符 赋值运算符通常组合析构函数（销毁左侧对象的资源）和构造函数（从右侧对象拷贝构造）的操作 拷贝赋值运算符要考虑到【自赋值】的正确性： 好的方法是先将右侧对象（动态内存的指针对象）拷贝到一个局部临时对象，再销毁左侧对象的资源。（P453例子） 行为像指针 共享状态，拷贝一个这种类的对象时，副本和原对象使用相同的底层数据，需要定义一个拷贝构造函数、一个析构函数、一个拷贝赋值运算符 最好使用shared_ptr管理资源，或者使用一个引用计数来直接管理（引用计数和资源一样是共享的，应该保存在动态内存中）。引用计数的工作方式： 除了初始化对象外，每个构造函数（拷贝构造函数除外）还要创建一个引用计数，用来记录有多少对象与正在创建的对象共享状态。创建一个对象时，计数器初始化为1。 拷贝构造函数不创建新的引用计数，而是拷贝对象的计数器并递增它。 析构函数递减计数器，如果计数器变为 0，则析构函数释放状态。 拷贝赋值运算符递增右侧运算对象的计数器，递减左侧运算对象的计数器。如果左侧运算对象的计数器变为 0 就销毁状态。 拷贝赋值运算符类似于shared_ptr，需要递增右侧对象的引用计数，递减左侧对象的引用计数 此时处理【自赋值】问题：先是右侧对象引用计数递增，后是左侧对象引用计数递减，自赋值时引用计数不变（P457例子） 13.3 交换操作 管理资源的类通常还定义一个名为swap的函数，经常用于重排元素顺序的算法。 优先使用自定义的swap，否则使用标准库的std::swap 通常可以使用swap来实现赋值运算符 右侧对象传值，然后将左侧对象与右侧对象的副本进行交换（copy and swap），可以正确处理自赋值的情况 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class HasPtr{ // 行为类似值 friend void swap(HasPtr\u0026amp;, HasPtr\u0026amp;); public: HasPtr(const std::string \u0026amp;s = std::string()) : ps(new std::string(s)), i(0) {} HasPtr(const HasPtr\u0026amp; p): ps(new std::string(*p.ps)), i(p.i) {} // 拷贝构造函数 HasPtr(HasPtr \u0026amp;\u0026amp;p) noexcept: ps(p.ps), i(p.i) {p.ps 0;} // 移动构造函数 HasPtr\u0026amp; operator = (const HasPtr\u0026amp; rhs){ // 拷贝赋值操作符 std::string* tmp = new std::string(*rhs.ps); delete ps; ps = tmp; i = rhs.i; return *this; } // 特点： // 1.用swap实现赋值运算符 // 2.既是拷贝赋值运算符（参数是左值），又是移动赋值运算符（参数是右值） HasPtr\u0026amp; operator = (HasPtr rhs){ // copy and swap // 传入的是rhs的副本（假设是rhs-copy），this还是指向本身（假设是lhs） swap(*this, rhs); // 交换左侧对象(lhs)和右侧对象的副本(rhs-copy) // 此时this指向rhs-copy（更准确来说还是指向lhs地址，但是原来lhs的内容已经被swap为了rhs-copy） // swap后的lhs没有变量来接管，因此被析构 // 因此实现了this指向从lhs改变为rhs return *this; } ~HasPtr() {delete ps;} private: std::string *ps; int i; }; inline void swap(HasPtr \u0026amp;lhs, HasPtr \u0026amp;rhs){ using std::swap; // 当某个成员没有自定义的swap时，使用标准库版本的swap swap(lhs.ps, rhs.ps); swap(lhs.i, rhs.i); } class Foo{ friend void swap(Foo\u0026amp;, Foo\u0026amp;); private: HasPtr h; }; void swap(Foo \u0026amp;lhs, Foo \u0026amp;rhs){ using std::swap; // 优先使用自定义版本的swap swap(lhs.h, rhs.h); // 使用HasPtr版本的swap } HasPtr p1(\u0026#34;test), p2, p3; p2 = p1; // 使用拷贝赋值运算符 p3 = std::move(p1); // 使用移动赋值运算符 13.4 拷贝控制示例 13.5 动态内存管理类 13.6 对象移动 使用对象移动的原因：\n一些拷贝操作后，原对象会被立即销毁，因此引入移动操作可以大幅度提升性能。 C++11可以用容器保存不可拷贝的类型，只要它们可以被移动即可。 标准库容器、string和shared_ptr类既可以支持移动也支持拷贝。IO类和unique_ptr类可以移动但不能拷贝。 左值与右值 左值： 返回左值的表达式：返回左值引用的函数，赋值、下标、解引用、前置递增递减运算符， 左值引用：可以绑定到变量（包括右值引用变量）、返回左值的表达式 const的左值引用可以绑定到右值 右值： 右值要么是字面常量（没有其他用户），要么是表达式求值过程中创建的临时变量（即将被销毁） 返回右值的表达式：返回非引用类型的函数，算数、关系、位、后置递增递减运算符 右值引用：可以绑定到要求转换的表达式、字面常量、返回右值的表达式 move函数： ^d3a2a0 可以将一个右值引用绑定到左值上 int a=1; int \u0026amp;\u0026amp;r = std::move(a); 定义在头文件utility中 move告诉编译器，我们有一个左值，但我希望像右值一样处理它。 对左值调用move意味着：不在使用该左值的值，除非销毁它或者对它重新赋值 使用move的代码应该使用std::move而不是move，可以避免潜在的名字冲突 移动构造函数和移动赋值运算符 移动构造函数 第一个参数是该类类型的一个右值引用，比如StrVec::StrVec(StrVec \u0026amp;\u0026amp;s) noexcept{} 在形参列表后添加关键字noexcept可以指明该函数不会抛出任何异常，在声明和定义中均应该指明noexcept 不抛出异常的移动构造函数和移动赋值运算符必须标记为noexcept 原因：如果用移动构造函数，移动到一半抛出异常，容器不能满足即使发生异常也保持自身不变的要求，因此需要显式标记noexcept；否则编译器基于上面的考虑，会调用拷贝构造函数而非移动构造函数 除了完成资源移动，还要确保移动后源对象是可以安全销毁的（比如将源对象中数组的指针指向nullptr，然后源对象进行正确析构，否则会释放掉刚才移动的对象），用户不能使用移动后源对象的值 移动赋值运算符 StrVec\u0026amp; StrVec::operator=(StrVec \u0026amp;\u0026amp; rhs) noexcept{} 使用非引用参数的单一赋值运算符可以实现拷贝赋值和移动赋值两种功能，依赖于实参的类型：实参是左值，则实参被拷贝；实参是右值，则实参被移动：StrVec\u0026amp; StrVec::operator=(StrVec rhs); 移动迭代器： 普通迭代器的解引用运算符返回一个指向元素的左值，移动迭代器的解引用运算符生成一个右值引用 make_move_iterator函数将一个普通迭代器转换为一个移动迭代器。 因此，可以将移动迭代器传递给算法或是allocator的伴随算法 但是，标准库不能保证哪些算法适用于移动迭代器，哪些不适用。由于移动一个对象可能销毁掉源对象，因此要确定以后不再访问这个元素时，才能将移动迭代器传递给算法。 移后源对象具有不确定的状态，必须确认移后源对象没有其他用户，因此要小心使用 合成的移动操作 如果一个类定义了自己的拷贝构造函数、拷贝赋值函数或者析构函数，编译器不会为它合成移动构造函数和移动赋值运算符 如果一个类没有移动操作，类会用对应的拷贝操作来代替移动操作，即使使用move函数也是如此 只有当一个类没有自定义的拷贝控制成员，且类的每个非static数据成员都可以移动（内置类型可以移动，类类型要有对应的移动操作）时，编译器才会为类合成移动构造函数和移动赋值运算符；否则即使显式要求合成移动操作=default，编译器也会将移动操作定义为=delele 与拷贝操作不同，移动操作永远不会隐式定义为=delete 例外：将合成的移动操作定义为删除的 如果一个类定义了一个移动构造函数和/或一个移动赋值运算符，则该类的合成拷贝函数和拷贝赋值运算符会被定义为删除的 定义了一个移动构造函数或移动赋值运算符的类必须也定义自己的拷贝操作。否则，这些成员默认地被定义为删除的 引用限定符 成员函数一般有接受拷贝的const T\u0026amp;版本和接受右值的T\u0026amp;\u0026amp;版本 引用限定符\u0026amp;和\u0026amp;\u0026amp;： 限制调用者必须是左值还是右值 语法相关： 引用限定符只能用于非static成员函数 引用限定符必须同时出现在函数的声明和定义中 一个函数可以同时使用const和引用限定，即引用限定符必须在const限定符之后 如果一个成员函数有引用限定符，则具有相同参数列表的所有重载版本都必须有引用限定符 可以综合使用引用限定符和const限定符来区分一个函数的重载版本 使用const \u0026amp;\u0026amp;进行限定时，调用者必须是右值 使用const \u0026amp;进行限定时，调用者可以是左值，也可以是右值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Test{ public: Test(int v): val(v) {} int show() \u0026amp; {std::cout\u0026lt;\u0026lt;1\u0026lt;\u0026lt;std::endl;return val;} // const int show() \u0026amp; {} // 报错：返回值与重载无关，见6.4 int show() \u0026amp;\u0026amp; {std::cout\u0026lt;\u0026lt;2\u0026lt;\u0026lt;std::endl;return val;} int show() const \u0026amp; {std::cout\u0026lt;\u0026lt;3\u0026lt;\u0026lt;std::endl;return val;} int show() const \u0026amp;\u0026amp; {std::cout\u0026lt;\u0026lt;4\u0026lt;\u0026lt;std::endl;return val;} // 右值本来就是常量，这种方法无法被调用（被show() \u0026amp;\u0026amp;）覆盖 private: int val; }; int main(){ Test t1(0); t1.show(); Test(0).show(); const Test t3(0); t3.show(); // const对象或是const对象的指针/引用，只能调用const成员函数 // 输出1 2 3 } ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch13-%E6%8B%B7%E8%B4%9D%E6%8E%A7%E5%88%B6/","summary":"第十三章 拷贝控制 一些术语 构造函数： （合成的）[[ch07-类#^15282e|默认构造函数]]：编译器创建或是使用=default修饰的构造","title":"Ch13 拷贝控制"},{"content":"第十二章 动态内存 对象的生命周期： 全局对象在程序启动时分配，结束时销毁。 局部对象在进入程序块时创建，离开块时销毁。 局部static对象在第一次使用前分配，在程序结束时销毁。 动态分配对象：只能显式地被释放。 对象的内存位置： 静态内存用来保存局部static对象、类static对象、定义在任何函数之外的变量。 栈内存用来保存定义在函数内的非static对象；由操作系统自动分配和释放，内存空间比较小 堆内存，又称自由空间，用来存储动态分配的对象；手动申请和释放，内存空间比较大 12.1 动态内存与智能指针 12.1.0 动态内存 使用new动态分配内存，返回的是一个指向该对象的指针 动态分配的对象是默认初始化的，也可以使用值初始化、直接初始化（圆括号中有初始值）、列表初始化方式来进行初始化 对于类而言，值初始化与默认初始化没有区别 对于内置类型而言， 值初始化有一个确定的初始值：int *p = new int(); // 此时所指对象值为0 默认初始化的初始值未定：int *p = new int; 直接初始化：auto *p = new int(2); 可以使用new分配const对象，返回指向const类型的指针，但是动态分配的const对象必须初始化 const int* pc = new const int(1); new失败会抛出bad_alloc异常 使用定位new可以阻止抛出异常，定位new允许将new传递额外参数 如果传递nothrow给new，则new在分配失败之后会返回空指针：int* p = new(nothrow) int; 使用delete销毁对象，并释放内存 delete后的指针称为空悬指针（dangling pointer），应该在delete之后将指针值置空。 使用new/delete，要么容易忘记释放内存引起内存泄露，要么释放内存后再使用引起use after free 智能指针：定义在头文件memory中 shared_ptr：允许多个指针指向同一个对象，共享内存 unique_ptr：独占所指向的对象 weak_ptr：是一种弱引用，指向shared_ptr所管理的对象 12.1.1 shared_ptr 声明和初始化 1 2 3 4 5 6 7 shared_ptr\u0026lt;T\u0026gt; sp1; // 指向类型T的空智能指针 shared_ptr\u0026lt;T\u0026gt; sp2(q); // 参数q为T*类型的内置指针, sp2接管对象的所有权 shared_ptr\u0026lt;T\u0026gt; sp3(q, d); // sp3使用删除器d代替默认删除器delete（删除器d必须接受一个T*类型的参数） shared_ptr\u0026lt;T\u0026gt; sp4(sp); // 参数sp为shared_ptr\u0026lt;T\u0026gt;，等价于sp4 = sp; shared_ptr\u0026lt;T\u0026gt; sp5 = sp4; // sp4引用计数递减，sp5引用计数递增 shared_ptr\u0026lt;T\u0026gt; sp6 = make_shared\u0026lt;T\u0026gt;(args); // 使用参数args初始化类型为T的对象 shared_ptr\u0026lt;T\u0026gt; sp7(u); // 参数u为unique_ptr\u0026lt;T\u0026gt;, sp7接管对象的所有权，并将u置为空 语法相关： 使用内置指针q进行初始化必须使用直接初始化形式（如sp2），不能使用拷贝初始化，因为调用了explicit的转换构造函数 默认内置指针q必须指向动态内存（因为智能指针默认使用delete释放对象），如果将智能指针绑定到指向其他类型资源的指针上，需要使用自定义的删除器代替delete 推荐使用sp6的初始化方式make_shared，即不要混合使用智能指针和内置指针 不推荐sp2方式进行初始化，因为同一个内置指针q不能绑定到多个独立创建的shared_ptr，否则析构时多次delete 如果使用q创建shared_ptr后（比如sp2），不要再使用q，因为q无法知道对象何时被shared_ptr释放，随时可能变成空悬指针 1 2 3 4 5 6 7 8 9 10 void add(shared_ptr\u0026lt;int\u0026gt; p) {} int* p1 = new int(1); shared_ptr\u0026lt;int\u0026gt; sp1(p1); // shared_ptr\u0026lt;int\u0026gt; sp(p1); // 报错，p1绑定到独立的两个shared_ptr int *p2 = new int(2); add(shared_ptr\u0026lt;int\u0026gt;(p2)); // 函数调用完后，智能指针引用计数为0，p2所指向内存被释放，此时p2成为悬空指针，危险！ sp3 = make_shared\u0026lt;int\u0026gt;(3); // 推荐 add(sp3); 其他操作 操作 解释 p.get() 返回p中保存的指针。如果智能指针释放了对象，则get返回一个悬空指针。 p.use_count() 返回与p共享对象的智能指针的数量 p.unique() 当前对象是否被p独占（或者当p.use_count()==1时返回true） p.reset() 如果p时唯一指向其对象的shared_ptr，则释放此对象 p.reset(q) 令p指向内置指针q p.reset(q, d) 令p指向内置指针q，并调用删除器d（而非默认删除器）来释放q 智能指针不支持指针算数运算 get函数 智能指针的get函数返回一个内置指针，指向智能指针管理的对象，主要用于向不能使用智能指针的代码传递内置指针。 使用get返回的指针不能用来delete 不要使用get函数初始化另一个智能指针或为智能指针赋值（因为析构时多次delete） 只有在确定代码不会delete指针的情况下，才使用get unique函数通常用与reset一起使用，检查shared_ptr是否独占当前对象，如果不是需要使用reset指向新的元素或拷贝。例子。 使用建议 不使用相同的内置指针初始化或reset多个智能指针 不delete get()返回的指针。 不使用get()初始化或reset另一个智能指针 如果你使用get()返回的指针，记得当最后一个对应的智能指针销毁后，你的指针就无效了。 如果你使用智能指针管理的资源不是new分配的内存，记住传递给它一个删除函数。 12.1.2 unique_ptr 声明和初始化 1 2 3 4 5 unique_ptr\u0026lt;T\u0026gt; u1; unique_ptr\u0026lt;T\u0026gt; u1(q); // q为类型T*的内置指针 uniuqe_ptr\u0026lt;T, D\u0026gt; u2; // 定义一个unique_ptr，指向类型T，有一个类型为D的删除器 unique_ptr\u0026lt;T, D\u0026gt; u3(q, d); unique_ptr\u0026lt;T\u0026gt; u4 = make_uniuqe\u0026lt;T\u0026gt;(args); // C++14 unique_ptr将删除器类型放在尖括号中，因为删除器类型也是unique_ptr类型的一部分 同一时刻只能有一个unique_ptr指向一个给定的对象。当unique_ptr被销毁时，它指向的对象也被销毁 1 2 3 int p = new int(1); uniuqe_ptr\u0026lt;int\u0026gt; u(p); // 正确，但是u销毁之后p成为空悬指针 uniuqe_ptr\u0026lt;int\u0026gt; up(new int(1)); // 推荐写法 unique_ptr必须使用内置指针进行直接初始化（圆括号初始化），不支持拷贝或赋值操作（unique的含义，而且其拷贝构造函数是删除的） 例外：可以拷贝或赋值一个即将被销毁的unique_ptr（移动构造、移动赋值） 其他操作 操作 解释 u.get() 返回u中保存的指针。如果智能指针释放了对象，则get返回一个悬空指针。 u.release() u放弃对指针的控制权（但不会释放指向对象的内存），返回内置指针，并将u置空。 u.reset() 释放u指向的对象 u.reset(q) 令u指向内置指针q指向的对象，u原来指向的对象被释放 release返回的指针通常用来初始化另一个智能指针(reset)或给智能指针赋值 1 2 3 4 unique_ptr\u0026lt;int\u0026gt; p1(new int(1)), p2(new int(2)), p3(new int(3)); p1.release(); // p1放弃了对象的控制权，对象的内存没有释放，而且对象的指针丢失 int* p = p2.release(); // 使用p保存对象的指针，但是后续需要使用delete(p)释放内存 unique_ptr\u0026lt;int\u0026gt; u(p3.release()); // u接管p3 12.1.3 weak_ptr 声明和初始化 1 2 3 weak_ptr\u0026lt;T\u0026gt; w1; weak_ptr\u0026lt;T\u0026gt; w2(sp); // sp是shared_ptr\u0026lt;T\u0026gt;类型, w2指向一个由shared_ptr管理的对象，但是不改变shared_ptr的引用计数 weak_ptr\u0026lt;T\u0026gt; w3 = p; // p可以是shared_ptr或weak_ptr weak_ptr是一种不控制所指向对象生存期的智能指针。 其他操作 操作 解释 w.reset() 将w置为空。 w.use_count() 与w共享对象的shared_ptr的数量。 w.expired() 若w.use_count()为0，返回true，否则返回false w.lock() 如果expired为true，则返回一个空shared_ptr；否则返回一个指向w的对象的shared_ptr。 weak_ptr不能直接访问对象。因为如果shared_ptr被销毁，即使有weak_ptr指向对象，对象仍然可能被释放 使用weak_ptr访问对象时，必须先调用lock函数，以检查指向的对象是否仍然存在 1 2 3 shared_ptr\u0026lt;int\u0026gt; sp = make_shared\u0026lt;int\u0026gt;(1); weak_ptr\u0026lt;int\u0026gt; wp(sp); if (shared_ptr\u0026lt;int\u0026gt; p = wp.lock()) cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;endl; 12.2 动态数组 C++中提供了两种动态数组的分配方式：\nnew动态数组，将内存分配和对象构造结合在一起，对应的delete将对象析构和内存释放结合在一起 使用allocator类，可以实现内存分配与对象构造的分离，管理内存更灵活 12.2.1 动态数组 new和动态数组 new一个动态数组，返回指向第一个对象的指针（返回的指针不是数组类型，而是数组元素类型） 由于new分配的内存不是数组类型（比如int[10]），因此不能对动态数组调用begin和end，也不能使用range-for遍历元素 new的数组可以进行值初始化、列表初始化 1 2 3 4 const int sz = 10; int *p1 = new int[sz]; // 没有初始化 int *p2 = new int[sz](); // 值初始化为0 int *p3 = new int[sz]{1,2,3,4,5}; // 列表初始化 因为值初始化时不能提供参数，所以没有默认构造函数的类是无法动态分配数组的。 动态分配一个空数组是合法的，此时返回一个合法的非空指针，类似于尾后指针 使用delete []释放动态分配的数组，使用delete释放动态分配的对象 unique_ptr和动态数组 可以使用unique_ptr管理new分配的数组\n1 2 3 unique_ptr\u0026lt;int[]\u0026gt; p(new int[10]()); // p指向一个包含10个元素的int数组，数组元素使用值初始化 p[1] = 1; // 指向数组的unique_ptr不支持成员访问运算符（点和箭头），支持下标访问 p.release(); // 自动用delete[]销毁其指针 shared_ptr和动态数组 shared_ptr不支持直接管理动态数组，如果想用shared_ptr管理动态数组，必须提供自定义的删除器（否则使用delete释放动态数组，报错） shared_ptr未定义下标运算符，智能指针也不支持指针算数运算。可以通过get函数获取内置指针再进行访问 1 2 3 shared_ptr\u0026lt;int\u0026gt; p(new int[10](), [](int *p){delete []p;} for(int i=0; i\u0026lt;10; ++i) cout\u0026lt;\u0026lt;*(p.get()+i)\u0026lt;\u0026lt;\u0026#34; \u0026#34;; 12.2.2 allocator类 标准库allocator类定义在头文件memory中，帮助我们将内存分配和对象构造分离开。 分配的是原始的、未构造的内存，程序需要再内存中构造对象。（直接使用未构造的内存是未定义的行为） 对象使用完之后，需要对每个构造的元素调用destroy进行销毁 标准库allocator类及其方法 操作 解释 allocator\u0026lt;T\u0026gt; a 定义了一个名为a的allocator对象，它可以为类型为T的对象分配内存 a.allocate(n) 分配一段原始的、未构造的内存，保存n个类型为T的对象，返回一个指向类型T的指针 a.deallocate(p, n) 释放从T*指针p中地址开始的内存，这块内存保存了n个类型为T的对象；p必须是一个先前由allocate返回的指针。且n必须是p创建时所要求的大小。在调用deallocate之前，用户必须对每个在这块内存中创建的对象调用destroy。 a.construct(p, args) p必须是一个类型是T*的指针，指向一块原始内存；args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象。使用时需要p++移动指针 a.destroy(p) p为T*类型的指针，此算法对p指向的对象执行析构函数。 construct和destroy一次只能构造或销毁一个对象，使用中可能需要使用指针对每个元素进行遍历 allocator伴随算法 操作 解释 uninitialized_copy(b, e, b2) 从【迭代器b和e给定的输入范围】中拷贝元素到【迭代器b2指定的未构造的原始内存】中。b2指向的内存必须足够大，能够容纳输入序列中元素的拷贝。 uninitialized_copy_n(b, n, b2) 从迭代器b指向的元素开始，拷贝n个元素到【b2开始的未构造内存】中。 uninitialized_fill(b, e, t) 在【迭代器b和e指向的原始内存范围】中创建对象，对象的值均为t的拷贝。 uninitialized_fill_n(b, n, t) 从【迭代器b指向的原始内存地址】开始创建n个对象。b必须指向足够大的未构造的原始内存，能够容纳给定数量的对象。 进行拷贝和填充未初始化内存 返回最后一个构造元素的尾后位置 12.3 使用标准库：文本查询程序 参考\n","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch12-%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98/","summary":"第十二章 动态内存 对象的生命周期： 全局对象在程序启动时分配，结束时销毁。 局部对象在进入程序块时创建，离开块时销毁。 局部static对象在第一次","title":"Ch12 动态内存"},{"content":"第十一章 关联容器 关联容器基于关键字访问元素，顺序容器基于位置访问元素 关联容器类型 11.2 关联容器概述 关联容器的初始化可以使用直接初始化（圆括号初始化）、列表初始化、拷贝初始化、迭代器范围初始化（会对关键字自动去重） map类型通常被称为关联数组 对于有序容器，关键字类型必须定义元素比较的方法（即\u0026lt;），严格弱序 pair类型 定义在utility头文件 map中的每个元素都是一个pair类型的对象，pair是一个模板类型，保存两个名为first和second的共有数据成员，first保存关键字，second保存值 操作 解释 pair\u0026lt;T1, T2\u0026gt; p; p是一个pair，两个类型分别是T1和T2的成员都进行了值初始化。 pair\u0026lt;T1, T2\u0026gt; p(v1, v2); first和second分别用v1和v2进行初始化。 pair\u0026lt;T1, T2\u0026gt;p = {v1, v2}; 等价于`p(v1, v2) make_pair(v1, v2); pair的类型从v1和v2的类型推断出来。 p.first 返回p的名为first的数据成员。 p.second 返回p的名为second的数据成员。 p1 relop p2 relop(relational operations,\u0026lt;,\u0026gt;,\u0026lt;=,\u0026gt;=)，运算关系符按字典序定义。 p1 == p2 必须两对元素两两相等 p1 != p2 同上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 定义一个重载键类型的类，重载()操作符 class MyCmp{ public: bool operator() (const string \u0026amp;a, const string \u0026amp;b) {return a.size() \u0026lt; b.size();} }; map\u0026lt;string, int, MyCmp\u0026gt; mp{{\u0026#34;a\u0026#34;, 1}, {\u0026#34;ab\u0026#34;, 2}, {\u0026#34;b\u0026#34;, 3}}; bool cmp(const string \u0026amp;a, const string \u0026amp;b) {return a.size() \u0026lt; b.size();} map\u0026lt;string, int, bool(*)(const string\u0026amp;, const string\u0026amp;)\u0026gt; mp2({{\u0026#34;a\u0026#34;, 1}, {\u0026#34;b\u0026#34;, 2}}, cmp); // 模板中传入函数类型，构造函数中传入函数指针 using CMP = bool(*)(const string\u0026amp;, const string\u0026amp;); map\u0026lt;string, int, CMP\u0026gt; mp3({{\u0026#34;a\u0026#34;, 1}, {\u0026#34;b\u0026#34;, 2}}, cmp); // 或者模板中传入函数类型的别名，构造函数中同样传入函数指针 map\u0026lt;string, int, decltype(cmp)*\u0026gt; mp4({{\u0026#34;a\u0026#34;, 1}, {\u0026#34;b\u0026#34;, 2}}, cmp); // 使用decltype获取函数指针 // 遍历 for(map\u0026lt;string, int, CMP\u0026gt;::iterator iter = mp3.begin(); iter != mp3.end(); ++iter) // 或者使用map\u0026lt;string, int\u0026gt;::iterator iter也可以 cout \u0026lt;\u0026lt; iter-\u0026gt;first \u0026gt;\u0026gt; \u0026#34; \u0026#34; \u0026gt;\u0026gt; iter-\u0026gt;second \u0026gt;\u0026gt;endl; 11.3 关联容器操作 关联容器额外的类型别名： 类型别名 解释 key_type 此容器类型的关键字类型 mapped_type 每个关键字关联的类型，只适用于map系列 value_type 对于map，是pair\u0026lt;const key_type, mapped_type\u0026gt;（注意关键字部分有const）; 对于set，和key_type相同。 解引用一个关联容器迭代器时，会得到一个类型为容器的value_type的值的引用。 map而言，value_type是pair类型（pair\u0026lt;const key_type, mapped_type\u0026gt;） set而言，value_type是const key_type，普通迭代器和const迭代器都是只读的，不能修改值 添加元素：insert insert操作 关联容器 c.insert(v) c.emplace(args) v是value_type类型的对象；args用来构造一个元素。函数返回一个pair，指向具有指定关键字的元素的迭代器，和一个指示插入是否成功的bool值。 c.insert(b, e) c.insert(il) b和e是迭代器，表示一个c::value_type类型值的范围；il是这种值的花括号列表。函数返回void。对于 map和set，只插入关键字不在c中的元素。 c.insert(p, v) c.emplace(p, args) 类似insert(v)，但将迭代器p作为一个提示，指出从哪里开始搜索新元素应该存储的位置。返回一个迭代器，指向具有给定关键字的元素。 向map添加元素（在参数列表中构建pair），例子： 1 2 3 4 word_count.insert({word, 1}); word_count.insert(make_pair(word, 1)); word_count.insert(pair\u0026lt;string, size_t\u0026gt;(word, 1)); word_count.insert(map\u0026lt;string, size_t\u0026gt;::value_type (word, 1)); 相对于下标操作，多使用insert（因为有返回值） 例子：wordcount 1 2 3 4 map\u0026lt;string, size_t\u0026gt; word_count; string word; while(cin \u0026gt;\u0026gt; word) ++word_count.insert({word, 0}).first-\u0026gt;second; 删除元素：erase 操作 解释 c.erase(k) 从c中删除每个关键字为k的元素。返回一个size_type值，指出删除的元素的数量。（顺序容器没有该操作） c.erase(p) 从c中删除迭代器p指定的元素。p必须指向c中一个真实元素，不能等于c.end()。返回一个指向p之后元素的迭代器。 c.erase(b, e) 删除迭代器对b和e所表示范围中的元素。返回e。 注意遍历容器删除元素时，map与vector不同 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 map\u0026lt;int, int\u0026gt; m; for(auto iter = m.begin(); iter != m.end(); ){ if(iter-\u0026gt;second == 0) m.erase(iter++); else iter++; } vector\u0026lt;int\u0026gt; v; for(auto iter = v.begin(); iter != v.end(); ){ if(*iter == 0) iter = v.erase(iter); else iter++; } 下标操作 操作 解释 c[k] 返回关键字为k的元素；如果k不在c中，添加一个关键字为k的元素，对其值初始化。 c.at(k) 访问关键字为k的元素，带参数检查；若k不存在在c中，抛出一个out_of_range异常。 下标和at操作只适用于非const的map和unordered_map，即使访问操作也不行 map的下标操作只能返回非常量引用，如果map本身是常量，则无法使用下标访问元素，只能使用at函数 查找元素 在一个关联容器中查找元素:\n操作 解释 c.find(k) 返回一个迭代器，指向第一个关键字为k的元素，若k不在容器中，则返回尾后迭代器 c.count(k) 返回关键字等于k的元素的数量。对于不允许重复关键字的容器，返回值永远是0或1。 c.lower_bound(k) 返回一个迭代器，指向第一个关键字大于等于k的元素。 c.upper_bound(k) 返回一个迭代器，指向第一个关键字大于k的元素。 c.equal_range(k) 返回一个迭代器pair，表示关键字等于k的元素的范围。若k不存在，pair的两个成员均等于c.end()。 lower_bound和upper_bound不适用于无序容器。 如果multimap或multiset中有多个元素有相同关键字，则这些元素在容器中会相邻存储 11.4 无序容器 有序容器使用比较运算符来组织元素；无序容器使用哈希函数和关键字类型的==运算符。 无序容器在存储上组织为一组桶(bucket)，每个桶保存零个或多个元素。无序容器使用一个哈希函数将元素映射到桶。无序容器首先计算元素的哈希值，找到应该搜索哪个桶（相同哈希值的元素保存到相同的桶中），再搜索桶。 无序容器管理操作： 操作 解释 桶接口 c.bucket_count() 正在使用的桶的数目 c.max_bucket_count() 容器能容纳的最多的桶的数目 c.bucket_size(n) 第n个桶中有多少个元素 c.bucket(k) 关键字为k的元素在哪个桶中 桶迭代 local_iterator 可以用来访问桶中元素的迭代器类型 const_local_iterator 桶迭代器的const版本 c.begin(n)，c.end(n) 桶n的首元素迭代器 c.cbegin(n)，c.cend(n) 与前两个函数类似，但返回const_local_iterator。 哈希策略 c.load_factor() 每个桶的平均元素数量，返回float值。 c.max_load_factor() c试图维护的平均比桶大小，返回float值。c会在需要时添加新的桶，以使得load_factor\u0026lt;=max_load_factor c.rehash(n) 重组存储，使得bucket_count\u0026gt;=n，且bucket_count\u0026gt;size/max_load_factor c.reverse(n) 重组存储，使得c可以保存n个元素且不必rehash。 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch11-%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8/","summary":"第十一章 关联容器 关联容器基于关键字访问元素，顺序容器基于位置访问元素 关联容器类型 11.2 关联容器概述 关联容器的初始化可以使用直接初始化（圆括号初始","title":"Ch11 关联容器"},{"content":"第十章 泛型算法 10.1 泛型算法 泛型算法本身不直接操作容器，而是遍历两个迭代器指定的一个元素范围来进行操作 必要的编程假定：算法（注意是标准库中的算法）永远不会改变底层容器的大小。算法可能改变容器中保存的元素的值，也可能在容器内移动元素，但不能直接添加或者删除元素。 10.2 初识泛型算法 只读算法 最好使用cbegin和cend。 accumulate函数：计算一个序列的和。序列中的元素必须与第三个元素匹配，或者能转换为第三个参数的类型（accumulate函数是模板函数，类型由第三个参数推导而来，此类型决定了使用哪种加法运算符） find函数：接受一对迭代器范围和目标查找值，如果找到，则返回对应的迭代器，否则返回尾后迭代器 find_if函数：接受一对迭代器范围和一个谓词，对范围内的每个元素调用给定谓词进行判断，返回第一个使谓词返回非零的元素，否则返回尾后迭代器。 find_first_of，输入：两对迭代器标记两段范围，在第一段中找第二段中任意元素，返回第一个匹配的元素，找不到返回第一段的end迭代器。 equal：确定两个序列是否保存相同的值。（顺序也相同） 写容器元素的算法 修改算法 fill： fill(vec.begin(), vec.end(), 0); fill_n： fill_n(vec.begin(), len, 0); for_each函数：接受一对迭代器和一个谓词，对范围内的每个元素调用谓词 transform函数：接受三个迭代器和一个谓词，前两个迭代器指定一个输入序列的范围，第三个迭代器指定目的位置，它对输入序列中的每个元素调用谓词，并将结果写入到目的位置。 拷贝算法 copy (src.begin(), src.end(), dst.begin());前两个参数指定输入范围，第三个指向目标序列的起始位置。 replace(src.begin(), src.end(), old, new)：将范围内old替换为new replace_copy(src.begin(), src.end(), dst.begin(), old, new)：基本同replace，但是保留原范围不变，将替换后的结果保存到dst位置 很多算法都提供copy版本，不会将新元素放回原序列，而是将结果保存到新序列中 重排容器元素的算法 排序算法sort：接受两个迭代器，利用元素的\u0026lt;运算符重排元素 stable_sort 消除重复unique：之前要先调用sort，返回的迭代器指向最后一个不重复元素之后的位置（最后一个不重复元素的尾后位置）；重复的元素在原来容器的后边，并没有真正删除。 10.3 定制操作 向算法传递函数 谓词（predicate）：是一个可调用的表达式，返回结果是一个能用作条件的值 接受谓词参数的算法会对输入序列中的元素调用谓词，因此序列的元素类型必须能转换为谓词的参数类型 可以向算法传递四种可调用对象：函数、函数指针、重载了函数调用运算符的类、lambda表达式 lambda表达式 形式：[capture list](parameter list) -\u0026gt; return type {function body}。 capture list捕获列表是一个由lambda所在函数定义的局部变量的列表（通常为空）。不可忽略。捕获列表只能用于局部非static变量，lambda表达式可以直接使用局部static变量和所在函数之外声明的名字。 return type是返回类型。可忽略（省略返回类型时，可以由return返回表达式的类型推断而来，否则返回类型为void），必须使用尾置返回。 parameter是参数列表。可忽略（等价于指定空参数列表），不能有默认实参。 function body是函数体。不可忽略。 定义一个lambda表达式时，编译器生成一个与lambda对应的未命名的类类型 当向函数传递一个lambda时，传递的参数实际上就是这个未命名类的对象。 [[ch14-重载运算与类型转换#lambda是函数对象|lambda是函数对象]] lambda捕获和返回 捕获：lambda表达式将局部变量包含在捕获列表中，在捕获列表中的参数可以被lambda函数体所使用，lambda 捕获列表 值捕获：被值捕获的变量的值是在lambda创建时拷贝，而非调用时拷贝。因此在lambda创建后改变被捕获的变量不会影响lambda中对应的值。 引用捕获：捕获的变量前加\u0026amp;，此时修改局部变量会影响lambda内对应的值，但是必须确保被引用的对象在 lambda 执行时是存在的。 隐式捕获：不显式列出捕获变量，而是编译器进行推断 \u0026amp;为引用捕获，=为值捕获 混合显式捕获与隐式捕获 此时捕获列表第一个元素必须是\u0026amp;或=，指定默认捕获方式，显式捕获的变量必须使用与隐式捕获不同的方式 可变lambda：默认情况下，通过值捕获得到的变量（的拷贝），lambda无法修改其值，如果希望改变，可以在参数列表后加上mutable 通过引用捕获的变量，取决于变量是否为const 如果lambda中除了return还有其他语句，此时应该指明返回类型；否则可以省略返回类型 lambda可以作为函数的返回值，此时lambda不能包含引用捕获。 1 2 3 4 5 6 int a = 1, b = 2, c = 4; auto g = [=, \u0026amp;b] (int c) -\u0026gt; void {b+=c; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl;}; // 隐式的值捕获(a),显式的引用捕获(b) auto f = [\u0026amp;, b] (int c) -\u0026gt; void {a+=c;}; // 隐式的引用捕获(a),显式的值捕获(b) auto gg = [=, \u0026amp;b] (int c) mutable -\u0026gt; void {b+=c; a+=c; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl;}; auto ff = [\u0026amp;, b] (int c) mutable -\u0026gt; void {b+=c; cout\u0026lt;\u0026lt;b\u0026lt;\u0026lt;endl;}; 参数绑定 例子：找到vector中第一个大于val的元素，即需要将二元谓词包装成一元谓词，可以使用bind绑定第二个参数 1 2 3 4 5 bool isBigger(int a, int val) {return a \u0026gt; val} vector\u0026lt;int\u0026gt; v{1,2,4,5}; int val = 3; vector\u0026lt;int\u0026gt;::iterator it = find_if(v.begin(), v.end(), isBigger); // 错误，find_if只能接受一元谓词，但是isBigger是二元谓词，可以使用bind进行参数绑定 vector\u0026lt;int\u0026gt;::iterator it = find_if(v.begin(), v.end(), bind(isBigger, val, std::placeholders::_1)); vector\u0026lt;int\u0026gt;::iterator iter = find_if(v.begin(), v.end(), [val] (int a) -\u0026gt; bool {return a\u0026lt;val;}; // 可以使用lambda表达式 标准库bind函数：auto newCallable = bind(callable, arg_list); 定义在头文件functional中，接受一个可调用对象和一些实参，生成一个新的可调用对象 我们在调用newCallable的时候，newCallable会调用callable并传递给它arg_list中的参数（将绑定的参数拷贝过去）。 参数绑定和重排：std::placeholder::_n表示将newCallable的第n个参数放在占位符_n的位置 绑定引用参数： ref函数接受一个参数，返回一个可以拷贝的对象，该对象含有参数的引用。 cref返回const的引用 1 2 3 4 5 6 7 8 9 10 11 12 void show(int a, int b, int c, int d, int e) {cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;c\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;d\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;e\u0026lt;\u0026lt;endl;} void out(ostream \u0026amp;os, int a, int b, int c, int d, int e) {os\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;c\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;d\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;e\u0026lt;\u0026lt;endl;} int a = 1, b = 2, c = 3, d = 4, e = 5; auto g = bind(show, a, b, placeholders::_2, d, placeholders::_1); // 将g的第一个参数放到placeholders::_1的位置 auto h = bind(show, a, b, placeholders::_1, d, placeholders::_2); // 重排参数顺序 g(e, c); // 将e放到placeholders::_1的位置，将c放到placeholders::_2的位置 h(e, c); // show(a, b, _1, d, _2), 其中_1是e，_2是c ostream\u0026amp; os = cout; auto f = bind(out, ref(os), a, b, placeholders::_2, d, placeholders::_1); // 绑定引用参数 f(e, c); 10.4 再探迭代器 插入迭代器 插入器是一种迭代器适配器，接受一个容器，生成一个迭代器，能实现向给定容器添加元素，定义在头文件iterator中 back_inserter：创建一个调用push_back操作的迭代器。 back_inserter是插入器，back_insert_iterator\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;是插入迭代器类型 front_inserter创建一个调用push_front操作的迭代器。 inserter创建一个调用insert操作的迭代器。接受第二个参数，即一个指向给定容器的迭代器，元素会被插入到迭代器所指向的元素之前。 随着插入过程，inserter永远指向指定的元素，而不是永远指向某个特定的位置 每向插入器赋值一次就相当于调用一次相关操作，*it, ++it, it++等操作虽然存在，但不会有任何作用（仍返回it） 1 2 3 4 5 6 7 8 9 10 11 deque\u0026lt;int\u0026gt; v{1, 2, 3, 4, 5}; back_insert_iterator\u0026lt;deque\u0026lt;int\u0026gt;\u0026gt; biter = back_inserter(v); // 相当于永远指向尾后位置 front_insert_iterator\u0026lt;deque\u0026lt;int\u0026gt;\u0026gt; fiter = front_inserter(v); // 每赋值一次就相当于调用一次相关操作 biter = 6; biter = 7; fiter = 0; fiter = -1; for_each(v.begin(), v.end(), [] (int i) -\u0026gt; void {cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;\u0026#34; \u0026#34;;}); 流迭代器 流迭代器将对应的流当作一个特定类型的元素序列来处理 istream_iterator：读取输入流 可以不绑定到流，相当于尾后迭代器 istream_iterator 操作：没有赋值操作，解引用操作相当于返回输入流中读取的值，需要递增操作 istream_iterator允许使用懒惰求值，即标准库不保证迭代器可以立即从输入流中获取数据，但是保证迭代器第一次解引用操作之前，从流中读取数据的操作已经完成。 ostream_iterator：向输出流中写入数据 ostream_iterator必须绑定到一个指定的流，不允许空的或者尾后位置 ostream_iterator 操作：赋值操作相当于输出流的输出操作，递增、解引用操作没有意义 向ostream_iterator赋值时，可以省略解引用和递增运算（实际上解引用和递增操作不会对ostream_iterator做任何事情）。但是不推荐省略，可以保持迭代器行为的一致性，便于修改。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 istream_iterator\u0026lt;int\u0026gt; int_iter(cin); // 可以将流迭代器绑定到一个流（输入流读取操作 就相当于 从流迭代器中取出值，流迭代器累加）， istream_iterator\u0026lt;int\u0026gt; int_eof; // 默认初始化相当于尾后迭代器或eof ostream_iterator\u0026lt;int\u0026gt; out_iter(cout, \u0026#34; \u0026#34;); // 必须将ostream_iterator绑定到一个指定的流, 每个值后面跟着一个C风格字符串str // 原始方式，注意输入时Ctrl+Z表示eof // vector\u0026lt;int\u0026gt; v; // for(; int_iter != int_eof; ++int_iter){ // v.push_back(*int_iter); // } vector\u0026lt;int\u0026gt; v(int_iter, int_eof); // 等价方式，更能体现流迭代器的特点 // for(int i: v){ // *(out_iter++) = i; // 原始方式（先后置递增，返回旧值，再解引用），但是更推荐 // // out_iter = i; // 等价方式，更简略 // } copy(v.begin(), v.end(), out_iter); // 最简单的写法，将序列范围直接复制到输出迭代器中 // copy(int_iter, int_eof, out_iter); // 直接将输入进行输出 反向迭代器 递增会移动到前一个元素 调用反向迭代器的base函数可以获得其对应的正向迭代器 rbegin()指向的是最后一个元素，而end()指向的是尾后元素；对应的，【反向迭代器】与【其调用base函数得到的正向迭代器】的关系类似于rbegin()与end()，指向的不是相同元素。图示 1 2 3 4 5 vector\u0026lt;int\u0026gt; v{1, 2, 3, 4, 5}; vector\u0026lt;int\u0026gt;::reverse_iterator riter = v.rbegin(); // 5 vector\u0026lt;int\u0026gt;::iterator iter = v.end(); // 尾后位置 cout\u0026lt;\u0026lt;*riter\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*(--iter)\u0026lt;\u0026lt;endl; // 5 5 cout\u0026lt;\u0026lt;*(++riter)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*riter.base()\u0026lt;\u0026lt;endl; // 4 5 移动迭代器 10.5 泛型算法结构 5类迭代器 算法所要求的迭代器操作可以分为 5 类，C++ 标准指明了泛型算法的每个迭代器参数的最小类别。 vector\u0026lt;int\u0026gt;::iterator迭代器是随机访问迭代器，list\u0026lt;int\u0026gt;::iteraotr迭代器是双向迭代器 迭代器类别 解释 支持的操作 输入迭代器 只读，不写；单遍扫描，只能递增 ==,!=,++,*,-\u0026gt; 输出迭代器 只写，不读；单遍扫描，只能递增 ++,* 前向迭代器 可读写；多遍扫描，只能递增 ==,!=,++,*,-\u0026gt; 双向迭代器 可读写；多遍扫描，可递增递减 ==,!=,++,--,*,-\u0026gt; 随机访问迭代器 可读写，多遍扫描，支持全部迭代器运算 ==,!=,\u0026lt;,\u0026lt;=,\u0026gt;,\u0026gt;=,++,--,+,+=,-,-=,*,-\u0026gt;,iter[n]==*(iter[n]) 算法的形参模式 alg(beg, end, other args); alg(beg, end, dest, other args); alg(beg, end, beg2, other args); alg(beg, end, beg2, end2, other args); 其中，alg是算法名称，beg和end表示算法所操作的输入范围。dest表示输出范围或输出流迭代器，beg2、end2表示第二个输入范围 算法命名规范 一些算法使用重载形式传递一个谓词，来代替\u0026lt;或==，比如sort 接受谓词参数的算法都有附加的_if后缀，没有的一般都是接受元素值 将执行结果写入额外目的空间的算法都有_copy后缀（即拷贝版本） 10.6 特定容器算法 对于list和forward_list，优先使用【成员函数版本的算法】而不是通用算法。 list和forward_list成员函数版本的算法： 操作 解释 lst.merge(lst2) 将来自lst2的元素合并入lst，二者都必须是有序的，元素将从lst2中删除。 lst.merge(lst2, comp) 同上，给定比较操作。 lst.remove(val) 调用erase删除掉与给定值相等(==)的每个元素 lst.remove_if(pred) 调用erase删除掉令一元谓词为真的每个元素 lst.reverse() 反转lst中元素的顺序 lst.sort() 使用\u0026lt;排序元素 lst.sort(comp) 使用给定比较操作排序元素 lst.unique() 调用erase删除同一个值的连续拷贝。使用==。 lst.unique(pred) 调用erase删除同一个值的连续拷贝。使用给定的二元谓词。 上面的操作都返回void 链表特有版本的算法操作会改变底层容器 list和forward_list的splice函数可以进行容器合并，使用lst.splice(args)或flst.splice_after(args) 参数 解释 (p, lst2) p是一个指向lst中元素的迭代器，或者一个指向flst首前位置的迭代器。函数将lst2中的所有元素移动到lst中p之前的位置或是flst中p之后的位置。将元素从lst2中删除。lst2的类型必须和lst相同，而且不能是同一个链表。 (p, lst2, p2) 同上，p2是一个指向lst2中位置的有效的迭代器，将p2指向的元素移动到lst中，或将p2之后的元素移动到flst中。lst2可以是与lst或flst相同的链表。 (p, lst2, b, e) b和e表示lst2中的合法范围。将给定范围中的元素从lst2移动到lst或first中。lst2与lst可以使相同的链表，但p不能指向给定范围中的元素。 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch10-%E6%B3%9B%E5%9E%8B%E7%AE%97%E6%B3%95/","summary":"第十章 泛型算法 10.1 泛型算法 泛型算法本身不直接操作容器，而是遍历两个迭代器指定的一个元素范围来进行操作 必要的编程假定：算法（注意是标准库中的算法","title":"Ch10 泛型算法"},{"content":"第九章 顺序容器 9.1 顺序容器概述 顺序容器（sequential container）：元素顺序不依赖于元素的值，而是与元素加入容器时的位置相对应。 顺序容器类型 容器类型 介绍 vector 随机访问，尾部插入/删除快 deque 随机访问，头尾插入/删除快 list 双向链表。只支持双向顺序访问，任何位置插入/删除都快 forward_list 单向链表。只支持单向顺序访问。任何位置插入/删除都快 array 固定大小数组，随机访问。不能添加或者删除元素。 string 随机访问，尾部插入/删除速度快。 list 的额外内存开销相比其他大很多。 通常使用vector是最好的选择，除非你有很好的理由选择其他容器。 如果不需要向中间插入数据，则先向vector中添加，再sort 如果一定要向中间插入数据，则先使用list，输入完成后再拷贝到vector中 9.2 容器库概览 类型 操作 解释 iterator 此容器类型的迭代器类型 const_iterator 可以读取元素但不能修改元素的迭代器类型 size_type 无符号整数类型，足够保存此种容器类型最大可能的大小 difference_type 带符号整数类型，足够保存两个迭代器之间的距离 value_type 元素类型 reference 元素的左值类型；和value_type \u0026amp;含义相同 const_reference 元素的const左值类型，即const value_type \u0026amp; 迭代器范围begin和end，其中end是指向尾后地址，左闭右开 当不需要修改时，尽量使用const iterator 构造函数 操作 解释 C c; 默认构造函数，构造空容器 C c1(c2);或C c1 = c2; 构造c2的拷贝c1 C c(b, e) 构造c，将迭代器b和e指定范围内的所有元素拷贝到c C c{a, b, c...} 列表初始化c C c(n) 只支持顺序容器，且不包括array，包含n个元素，这些元素进行了值初始化 C c(n, t) 包含n个初始值为t的元素 三种构造方式： 直接拷贝：将一个容器复制给另一个容器时，类型必须匹配：容器类型和元素类型都必须相同。 迭代器范围构造：不要求容器类型相同，容器内的元素类型也可以不同，但是要能进行类型转换 列表初始化 array初始化 定义array需要同时指定元素类型和大小，默认初始化为0 array只能默认初始化或列表初始化，如果定义的数组很大并且需要初始化，可以先默认初始化然后用 fill 函数填充值。 赋值和swap 操作 解释 c1 = c2; 将c1中的元素替换成c2中的元素 c1 = {a, b, c...} 将c1中的元素替换成列表中的元素（不适用于array） c1.swap(c2) 交换c1和c2的元素 swap(c1, c2) 等价于c1.swap(c2) c.assign(b, e) 将c中的元素替换成迭代器b和e表示范围中的元素，b和e不能指向c中的元素，可以用不同但相容的类型赋值，或者用容器的子序列赋值 c.assign(il) 将c中的元素替换成初始化列表il中的元素 c.assign(n, r) 将c中的元素替换为n个值是t的元素 swap： 对于array，swap会真正交换它们的元素；对于其他元素，swap不交换元素，只交换数据结构，因此很快 对于 string，swap 后，指针、引用和迭代器会失效。对于其他容器，交换后指针指向了另一个容器的相同位置。 建议统一使用swap(a,b) assign赋值： assign操作不适用于关联容器和array =赋值要求两边类型相同，assign只要求可以转换即可 array赋值： 不能对内置数组拷贝或赋值，但是 array 可以。 使用一个 array 对另一个 array 赋值，需要两个array 元素类型与大小都相同。 不能用花括号列表对 array 赋值（只可以初始化） 大小 操作 解释 c.size() c中元素的数目（不支持forward_list） c.max_size() c中可保存的最大元素数目 c.empty() 若c中存储了元素，返回false，否则返回true forward_list支持max_size和empty，但是不支持size 9.3 顺序容器操作 添加元素 操作 解释 c.push_back(t) 在c尾部创建一个值为t的元素，返回void c.emplace_back(args) 同上 c.push_front(t) 在c头部创建一个值为t的元素，返回void c.emplace_front(args) 同上 c.insert(p, t) 在迭代器p指向的元素之前创建一个值是t的元素，返回指向新元素的迭代器 c.emplace(p, args) 同上 c.insert(p, n, t) 在迭代器p指向的元素之前插入n个值为t的元素，返回指向第一个新元素的迭代器 c.insert(p, b, e) 将迭代器b和e范围内的元素，插入到p指向的元素之前 c.insert(p, il) il是一个花括号包围中的元素值列表，将其插入到p指向的元素之前 向vector、string或deque插入元素会使所有指向容器的迭代器、引用和指针失效。 头尾添加返回void，中间添加返回指向新添加元素的迭代器 push和insert传递的是元素类型的对象，emplace则将参数传递给元素类型的构造对象 传递给emplace的参数必须和元素类型的构造函数相匹配。 insert 返回值是指向添加的元素中第一个元素的迭代器 添加的都是元素的拷贝，不是元素本身。 访问元素 操作 解释 c.back() 返回c中尾元素的引用。若c为空，函数行为未定义 c.front() 返回c中头元素的引用。若c为空，函数行为未定义 c[n] 返回c中下标是n的元素的引用，n时候一个无符号整数。若n\u0026gt;=c.size()，则函数行为未定义 c.at(n) 返回下标为n的元素引用。如果下标越界，则抛出out_of_range异常 访问成员函数返回的是引用。 删除元素 操作 解释 c.pop_back() 删除c中尾元素，若c为空，则函数行为未定义。函数返回void c.pop_front() 删除c中首元素，若c为空，则函数行为未定义。函数返回void c.erase(p) 删除迭代器p指向的元素，返回一个指向被删除元素之后的元素的迭代器，若p本身是尾后迭代器，则函数行为未定义 c.erase(b, e) 删除迭代器[b,e)内的元素，返回指向最后一个被删元素之后元素的迭代器，若e本身就是尾后迭代器，则返回尾后迭代器 c.clear() 删除c中所有元素，返回void 头尾删除返回void，特定位置删除，返回被删除元素之后元素的迭代器 添加、删除操作可能使迭代器失效 特殊的forward_list操作 forward_list 是单向链表，添加和删除操作都会同时改变前驱和后继结点 forward_list定义了before_begin()，即【首前（off-the-beginning）迭代器】，允许我们再在首元素之前添加或删除元素。 前面的insert都是在当前元素之前插入，insert_after插入到当前元素之后 操作 解释 lst.before_begin() 返回指向链表首元素之前不存在的元素的迭代器，此迭代器不能解引用。 lst.cbefore_begin() 同上，但是返回的是常量迭代器。 lst.insert_after(p, t) 在迭代器p之后插入元素。t是一个对象 lst.insert_after(p, n, t) 在迭代器p之后插入元素。t是一个对象，n是数量。若n是0则函数行为未定义 lst.insert_after(p, b, e) 在迭代器p之后插入元素。由迭代器b和e指定范围。 lst.insert_after(p, il) 在迭代器p之后插入元素。由il指定初始化列表。 lst.emplace_after(p, args) 使用args在p之后的位置，创建一个元素，返回一个指向这个新元素的迭代器。若p为尾后迭代器，则函数行为未定义。 lst.erase_after(p) 删除p指向位置之后的元素，返回一个指向被删元素之后的元素的迭代器，若p指向lst的尾元素或者是一个尾后迭代器，则函数行为未定义。 lst.erase_after(b, e) 类似上面，删除对象换成从(b,e)指定的范围。 改变容器大小 操作 解释 c.resize(n) 调整c的大小为n个元素，若n\u0026lt;c.size()，则多出的元素被丢弃。若必须添加新元素，对新元素进行值初始化 c.resize(n, t) 调整c的大小为n个元素，任何新添加的元素都初始化为值t 迭代器 操作 解释 c.begin(), c.end() 返回指向c的首元素和尾元素之后位置的迭代器 c.cbegin(), c.cend() 返回const_iterator c.rbegin(), c.rend() 返回指向c的尾元素和首元素之前位置的迭代器 c.crbegin(), c.crend() 返回const_reverse_iterator 添加、删除操作可能使迭代器失效 在向容器添加元素后： 如果容器是vector或string，且存储空间被重新分配，则指向容器的迭代器、指针、引用都会失效。 对于deque，插入到除首尾位置之外的任何位置都会导致指向容器的迭代器、指针、引用失效。如果在首尾位置添加元素，迭代器会失效，但指向存在元素的引用和指针不会失效。 对于list和forward_list，指向容器的迭代器、指针和引用依然有效。 在从一个容器中删除元素后：尾后迭代器总是会失效 对于list和forward_list，指向容器其他位置的迭代器、引用和指针仍然有效。 对于deque，如果在首尾之外的任何位置删除元素，那么指向被删除元素外其他元素的迭代器、指针、引用都会失效；如果是删除deque的尾元素，则尾后迭代器会失效，但其他不受影响；如果删除的是deque的头元素，这些也不会受影响。 对于vector和string，指向被删元素之前的迭代器、引用、指针仍然有效。 9.4 vector对象是如何增长的 vector和string在内存中是连续保存的，如果原先分配的内存位置已经使用完，则需要重新分配新空间，将已有元素从就位置移动到新空间中，然后添加新元素。\n管理容量的成员函数 操作 解释 c.shrink_to_fit() 将capacity()减少到和size()相同大小 c.capacity() 不重新分配内存空间的话，c可以保存多少个元素 c.reverse(n) 分配至少能容纳n个元素的内存空间(预分配，而且如果需求容量小于当前容量，什么都不做) shrink_to_fit只适用于vector、string和deque capacity和reverse只适用于vector和string。 9.5 额外的string操作 构造string的其他方法 操作 解释 string s(cp, n) s是cp指向的数组中前n个字符的拷贝，此数组至少有n个字符 string s(s2, pos2) s是string s2从下标pos2开始的字符到末尾的拷贝。若pos2 \u0026gt; s2.size()，则构造函数的行为未定义。 string s(s2, pos2, len2) s是string s2从下标pos2开始的len2个字符的拷贝。 最初的构造函数：直接初始化（圆括号初始化）、迭代器范围初始化、列表初始化 substr操作 操作 解释 s.substr(pos, n) 返回一个string，包含s中从pos开始的n个字符的拷贝。 改变string的其他方法 操作 解释 s.insert(pos, args) 在pos之前插入args指定的字符。pos可以使是下标或者迭代器。接受下标的版本返回指向s的引用；接受迭代器的版本返回指向第一个插入字符的迭代器。 s.erase(pos, len) 删除从pos开始的len个字符，如果len被省略，则删除后面所有字符，返回指向s的引用。 s.assign(args) 将s中的字符替换成args指定的字符。返回一个指向s的引用。（args不变） s.append(args) 将args指定的字符追加到s，返回一个指向s的引用。 s.replace(range, args) 删除s中范围range中的字符，替换成args指定的字符。返回一个指向s的引用。 string搜索操作 string类提供了6个不同的搜索函数，每个函数都有4个重载版本。 每个搜索操作都返回一个string::size_type值，表示匹配发生位置的下标。如果搜索失败则返回一个名为string::npos的static成员（类型是string::size_type，初始化值是-1，也就是string最大的可能大小）。 搜索操作 解释 s.find(args) 查找s中args第一次出现的位置 s.rfind(args) 查找s中args最后一次出现的位置 s.find_first_of(args) 在s中查找args中任何一个字符第一次出现的位置 s.find_last_of(args) 在s中查找args中任何一个字符最后一次出现的位置 s.find_first_not_of(args) 在s中查找第一个不在args中的字符 s.find_first_not_of(args) 在s中查找最后一个不在args中的字符 args必须是一下的形式之一：\nargs形式 解释 c, pos 从s中位置pos开始查找字符c。pos默认是0 s2, pos 从s中位置pos开始查找字符串s2。pos默认是0 cp, pos 从s中位置pos开始查找指针cp指向的以空字符结尾的C风格字符串。pos默认是0 cp, pos, n 从s中位置pos开始查找指针cp指向的前n个字符。pos和n无默认值。 1 2 3 4 5 6 // 使用pos循环查找所有str包含的字符的位置 string::size_type pos = 0; while((pos = s.find_first_of(str, pos)) != string::npos){ cout\u0026lt;\u0026lt;pos\u0026lt;\u0026lt;endl; ++pos; } s.compare的几种参数形式 逻辑类似于C标准库的strcmp函数，根据s是等于、大于还是小于参数指定的字符串，s.compare返回0、正数或负数。\n参数形式 解释 s2 比较s和s2 pos1, n1, s2 比较s从pos1开始的n1个字符和s2 pos1, n1, s2, pos2, n2 比较s从pos1开始的n1个字符和s2从pos2开始的n2个字符 cp 比较s和cp指向的以空字符结尾的字符数组 pos1, n1, cp 比较s从pos1开始的n1个字符和cp指向的以空字符结尾的字符数组 pos1, n1, cp, n2 比较s从pos1开始的n1个字符和cp指向的地址开始n2个字符 string和数值转换 转换 解释 to_string(val) 一组重载函数，返回数值val的string表示 stoi(s, p, b) 返回s起始子串（表示整数内容）的数值，p是s中第一个非数值字符的下标，默认是0，b是转换所用的基数。返回int 9.6 容器适配器（adapter） 适配器是使一事物的行为看起来像另一事物的行为的一种机制，例如stack可以使任何一种顺序容器以栈的方式工作。 默认情况下，stack和queue是基于deque实现的，priority_queue是基于vector实现的，基础容器不能是array和forward_list 因此可以直接使用一个deque来初始化stack和queue，使用一个有序vector初始化priority_queue 也可以指定实现的顺序容器： stack\u0026lt;string, vector\u0026lt;string\u0026gt; \u0026gt; str_stk; 适配器的通用操作和类型 操作 解释 size_type 一种类型，须以保存当前类型的最大对象的大小 value_type 元素类型 container_type 实现适配器的底层容器类型 A a; 创建一个名为a的空适配器 A a(c) 创建一个名为a的适配器，带有容器c的一个拷贝 关系运算符 每个适配器都支持所有关系运算符：==、!=、\u0026lt;、 \u0026lt;=、\u0026gt;、\u0026gt;=这些运算符返回底层容器的比较结果 a.empty() 若a包含任何元素，返回false;否则返回true a.size() 返回a中的元素数目 swap(a, b) 交换a和b的内容，a和b必须有相同类型，包括底层容器类型也必须相同 a.swap(b) 同上 stack 操作 解释 s.pop() 删除栈顶元素，不返回。 s.push(item) 创建一个新元素，压入栈顶，该元素通过拷贝或移动item而来 s.emplace(args) 同上，但元素由args来构造。 s.top() 返回栈顶元素，不删除。 定义在stack头文件中。 stack可以基于deque（默认）、list、vector实现 queue和priority_queue 操作 解释 q.pop() 删除队首元素，但不返回。 q.front() 返回队首元素的值，不删除。 q.back() 返回队尾元素的值，不删除。只适用于queue q.top() 返回具有最高优先级的元素值，不删除。 q.push(item) 在队尾压入一个新元素。 q.emplace(args) 定义在queue头文件中。 queue可以基于deque（默认）、list、vector实现，priority_queue可以基于deque（默认）、vector实现 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch09-%E9%A1%BA%E5%BA%8F%E5%AE%B9%E5%99%A8/","summary":"第九章 顺序容器 9.1 顺序容器概述 顺序容器（sequential container）：元素顺序不依赖于元素的值，而是与元素加入容器时的位置相对应。","title":"Ch09 顺序容器"},{"content":"第八章 IO库 前面章节已经在用的IO库设施 istream：输入流类型，提供输入操作。 ostream：输出流类型，提供输出操作 cin：一个istream对象，从标准输入读取数据。 cout：一个ostream对象，向标准输出写入数据。 cerr：一个ostream对象，向标准错误写入消息。 \u0026raquo;运算符：用来从一个istream对象中读取输入数据。 \u0026laquo;运算符：用来向一个ostream对象中写入输出数据。 getline函数：从一个给定的istream对象中读取一行数据，存入到一个给定的string对象中。 8.1 IO类 标准库定义的IO类型 iostream头文件：从标准流中读写数据，istream、ostream等。 fstream头文件：从文件中读写数据，ifstream、ofstream等。 sstream头文件：从内存string中读写数据，istringstream、ostringstream IO对象不可复制或赋值 不能拷贝或赋值IO对象，因此形参和返回类型也不能是流类型，一般是流的引用。 读写一个IO对象会改变其状态，因此引用不能是const的。 条件状态 状态 解释 strm:iostate 是一种机器无关的类型，提供了表达条件状态的完整功能 strm:badbit 用来指出流已经崩溃（不可恢复的读写错误，此时流无法使用） strm:failbit 用来指出一个IO操作失败了（可恢复的错误） strm:eofbit 用来指出流到达了文件结束 strm:goodbit 用来指出流未处于错误状态，此值保证为零 s.eof() 若流s的eofbit置位，则返回true s.fail() 若流s的failbit置位或badbit置位，则返回true s.bad() 若流s的badbit置位，则返回true s.good() 若流s处于有效状态，则返回true s.clear() 将流s中所有条件状态位复位，将流的状态设置成有效，返回void s.clear(flags) 将流s中指定的条件状态位复位（覆盖原始流状态），返回void s.setstate(flags) 根据给定的标志位，将流s中对应的条件状态位置位（叠加原始流状态），返回void s.rdstate() 返回流s的当前条件状态，返回值类型为strm::iostate 其中strm是一种IO类型比如istream， s是一个流对象。 到达文件结束位置，eofbit和failbit都会置位 如果badbit、failbit、eofbit任何一个被置位，检测流状态的条件都会失败 检查流的状态：while(cin \u0026gt;\u0026gt; word); // cin\u0026gt;\u0026gt;word 表达式返回流的状态 设置某个标志位：cin.clear(cin.rdstate() \u0026amp; ~cin.failbit); // 将failbit复位 管理输出缓冲 每个输出流都管理一个缓冲区，输出可能立即打印或是暂存在缓冲区中 IO操纵符（显式刷新缓冲区）： endl：输出一个换行符并刷新缓冲区。 flush：刷新流，单不添加任何字符。 ends：在缓冲区插入空字符null，然后刷新。 unitbuf：告诉流接下来每次操作之后都要进行一次flush操作，默认情况对cerr是设置unitbuf的 nounitbuf：重置流，回到正常的缓冲方式 程序异常终止时，输出缓冲区不会被刷新 关联输入和输出流 当一个输入流关联到一个输出流，每次从该输入流读取数据前都会先刷新关联的输出流。 标准库将cout和cin关联在一起 输入流的成员函数tie，（无参数时）可以返回关联的输出流的指针，（有参数时）可以设定关联到某个输出流 每个输入流同时最多关联一个输出流，但是多个输入流可以同时关联同一个输出流 8.2 文件输入输出 头文件fstream定义了三个类型来支持文件IO： ifstream从一个给定文件读取数据。 ofstream向一个给定文件写入数据。 fstream可以读写给定文件。 当要读写一个文件时，创建一个文件流对象并将之绑定到该文件。 fstream特有的操作 操作 解释 fstream fstrm; 创建一个未绑定的文件流。 fstream fstrm(s); 创建一个文件流，并打开名为s的文件，s可以是string也可以是char指针，自动调用open fstream fstrm(s, mode); 与前一个构造函数类似，但按指定mode打开文件 fstrm.open(s) 打开名为s的文件，并和fstrm绑定；如果 open 失败，failebit 会被置位 fstrm.close() 关闭和fstrm绑定的文件，注意close并不会重置流的条件状态，需要使用clear重置。当一个 fstream 对象被销毁时，close 函数会自动被调用。 fstrm.is_open() 返回一个bool值，指出与fstrm关联的文件是否成功打开且尚未关闭 文件模式 文件模式 解释 in 以读的方式打开，与ifstream对象关联的文件默认以in模式打开 out 以写的方式打开，与ofstream对象关联的文件默认以out模式打开 app 每次写操作前均定位到文件末尾。设置了trunc就不能再设置app模式；在app模式下，即使没有设定out模式，文件也是以输出方式打开 ate 打开文件后立即定位到文件末尾 trunc 截断文件，只有设置了 out 才能设置trunc模式，只设置out模式会默认也设置trunc模式 binary 以二进制方式进行IO操作。 与fstream对象关联的文件默认以in和out模式打开 默认情况下以 out 模式打开文件会使文件内容被清空，如果要保留文件内容 需要同时指定app模式：数据追加到末尾 或是同时指定in模式：同时进行读写操作 8.3 string流 头文件sstream定义了三个类型来支持读写string： istringstream从string读取数据。 ostringstream向string写入数据。 stringstream可以读写给定string。 stringstream特有的操作 操作 解释 sstream strm 定义一个未绑定的stringstream对象 sstream strm(s) 用s初始化对象 strm.str() 返回strm所保存的string的拷贝 strm.str(s) 将s拷贝到strm中，返回void 上表中sstream是头文件sstream中任意一个类型。s是一个string。 使用例子 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch08-io%E5%BA%93/","summary":"第八章 IO库 前面章节已经在用的IO库设施 istream：输入流类型，提供输入操作。 ostream：输出流类型，提供输出操作 cin：一个ist","title":"Ch08 IO库"},{"content":"第七章 类 7.1 定义抽象数据类型 类成员 必须在类的内部声明，不能在其他地方增加成员。 成员可以是数据，函数，类型别名。 类的const成员函数不会修改类的数据成员：void func() const; const成员函数的声明和定义处都要加const const成员函数不能调用本类的非const成员函数 内联函数 定义在类内部的函数是隐式inline函数 inline成员函数应该与类定义同一个头文件中 可变数据成员 （mutable data member）：表示数据成员永远可变 mutable int cnt;，这样即使在const成员函数中也可以修改cnt的值 [[ch07-类#返回this的成员函数|返回this的成员函数]] 构造函数 构造函数初始值列表：Sales_item(): units_sold(0), revenue(0.0) { } ^742596 但是类内初始值必须使用等号或者花括号进行初始化 当一个类没有定义任何构造函数时，编译器才会生成一个默认构造函数（也称合成的默认构造函数），使用=default要求编译器使用合成的默认的构造函数。 ^15282e 非成员函数 和类相关的非成员函数，定义和声明都应该在类的外部。 7.2 访问控制与封装 访问说明符（access specifiers）：public、private、protected class与struct都可以被用于定义一个类，唯一的却别在于默认访问权限： class：默认成员是 priavte的。 struct：默认成员是 public的。 友元 在类A中设置友元B（函数或类），即允许B访问A中的非共有成员 语法相关： 通常将友元声明成组地放在类定义的开始或者结尾，但友元不是类的成员，不受public/private的约束 如果类想把一组重载函数声明为友元，需要对这组函数中的每一个分别声明。 友元关系不存在传递性。 把其他类的成员函数声明为友元时，必须明确指定该函数所属的类名。 友元函数可以直接定义在类的内部（隐式内联），但是必须在类外部提供相应声明，并且要在调用之前进行声明 1 2 3 4 5 6 7 8 9 10 11 12 struct X { friend void fir() { /* do something */ } public: void pub(); private: void pri(); }; void X::pub() { fir(); } // 错误：友元函数fri在类外必须进行声明且需要在调用之前进行声明 void fir(); // 类X的友元函数fri，在类外进行声明 void X::h() { f(); } 7.3 类的其他特性 this 每个成员函数都有一个额外的、隐含的形参this，this总是指向调用该成员函数的对象 在普通成员函数中，this是一个T *const类型的指针 在const成员函数中，this是一个const T *const类型的指针（因此数据成员无法修改） 静态函数中不能使用this指针 const对象或是const对象的指针/引用，只能调用const成员函数；否则均可 return *this;可以让成员函数连续调用。 类类型 可以声明一个类而暂时不定义它，称为前向声明，用于引入类的名字；在前向声明之后、定义之前是一个不完全类型 可以定义指向不完全类型的指针或引用，也可以声明（但是不能定义）以不完全类型作为参数或返回值类型的函数 [[ch07-类#友元|友元]] 7.4 类的作用域 类型别名如果在类外已经定义过，不能在类内再次定义。\n7.5 构造函数再探 使用初始值列表进行初始化才是真正的初始化，在构造函数体中进行“初始化”只是赋值 如果是const成员或是引用类型，则必须在构造函数初始值列表中将其初始化（圆括号初始化）例子 委托构造函数 （delegating constructor） 委托构造函数通过其他构造函数来执行自己的初始化过程 - Sale_data(): Sale_data(\u0026quot;\u0026quot;, 0, 0) {}\n隐式的类型转换 转换构造函数：如果构造函数只接受一个实参，则它实际上定义了转换为此类类型的隐式转换机制，因此可以叫做转换构造函数。 编译器只会自动进行一步的隐式类型转换 将转换构造函数声明为explicit从而抑制隐式类型转换 explicit关键字只对接受一个实参的构造函数有效，需要多个实参的构造函数不能用于执行隐式转换，因此也无须将其指定为explicit 只在类内声明构造函数时使用explicit，在类外部定义时不应重复 explicit构造函数只能用于直接初始化（圆括号初始化），不能用于拷贝赋值初始化（例子） 聚合类 字面值常量类 constexpr函数的参数和返回值必须是字面值。 字面值类型：算数类型，引用，指针，聚合类 constexpr 构造函数 7.6 类的静态成员 语法相关： 静态成员可以是public或是private的 静态成员可以是常量、指针、引用、类 静态成员函数不包含this指针，不能声明为const成员函数 定义和初始化 在类内声明，类外定义并初始化。 在类外定义时，不能重复 static 关键字，static 只出现在类内的声明中。 只有constexpr类型的静态数据成员可以在类内定义。 使用： 使用作用域运算符::直接访问静态成员:r = Account::rate(); 也可以使用类的对象访问：r = ac.rate(); 特殊场景：例子 静态数据成员的类型可以是不完全类型，比如可以是它所属的类类型，而普通变量不能（只能声明为所属类类型的指针或引用） 可以使用静态成员变量作为函数的默认实参 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch07-%E7%B1%BB/","summary":"第七章 类 7.1 定义抽象数据类型 类成员 必须在类的内部声明，不能在其他地方增加成员。 成员可以是数据，函数，类型别名。 类的const成员函数不会修改类","title":"Ch07 类"},{"content":"第六章 函数 6.1 函数基础 调用运算符：一对圆括号 ()，作用于函数指针 函数调用过程： 主调函数（calling function）的执行被中断，使用实参初始化对应的形参 控制权移交给被调函数，被调函数（called function）开始执行。 函数的返回类型不能是数组类型或者函数类型，但可以是指向数组或者函数的指针。 局部对象 生命周期：对象的生命周期是程序执行过程中该对象存在的一段时间。 局部静态对象： static类型的局部变量，在程序执行路径第一次经过对象定义语句时进行初始化，直到程序终止才被销毁 函数声明 函数声明不需要形参的名字 函数三要素：返回类型，函数名，形参类型 6.2 参数传递 形参初始化的机理和变量初始化一样 形参的顶层const被忽略：void func(const int i)与void func(int i)具有相同的函数签名 ^f06638 原因：引用没有顶层const；如果传值，传递的是实参的副本，不会改变实参的值 但是前面这个函数体中i是const的，连副本也无法修改 两种传参方式： 传值参数（值传递，传值调用） 传引用参数（引用传递，传引用调用） 如果无需改变引用形参的值，最好将其声明为常量引用。 不能将const对象、字面值或需要类型转换的对象传递给普通引用形参，但是可以传递给常量引用形参 数组形参 数组有两个特殊性质：不允许拷贝数组、使用数组时通常会将其转换为指针 数组形参： 1 2 3 4 // 以下几种方式形参等价，编译器只会检查传参类型是否为const int* void func(const int*) void func(const int[]) // 可以看出函数意图是传递数组 void func(const int[10] // 可以提示数组长度 当我们为函数传递一个数组时，实际上传递的是指向数组首元素的指针，因此也要传入数组长度 数组引用形参：形参是数组引用，实参要传递相同类型及大小的数组 1 2 3 void func(int (\u0026amp;a)[5]){} int a[5] = {1,2,3,4}; func(a); 传递多维数组：数组第二维（及更多维）的大小都是数组类型的一部分，不能省略 1 2 void func(int (*matrix)[10], int size){} // matrix是一个指针，指向int[10]类型 void func(int matrix[][10], int size){} // 等价定义 main处理命令行选项 int main(int argc, char *argv[]) {} argc代表参数的个数；argv是一个数组，数组元素是char*（或者说char数组），第一个元素是程序的名字或一个空字符串， 可变形参 处理不同数量实参的函数 如果所有实参类型相同，可以传递一个initializer_list标准库类型 如果实参类型不同，可以定义可变参数模板 省略符形参：void func(param_list, ...) 一般只用于与C函数交互的接口程序，便于CPP访问某些C代码 大多数类类型的对象在传递给省略符形参时都无法正确拷贝 省略符形参对应的实参无须类型检查 initializer_list：定义在同名头文件中的模板类型 initializer_list与vector类似，但是它元素永远是常量 initializer_list只能使用列表初始化 含有initializer_list形参的函数也可以有其他形参 其他容器使用列表初始化本质上都是采用了initializer_list形参的构造函数进行初始化的 initializer_list 提供的操作： 1 2 3 4 5 6 7 initializer_list\u0026lt;int\u0026gt; lst1, lst2;//默认初始化:空列表 initializer_list\u0026lt;int\u0026gt; initlst{1,2,3,4};//initlast 的元素数量与初始值一样多 lst1(initlst); // 直接初始化，lst1与initlst共享元素（不会复制） lst2(initlst); // 赋值初始化，lst2与initlst共享元素（不会复制） void func(int x, initializer_list\u0026lt;char\u0026gt; lst); func(1, {\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;}); 6.3 返回类型和return语句 不要返回局部对象的引用或指针 引用返回左值：调用一个返回引用的函数得到左值，其他返回类型得到右值。 列表初始化返回值：函数可以返回花括号包围的值的列表，并对函数返回的临时量进行初始化。 vector\u0026lt;int\u0026gt; func() { return {\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}; } 这样可以减少一次拷贝？ 相关：RVO 参考：《程序员的自我修养》P305（声明狼藉的C++返回对象） main的返回值：cstdlib头文件定义了两种预处理变量来表示成功（EXIT_FAILURE）与失败（EXIT_SUCCESS） 返回数组指针 取别名比较方便 可以使用尾置返回类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; // int ( *p )[10]; // 数组指针：指向数组的指针 // int ( *func(params) )[10]; // 返回数组指针：函数参数是params，返回指向int[10]的数组指针 // 形式： Type (*function (parameter_list))[dimension] int ( *func1(int (*arr)[5]) )[5]{ // 传入数组指针，返回数组指针, int (*arr)[5]是传入的数组指针 for(int *it = begin(*arr), *ed = end(*arr); it != ed; ++it) (*it) += 1; return arr; } // 使用类型别名进行简化 using arrT = int[5]; // typedef int arrT[10]; // 感觉没有using直观 arrT* func2(arrT* arr, int n){ // 使用别名，传入数组指针，返回数组指针 for(int i = 0; i \u0026lt; n; i++) (*arr)[i] += 1; // 数组指针解引用得到数组 return arr; } // 使用尾置返回类型，简化函数的声明和定义（尤其当返回值比较复杂时） // 在形参列表后面跟一个-\u0026gt;，表示真正的返回值类型跟在形参列表之后，开头返回值用auto代替 auto func3( int (*arr)[5] ) -\u0026gt; int(*)[5]{ for(int *it = begin(*arr), *ed = end(*arr); it != ed; ++it) (*it) += 1; return arr; } // 还可以使用 `decltype`，见P206 int main(){ int arr[5] = {1,2,3,4,5}; int (*p)[5] = \u0026amp;arr; // p是指向数组的指针， p的内容是数组首地址 arrT* pp = \u0026amp;arr; // pp同样是数组的指针 int (*a)[5] = func1(p); for(int *it = begin(*a), *ed = end(*a); it != ed; ++it) cout\u0026lt;\u0026lt;*it\u0026lt;\u0026lt;\u0026#34; \u0026#34;; cout\u0026lt;\u0026lt;endl; int (*aa)[5] = func2(pp, 5); for(int *it = begin(*aa), *ed = end(*aa); it != ed; ++it) cout\u0026lt;\u0026lt;*it\u0026lt;\u0026lt;\u0026#34; \u0026#34;; cout\u0026lt;\u0026lt;endl; int (*a3)[5] = func3(p); for(int *it = begin(*a3), *ed = end(*a3); it != ed; ++it) cout\u0026lt;\u0026lt;*it\u0026lt;\u0026lt;\u0026#34; \u0026#34;; cout\u0026lt;\u0026lt;endl; } 6.4 函数重载 语法相关： 不允许两个函数除了返回类型以外的其他所有要素都相同，或者说返回值与重载无关 因为[[ch06-函数#^f06638|形参的顶层const被忽略]]，所以在重载函数中，一个有顶层const形参，另一个重载函数相应参数是普通形参，相当于重复声明，但是可以区分底层const。例子 使用： 一个函数的形参可能有常量引用和非常量引用两种版本，可以使用const_cast进行类型的转换 1 2 3 4 5 const string\u0026amp; func(const string \u0026amp;s) {/* do something*/} // 底层const string func(string s) { const string\u0026amp; r = func(const_cast\u0026lt;const string\u0026amp;\u0026gt;(s)); return const_cast\u0026lt;string\u0026amp;\u0026gt;(r); } 重载和作用域：因为C++中名字查找发生在类型检查之间，所以编译器一旦在当前作用域内找到了所需的名字，编译器就会忽略掉外层作用域中的同名实体。 因此，不同的重载版本要定义在同一作用域中，一般是全局作用域 6.5 特殊用途语言特性 默认实参 形参顺序：普通形参，不怎么使用默认值的形参，经常使用默认值的形参 设置默认值的形参必须放在没有默认值的形参之后 一旦某个形参被赋予（或使用）默认值，那么它之后的形参都必须要有默认值 虽然多次声明同一个函数是合法的，但是在给定的作用域中一个形参只能被赋予一次默认实参。函数的后续声明只能为之前那些没有默认值的形参添加默认实参，而且该形参右侧的所有形参必须都有默认值。 1 2 void screen(int w, int h, char c=\u0026#39; \u0026#39;); // 第一次声明 void screen(int w, int h = 80, char c); // 第二次声明，添加了默认实参 默认实参只能出现在函数声明和定义其中一处，通常应该在头文件中的函数声明中指定默认实参。 局部变量不能作为函数的默认实参，全局变量和字面值都可以 内联（inline）函数 在函数声明和定义中都能使用关键字inline，但是建议只在函数定义时使用。 一般来说，内联机制适用于优化规模较小、流程直接、调用频繁的函数。内联函数中不允许有循环语句和switch语句，否则函数会被编译为普通函数。 constexpr 函数 不是很理解，个人理解是在编译器就能确定返回值的函数\n内联函数和constexpr函数通常定义在头文件中。 调试帮助 调试帮助：用类似头文件保护的方式，有选择的执行调试代码。即在开发过程中，程序可以包含一些用于调试的代码，当程序发布时，需要先屏蔽掉调试代码。调试帮助通常包含两种预处理功能：assert和DNEBUG\nassert是一种预处理宏（preprocessor macro）：assert(expr); 当表达式为假时，assert输出信息并终止程序；如果真，assert什么都不做 常用来检查不能发生的条件 NDEBUG预处理变量：关闭调试状态 可以使用#define NDEBUG来定义NDEBUG，但很多编译器都提供了命令行选项-D NDEBUG 如果定义了NDEBUG，则assert什么都不做；默认情况下没有定义NDEBUG 几个用于调试的变量名称： 变量名称 内容 __func__ 当前函数名称 __FILE__ 当前文件名称 __LINE__ 当前行号 __TIME__ 文件编译时间 __DATE__ 文件编译日期 1 2 3 4 5 6 void print(){ #ifndef NDEBUG // 默认情况下没有定义NDEBUG，可以在这里编写自己的调试代码 // 如果定义了NDEBUG，则跳过 cerr \u0026lt;\u0026lt; __func__ \u0026lt;\u0026lt; \u0026#34;...\u0026#34; \u0026lt;\u0026lt; endl; #endif } 6.6 函数匹配 函数匹配（或称为重载确定）\n重载函数匹配的三个步骤： 找候选函数：同名函数 选可行函数：形参实参数量相等，类型匹配或者能进行转换 寻找最佳匹配：实参类型和形参类型越接近，它们匹配越好 精确匹配、从数组类型或函数类型转换为对应的指针类型、添加/删除顶层const const转换 类型提升 算数类型转换、指针转换 类类型转换 如果有若干个匹配，但没有一个最佳匹配时，编译器可能报告二义性调用的信息 6.7 函数指针 对于重载函数，函数指针类型必须与重载函数中某一个精确匹配 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 using Func = int(int, int); // 函数类型 typedef int Func2(int, int); // 函数类型，等价于Func using FuncP = int(*)(int, int); // 函数指针类型 typedef int (*FuncP2)(int, int); // 函数指针类型，等价于FuncP int add(int a, int b) {return a + b;} double add(double a, double b) {return a + b;} int op1(int a, int b, int (*f)(int, int) ) {return (*f)(a, b);} int op2(int a, int b, Func* f) {return (*f)(a, b);} // 函数不能做形参 int op3(int a, int b, FuncP fp) {return (*fp)(a, b);} int test() {return 1;} typedef decltype(test) FuncT; // 函数类型 typedef decltype(test) (*FuncTP); // 函数指针类型，decltype返回函数类型，需要在别名类型前加上*表示函数指针 int main(){ Func *f = \u0026amp;add; FuncP g = \u0026amp;add; cout\u0026lt;\u0026lt;op1(1,2,add)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;op2(1,2,f)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;op3(1,2,g); } 函数指针可以作为形参 形参类型可能为函数类型，传入的也可能是函数名，但是最终都是转换为函数指针 函数指针可以作为返回值，函数类型不可以作为返回值 1 2 3 4 5 6 7 using Func = int(int, int); // 函数类型 using FuncP = int(*)(int, int); // 函数指针类型 int (*ret_func1(params)) (int, int); // 一个名为ret_func1的函数，其参数为params，返回一个int(*)(int, int)类型的函数指针 auto ret_func2(params) -\u0026gt; int(*)(int, int); // 尾置返回类型 Func* ret_func3(params); // 使用别名，返回指向函数类型的指针，不能返回Func FuncP ret_func4(params); // 使用别名，返回函数指针 复杂例子：假设函数指针类型是int(*)(int, int)，数组指针类型是int (*)[5] 1 2 using FuncP = int(*)(int, int); using Arr = int[5]; 返回值是函数指针，函数形参是数组指针 1 2 3 int ( *f( int(*arr)(int,int) ) ) (int (*)[5]); auto f( int(*arr)[5] ) -\u0026gt; int(*)(int, int); FuncP f(Arr* arr); 返回值是函数指针，函数形参是函数指针 1 2 3 int (*f( int(*fp)(int, int) )) (int, int); auto f( int(*fp)(int, int) ) -\u0026gt; int(*)(int, int); FuncP f(FuncP fp); 返回值是数组指针，函数形参是函数指针 1 2 3 int ( *f( int(*fp)(int, int) ) )[5]; auto f( int(*fp)(int, int) ) -\u0026gt; int(*)[5]; Arr* f(FuncP fp); 返回值是数组指针，函数形参是数组指针 1 2 3 int (*f( int(*arr)[5] ))[5]; auto f( int(*arr)[5] ) -\u0026gt; int(*)[5]; Arr* f(Arr* arr); ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch06-%E5%87%BD%E6%95%B0/","summary":"第六章 函数 6.1 函数基础 调用运算符：一对圆括号 ()，作用于函数指针 函数调用过程： 主调函数（calling function）的执行被中断，使用实参","title":"Ch06 函数"},{"content":"第五章 语句 简单语句 表达式语句：一个表达式末尾加上分号，就变成了表达式语句。 空语句：有时语法上需要一个语句，但是逻辑上不需要，可以直接写一个分号。 复合语句（块）：用花括号 {}包裹起来的语句和声明的序列。一个块就是一个作用域。空块等价于空语句。 条件语句 悬垂else（dangling else）：用来描述在嵌套的if else语句中，如果if比else多时如何处理的问题。C++使用的方法是else匹配最近没有配对的if。 迭代语句 range-for中不能改变序列的元素数量，因为预存了end()的值，改变预存的值失效 try语句块和异常处理 1 2 3 4 5 6 7 8 9 try{ throw runtime_error(\u0026#34;Data must be same as size\u0026#34;); // throw抛出使用字符串初始化的异常类型的对象 } catch(runtime_error err)//异常类型对象的声明（也称异常声明） { // catch子句也称为异常处理代码 cout \u0026lt;\u0026lt; err.what();//每个标准异常类都有一个what成员函数，返回初始化对象时使用的字符串 }// catch(...){ /* 捕获所有异常*/ } 标准异常及其继承关系： ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch05-%E8%AF%AD%E5%8F%A5/","summary":"第五章 语句 简单语句 表达式语句：一个表达式末尾加上分号，就变成了表达式语句。 空语句：有时语法上需要一个语句，但是逻辑上不需要，可以直接写一个分","title":"Ch05 语句"},{"content":"第四章 表达式 4.1 表达式基础 左值和右值： 一个对象被用作左值时，使用的是对象的身份（在内存中的地址，左值可以按名访问，而且其地址可以被赋值） 一个对象被用作右值时，使用的是对象的值（内容） （自己的理解）即使一个对象可以按名访问，但如果该对象的内容在只读数据段，该对象也是右值 需要右值的地方可以使用左值代替，但是反过来不行 decltype作用于表达式（注意不是变量），推导出来是左值还是右值，与表达式返回值是左值还是右值相同 求值顺序： 如果改变了某个运算对象的值，在同一表达式中不要再使用该运算对象，参考 只有四种运算符明确规定了求值顺序：\u0026amp;\u0026amp;、||、?:、, 4.2 算术运算符 整数除法的结果向0舍入 取余运算m%n，结果符号与被除数m相同 4.3 逻辑和关系运算符 短路求值 4.4 赋值运算符 C++11允许使用花括号括起来的初始值列表作为右侧运算对象，初始化列表为空时进行值初始化 赋值运算的返回结果是它的左侧运算对象，是一个左值 赋值运算符满足右结合律，这点和其他二元运算符不一样。 比如：ival = jval = 0;等价于jval = 0; ival = jval; 复合赋值运算符只求值一次，而普通运算符需要两次。 比如：a=a+1 要先求一次 a+1，再将结果赋值给 a 4.5 递增和递减运算符 前置版本j = ++i，先i加一，后给j赋值，优先使用 后置版本j = i++，先给j赋值，后i加一 混用解引用和递增运算符：*p++ 等价于 *(p++) 首先进行自加，p指向下一个位置，返回原来对象的副本 将原来对象的副本进行解引用 1 2 3 auto iter = vi.begin(); while (iter!=vi.end()) cout\u0026lt;\u0026lt;*iter++\u0026lt;\u0026lt;endl; // 输出当前值，指针向前移1 4.6 成员访问运算符 ptr-\u0026gt;mem等价于(*ptr).mem\n4.7 条件运算符 条件运算符（?:）：cond? expr1: expr2 可以嵌套使用，右结合律，从右向左顺序组合 4.8 位运算符 位运算符是作用于整数类型的运算对象。 向左移（\u0026lt;\u0026lt;），向右移（\u0026gt;\u0026gt;），位取反（~）（逐位求反）、与（\u0026amp;）、或（|）、异或（^） 有符号数负值可能移位后变号，所以强烈建议位运算符仅用于无符号数。 4.9 sizeof运算符 语法： sizeof (type)：返回类型的大小 sizeof expr：返回表达式结果类型的大小 返回类型是 size_t的常量表达式 sizeof并不实际计算其运算对象的值。 对数组执行sizeof运算得到整个数组所占空间的大小。 对string或vector对象执行sizeof运算只返回该类型固定部分的大小，不会计算对象中元素所占空间的大小。 4.10 逗号运算符 从左向右依次求值，左侧求值结果丢弃，返回结果是右侧表达式的值。\n4.11 类型转换 C++不会直接将两个不同类型的值相加，会先通过类型转换将运算对象的类型统一之后再求值\n隐式类型转换 整型提升 数组转换成指针：大多数情况下，数组名字自动转换成指向数组首元素的指针 decltype关键词参数、取地址符、sizeof、typeid不会发生这种转换 指针的转换： 常量整数值0或字面值nullptr能转换成任意指针类型 指向任意非常量的指针能转换成void* 指向任意对象的指针能转换成const void* 指向派生类的指针自动转换为指向基类的指针 转换成布尔类型 转换成常量：指向非常量类型的指针能转换成指向相应的常量类型的指针 1 2 3 4 5 int i = 0; const int *p = \u0026amp;i; const int \u0026amp;r = i; i = 9; // 可以通过i修改变量的值，但是不能通过p和r修改 cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;r; 类类型的转换 1 2 while(cin \u0026gt;\u0026gt; s); //将cin转换为bool string s = \u0026#34;value\u0026#34;; // 将字符数组转换为string 显式类型转换（即强制类型转换） 形式：cast_name\u0026lt;type\u0026gt;(expression); type: 转换的目标类型，如果type是引用类型，则结果是左值 cast_name: static_case, dynamic_cast, const_cast, reinterpret_cast中的一种 static_cast：任何明确定义的类型转换，只要不包含底层const，都可以使用 把一个较大的算数类型赋值给较小的类型（可能有精度损失） 找回void*中的值 const_cast：只能改变运算对象的底层const，一般用于去除const属性 只有const_cast可以改变表达式的const属性（顶层const或底层const都可以） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int a = 2; const int *i = \u0026amp;a; // i是底层const int *j = const_cast\u0026lt;int*\u0026gt;(i); *j = 3; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*i\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*j; // 3 3 3 const int a = 2; const int *i = \u0026amp;a; // i是底层const int *j = const_cast\u0026lt;int*\u0026gt;(i); *j = 3; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*i\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*j; // 2 3 3 int a = 2; int *const i = \u0026amp;a; // i是顶层const int *j = const_cast\u0026lt;int*\u0026gt;(i); *j = 4; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*i\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*j; // 4 4 4 const_cast常用于有函数重载的上下文中 reinterpret_cast：通常为运算对象的位模式提供低层次上的重新解释，慎重使用 1 2 3 int *i; char *c = reinterpret_cast\u0026lt;char*\u0026gt;(i); // 但是c所指的真实对象是一个int而非char // char *c = (char*) i; // 旧式的强制类型转换，等价 [[ch19-特殊工具与技术#dynamic_cast运算符|dynamic_cast]]：在运行时，将基类类型转换为派生类类型 旧式的强制类型转换本质上采用了static_cast, const_cast, reinterpret_cast中的一种，但是旧式的强制类型转化不够清晰，出了问题难以追踪 4.12 运算符优先级表 运算符优先级表\n","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch04-%E8%A1%A8%E8%BE%BE%E5%BC%8F/","summary":"第四章 表达式 4.1 表达式基础 左值和右值： 一个对象被用作左值时，使用的是对象的身份（在内存中的地址，左值可以按名访问，而且其地址可以被赋值） 一个对","title":"Ch04 表达式"},{"content":"第三章 字符串、向量和数组 3.1 using声明 可以对单个名字进行独立的using声明，比如using std::cin 头文件中不应该包含using声明。 3.2 string 初始化 string 对象的方式\n拷贝初始化（copy initialization）：= 直接初始化（direct initialization）：() string 的操作 字符串字面值和string是不同的类型（为了与C兼容） cctype头文件中定义了一组标准库函数来处理string的字符 3.3 vector 初始化 vector 对象的方法\n列表初始化： vector\u0026lt;string\u0026gt; v{\u0026quot;a\u0026quot;, \u0026quot;an\u0026quot;, \u0026quot;the\u0026quot;}; （C++11） 拷贝初始化：= 直接初始化：() 数组初始化：vector\u0026lt;int\u0026gt; v(arr.begin(), arr.end());\nvector 支持的操作 范围for语句内不应该改变其遍历序列的大小。 vector对象（以及string对象）的下标运算符，只能对确知已存在的元素执行下标操作，不能用于添加元素。 3.4 迭代器iterator 使用迭代器 养成使用迭代器和!=的习惯（泛型编程），循环判断中少使用\u0026lt;（因为所有标准库迭代器都定义了==和!=，但是只有很少一部分定义了\u0026lt;）。 但凡是使用了迭代器的循环体，都不要向迭代器所属的容器添加元素。 3.5 数组 定义和初始化内置数组 初始化：列表初始化 字符数组可以用字符串字面值进行初始化，结尾\\0也拷贝到字符数组中 数组不允许直接拷贝或赋值给另一个数组。 想复制可以使用memcpy(void *dst, void *src, size_t size) 复杂的数组声明，指向数组的指针，绑定到数组的引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 int arr[10] = { 1,2,3,4,5,6,7,8,9,10 }; // arr是int[10]类型 int (*pa)[10] = \u0026amp;arr; // pa是指向arr(int[10]类型)的指针，右边当然要取地址（虽然arr==\u0026amp;arr） for(int i = 0; i \u0026lt; 10; ++i) cout\u0026lt;\u0026lt;*( (*pa) +i)\u0026lt;\u0026lt;\u0026#34; \u0026#34;; // *pa是数组指针解引用，即得到arr（即为数组名）;剩下部分即为通常的指针访问数组 // cout\u0026lt;\u0026lt; (*pa)[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; // 或者这样访问元素 cout\u0026lt;\u0026lt;endl; int (\u0026amp;ra)[10] = arr; // ra是绑定到arr(int[10]类型)的引用，右边即为对象 for(int i = 0; i \u0026lt; 10; ++i) cout\u0026lt;\u0026lt;*(ra + i) \u0026lt;\u0026lt; \u0026#34; \u0026#34;; // cout\u0026lt;\u0026lt; ra[i] \u0026lt;\u0026lt;\u0026#34; \u0026#34;; cout\u0026lt;\u0026lt;endl; int m[3][5] = { {1,2,3,4,5},{6,7,8,9,10},{11,12,13,14,15} }; int (*p)[5] = m; // 左边是指向int[5]类型的指针，右边是\u0026amp;m[0]（即为m） for(int i = 0; i \u0026lt; 3; ++i) for(int j = 0; j \u0026lt; 5; ++j) cout\u0026lt;\u0026lt; (*(p + i)) [j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; // p+i表示指向哪一个int[5]类型，解引用即为者5个int数组的数组名 // 等价写法：p[i][j], *(p[i] + j), *(*(p+i) + j) int (*pp[10])[5]; // 首先pp与[10]结合，表明这是一个数组 // 剩下的部分就是数组元素的类型：int (*)[5] // 即每个数组元素是一个指针，指向int[5]类型 各类指针的详细介绍 数组与指针 很多情况下，编译器会将数组名自动替换为指向数组首元素的指针（相当于顶层const指针） 数组的类型推断 当auto变量基于数组名进行类型推断时，得到的是对应类型的指针 当使用decltype进行类型推断时，返回数组类型 1 2 3 4 int arr[] = {1,2,3}; auto ptr(arr); //ptr是int*类型 decltype(arr) arr2 = {4,5}; // 相当于arr2的类型是int[3] for(auto i: arr2) cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;\u0026#34; \u0026#34;; // 输出是4 5 0而非4 5 3 数组名不是指针 证据一：sizeof(数组名) = 整个数组所占内存大小，如果数组名是指针，则为4或8 证据二：对数组名取地址得到的是整个数组的地址，如果数组名是指针，则对数组名取地址是另外一个地址（指针的地址） arr（数组首个元素的地址）与\u0026amp;arr（数组地址）在值上是相等的，但是意义不同 函数传参和接受参数时，传递的都是指针，即使形参是int arr[]这样表示整个数组（可能情形是，外面传入的实参是数组名，但是形参实例化时自动转换为指针） 否则需要进行数组的拷贝，效率低 int arr[x]中即使带数组容量，也会被忽略，x随便取都无所谓 参考 好文章：# 指针与数组的联系与区别【一万六千字超详解】 C风格字符串 C风格字符串：以空字符\\0结束的char数组 相互使用： 可以直接将char字符数组赋值给string字符串 字符串到字符数组：const char *arr = str.c_str(); str, arr使用的是同一块数据 C 风格字符串的函数：strlen, strcmp, strcat, strcpy 传入参数必须是字符数组，注意列表初始化字符数组时必须最后带\\0 字符串与字符数组： 字符串：使用字符指针指向只读数据段的一片区域 字符数组：放在栈中或者数据段 参考 3.6多维数组 多维数组阅读顺序由内向外 多维数组的初始化 1 2 3 4 5 int ia[2][4] = { {0, 1, 2, 3}, {4, 5, 6, 7} }; int ib[2][4] = {0, 1, 2, 3, 4, 5, 6, 7}; // 初始化部分元素 int ic[2][4] = {{ 0 }, { 4 }}; // 初始化第一列 int id[2][4] = {0, 3, 6, 9}; // 初始化第一行 使用range-for语句时，除了最内层的循环外，外层循环的控制变量都应该是引用类型。 否则编译器自动将数组名转换为指针，无法使用range-for语法 遍历：int ia[2][4] = { {0, 1, 2, 3}, {4, 5, 6, 7} }; range-for： 1 2 3 4 5 6 7 8 9 // row为int[4]类型，如果row不是引用类型（不加\u0026amp;），编译器会自动将row从int[4]类型转变为指针，无法遍历指针 for(auto \u0026amp;row: ia) for(auto item: row) cout\u0026lt;\u0026lt;item\u0026lt;\u0026lt;\u0026#34; \u0026#34;; // 不使用auto，写出变量类型： for(int (\u0026amp;row)[4]: ia) // 理解山相当于：int[4] \u0026amp;row for(int item: row) cout\u0026lt;\u0026lt;item\u0026lt;\u0026lt;\u0026#34; \u0026#34;; 使用i，j下标进行访问 使用指针访问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 for(auto p = ia; p != ia+2; ++p) for(auto q = *p; q!= *p+4; ++q) cout\u0026lt;\u0026lt;*q\u0026lt;\u0026lt;\u0026#34; \u0026#34;; // 不使用auto： for(int (*p)[4] = ia; p != ia+2; ++p) for(int *q = *p; q != *p+4; ++q) cout\u0026lt;\u0026lt;*q\u0026lt;\u0026lt;\u0026#34; \u0026#34;; // 使用类型别名 using arr = int[4]; // typedef int arr[4]; // 看起来比较奇怪 for(arr *p = ia; p != ia+2; ++p) for(int *q = *p; q != *p+4; ++q) cout\u0026lt;\u0026lt;*q\u0026lt;\u0026lt;\u0026#34; \u0026#34;; 其他 const、指针和引用、多维数组 1 2 3 4 5 6 7 8 9 10 11 12 13 int m[3][4] ={ {0, 1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10, 11} }; int (\u0026amp;r_m)[4] = m[0]; // r_m是一个绑定到int[4]数组的引用， // int* (\u0026amp;rr_m)[3] = m; // rr_m是一个绑定到(int*)[3]数组的引用，即绑定到大小为3的指针数组；但是m[0], m[1], m[2]各自都是一个int[4]数组的引用，m的类型是int[3][4]，类型都不匹配 int (\u0026amp;rr_m)[3][4] = m; // rr_m是一个绑定到int[3][4]的引用 int (*p)[4] = m; // p是一个指向int[4]数组的指针（即每个元素是int[4]数组，即m） int* pp[3] = {m[0], m[1], m[2]}; // m[0], m[1], m[2]每个是一维数组的数组名，只是编译器将数组名转换为指针，{m[0], m[1], m[2]}就变成了一个指针数组 int* (\u0026amp;r)[3] = pp; // int* (\u0026amp;r)[3] = {m[0], m[1], m[2]}; // 报错，因为{m[0], m[1], m[2]}是右值，尝试将右值赋值给引用 也进行顶层const和底层const的区分 动态数组 使用 new和 delete表达和c中malloc和free类似的功能，即在堆中分配存储空间。 定义： int *pia = new int[n]; 释放： delete [] pia;，注意不要忘记[]。 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch03-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%90%91%E9%87%8F%E5%92%8C%E6%95%B0%E7%BB%84/","summary":"第三章 字符串、向量和数组 3.1 using声明 可以对单个名字进行独立的using声明，比如using std::cin 头文件中不应该包含using声明。 3.2 string 初始化","title":"Ch03 字符串、向量和数组"},{"content":"第二章 变量和基本类型 2.1 基本内置类型 1 2 sizeof(int) = 4; sizeof(long int) = 8; sizeof(long long int) = 8; sizeof(float) = 4; sizeof(double) = 8; sizeof(long double) = 16; 字面值常量（literal） 分多行书写字符串：C++ 允许在一条语句中自动连接多个双引号字符串（连接处无空格）\n1 2 std:cout\u0026lt;\u0026lt;\u0026#34;wow, a really, really long string\u0026#34; \u0026#34;literal that spans two lines\u0026#34; \u0026lt;\u0026lt;std::endl; 2.2 变量 声明和定义 初始化（initialize）：初始化不是赋值 初始化 = 创建变量 + 赋予初始值 赋值 = 擦除对象的当前值 + 用新值代替 变量的声明（declaration）和定义（define） 声明使得名字为程序所知；定义负责创建与名字关联的实体（分配内存）。 extern：表示符号的定义在模块外部，但如果包含了初始值，就变成了定义 C和C++关于声明和定义、强符号和弱符号、变量在ELF节中的位置规定似乎不同 1 2 3 4 5 6 7 8 9 10 // a.c（或a.cpp） #include \u0026lt;stdio.h\u0026gt; int x; int main(){ printf(\u0026#34;%d\\n\u0026#34;, x); return 0; } // b.c（或b.cpp） int x = 3; gcc a.c b.c -o test1：编译链接并运行，正常 gcc a.cpp b.cpp -o test2：链接出错：x多重符号定义 作用域 同时存在同名的全局和局部变量时，在内层作用域中可以使用::reused显式访问全局变量reused。 2.3 复合类型 复合类型的含义：比如int型是基本类型，但是引用和指针（即\u0026amp;、*称为类型修饰符）可以再作为声明符的一部分（类型修饰符+变量标识符），构成复合类型\n类型修饰符是声明符的一部分，因此int *a, b, \u0026amp;c;中只有a是指针，c是引用 但是理解上类型修饰符可以看作是类型的一部分，比如int *\u0026amp;pa=a;中pa是对int*类型（指向int的指针）的引用 判断类型是从右向左读，最靠近变量名的类型修饰符说明这是一个什么复合类型，其余符号和基本类型共同说明指向/引用何种（复合）类型 (左值)引用 引用必须初始化。 引用和它的初始值是绑定在一起的，而不是拷贝。一旦定义就不能更改绑定为其他的对象 引用只能绑定到对象上，不能与字面值或某个表达式的计算结果绑定 引用不是对象 指针 void*指针可以存放任意对象的地址。因无类型，仅操作内存空间，对所存对象无法访问（不能直接操作void*指向的对象）。 指针的类型要与所指向的对象严格匹配，两个例外： 可以使用指向常量的指针指向非常量 可以使用基类的指针指向派生类 注意不能直接给指针赋值一串地址，给指针赋值应该是另一个指针或是变量取地址 1 2 3 4 5 6 7 8 int a = 1; int *p = \u0026amp;a; // a是int型, p是int型的指针(int *) int *q = p; // q也是int型的指针, 将p赋值给q int* *pp = \u0026amp;p; // pp是指向int*类型变量的指针 // 不能是 int *pp = \u0026amp;p, 即犯了直接把内存地址赋值给指针的错误 int** *ppp = \u0026amp;pp; // ppp是指向int**类型的指针 int*** \u0026amp;r_ppp = ppp; // r_ppp是指向int***类型的引用 cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;**pp\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;***ppp\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;***r_ppp; # 各类指针的详细介绍 指针与引用 不同 指针存储一个变量地址，是一个对象；而引用只是变量的一个别名 引用在定义时必须要进行初始化，而指针不用 指针可以在任意时候改变指向，引用在初始化时绑定对象后就无法改变绑定的对象 sizeof(引用)=引用类型的大小，sizeof(指针)=4或8（地址空间所占字节数） 自加效果不同 有多级指针，但是没有多级引用 存在指向指针的指针，无引用的引用，不能定义指向引用的指针，可以定义指向指针的引用。 编译器实际上是将对引用的操作翻译成对指针的操作 [# 简谈 C++ 中指针与引用的底层实现](# 简谈 C++ 中指针与引用的底层实现) 2.4 const限定符 初始化和const const表示编译器限制该变量只能是只读的，修改变量时编译器会报错，因此const对象必须在一开始声明时进行赋值 在C中，可以使用指针指向const对象，进行修改（不要这样写） 在CPP中，使用非const指针指向const对象会报错（但是可以将const指针强转为普通指针进而修改，不要这样写） const变量默认不能被其他文件访问（作用域在本模块中） 如果非要共享const对象，不管是声明还是定义，都要加上extern关键字（因此C++中const变量从内部变量转变为extern const的外部变量，如果再初始化就变成强符号） - const extern const C global global global C++ global local global 两个例子\n参考 const关键字到底该怎么用 C++和C中的const关键字有何区别？ 好文章：const在C语言和C++中的区别 引用和const reference to const（对常量的引用，简称为常量引用）：指向const对象的引用 1 2 3 const int ival = 1; // const const int \u0026amp;r = ival; // 常量引用，指向常量的引用 int \u0026amp;r2 = ival; // 错误：非常量引用绑定一个常量对象 引用的类型必须与所引用对象的类型一致 例外：在初始化常量引用时允许用任意表达式作为初始值 因此，对const的引用（常量引用）可能引用一个非const的对象 1 2 3 int a = 1; const int \u0026amp;r = a; a = 2; // 可以修改a的值,但是不能通过引用r来修改值 原理：如果不一致，则中间使用临时量进行类型转换，引用指向这个临时量 1 2 3 4 5 6 7 8 9 10 11 12 13 double dval = 3.14; const int \u0026amp;r1 = dval; // 常量引用r1的类型int与所引用对象dval的类型double不同 /* 相当于： const int tmp = dval; // 临时未命名对象（临时量） const int \u0026amp;r1 = tmp; // 因此修改dval的值，不会影响r1 */ // 除了初始化常量引用时，普通引用的类型必须与所引用对象的类型一致 int \u0026amp;r2 = dval; // 错误 /* 相当于： int tmp = dval; int \u0026amp;r2 = tmp; // 引用绑定的是一个临时量，C++规定非法 */ int变量 const int常量 double变量 const double变量 int\u0026amp;普通引用 √ × × × const int\u0026amp;常量引用 √（可以修改int的值，但是不能通过引用来修改） √ warning（见dval） √ 指针和const pointer to const（指向常量的指针）：const int i = 0; const int *p = \u0026amp;i; 变量p的类型是指针*，指向的类型是const int 指向常量的指针可以指向一个非常量对象，但是不允许通过指针修改变量的值 底层 const属性 底层const属性对元素赋值有影响：等号两边需要有相同的底层const资格，或者非常量转换为常量 const pointer（常量指针）：int i = 0; int *const ptr = \u0026amp;i; 顶层const属性：这个类型的变量是只读的 对于常量指针而言，指针本身是常量（即指针固定指向某个地址） 顶层const属性对指向元素的拷贝无影响 变量ptr的类型是常量指针*const，指向的类型是int constexpr和常量表达式 常量表达式：值不会改变，且在编译过程中就能得到计算结果的表达式。 constexpr 背景：有时很难判断一个初始值是否为常量表达式（因为有的const对象的值直到运行时才能知道） 使用：C++11规定，将变量声明为constexpr类型以便由编译器来验证变量的值是否是一个常量的表达式，constexpr对象的值必须在编译期间确定。 定义在函数体内部的变量，地址在编译器无法确定，无法用来初始化constexpr指针 定义在函数体外部的变量，地址固定，可以用来初始化constexpr指针 constexpr指针相当于顶层const constexpr表示真正的常量，const表示只读 2.5 处理类型 类型别名 传统别名：使用typedef来定义类型的同义词：typedef int* ptr C++11 别名声明（alias declaration）： using ptr=int*; 不能将类型别名像宏一样代回进行理解，类型别名本身就表示一种类型 1 2 3 4 5 typedef int* ptr; int a = 1; const ptr p_a = \u0026amp;a; // p_a是const ptr类型的对象，即指向int的常量指针（顶层const） const int* p = \u0026amp;a; // p是指向const int的指针（底层const） const ptr* pp_a = \u0026amp;p_a; // pp_a是指向const ptr的指针，即指向int的常量指针的指针（底层const） auto类型说明符 一条声明语句中只能有一个基本数据类型，但可以有复合类型（比如指针和引用） 复合类型自动推导 auto会忽略引用类型： int i = 0, \u0026amp;r = i; auto a = r; 推断a的类型是int而非int\u0026amp; 用 auto 定义引用时，必须用\u0026amp;指明要定义的是引用 auto会忽略顶层const，但保留底层const： 1 2 3 4 5 6 const int i = 1; const int* pi = \u0026amp;i; // 底层const auto a = *pi; // *pi类型是const int，推断a的类型是int，auto忽略顶层const const auto b = *pi; // 如果希望是顶层const需要自己加const auto p = pi; // 推断p的类型是const int*，auto保留底层const // *p = 2; // 报错 decltype类型指示符 背景：希望获得表达式的类型但是不需要值（编译器分析类型但是不求值） 使用 不会忽略顶层const和引用 当获得的类型是引用时，必须进行初始化 如果表达式不是一个变量，返回表达式结果对应的类型，比如b 一些表达式比如【指针解引用、变量加括号、赋值操作】的结果均为引用类型 1 2 3 4 5 6 int a = 1, \u0026amp;r = a, *p = \u0026amp;a, b = 2; decltype(r) r_a = a; // r_a是int\u0026amp; decltype(r+0) b = a; // b是int型 decltype(*r) r_a2 = a; // r_a2是int\u0026amp; decltype((a)) r_a3 = a; // r_a3是int\u0026amp; decltype(a = b) r_a4 = a; //r_a4是int\u0026amp; 2.6 自定义数据结构 struct 1 2 3 4 5 6 7 // 复杂写法 struct student {}; struct student xiaoli; // 简单写法：使用typedef取别名，不用写struct student，而是直接写stu typedef struct student {} stu; stu xiaozhang; 编写自己的[[ch01-开始#头文件|头文件]] 其他 各种“符” 声明符（declarator）：类型修饰符（可有可无）+变量名（也称标识符） 类型修饰符：*，\u0026amp; 标识符（identifier）：变量名 类型说明符（type specifier）：int，char，void等 数据类型修饰符：unsigned等 类型限定符（qualifier）：const，static等 访问限定符：public, private, protected const和指针、引用的组合 1 2 int a = 0; const int ca = 1; 常量指针（const pointer）：int *const p = \u0026amp;a，是顶层const 指向常量的指针（pointer to const）：const int *p = \u0026amp;a;*，是底层const 对常量的引用（reference to const）：const int \u0026amp;r = a; 常量引用（const reference）：不存在 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch02-%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/","summary":"第二章 变量和基本类型 2.1 基本内置类型 1 2 sizeof(int) = 4; sizeof(long int) = 8; sizeof(long long int) = 8; sizeof(float) = 4; sizeof(double) = 8; sizeof(long double) = 16; 字面值常量（literal） 分多行书写字符串：C++ 允许在","title":"Ch02 变量和基本类型"},{"content":"第一章 开始 查看程序运行状态：echo $? 返回上一个命令的状态\n程序正常运行，返回0，表示没有错误\n返回值-1，打印255；返回值3，打印3；返回值-3，打印打印253\nendl：这是一个被称为操纵符（manipulator）的特殊值，效果是结束当前行，并将设备关联的缓冲区（buffer）中的内容刷到设备中。\nUNIX和Mac下键盘输入文件结束符：ctrl+d，Windows下：ctrl+z\n库文件：\n库文件包含了一系列库函数，一般以二进制文件（链接库）的形式存放 源代码进行预处理编译汇编生成可重定位目标文件后，与库文件进行链接 头文件 背景：不同代码写在不同模块中分别编译，链接时变量或函数需要“有且仅有一次定义，但可以多次声明”，头文件为使用模块的用户提供接口 extern进行外部变量的声明（如果对extern变量进行显式初始化则相当于进行了变量的定义） 使用头文件相当于将头文件中每个变量和函数的声明复制到源文件中 不同.cpp将可以include相同的头文件，如果.cpp编译汇编出来的目标文件进行链接，相当于进行多次声明 使用： 可以将函数原型，#define预编译指令，const定义，结构声明，类声明，模板声明，内联函数放在头文件中，其定义放在对应.cpp文件中 头文件不会参与编译 使用时进行include，就相当于预处理器将extern声明插入到源代码 一般情况下，头文件不能放变量或函数的定义（因为可能被多个.cpp文件包含，进而链接时产生多重定义），特殊情况有： 可以定义const变量：const修饰的全局变量作用域只在当前文件中，因此不同文件中的同名const变量是不相同的两个变量，同时const保证了变量值都是常量（static变量虽然作用域只在当前文件中，但是变量值不是常量） 可以定义static变量和static函数 可以定义内联函数：编译器将内联函数进行展开，因此编译期就需要得到内联函数的完整定义 头文件可以定义类（否则编译器无法知道类的成员和偏移，也无法分配内存大小），而且建议头文件名字和类名一致： 对于数据成员，需要等到具体的对象创建时才被定义（分配空间） 对于函数成员，定义类时即被创建：可以将函数成员的实现放在类定义中，此时编译器视这个函数为内联的（不确定）；也可以将函数成员的实现单独放在一个.cpp文件中 头文件中的模板：模板实现为会放到头文件中 两种加载头文件的方式：搜索顺序不同，先找到哪个就使用哪个 标准库的头文件使用\u0026lt;\u0026gt;：编译时指定的头文件目录（-I参数指定）、系统环境变量CPLUS_INCLUDE_PATH（C++）或C_INCLUDE_PATH（C）指定的目录、gcc默认目录 标准库的头文件、操作系统相关头文件、安装的特定库的头文件 非标准库的头文件使用\u0026quot;\u0026quot;：源文件所在目录、\u0026lt;\u0026gt;头文件搜索目录 防止重复包含 1 2 3 4 #ifndef HEADFILE_H_ // 判断是否定义过预处理变量HEADFILE_H_（即没有include该头文件） #define HEADFILE_H_ // 将一个名字设定为预处理变量（即定义HEADFILE_H_变量）；预处理变量的名称需要唯一（无视作用域的规则），且保持全部大写。 // Definition of Sales_itemclass and related functions goes here #endif // 一旦检查预处理变量的结果为真，则执行后续操作，直到遇到#endif 高级IDE中可以使用#pragma once来防止头文件的重复包含 参考 C++头文件源文件详解 C++理论梳理3——深刻理解头文件的作用 好文章：细说C++头文件 more reading C++风格指南-头文件 【C语言精华】头文件组织与包含原则！纯干货，这是一篇有价值的文章！ C语言中头文件包含的处理原则 ","permalink":"https://qinganzhang.github.io/posts/cpp-primer/ch01-%E5%BC%80%E5%A7%8B/","summary":"第一章 开始 查看程序运行状态：echo $? 返回上一个命令的状态 程序正常运行，返回0，表示没有错误 返回值-1，打印255；返回值3，打印3；返回值","title":"Ch01 开始"},{"content":"41：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递 一般C++传参方式有三种： 对左值引用和右值引用分别重载，需要实现两个版本 使用万能引用，使用时可能会实例化出多个版本，传参报错可读性差 传值： 可以考虑参数使用按值传递的情况： 构造（拷贝构造或移动构造）：对于可拷贝的，移动开销低的，并且总是会被拷贝的形参而言，按值传递和按引用传递的效率很接近，而且按值传递更容易实现，还可能会生成更少的目标代码，只是略微引入了一点性能开销 按值传递的前提是移动操作的成本足够低廉，因为按值传递比按引用传递多一次移动操作 只有当形参一定会被拷贝时，才考虑按值传递；比如有时函数开始先进行if检查，即使没有满足if条件而跳出函数，也会产生形参传值构造和析构的开销 赋值（拷贝赋值或移动赋值） 有时移动操作可能比直接拷贝开销更大：因为移动操作会涉及到原来对象的析构、新对象的构造，如果新对象比原来对象小，拷贝可以直接在原对象的位置上进行（具体见参考中的密码例子，如果新密码的长度比旧密码短，则新密码直接拷贝到旧密码的位置） 参考 https://blog.csdn.net/Dong_HFUT/article/details/127054642 42：考虑置入而非插入 push_back可能会创建中间临时对象，但是emplace_back使用完美转发（直接将参数匹配到构造函数），不会创建临时对象\n多数场景下使用emplace_back比push_back高效\n要插入的值是通过构造函数插入容器，而非赋值 赋值：比如emplace到容器begin，此时需要构造临时对象，然后将其移动到begin，此时emplace没有优势 传入参数的类型和容器元素的类型不同 如果传参类型和容器元素类型相同，也就不需要产生临时对象，emplace与push相同 如果某个元素值添加重复，会使用新创建的元素值替换为原来旧的元素值 使用注意：\n资源管理 1 2 3 std::list\u0026lt;std::shared_ptr\u0026lt;Widget\u0026gt;\u0026gt; ptrs; ptrs.push_back(std::shared_ptr\u0026lt;Widget\u0026gt;(new Widget, myDeleter)); // ok，不会发生内存泄露 ptrs.emplace_back(new Widget, myDeleter); // 如果emplace_back内部、调用构造函数之前发生异常，则会发生内存泄露 原因是延迟了资源管理对象的创建 因此要么使用make_shared创建智能指针，要么先创建一个临时对象然后move到emplace中 与显式构造函数的交互 参考\nhttps://blog.csdn.net/Dong_HFUT/article/details/127073175 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch08-%E5%BE%AE%E8%B0%83/","summary":"41：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递 一般C++传参方式有三种： 对左值引用和右值引用分别重载，需要实","title":"[Effective Modern Cpp Notes] Ch08 微调"},{"content":"","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch07-%E5%B9%B6%E5%8F%91api/","summary":"","title":"[Effective Modern Cpp Notes] Ch07 并发API"},{"content":"","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/effective-modern-cpp-reading-notes/","summary":"","title":"Effective Modern Cpp Reading Notes"},{"content":"31：避免默认捕获模式 闭包：lambda所创建的运行期对象 默认捕获可能导致引用悬挂 默认传引用可能导致引用悬挂 显式传引用也可能导致引用悬挂，但是可以更容易发现此处可能有引用悬挂 默认传值捕获也可能导致引用悬挂 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 std::vector\u0026lt;std::function\u0026lt;bool(int)\u0026gt;\u0026gt; filters; class Widget{ public: // void addFilter() const{ // filters.emplace_back( // [=](int value) {return value % divisor == 0;} // ); // 看似是传值捕获，不会有引用悬挂；但是lambda只能捕获作用域中的非静态局部变量，此处的divisor其实是this-\u0026gt;divisor，容易产生引用悬挂 // } // 解决方法：使用一个局部变量复制成员变量，然后使用显式的值捕获 void addFilter() const{ int divisorCopy = divisor; filters.emplace_back( [divisorCopy] (int value) {return value % divisorCopy == 0;} ); } private: int divisor; }; lambda只能捕获作用域中的非静态局部变量，无法捕获静态或全局变量 捕获表示将值拷贝到闭包类中，而lambda中使用静态或全局变量，相当于是对外部的引用，因此此时lambda不是独立的 参考 https://blog.csdn.net/Dong_HFUT/article/details/125037605 32：使用初始化捕获将对象移入闭包 C++14使用初始化捕获模式（也称广义lambda捕获）来实现移动捕获 1 2 3 4 5 struct Widget{ bool isValid() const; }; auto func = [pw = std::make_unique\u0026lt;Widget\u0026gt;()] // 左边是lambda闭包内成员名称，右边是初始化 {return pw-\u0026gt;isValid();} C++11使用std::bind间接实现移动捕获 1 2 3 4 5 6 7 struct Widget{ bool isValid() const; }; auto func = std::bind( [] (const std::unique_ptr\u0026lt;Widget\u0026gt;\u0026amp; pw) {return pw-\u0026gt;isValid();}, std::make_unique\u0026lt;Widget\u0026gt;() ); 参考 https://blog.csdn.net/Dong_HFUT/article/details/125111586 33：泛型lambda的完美转发版本 对auto\u0026amp;\u0026amp;类型的形参使用decltype，以std::forward之\n泛型lambda（C++14）：可以使用auto声明形参（即闭包类中的operator()可以使用模板实现） 1 2 3 4 5 6 7 auto f = [] (auto x) {return func(x);} // 闭包类中的operator()的大致实现：auto形参实际上是模板类型推导 class SomeCompilerGeneratedClassName{ public: template \u0026lt;typename T\u0026gt; auto operator() (T x) const {return func(x);} } 泛型lambda的完美转发版本： 1 2 3 4 5 6 7 8 9 auto f = [] (auto\u0026amp;\u0026amp; param) {return func( std::forward\u0026lt;decltype(param)\u0026gt;(param) );} // 闭包类中的operator()的大致实现 class SomeCompilerGeneratedClassName{ public: template \u0026lt;typename T\u0026gt; auto operator() (T\u0026amp;\u0026amp; param) const { return func( std::forward\u0026lt;decltype(param)\u0026gt;(param) ); } }; auto fs = [] (auto\u0026amp;\u0026amp;... params) {return func( std::forward\u0026lt;decltype(params)\u0026gt;(params)... );} // 变长参数版本 参考 https://blog.csdn.net/Dong_HFUT/article/details/125116613 34：优先选用lambda表达式，而非std::bind 对于C++11，除了个别边缘case，lambda比std::bind更有优势；C++14，lambda完全可以替代std::bind\nlambda可读性更强，更容易理解 使用std::bind需要保持参数位置，同时需要了解其实现机制 std::bind需要保持参数位置，因此使用时需要查看原来函数的声明，才能知道占位符对应的参数类型和参数含义；但是lambda形参列表很明确 std::bind默认将参数拷贝到绑定对象内部（可以使用std::ref指定传引用），但是lambda可以明确指出值捕获还是引用捕获 std::bind绑定对象的函数调用使用了完美转发机制，但是lambda可以从形参列表中清晰看出传值还是传引用 1 2 3 4 5 6 7 Widget w; Logger logger; auto f = [w, \u0026amp;logger] (CompressLevel level) { return compress(w, level, logger); } // 捕获对象：w值捕获，logger引用捕获；形参：level传值 auto g = std::bind(compress, w, std::placeholders::_1, std::ref(logger)); // 需要对应参数顺序 // 绑定对象：w值绑定（复制），logger引用绑定；形参：level使用完美转发机制 std::bind参数绑定和对象调用不是一个时间，因此可能出现逻辑错误（见参考） lambda灵活性更强 如果std::bind绑定的函数存在重载版本，则编译器无法确定使用哪个版本的重载函数 1 2 3 4 5 6 7 void func(int a); void func(int a, int b); auto f = [] (int b) { return func(0, b); } using funcType = void(int, int); auto bnd = std::bind(static_cast\u0026lt;funcType\u0026gt;(func), 0, std::placeholders::_1) lambda可以内联 因为std::bind中绑定的是函数指针，需要在运行时才能确定；但是lambda中包含函数体，可以进行内联 使用std::bind的两个场景：在C++11中 使用std::bind间接实现移动捕获（[[ch06-lambda表达式#32：使用初始化捕获将对象移入闭包|C++14支持移动捕获]]） 使用std::bind绑定参数的完美转发机制，间接多态函数对象（[[ch06-lambda表达式#33：泛型lambda的完美转发版本|C++14支持泛型lambda]]） 1 2 3 4 5 6 7 8 auto f = [callableObject] (const auto\u0026amp; param) { callableObject(param); }; class CallableObject{ public: template \u0026lt;typename T\u0026gt; void operator() (const T\u0026amp; param); }; auto g = std::bind(CallableObject(), std::placeholders::_1); // 将占位符参数完美转发到可调用对象的调用运算符中 参考 https://blog.csdn.net/Dong_HFUT/article/details/125130410 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch06-lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","summary":"31：避免默认捕获模式 闭包：lambda所创建的运行期对象 默认捕获可能导致引用悬挂 默认传引用可能导致引用悬挂 显式传引用也可能导致引用悬挂，但","title":"[Effective Modern Cpp Notes] Ch06 Lambda表达式"},{"content":"23：理解std::move和std::forward std::move：返回变量的右值引用 对const对象的移动操作会被转换为拷贝操作 因为const对象经过std::move会返回一个const右值引用，而一般函数重载的移动版本形参都是非const的右值引用，无法匹配 std::move不移动对象，而且也不保证对象一定被移动，仅仅返回对象的右值引用 1 2 3 4 5 6 template\u0026lt;typename T\u0026gt; // C++14 decltype(auto) move(T\u0026amp;\u0026amp; param) { using ReturnType = remove_reference_t\u0026lt;T\u0026gt;\u0026amp;\u0026amp;; return static_cast\u0026lt;ReturnType\u0026gt;(param); } std::forward：实现完美转发（保持对象的左值性或右值性） 通常情况下，形参总是左值，即使其类型是右值引用 std::move和std::forward只是进行类型转换，在运行时不做任何事 参考 https://blog.csdn.net/Dong_HFUT/article/details/123765869 24：区分万能引用和右值引用 万能引用和右值引用只是形式上类似，但这是两个概念\n万能引用：形式为T\u0026amp;\u0026amp;或auto\u0026amp;\u0026amp;，并且存在类型推导 函数模板参数：template \u0026lt;typename T\u0026gt; void func(T\u0026amp;\u0026amp; param); auto类型推导：auto\u0026amp;\u0026amp; val = myVal; 1 auto myFunc = [] (auto\u0026amp;\u0026amp; func, auto\u0026amp;\u0026amp;... params) {/* do something */} 右值引用 带const（不是纯粹的T\u0026amp;\u0026amp;形式）：template \u0026lt;typename T\u0026gt; void func(const T\u0026amp;\u0026amp; param); 形式是T\u0026amp;\u0026amp;，但是不存在类型推导：比如vector的push_back，但是emplace_back中参数是万能引用 1 2 3 4 5 6 7 8 template \u0026lt;typename T, typename Allocator = allocator\u0026lt;T\u0026gt;\u0026gt; class vector{ public: void push_back(T\u0026amp;\u0026amp; x); // 调用push_back时，类型T已知 template \u0026lt;typename... Args\u0026gt; void emplace_back(Args\u0026amp;\u0026amp;... args); // 参数包args的类型Args独立于T，存在类型推导，这里是万能引用 } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123773321 25：针对右值引用实施std::move，针对万能引用实施std::forward 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Widget{ // 以例子来说明 public: Widget(Widget\u0026amp;\u0026amp; rhs): name(std::move(rhs.name)), sp(std::move(rhs.sp)) {} // 形参为右值引用，将形参（左值）进行移动 template \u0026lt;typename T\u0026gt; void setName(T\u0026amp;\u0026amp; newName){ // 形参为万能引用，保持形参的左值性或右值性 cout\u0026lt;\u0026lt;\u0026#34;set new name:\u0026#34;\u0026lt;\u0026lt;newName\u0026lt;\u0026lt;endl; name = std::forward\u0026lt;T\u0026gt;(newName); // 在函数中使用move或forward时，使用的位置应该是该参数最后一次使用的时候 } Widget operator+(Widget\u0026amp;\u0026amp; lhs, Widget\u0026amp;\u0026amp; rhs){ lhs.name += rhs.name; return std::move(lhs); } template \u0026lt;typename T\u0026gt; T doNothing(T\u0026amp;\u0026amp; t) { return std::forward\u0026lt;T\u0026gt;(t); } private: string name; shared_ptr\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; sp; }; 重载setName不是一个好的设计 可能效率低：如果传入字面量，即使匹配到右值版本的函数，形参仍然会作为临时对象 如果有多个参数，需要重载$2^N$种，如果使用参数包，则无法实现 在函数中使用move或forward时，使用的位置应该是该参数最后一次使用的时候 如果函数中将形参进行处理，然后返回 传值返回：如果形参是右值引用（比如Widget operator+成员函数），使用move返回；如果形参是万能引用（比如doNothing成员函数），使用forward返回 如果返回值是函数中的局部变量，则编译器有特定的优化：RVO 返回值优化RVO（Return Value Optimization）：减少函数返回时产生临时对象，进而消除部分拷贝或移动操作 1 2 3 4 5 6 7 8 9 10 11 12 // 原来 Widget func() { return Widget(); } // 有一次默认构造，一次拷贝构造 Widget w = func(); // 再加上一次拷贝构造 // 使用RVO优化，上面过程相当于： void func(Widget\u0026amp; w) { w.Widget::Widget(); } // Widget w在外面分配空间，直接传入func中进行构造，因此只需要一次（默认）构造 // NRVO(Named Return Value Optimization)原理类似 Widget func() { Widget w; return w; // 返回对象已经具名 } 使用前提：局部对象的类型和返回值类型相同，而且局部对象就是返回值 限制场景： 返回std::move()：默认构造+移动构造 进行赋值而非初始化Widget w; w = func();：默认构造+func中的默认构造和拷贝构造 不同的分支条件下，返回不同的局部对象 参考 https://blog.csdn.net/Dong_HFUT/article/details/123946594 26：避免依万能引用类型进行重载 原因：函数匹配规则 如果模板实例化出的函数和普通重载函数都精确匹配，则优先选择普通重载函数，其次选择模板函数实例化出来的精确版本 例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Person{ public: explicit Person(int idx): _name(nameFromIdx(idx)) {} template \u0026lt;typename T\u0026gt; // 对Person(int)的重载 explicit Person(T\u0026amp;\u0026amp; name): _name(std::forward\u0026lt;T\u0026gt;(name)) {} private: std::string _name; }; short id = 1; Person p1(id); // 会调用模板实例化的版本，而非进行类型转换调用普通版本 const Person p2(id); // 这个情况极其容易混淆， Person q2(p2); // 会调用生成的拷贝构造函数（因为其实参为const Person\u0026amp;） Person q1(p1); // 会调用模板实例化的版本，而非调用生成的拷贝构造函数 // 尤其当Person作为基类，派生类在构造函数中初始化基类部分时 class SpecialPerson: public Person{ public: SpecialPerson(const SpecialPerson\u0026amp; rhs): Person(rhs) {} SpecialPerson(SpecialPerson\u0026amp;\u0026amp; rhs): Person(std::move(rhs)) {} // 这两个构造函数均使用基类Person构造函数的完美转发版本， } // 对万能引用参数的函数进行重载，不是一个好的设计 27：熟悉依万能引用类型进行重载的替代方案 放弃重载，使用不同的函数名\n但是对于构造函数就无能为力 普通函数形参为const type\u0026amp;类型\n因此传入const实参，会优先使用原来的普通版本，而非重载的万能引用版本 将形参从引用类型换成值类型：当知道肯定要复制形参时，考虑按值传递\n1 2 3 4 5 6 7 class Person{ public: explicit Person(std::string name): _name(std::move(name)) {} explicit Person(int idx): name(nameFromIdx(idx)) {} private: std::string _name; } 使用Tag分发：使用Tag对参数进行区分，进而分发到不同的函数实现\n背景：如果想使用完美转发，就必须要使用万能引用 例子： 1 2 3 4 5 6 7 8 9 10 // 两个函数实现的版本 template \u0026lt;typename T\u0026gt; void logAndAddImpl(T\u0026amp;\u0026amp; name, std::false_type) {} template \u0026lt;typename T\u0026gt; void logAndAddImpl(int idx, std::true_type) {} // 使用Tag对参数进行区分 template \u0026lt;typename T\u0026gt; void logAndAdd(T\u0026amp;\u0026amp; name) { logAndAddImpl( std::forward\u0026lt;T\u0026gt;(name), std::is_integral\u0026lt;typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026gt;() ); // 或者C++14：std::is_integral\u0026lt;typename std::remove_reference_t\u0026lt;T\u0026gt; } 如果传入true or false，到运行时才能决定 在编译阶段进行模板匹配，std::is_integral在编译阶段就可以判断类型是否为整型 约束接受万能引用的模板：std::enable_if判断\n背景：构造函数无法使用Tag分发 例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;type_traits\u0026gt; class Person{ public: explicit Person(int idx): _name(nameFromIdx(idx)) {} template\u0026lt;typename T, typename = std::enable_if_t\u0026lt; !std::is_base_of_v\u0026lt;Person, std::decay_t\u0026lt;T\u0026gt;\u0026gt; \u0026amp;\u0026amp; !std::is_integral_v\u0026lt;std::remove_reference_t\u0026lt;T\u0026gt;\u0026gt; \u0026gt; \u0026gt; // 当类型T不为Person或者其派生类，抑或T不为int型时，才会选择这个的重载版本，使用万能引用进行重载并实现完美转发 explicit Person(T\u0026amp;\u0026amp; name): _name(std::forward\u0026lt;T\u0026gt;(name)) { static_assert( std::is_constructible(std::string, T)::value, \u0026#34;Parameter name can\u0026#39;t be used to construct a std::string\u0026#34; ); // 验证类型为std::string的对象能否被类型为T的对象构造 } private: std::string _name; }; std::enable_if\u0026lt;condition\u0026gt;::type：只有满足条件的模板才会使用（C++14std::enable_if_t） std::is_same\u0026lt;T1, T2\u0026gt;::value（C++17std::is_same_v） std::is_base_of\u0026lt;T1, T2\u0026gt;::value：如果T2继承于T1，则为true；且std::is_base_of\u0026lt;T, T\u0026gt;::value==true（C++17std::is_base_of_v） std::decay\u0026lt;T\u0026gt;::type的类型与T的类型相同，忽略了引用、const、volatile（C++14std::decay_t） 权衡\n前三种方案都需要对需要调用的函数形参逐一指定其类型，后两种方案使用万能引用实现了完美转发 虽然完美转发效率更高（避免创建临时对象），但是某些对象无法实现完美转发，并且使用完美转发并编译报错时，报错信息的可读性很差 std::is_constructible可以在编译期测试一个类型的对象能否被另一个不同类型的对象（或者多个不同类型的多个对象）构造，因此可以用来验证转发函数的万能引用参数是否合法 参考\nSFINAE技术 https://blog.csdn.net/Dong_HFUT/article/details/124227488 28：理解引用折叠 几种引用折叠的应用场景： 万能引用的实例化：在模板类型推导时，可能出现“引用的引用”的情况，此时需要用到引用折叠 std::forward完美转发： 1 2 3 4 template \u0026lt;typename T\u0026gt; T\u0026amp;\u0026amp; forward(typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp; param){ return static_cast\u0026lt;T\u0026amp;\u0026amp;\u0026gt;(param); } auto类型推导，decltype类型推导 typedef类型别名 参考 https://blog.csdn.net/Dong_HFUT/article/details/124517043 29：假定移动操作不存在、成本高、未使用 几种移动语义不可用、不高效的情况： 没有移动操作：编译器只有在没有用户自定义拷贝操作和析构函数时，才自动生成移动操作 移动未能更快： std:array 一般STL中容器的对象都分配在堆上，对象中有指向堆上内存的指针，因此移动操作只需要进行指针的更新、源对象的指针置空即可 但是std::array中内容分配在栈上（栈上的数组），移动操作等于复制操作 std::string std::string针对小对象有一个优化SSO（Small String Optimization），小对象直接存储在栈上而非堆上，省去动态内存分配 移动不可用：移动操作没有标记为noexcept 如果移动操作没有标记为noexcept，即使是适合使用移动操作的场景，编译器也会使用复制操作替代 源对象是左值：只有右值可以作为移动操作的源（左值可以用，但是很容易造成空悬问题） 参考 https://blog.csdn.net/Dong_HFUT/article/details/124577258 30：熟悉完美转发的失败情形 完美转发的含义：不仅转发对象，而且转发其特征（左值、右值、const、volatile） 完美转发的失败情形 列表初始化 1 2 3 4 5 6 7 8 void f(const std::vector\u0026lt;int\u0026gt;\u0026amp; v) {} template \u0026lt;typename T\u0026gt; void fwd(T\u0026amp;\u0026amp; param) {} f({1,2,3}); // ok fwd({1,2,3}); // 编译报错：无法推断出T的类型 auto il = {1,2,3}; fwd(il); // T=initializer_list\u0026lt;int\u0026gt; 0或NULL作为空指针 0或NULL会被推导为int型而非空指针类型，因此完美转发后得到的类型是int，但是形参是指针类型 仅仅声明整型的静态常量数据成员 1 2 3 4 5 class Widget{ public: static cosnt int cnst = 12; // 声明而非定义，不会分配实际的存储空间，而是常量传播（直接将用到cnst的地方替换为12） }; fwd(Widget::cnst); // 编译报错：找不到cnst的定义 只声明不会分配空间，因此无法取地址，也无法使用引用，不能使用完美转发 解决方法：在类外或是对应.cpp文件中添加定义：const int cnst = 12; 函数重载和函数模板 1 2 3 4 5 6 7 8 9 10 void f(int (*pf)(int)); int func(int a); int func(int a, int b); f(func); // ok fwd(func); // 模板类型推导失败：无法确定是哪个重载版本 // 解决方法： using FuncType = int (*)(int); fwd(static_cast\u0026lt;FuncType\u0026gt;(func)); // 但是万能引用和完美转发一般是针对任意类型的，这里限定了类型，语义与实现矛盾 位域：位域只是int类型的一部分，没有一个确切地址，也就无法引用 参考 https://blog.csdn.net/Dong_HFUT/article/details/124787082 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch05-%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E7%A7%BB%E5%8A%A8%E8%AF%AD%E5%8F%A5%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/","summary":"23：理解std::move和std::forward std::move：返回变量的右值引用 对const对象的移动操作会被转换为拷贝操作 因为","title":"[Effective Modern Cpp Notes] Ch05 右值引用、移动语句和完美转发"},{"content":"18：使用std::unique_ptr管理具备专属所有权的资源 std::unique_ptr表示独占所有权，因此无法拷贝（拷贝构造、拷贝赋值是delete的），只能进行移动操作从而转移资源控制权 例外：可以从函数返回一个std::unique_ptr 1 2 3 4 5 std::unique_ptr\u0026lt;int\u0026gt; func(int x){ auto delInt = [\u0026amp;](int* p) { cout\u0026lt;\u0026lt;\u0026#34;My deleter\u0026#34;\u0026lt;\u0026lt;endl; delete p;} std::unique_ptr\u0026lt;int, decltype(delInt)\u0026gt; pInt(new int(x), delInt); return pInt; } 删除器是std::unique_ptr类型的一部分 在不定义删除器的情况下，std::unique_ptr内存占用和原始指针相同 如果自定义删除器，则std::unique_ptr内存占用会变大 std::unique_ptr可以指向数组，默认删除器为delete[]：std::unique_ptr\u0026lt;int[]\u0026gt; p(new int[5]{1,2,3,4,5}); 但是数组形式用到的场合很少，尽量使用STL std::unique_ptr可以直接隐式转换为std::shared_ptr 典型应用：针对继承体系，作为工厂函数的返回值类型 1 2 3 4 5 6 7 8 9 10 11 class Animal {}; class Dog: public Animal {}; class Cat: public Animal {}; template \u0026lt;typename... Ts\u0026gt; auto makeAnimal(AnimalType type, Ts\u0026amp;\u0026amp;... AnimalInfo){ // C++14中函数返回值可以写为auto，因此unique_ptr的删除器可以放在函数内部，否则显式写出返回类型时需要知道删除器类型，因此删除器只能写在函数外部 auto delAnimal = [](AnimalType* ptr) { makeMyLog(ptr); delete ptr; } std::unique_ptr\u0026lt;Animal, decltype(delAnimal)\u0026gt; up(nullptr, delAnimal); if(type == Dog) up.reset(new Dog(std::forward\u0026lt;Ts\u0026gt;(AnimalInfo)...)); // 参数是万能引用，这里进行完美转发 if(type == Cat) up.reset(new Cat(std::forward\u0026lt;Ts\u0026gt;(AnimalInfo)...)); // 使用reset使得指针独占资源的所有权，不能直接将原始指针赋值给智能指针 return up; // 返回unique_ptr } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123465058 19：使用std::shared_ptr管理具备共享所有权的资源 std::shared_ptr可以拷贝，通过引用计数来管理资源的生命周期 std::shared_ptr内存模型 一个std::shared_ptr大小通常为普通指针的两倍：一个指针指向资源，另一个指针指向控制块 控制块中通过原子操作维护引用计数，保存deleter（因此deleter不属于std::shared_ptr类型的一部分），保存弱计数等 std::shared_ptr的使用： 使用std::make_shared、std::unique_ptr、原始指针创建std::shared_ptr，会为资源创建一个控制块 如果资源有多个控制块，就会被多次析构，因此尽量避免使用原始指针构造std::shared_ptr 使用std::shared_ptr或std::weak_ptr创建一个std::shared_ptr，不会创建一个新的控制块 this的陷阱： 1 2 3 4 5 6 7 8 9 10 11 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal{ virtual void eat(){ eatList.emplace_back(this); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(this)); } }; struct Cat: public Animal{}; struct Dog: public Animai{}; shared_ptr\u0026lt;Animal\u0026gt; myCat(new Cat); myCat-\u0026gt;eat(); // 针对同一个对象创建了两个控制块 解决方法一：使类继承自std::enable_shared_from_this，类内部使用shared_from_this方法，搜索当前对象的控制块，如果有就不用创建控制块了，如果没有则抛出异常，因此适合于当前对象已经创建过控制块的情况 1 2 3 4 5 6 7 8 9 10 11 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal: public std::enable_shared_from_this\u0026lt;Animal\u0026gt;{ virtual void eat(){ eatList.emplace_back(shared_from_this()); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(shared_from_this())); } }; struct Cat: public Animal{}; struct Dog: public Animai{}; shared_ptr\u0026lt;Animal\u0026gt; myCat(new Cat); myCat-\u0026gt;eat(); 解决方法二：见127页，代码是自己实现的，有误 1 2 3 4 5 6 7 8 9 10 11 12 13 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal: public std::enable_shared_from_this\u0026lt;Animal\u0026gt;{ public: template \u0026lt;typename... Ts\u0026gt; static shared_ptr\u0026lt;Animal\u0026gt; create(Ts\u0026amp;\u0026amp;... params) { return shared_ptr\u0026lt;Animal\u0026gt;(Animal(std::foward\u0026lt;Ts\u0026gt;(params)...)); } virtual void eat(){ eatList.emplace_back(shared_from_this()); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(shared_from_this())); } private: Animal() {} // 构造函数 }; struct Cat: public Animal{}; struct Dog: public Animai{}; 参考 https://blog.csdn.net/Dong_HFUT/article/details/123599599 20：对于类似std::shared_ptr但是可能空悬的指针使用std::weak_ptr std::weak_ptr通常视为std::shared_ptr的辅助工具，通过std::shared_ptr构造std::weak_ptr std::weak_ptr不会影响对象的引用计数 但是std::weak_ptr没有解引用操作，必须调用lock转换为std::shared_ptr来访问对象 例子：if(shared_ptr\u0026lt;int\u0026gt; p = wp.lock()\u0026gt; cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;endl; 典型应用： 避免shared_ptr循环引用：将其中一个shared_ptr改为weak_ptr 1 2 3 4 5 6 7 8 9 10 struct A{ std::shared_ptr\u0026lt;B\u0026gt; pb; // std::weak_ptr\u0026lt;B\u0026gt; pb; }; struct B{ std::shared_ptr\u0026lt;A\u0026gt; pa; }; std::shared_ptr\u0026lt;A\u0026gt; pa = std::make_shared\u0026lt;A\u0026gt;(); std::shared_ptr\u0026lt;B\u0026gt; pb = std::make_shared\u0026lt;B\u0026gt;(); pa-\u0026gt;pb = pb; // pb和pa-\u0026gt;pb同时指向同一个对象B，引用计数为2 pb-\u0026gt;pa = pa; 带缓存的工厂方法 1 2 3 4 5 6 7 8 9 std::shared_ptr\u0026lt;const Widget\u0026gt; fastLoadWidget(WidgetID id){ static std::unordered_map\u0026lt;WidgetID, weak_ptr\u0026lt;const Widget\u0026gt;\u0026gt; cache; std::shared_ptr\u0026lt;const Widget\u0026gt; widgetPtr = cache[id].lock(); if(!widgetPtr){ // 缓存中没有 widgetPtr = loadWidget(id); // 调用原始工厂方法创建，并加入到缓存中 cache[id] = widgetPtr; } return widgetPtr; } 观察者设计模式：多个观察者（observer）对象同时监听一个主题（subject）对象，主题对象会在其发生状态改变时发出通知。主题对象不会控制其观察者的生存期，但需要确认当一个观察者对象被析构后，主题对象不会再访问它。一种合理的设计就是让每个主题对象持有指向其观察者对象的std::weak_ptr，以便在使用之前确认它是否空悬。 参考： https://blog.csdn.net/Dong_HFUT/article/details/123612236 21：优先选用std::make_unqiue和std::make_shared，而非直接使用new make函数可以传入任意集合的参数，然后完美转发给构造函数，并动态创建一个对象，返回智能指针 支持auto 避免异常：将[[ch03-资源管理#17：以独立语句将new的对象置入智能指针| effective C++ item17：以独立语句将new的对象置入智能指针]]改进为使用make函数 1 2 3 4 5 6 7 void func(shared_ptr\u0026lt;Widget\u0026gt; sp, int priority); void func(shared_ptr\u0026lt;Widget\u0026gt;(new Widget), priority); // 可能由于异常导致内存泄露 void func(make_shared\u0026lt;Widget\u0026gt;(), priority); // 不会由于异常导致内存泄露 // 如果需要自定义删除器，并且又可以避免异常 shared_ptr\u0026lt;Widget\u0026gt; sp(new Widget, myDeleter); func(std::move(sp), priority); // 直接传递一个右值，避免了修改引用计数 效率更高：make函数只需要申请一次内存（同时存储对象和控制块），但是使用shared_ptr\u0026lt;Widget\u0026gt;(new Widget)需要申请两次内存（一次对象，一次控制块） make函数的缺点： 无法自定义deleter 语义歧义：比如使用()和{}初始化vector代表不同的方式，make函数可以完美转发()，不支持完美转发{} 1 2 3 4 auto sp1 = make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(2,3); // {3,3}; shared_ptr\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; sp2(new vector{1,2,3,4,5}); auto initList = {1,2,3,4,5}; auto sp3 = make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(initList); // 不支持：make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;({1,2,3,4,5}); 不建议对自定义内存管理方式的类使用 make 函数：通常情况下，类自定义的operator new和operator delete被设计成用来分配和释放能精确容纳该类大小的内存块，但std::allocate_shared所要求的内存大小并不等于动态分配对象的大小，而是在其基础上加上控制块的大小。 若存在非常大的对象和比相应的std::shared_ptr生存期更久的std::weak_ptr，不建议使用 make 函数，会导致对象的析构和内存的释放之间产生延迟 如果只申请一块内存（make函数），如果后来shared_ptr的引用计数为0，但是weak_ptr的引用计数不为0时，对象销毁会被延长，只有当weak_ptr的引用计数为0时，控制块才被释放 如果使用new的话，可以立即销毁对象 参考 https://blog.csdn.net/Dong_HFUT/article/details/123622543 22：使用Pimpl习惯用法时，将特殊成员函数的定义放到实现文件中 PImpl技术（Pointer to Implementation，编译防火墙）：将类的实现放在另一个单独的类中，并通过不透明的指针进行访问。因此可以有效减少编译依赖。 原理：一个只声明但是不定义的类型是不完整类型，声明指向它的指针是可以通过编译的 常见错误： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // in \u0026#34;widget.h\u0026#34; #include \u0026lt;memory\u0026gt; class Widget { public: Widget(); private: struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; pImpl; }; //==================================================================================// // in \u0026#34;widget.cpp\u0026#34; #include \u0026#34;widget.h\u0026#34; #include \u0026lt;string\u0026gt; struct Widget::Impl { std::string name; }; Widget::Widget(): pImpl(std::make_unique\u0026lt;Impl\u0026gt;()){} //==================================================================================// // in \u0026#34;main.cpp\u0026#34; #include \u0026#34;widget.h\u0026#34; int main(){ Widget w; // 报错：/usr/include/c++/9/bits/unique_ptr.h:79:16: error: invalid application of ‘sizeof’ to incomplete type ‘Widget::Impl’ return 0; } 报错原因：在析构Widget w时，此时看到的Impl是不完整类型 在编译widget.cpp时没有问题：g++ -c widget.cpp -o widget.o 在编译main.cpp时出问题：g++ -c main.cpp -o main.o 没有定义Widget的析构函数，因此使用自动生成的析构函数（默认是inline的） 本来如果声明了Widget的析构函数，编译时无法进行处理，后面链接时链接到定义，运行时才能析构pImpl（因为经过链接，此时也知道Impl是完整类型） 但是正因为自动生成的析构函数是inline的，编译时就可以展开，此时析构pImpl当然看到的Impl是不完整类型（还没有链接到widget.o） 使用说明 考虑到如上报错和[[ch03-转向现代C++#17：理解特殊成员函数的生成机制|item17：理解特殊成员函数的生成机制]]，因此最好将拷贝控制成员和析构函数自定义，且声明与实现分离（防止进行内联） 为了实现PImpl技术，使用unique_ptr是最合适的，因为pImpl指针独享Impl的所有权，如果使用shared_ptr则上述报错不会出现（因为删除器不属于类型的一部分，属于控制块，不会包含删除器的代码） 参考 https://blog.csdn.net/Dong_HFUT/article/details/123704824 https://github.com/liuzengh/CppIdioms/blob/main/code/pimpl/person.cpp 实例 widget.h 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;memory\u0026gt; class Widget{ public: Widget(std::string s); Widget(const Widget\u0026amp; rhs); Widget\u0026amp; operator=(const Widget\u0026amp; rhs); Widget(Widget\u0026amp;\u0026amp; rhs); Widget\u0026amp; operator=(Widget\u0026amp;\u0026amp;); ~Widget(); std::string getName() const; private: // std::string _name; struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; pImpl; }; widget.cpp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026#34;widget.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; struct Widget::Impl{ Impl(std::string name): _name(name) {}; std::string _name; std::string getName() const {return _name;} }; Widget::Widget(std::string s): pImpl(std::make_unique\u0026lt;Impl\u0026gt;(s)) {} Widget::~Widget() {} Widget::Widget(const Widget\u0026amp; rhs): pImpl(std::make_unique\u0026lt;Impl\u0026gt;(*rhs.pImpl)) {} Widget\u0026amp; Widget::operator=(const Widget\u0026amp; rhs){ *pImpl = *rhs.pImpl; return *this; } Widget::Widget(Widget\u0026amp;\u0026amp; rhs) =default; Widget\u0026amp; Widget::operator=(Widget\u0026amp;\u0026amp; rhs) =default; std::string Widget::getName() const { return pImpl-\u0026gt;getName();} main.cpp 1 2 3 4 5 6 7 8 #include \u0026#34;widget.h\u0026#34; #include \u0026#34;iostream\u0026#34; int main(){ Widget w(\u0026#34;zhang\u0026#34;); std::cout\u0026lt;\u0026lt;w.getName()\u0026lt;\u0026lt;std::endl; return 0; } ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch04-%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","summary":"18：使用std::unique_ptr管理具备专属所有权的资源 std::unique_ptr表示独占所有权，因此无法拷贝（拷贝构造、拷贝赋","title":"[Effective Modern Cpp Notes] Ch04 智能指针"},{"content":"07：在创建对象时注意区分()和{} 初始化方式 1 2 3 4 int x1(1); int x2 = 2; int x3{3}; // 统一初始化（列表初始化） int x4 = {4}; // 和第三种方式相同 ()和=初始化的限制 ()不能用于non-static成员的初始化 不能拷贝的对象不能使用()初始化 {}初始化的优点 禁止基本类型之间的隐式窄化类型转换：比如不能使用double初始化int型变量 避免了C++复杂的语法分析：C++\u0026rsquo;s most vexing parse 1 2 3 Widget w1(10); // 传入一个实参，构造出一个对象 Widget w2(); // 本来想调用无形参的构造函数构造一个对象，但是实际上声明了一个函数 Widget w3{}; // 调用无形参的构造函数，构造出一个对象 {}的缺陷 auto类型推导中使用{}进行初始化，则auto被推断为initializer_list\u0026lt;T\u0026gt; 会优先使用形参为initializer_list\u0026lt;T\u0026gt;的构造函数，即使其他的构造函数更加匹配 只有当{}中参数无法转换为initializer_list中类型时，编译器才匹配普通函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Widget{ public: Widget() {cout\u0026lt;\u0026lt;\u0026#34;0\u0026#34;\u0026lt;\u0026lt;endl;} Widget(int i, int d) {cout\u0026lt;\u0026lt;\u0026#34;1\u0026#34;\u0026lt;\u0026lt;endl;} Widget(int i, bool d) {cout\u0026lt;\u0026lt;\u0026#34;2\u0026#34;\u0026lt;\u0026lt;endl;} Widget(initializer_list\u0026lt;int\u0026gt; il) {cout\u0026lt;\u0026lt;\u0026#34;2\u0026#34;\u0026lt;\u0026lt;endl;} Widget(const Widget\u0026amp; w) {cout\u0026lt;\u0026lt;\u0026#34;copy ctor\u0026#34;\u0026lt;\u0026lt;endl;} Widget(Widget\u0026amp;\u0026amp; w) {cout\u0026lt;\u0026lt;\u0026#34;move copy ctor\u0026#34;\u0026lt;\u0026lt;endl;} operator int() const { cout\u0026lt;\u0026lt;\u0026#34;convert to int\u0026#34;\u0026lt;\u0026lt;endl; return 1; } }; Widget w1{1, true}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，即使Widget(int i, bool d)更加匹配 Widget w2{1, 1.0}; // 编译报错，本来调用Widget(initializer_list\u0026lt;int\u0026gt; il)，但是使用{}初始化禁止窄化类型转换（存在从double到int的转换） Widget w3{w1}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)（中间先将w1转为int），即使Widget(const Widget\u0026amp; w)更加匹配（如果w1无法转换为int，则调用该构造函数） Widget w4{std::move(w1)}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，即使Widget(Widget\u0026amp;\u0026amp; w)更加匹配 // 特殊情况： Widget w4{}; // 调用Widget()，而非调用Widget(initializer_list\u0026lt;int\u0026gt; il) Widget w5{{}}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，而非调用Widget() Widget w6({}); // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，而非调用Widget() 使用模板创建对象时，仔细考虑使用()还是{}进行初始化 标准库函数std::make_unique和std::make_shared也面临着这个问题，它们的解决方案是在内部使用小括号，并将这个决定写进文档中，作为其接口的组成部分。 1 2 3 4 5 6 7 8 9 template \u0026lt;typename T, typename... Ts\u0026gt; void f(Ts\u0026amp;\u0026amp;... params){ // 使用可变参数模板 T localVector1(std::forward\u0026lt;Ts\u0026gt;(params)...); T localVector2{std::forward\u0026lt;Ts\u0026gt;(params)...}; } f\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(3,4); // 推断出T=vector\u0026lt;int\u0026gt;, Ts=int // localVector1: 4,4,4 // localVector2: 3,4 参考 https://blog.csdn.net/Dong_HFUT/article/details/122811753 08：优先选用nullptr，而非0或NULL 字面量0是一个int，NULL的实现为0L，可以转换为int，bool，void* nullptr可以理解为任意类型的空指针 使得重载函数的调用明确 提高代码的清晰度 使用类型推导时，nullptr可以隐式转换为任意类型指针 参考 https://blog.csdn.net/Dong_HFUT/article/details/122891898 09：优先选用别名声明，而非typedef using别名的优点： 清晰，比typedef更容易理解 可以直接对模板起别名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template \u0026lt;typename T\u0026gt; using MyAllocList = std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt;; // 如果非要使用typedef，需要包装一层 template \u0026lt;typename T\u0026gt; struct MyAllocList{ typedef std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt; type; }; template \u0026lt;typename T\u0026gt; class Widget{ MyAllocList\u0026lt;T\u0026gt; list1; // list1=std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt;,此时MyAllocList一定是一个别名 typename MyAllocList\u0026lt;T\u0026gt;::type list2; // list2=MyAllocList\u0026lt;T\u0026gt;中的std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt; // 需要使用typename显式说明MyAllocList\u0026lt;T\u0026gt;::type是一个类型，而非数据成员 } 应用：标准库的\u0026lt;type_traits\u0026gt;中提供了一整套用于类型转换的类模板 虽然C++11中仍然是使用typedef实现的，但是C++14中是使用using声明实现的 1 2 std::remove_const\u0026lt;T\u0026gt;::type // C++11中, 是一个内部包裹typedef的类模板，将T中的const属性移除 std::remove_const_t\u0026lt;T\u0026gt; // C++14中, 是一个类模板中typedef别名的别名，将T中的const属性移除 参考 https://blog.csdn.net/Dong_HFUT/article/details/122847510 10：优先选用限定作用域的枚举类型，而非不限作用域的枚举类型 无作用域限制的枚举（unscoped enums，C++98） 有时使用可能简便一点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 using UserInfo = std::tuple\u0026lt;std::string, std::string, std::size_t\u0026gt; //name, email,age enum UserInfoFields {uiName, uiEmail, uiAge}; UserInfo uInfo; auto email = std::get\u0026lt;1\u0026gt;(uInfo); // 位置1为email auto email = std::get\u0026lt;uiEmail\u0026gt;(uInfo); // 发生隐式类型转换 auto email = std::get\u0026lt;static_cast\u0026lt;std::size_t\u0026gt;(UserInfoFields::uiEmail)\u0026gt;(uInfo); // 冗余 // C++14下的辅助类:既想使用有作用限制的枚举，又不想过于啰嗦 template \u0026lt;typename E\u0026gt; constexpr auto toUType(E enumerator) noexcept { return static_cast\u0026lt;std::underlying_type_t\u0026lt;E\u0026gt;\u0026gt;(enumerator); } auto email = std::get\u0026lt;toUType(UserInfoFields::uiEmail)\u0026gt;(uInfo); 有作用域限制的枚举（scoped enums，C++11） 减少名称污染 1 2 3 4 5 enum unscopedColor{black, white}; auto black = false; // 无作用域限制的枚举，因此枚举类型暴露在{}之外 enum class scopedColor {red, blue}; auto red = false; // 有作用域限制的枚举，枚举类型限制在{}之内，因此减少名称污染 有强类型 1 2 3 4 5 enum unscopedColor{black, white}; double d1 = black; // 无作用域限制的枚举，可以发生隐式类型转换 enum class scopedColor {red, blue}; double d2 = static_cast\u0026lt;double\u0026gt;(scopedColor::red); // 有作用域限制的枚举，不会发生隐式类型转换，类型转换需要显式说明 可以前向声明：只有在指定底层类型后，才能进行前向声明 1 2 enum unscopedColor: std::uint8_t; // 没有提供默认底层类型 enum class; //默认底层类型为int 参考 https://blog.csdn.net/Dong_HFUT/article/details/122914289 11：优先选用删除函数，而非private未定义函数 背景：编译期会自动生成某些函数，但是有时不需要这些函数； C++98的做法：声明为private的，且只声明不定义（effective C++中item6） 在private中声明但是不定义，使之在链接阶段因为没有定义而报错 在基类中声明为private的，会因为无法拷贝控制派生类中的基类部分，将报错从链接期提前到编译期 C++11的做法：在声明中标记为=delete 将删除的函数声明为public的，原因是编译器先检查访问权限，再检查delete状态。如果将删除的函数声明为private的，调用删除的函数时，可能报错原因提示是private的；但是更期望的更明确的含义是这些函数是删除的 =delete可以在任意函数中进行标记，不仅仅局限于成员函数 应用： 比如可以阻止某些形参的隐式类型转换 1 2 void func(int a); void func(double) =delete; // 因此禁止double和float两种参数的调用（C++总是倾向于将 float 转换为 double） 阻止某些模板类型的实例化 1 2 3 4 5 6 7 template \u0026lt;typename T\u0026gt; void func(T* ptr); template \u0026lt;\u0026gt; void func\u0026lt;void\u0026gt;(void* ptr) =delete; struct Widget{ template\u0026lt;typename T\u0026gt; void g(T* ptr); }; template\u0026lt;\u0026gt; void Widget::g\u0026lt;void\u0026gt;(void* ptr) = delete; // 成员模板函数在类外阻止某些类型的实例化 参考 https://blog.csdn.net/Dong_HFUT/article/details/123005509 12：给意在改写的函数添加override声明 重写override需要满足的条件 基类的重写函数必须是虚函数 基类和派生类的重写函数 函数名（析构函数除外）、形参类型、函数常量性完全相同 函数引用限定符完全相同（C++11，函数引用限定符：该成员函数可以被左值对象还是右值对象调用） 返回值类型、异常规格说明兼容 将重写的函数标记为override，如果不满足重写条件则报错 参考 https://blog.csdn.net/Dong_HFUT/article/details/123008755 13：优先选用const_iterator，而非iterator C++98在容器的成员函数中对const_iterator支持有限 C++11在容器的成员函数中支持const_iterator，但是只提供了非成员的begin和end 1 2 3 4 template \u0026lt;typename Container\u0026gt; // C++11实现cbegin的方法 auto cbegin(const Container\u0026amp; container) -\u0026gt; decltype(std::begin(container)){ // auto=const Container::iterator\u0026amp; return std::begin(container); } C++14提供了非成员的cbegin和cend 尽量使用非成员的cbegin和cend，因为某些数据结构（比如数组）没有成员函数cbegin和cend，非成员的cbegin和cend更加通用 1 2 3 4 5 6 7 template\u0026lt;typename C, typename V\u0026gt; void findAndInsert(C\u0026amp; container, const V\u0026amp; targetVal, const V\u0026amp; insertVal) { using std::cbegin; using std::cend; auto it = std::find(cbegin(container), cend(container), targetVal); container.insert(it, insertVal); } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123030976 14：只要函数不会抛出异常，就为其加上noexcept声明 noexcept 是函数接口的一部分，并且调用者可能会依赖这个接口。 相较于 non-noexcept 函数，noexcept 函数有被更好优化的机会。 noexcept 对于 move 操作、swap、内存释放函数和析构函数是非常有价值的。 大部分函数是异常中立的而不是 noexcept。 背景： C++98中异常规范的局限性：接口的实现一旦被修改，其异常规范可能也变化 因此C++11只需要指明接口是否可能抛出异常 优点：一个noexcept函数有更多编译优化的机会 不需要保持运行栈为解开的状态 不需要保证对象以构造顺序的逆序完成析构 应用：如果知道一个函数不会抛出异常，一定要加上noexcept noexcept属性对于移动操作、swap、内存释放函数和析构函数最有价值。C++11 STL 中的大部分函数遵循 “能移动则移动，必须复制才复制” 策略 默认noexcept函数：C++11内存释放函数和所有的析构函数都默认隐式地具备noexcept属性 析构函数未隐式地具备noexcept属性的唯一情况，就是所有类中有数据成员（包含递归的成员）的类型显式地将其析构函数声明为noexcept(false) 如果标准库使用了某个对象，其析构函数抛出了异常，则该行为是未定义的。 条件noexcept：一个函数是否为noexcept，取决于noexcept中的表达式是否为noexcept 只有被调用的低层次的函数是noexcept，高层次的调用方才是noexcept的 1 2 3 4 template \u0026lt;typename T1, typename T2\u0026gt; struct myPair{ void swap(myPair\u0026amp; p) noexcept( noexcept(swap(first, p.first)) \u0026amp;\u0026amp; noexcept(swap(second, p.second)) ); } 异常中立函数：本身不抛出异常，但是调用的函数可能抛出异常，因此不适合标记为noexcept 但是允许noexcept函数中调用没有noexcept保证的函数 通常只为宽松规约提供noexcept声明 宽松规约（wide contract，宽接口）：不带前提条件，被调用时不需要关注程序的状态，传入的参数方面没有限制，宽接口的函数永远不会出现未定义的行为 狭隘规约（narrow contract，窄接口）：带前提条件，如果违反前提条件，则结果是未定义的 调用者来保证调用时满足前提条件 如果调用时违反前提条件，则抛出异常；如果定义为noexcept的，违反前提条件结果是未定义的；相较而言，找出抛出异常的原因相对简单一些 参考 https://blog.csdn.net/Dong_HFUT/article/details/123163671 15：只要有可能使用constexpr，就使用它 constexpr对象：具备const属性，并且在编译期（和链接期）可以确定其值 const对象不能保证在编译期确定其值 constexpr函数 含义： 如果所有传入 constexpr 函数的参数都能在编译时知道，则结果将在编译时计算出来。 如果传入 constexpr 函数的参数有任何一个不能在编译期知道，则结果在运行时计算出来 使用 C++11中，constexpr函数有且只能有一条return语句；C++14无此限制 constexpr 函数被限制只能接受和返回 literal 类型（字面量，非指针和引用，自定义类型也可能是字面量类型的） C++11中，如果成员函数修改了操作的对象，或者成员函数的返回值是void的，则该成员函数无法成为constexpr的；C++14无此限制 1 2 3 4 5 6 7 8 9 10 11 class Point{ public: constexpr Point(double xVal=0, double yVal=0) noexcept: x(xVal), y(yVal) {} constexpr double getX() const noexcept {return x;} constexpr double getY() const noexcept {return y;} constexpr void setX(double newX) noexcept { x = newX;} // C++14中，移除了两条限制，因此可以设置为constexpr的 constexpr void setY(double newY) noexcept { y = newY;} private: double x, y; }; constexprt Point p1(1.0, 2.0); 参考 https://blog.csdn.net/Dong_HFUT/article/details/123172189 16：保证const成员函数的线程安全性 const成员的好处：不会修改成员变量，而且可以区分重载（const对象和非const对象调用） 保证const成员函数的线程安全性 使用std::mutex，进入临界区锁对象获取互斥量，出临界区析构锁（释放互斥量） 使用std::atomic，但是只能同步单一变量或者内存单元 std::mutex和std::atomic都是move-only的 参考 https://blog.csdn.net/Dong_HFUT/article/details/123316263 17：理解特殊成员函数的生成机制 特殊成员函数（special member function）： 一般是public、inline和novirtual的 例外：如果基类中的析构函数是virtual的，派生类中的析构函数也是virtual的 拷贝构造和拷贝赋值是两个独立的操作 移动构造和移动赋值不是独立的操作，如果声明了其中一个，编译器会阻止生成另外一个 如果显式申明一个拷贝操作，则两个移动操作不会自动生成 三法则（The Rule of Three）：如果声明了{拷贝构造函数、拷贝赋值操作、析构函数}中任意一个，则应该声明所有这三个函数，因为往往意味着类要管理某些资源 因此，如果只声明了一个析构函数，编译器应该不会自动生成拷贝操作 但实际上编译器还是可能自动生成拷贝操作（历史遗留原因，以及C++11为了兼容历史代码） 因此，只有当类中没有声明析构函数、拷贝操作、移动操作，而且需要时，编译器才会生成移动操作 如果想让编译器自动生成相关函数（即使违背了这些限制），添加=default进行标记 C++11中对特殊成员函数的生成规则： 默认构造函数：同C++98 析构函数：本质同C++98，只是默认声明为noexcept 拷贝构造函数：运行期行为同C++98（memberwise 拷贝构造 non-static 成员变量） 如果类中声明了一个移动操作，则拷贝构造函数和拷贝赋值运算符被标记为=delete的 如果类中自定义拷贝赋值运算符或析构函数，可以生成拷贝构造函数，但是已经成为被废弃的方法 拷贝赋值运算符：规则同拷贝构造函数 移动构造函数和移动赋值运算符：仅当类中不包含用户声明的拷贝操作、移动操作和析构函数时才生成 特殊情况：成员模板函数不会抑制特殊成员函数的自动生成 1 2 3 4 5 class Widget{ public: template \u0026lt;typename T\u0026gt; Widget(const T \u0026amp;rhs); template \u0026lt;typename T\u0026gt; Widget\u0026amp; operator=(const T\u0026amp; rhs); }; // 编译器仍然会生成copy和move操作，即使可以实例化得到 参考 https://blog.csdn.net/Dong_HFUT/article/details/123433559 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch03-%E8%BD%AC%E5%90%91%E7%8E%B0%E4%BB%A3c++/","summary":"07：在创建对象时注意区分()和{} 初始化方式 1 2 3 4 int x1(1); int x2 = 2; int x3{3}; // 统一初始化（列表初始化） int x4 = {4}; // 和第三种方式相同 ()和=初始化的限","title":"[Effective Modern Cpp Notes] Ch03 转向现代C++"},{"content":"05：优先选用auto，而非显式类型推断 优点一：避免变量未初始化 使用auto声明的变量未初始化，直接导致编译报错 优点二：简化变量声明（避免写一长串类型名） 优点三：声明闭包类型（lambda表达式） C++11中lambda式返回值可以使用auto，C++14中lambda式形参也可以使用auto std::function通常比起auto更大更慢，还可能导致内存消耗异常，因此实际使用时更推荐auto。 使用auto声明的、存储着一个闭包的变量和该闭包是同一类型，从而它要求的内存量也和该闭包相同 使用std::function声明的、存储着一个闭包的变量是std::function的一个实例，不管给定的签名如何，它都占有固定大小的内存，而这个大小对于其存储的闭包而言并不一定够用，如果是这样，那么std::function的构造函数就会分配堆上的内存来存储该闭包。 优点四：避免类型截断 优点五：避免类型不匹配 1 2 3 4 5 std::unordered_map\u0026lt;std::string, int\u0026gt; mp; for(auto\u0026amp; item: mp) { // auto=std::pair\u0026lt;const std::string,int\u0026gt; // 但是如果显式定义类型，很容易定义为std::pair\u0026lt;std::string, int\u0026gt;\u0026amp; } 06：当auto推导的类型不符合要求时，使用带显式类型的初始化习惯用法 隐式的代理类型可能导致auto类型推导结果不符合预期，因此应该显式声明类型 代理类：模拟和拓展某些其他类型的行为，比如智能指针，比如std::vector\u0026lt;bool\u0026gt;::reference std::vector\u0026lt;bool\u0026gt;进行了特化，与一般std::vector不同： 一般对于vector\u0026lt;T\u0026gt;的operator []操作，返回类型为T\u0026amp;；但是对于vector\u0026lt;bool\u0026gt;的operator []操作，返回类型为vector\u0026lt;bool\u0026gt;::reference（因此可能发生到bool的隐式类型转换），这是因为标准库无法返回对bit的引用 vector\u0026lt;bool\u0026gt;::reference的实现中，可能有一个指向word的指针和一个对应的offset，很可能出现难以预料的错误 1 2 3 vector\u0026lt;bool\u0026gt; func(); auto flg = func()[0]; // func()返回一个临时的右值对象，flg是vector\u0026lt;bool\u0026gt;::reference类型，然后临时的右值对象被析构 // 因为vector\u0026lt;bool\u0026gt;::reference类型中可能有一个指针，再使用flg可能出现未定义的行为 表达式模板中，计算结果可能被解析为一棵语法解析树，而非直接返回计算结果，因此实际得到的结果类型（语法解析树）可能并非期望的类型 # C++元编程之表达式模板优化数组计算 总之，对(隐形)代理类的auto类型推导往往得到的不是预期的类型，因此要么显式声明类型，要么使用static_cast强转然后进行auto类型推导 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch02-auto/","summary":"05：优先选用auto，而非显式类型推断 优点一：避免变量未初始化 使用auto声明的变量未初始化，直接导致编译报错 优点二：简化变量声明（避免写","title":"[Effective Modern Cpp Notes] Ch02 Auto"},{"content":"01：理解模板类型推导 在模板类型推导中，引用类型参数将被视为非引用类型处理，也就是说其引用性被忽略。 - 在万能引用参数类型推导时，左值参数被特殊处理。 - 值传递形参的类型推导时，其 const 和 volatile 被忽略。 - 在模板类型推导时，数组或者函数类型被转换为指针类型，除非它们用来初始化引用。 背景：有时模板类型推导无法一下看出来T是什么类型 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(ParamType param); f(expr); // 比如实参可能是int, const int, const int\u0026amp; 类型T的推导不仅取决于expr的类型，也取决于ParamType的形式 情况一：ParamType是指针或引用，但不是万能引用 1 2 3 template \u0026lt;typename T\u0026gt; void f(T\u0026amp; param); template \u0026lt;typename T\u0026gt; void f(const T\u0026amp; param); template \u0026lt;typename T\u0026gt; void f(T* param); 情况二：ParamType是万能引用，因此可能发生引用折叠 1 template \u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp; param); 情况三：ParamType不是指针，也不是引用，因此视为值传递（实参的const/volatile性质被忽略，因为值进行了复制，形参副本不影响原来的实参） 1 template \u0026lt;typename T\u0026gt; void f(T param); 特殊情况一：传入的实参为数组类型 如果模板是情况一：推导出T为数组类型（包含类型和元素数量） 1 2 3 template \u0026lt;typename T\u0026gt; void f(T\u0026amp; param); const char name[] = \u0026#34;zhang\u0026#34;; f(name); // 推导出T=const char[6], f(const char(\u0026amp;param)[6]) 应用：比如可以在编译阶段计算数组元素个数： 1 2 template \u0026lt;typename T, std::size_t N\u0026gt; constexpr std::size_t arraySize(T (\u0026amp;)[N]) noexcept {return N;} 如果模板是情况三：将数组名视为指针，因此T是指针类型 特殊情况二：传入的实参为函数类型 如果模板是情况一：推导出T为函数引用类型 如果模板是情况三：推导出T为函数指针类型 参考： https://blog.csdn.net/Dong_HFUT/article/details/122727237 02：理解auto类型推导 一般情况下，auto类型推导和模板类型推导完全相同；但是auto类型推导会假定使用{}的列表初始化表达式是一个std::initializer_list，但是模板类型推导不会 在函数返回值或lambda式形参中使用auto，意思是使用模板类型推导而非使用auto类型推导 背景：将一个变量赋值给auto类型变量，auto是什么类型 同[[ch01-类型推导#01：理解模板类型推导|01：理解模板类型推导]]中的总体原则：将实参赋值给形参 除了一个例外：使用{}进行列表初始化 auto类型推导： 1 2 auto x = {1, 2, 3}; // auto=std::initializer_list\u0026lt;int\u0026gt;,首先推导为std::initializer_list\u0026lt;T\u0026gt;，然后再推断类型T=int auto y{2}; // auto=int 模板类型推导：不能直接将{}的列表初始化表达式推导为T=std::initializer_list\u0026lt;type\u0026gt;， 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(T param); f({1, 2, 3}); // 报错：直接传入{}列表初始化的实参，模板类型推导失败 template \u0026lt;typename T\u0026gt; void g(std::initializer_list\u0026lt;T\u0026gt; initList); g({1, 2, 3}); // T=int 为什么两种行为不同的一个可能解释 1 2 3 template \u0026lt;typename T\u0026gt; void func(T\u0026amp; a, T\u0026amp; b); func(vector\u0026lt;int\u0026gt;{1,2,3}, {1,2,3}); // 左边推导出T=vector\u0026lt;int\u0026gt;, 右边如果推导出T=initializer_list\u0026lt;int\u0026gt;,则左右冲突 auto可以作为函数返回值类型、lambda式形参类型（C++14） 但是原理是模板类型推导，而非auto类型推导 参考 https://blog.csdn.net/Dong_HFUT/article/details/122740091 03：理解decltype 绝大多数情况下，decltype会得到变量或表达式的类型，而不进行修改 对于类型为T的左值表达式，除非该表达式只有一个名字，否则decltype总是返回T\u0026amp; C++14支持decltype(auto)：auto 表示类型需要推导，decltype 表示使用decltype规则进行推导 背景：给定一个名字或表达式，decltype返回其类型：原来是值/左值/右值，返回值/左值/右值 体会auto类型推导和decltype类型推导的区别 auto类型推导：将变量rhs赋值给lhs，推导出lhs的类型 decltype类型推导：返回变量rhs的类型 使用场景： 声明一个函数模板，其返回值类型取决于参数类型 1 2 template \u0026lt;typename Container, typename Index\u0026gt; auto getItem(Container\u0026amp; c, Index i) -\u0026gt; decltpye(c[i]) { return c[i]; } // 返回类型是引用T\u0026amp; 如果返回值为auto，使用auto类型推导，返回类型将不是引用 1 2 template \u0026lt;typename Container, typename Index\u0026gt; auto getItem(Container\u0026amp; c, Index i) { return c[i]; } // 返回类型是T 可以同时使用auto和deltype：auto 表示类型需要推导，decltype 表示使用decltype规则进行推导 1 2 template \u0026lt;typename Container, typename Index\u0026gt; decltype(auto) getItem(Container\u0026amp; c, Index i) { return c[i]; } // 返回类型是引用T\u0026amp; 优化与完善：为了传入右值的Container，使用万能引用，同时使用完美转发 1 2 template \u0026lt;typename Container, typename Index\u0026gt; decltype(auto) getItem(Container\u0026amp;\u0026amp; c, Index i) { return std::forward\u0026lt;Container\u0026gt;(c)[i]; } // C++14，或者C++11使用尾置返回类型 一般而言decltype返回的类型都比较直观，除了一种情况： 1 2 3 int x = 0; // decltype(x)=int // decltype((x))=int\u0026amp; 参考 https://blog.csdn.net/Dong_HFUT/article/details/122745518 https://zyfforlinux.blog.csdn.net/article/details/52658452 04：掌握查看类型推导结果的方法 在代码编辑阶段查看类型推导结果：IDE 在代码编译阶段查看类型推导结果：查看编译报错 在代码运行阶段查看类型推导结果： typeid：不同编译期实现不同，无法保证完全可靠，而且类型的引用、const、volatile等性质被忽略 Boost库的模板函数boost::typeindex::type_id_with_cvr 如果类型不包含引用、const、volatile等性质，则type_id_with_cvr与typeid返回相同 1 2 3 4 5 6 7 8 #include \u0026lt;boost/type_index.hpp\u0026gt; template \u0026lt;typename T\u0026gt; void f(const T\u0026amp; param){ using std::cout; using boost::typeindex::type_id_with_cvr; // c:const, v:volatile, r:reference cout\u0026lt;\u0026lt;type_id_with_cvr\u0026lt;T\u0026gt;().pretty_name()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; cout\u0026lt;\u0026lt;type_id_with_cvr\u0026lt;decltype(param)\u0026gt;().pretty_name()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch01-%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/","summary":"01：理解模板类型推导 在模板类型推导中，引用类型参数将被视为非引用类型处理，也就是说其引用性被忽略。 - 在万能引用参数类型推导时，左值参数被特","title":"[Effective Modern Cpp Notes] Ch01 类型推导"},{"content":"49：了解new-handler的行为 new申请内存失败会抛出bad alloc的异常，此前会调用一个错误处理函数，此函数由std::set_new_handler()指定 set::set_new_handler() 接受一个错误处理函数，返回旧的错误处理函数 throw表示可能抛出的异常类型，参数为空表示不抛出任何异常 1 2 typedef void (*new_handler)(); // 无形参，返回值为void的函数指针 new_handler set_new_handler(new_handler f) throw(); 当new申请不到足够的内存时，会不断调用错误处理函数f，因此错误处理函数应该进行下面的处理之一： 提供更多可用的内存 向set_new_handler中传入一个新的错误处理函数 set_new_handler函数中传入一个空指针，因此内存分配失败时不进行处理，直接抛出异常 抛出bad_alloc的异常 不返回：调用std::abort或std::exit abort会设置程序非正常退出 exit会设置程序正常退出，当存在未处理异常时，会调用terminate，内部回调set::set_terminate设置的回调函数，默认会调用abort 类型相关错误处理 为不同的类分配对象时，使用不同的错误处理函数 重载set_new_handler和operator new，重载为static成员 可以写成模板 此处的模板参数T并没有真正被当成类型使用，而仅仅是用来区分不同的派生类，使得模板机制为每个派生类具现化出一份对应的currentHandler 这个做法用到了所谓的 CRTP（curious recurring template pattern，奇异递归模板模式），也常被用于静态多态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 template \u0026lt;typename T\u0026gt; class NewHandlerSupport { public: static std::new_handler set_new_handler(std::new_handler p) noexcept; static void* operator new(std::size_t size); ~NewHandlerSupport() {std::set_new_handler(currentHandler);} private: NewHandlerSupport(const NewHandlerSupport\u0026amp;); // 阻止拷贝构造 NewHandlerSupport\u0026amp; operator=(const NewHandlerSupport\u0026amp;); // 阻止拷贝复制 static std::new_handler currentHandler; }; template \u0026lt;typename T\u0026gt; std::new_handler NewHandlerSupport\u0026lt;T\u0026gt;::currentHandler = nullptr; template \u0026lt;typename T\u0026gt; std::new_handler NewHandlerSupport\u0026lt;T\u0026gt;::set_new_handler(std::new_handler p) noexcept { std::new_handler oldHandler = currentHandler; currentHandler = p; return oldHandler; } template \u0026lt;typename T\u0026gt; void* NewHandlerSupport\u0026lt;T\u0026gt;::operator new(std::size_t size) { NewHandlerSupport h(std::set_new_handler(currentHandler)); // 返回的函数指针初始化了一个对象h，在退出函数时，执行h的析构过程，即将原来的handle恢复 return ::operator new(size); } // 使用 class Widget: public NewHandlerSupport\u0026lt;Widget\u0026gt;{ ... }; new分配失败后，可能不会抛出异常，而是返回null，这种称为nothrow new 例子：new (std::nothrow) int[10]; nothrow new只能保证内存分配错误时不抛出异常，无法保证对象的构造函数不抛出异常 50： 了解new和delete的合理替换时机 为什么需要自定义operator new 检测使用错误：检测多次delete，检测越界 提高效率：手动维护更适合应用场景的存储策略 比如针对特定类型，增加分配和归还的速度 比如将相关对象集成到簇中（即尽量分配到一个内存页上） 收集使用的统计信息 其他原因：比如安全性（将申请到的内存初始化为0），字节对齐等 51： 编写new和delete时需固守常规 operator new需要无限循环地获取资源，如果没能获取则调用\u0026quot;new handler\u0026quot;，不存在\u0026quot;new handler\u0026quot;时应该抛出异常；\noperator new应该处理size == 0的情况；\noperator delete应该兼容空指针；\noperator new/delete作为成员函数应该处理size \u0026gt; sizeof(Base)的情况（因为继承的存在）。\n外部（非成员函数的）operator new：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void* operator new(std::size_t size) throw(std::bad_alloc){ if(size == 0) size = 1; // size=0时，返回合法的指针就说明成功分配了内存 while(true){ void *p = malloc(size); if(p) return p; // 申请失败，获得new handler，多线程需要加锁 new_handler h = set_new_handler(0); set_new_handler(h); // auto h = get_new_handler(); // C++11方式 if(h) (*h)(); // new-handler应该实现item49中描述的五种行为之一，否则，此处陷入死循环 else throw bad_alloc(); } } 成员operator new\n如果operator new是针对基类的，也就是说operator new是针对大小为sizeof(Base)的内存进行优化的 一般来说派生类不应该使用基类的operator new，因为派生类对象大小与基类对象大小一般不同 1 2 3 4 5 6 7 8 9 10 11 12 class Base{ public: static void* operator new(std::size_t size); }; void* Base::operator new(std::size_t size) { if(size != sizeof(Base)) // sizeof(Base)永远不会为0（至少为1），因为空对象至少会插入一个char return ::operator new(size); // 使用全局的operator new ... } class Derived: public Base { ... }; operator new[]与operator new有相同的参数和返回值，只需要分配一块原始内存 delete\ndelete 惯例：delete一个空指针是安全的 外部operator delete\n1 2 3 4 void operator delete(void* rawMemory) noexcept { if (rawMemory == 0) return; // 释放 rawMemory 所指的内存 } 成员operator delete 如果基类的析构函数不是虚函数，则size大小为静态类型的大小； 比如Base* p = new Derived; delete p;中，很可能派生类大小大于基类大小，因此存在内存泄露 否则size为动态类型的大小 1 2 3 4 5 6 7 8 void Base::operator delete(void* rawMemory, std::size_t size) noexcept { if (rawMemory == 0) return; if (size != sizeof(Base)) { ::operator delete(rawMemory); // 转交给标准的 operator delete 进行处理 return; } // 释放 rawMemory 所指的内存 } 52： 写了placement new也要写`palcement delete placement new：广义上指拥有额外参数的operator new 背景： 在使用new创建对象时，往往进行了两个函数的调用：一个是operator new，进行内存分配；一个是对象的构造函数 如果构造失败，此时对象没有被创建，对象无法被析构，且此时还没有拿到分配内存的地址 因此需要运行时系统进行delete，运行时系统需要知道使用的是哪一种operator new，因此调用对应的operator delete 如果没有对应的operator delete函数，则运行时系统什么都不做，导致内存泄露 当定义了placement new时，同时也要定义对应的placement delete 用户直接调用delete时，运行时系统不会将其解释为placement delete，因此还需要定义一个正常的delete 1 2 3 4 5 6 class Widget{ public: static void* operator new(std::size_t size, std::ostream\u0026amp; log) throw(std::bad_alloc); static void operator delete(void *mem, std::ostream\u0026amp; log); static void operator delete(void *mem) throw(); }; 名称隐藏：类中的名称会隐藏类外的名称，子类的名称会隐藏父类的名称 三种全局new 1 2 3 void* operator(std::size_t) throw(std::bad_alloc); // normal new void* operator(std::size_t, void*) noexcept; // placement new void* operator(std::size_t, const std::nothrow_t\u0026amp;) noexcept; // nothrow new 最佳实践： 将全局版本new在一个基类中进行重载，内部调用全局new进行实现 然后在自定义类Widget中，public继承，并使用using声明使得三种new和三种delete对Widget可见，因此同时Widget可以定义自己版本的placement new 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class StandardNewDeleteForms { public: // normal new/delete static void* operator new(std::size_t size) throw(std::bad_alloc) { return ::operator new(size); } static void operator delete(void *pMemory) throw() { ::operator delete(pMemory); } // placement new/delete static void* operator new(std::size_t size, void *ptr) throw() { return ::operator new(size, ptr); } static void operator delete(void *pMemory, void *ptr) throw() { return ::operator delete(pMemory, ptr); } // nothrow new/delete static void* operator new(std::size_t size, const std::nothrow_t\u0026amp; nt) throw() { return ::operator new(size, nt); } static void operator delete(void *pMemory, const std::nothrow_t\u0026amp;) throw() { ::operator delete(pMemory); } }; class Widget: public StandardNewDeleteForms { public: using StandardNewDeleteForms::operator new; using StandardNewDeleteForms::operator delete; static void* operator new(std::size_t size, std::ostream\u0026amp; log) throw(std::bad_alloc); // 自定义 placement new static void operator delete(void *pMemory, std::ostream\u0026amp; logStream) throw(); // 对应的 placement delete }; ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch08-%E5%AE%9A%E5%88%B6new%E5%92%8Cdelete/","summary":"49：了解new-handler的行为 new申请内存失败会抛出bad alloc的异常，此前会调用一个错误处理函数，此函数由std::set_","title":"[Effective Cpp Notes] Ch08 定制new和delete"},{"content":"41： 了解隐式接口与编译期多态 面向对象中的类设计时需要考虑显式接口和运行时多态，而模板编程中需要考虑隐式接口和编译器多态\n如果函数的形参是普通类： 普通类的显式接口由函数签名（函数名、形参类型、返回值类型）表征，运行时多态由虚函数实现 在函数进行编译时，就可以知道该普通类有哪些接口 如果函数的形参是模板类型： 模板类型的隐式接口由表达式的合法性表征（即该模板类型应该支持函数中形参调用的方法），编译器多态由模板初始化和重载函数的解析实现 在函数进行编译时，无法知道模板类型有哪些接口，因此视为鸭子类型（即传入对象支持函数中调用的方法即可） 在编译函数时当然无法确定模板类型，但是当传入实参后，内部如果调用了实参未定义的函数，同样会在编译期报错而非运行期 参考： https://www.zhihu.com/question/423699453 42： 了解typename的双重意义 在模板声明中，使用class与typename完全相同 在模板内部，typename还可以用来显式指明【嵌套从属类型名称】 背景：比如编译器无法在模板内部判断T::mem是一个static成员（默认），还是一个类型 嵌套从属类型名称：T::mem是一个依赖于模板参数T的类型 例子：模板内部typename T::age myAge = 25; typename还可以用来显式指明【嵌套从属类型名称】，可以出现在模板内部、函数形参列表，但是不可以出现在【类派生列表】和【构造函数中成员初始化列表】中 当类型名称过于复杂时，可以使用类型别名 参考 https://harttle.land/2015/09/09/effective-cpp-42.html 43： 使用模板化基类中的成员函数 背景：如果基类是一个模板类，派生类进行继承 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Buff {}; class RedBuff: public Buff {}; class BlueBuff: public Buff {}; template \u0026lt;typename T\u0026gt; // 基类 class Container { /* 假设有成员函数func() */}; //template \u0026lt;\u0026gt; // 全特化基类 //class Container\u0026lt;Buff*\u0026gt; { /* 假设没有成员函数func() */ }; // template \u0026lt;typename T=Buff*\u0026gt; // 使用默认模板实参，同全特化基类 // class Container\u0026lt;T\u0026gt; { /* 假设没有成员函数func() */ } template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { func(); } // 这里编译报错 }; 对于模板化基类，可能有特化版本，且其中可能有不同的接口 对于派生类而言，也无法确定类型T，因此C++规定派生类不在模板化基类中查找继承而来的接口 解决方法：向编译器承诺所有的特化版本都遵循模板化基类的接口（或者说使用非特化版本的模板化基类中的接口） 使用this显式指出访问基类的成员函数 1 2 3 4 5 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { this-\u0026gt;func(); } // this指针可以访问所有成员函数 }; 使用using声明 1 2 3 4 5 6 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: using Container\u0026lt;T\u0026gt;::func; // 告诉编译器，func在模板化基类中 void test() { func(); } }; 使用作用域运算符::明确指出，不推荐使用，因为如果func是虚函数，使用这种方法不会产生多态 1 2 3 4 5 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { Container\u0026lt;T\u0026gt;::func(); } // 明确指出 }; 44： 将与参数无关的代码抽离模板 背景：代码膨胀 模板提供的是编译期多态，不同的类型参数会生成不同的模板 比如一个模板类接受一个类型参数T与一个非类型参数N，大部分成员都使用类型参数T，只有极少部分成员使用非类型参数N 如果使用相同的类型type、但是不同的非类型参数n进行实例化，生成的代码中大部分都相同，只有极少部分不同 抽取公共代码： 模板中生成的冗余代码是隐式的，因为模板只有一份，生成不同实例后才可能产生冗余 比如可以将与参数无关的代码（成员函数，数据成员）放入基类中，然后private继承 参考 https://harttle.land/2015/09/12/effective-cpp-44.html 45： 运用成员函数模板接受所有兼容类型 背景：假如类型参数T存在继承关系，但是模板实例化后是完全不同的两个类 比如有一个继承体系，基类Base，派生类Derived 指向派生类的指针可以转换为指向基类的指针：Base* p = new Derived(); 但是指向派生类的智能指针无法转换为指向基类的智能指针： shared_ptr\u0026lt;Base*\u0026gt; sp = make_shared\u0026lt;Derived*\u0026gt;(new Derived()); 重载构造函数 接受同一模板的其他实例的构造函数称为通用构造函数 兼容类型检查：将MySmartPtr\u0026lt;U\u0026gt;转换为MySmartPtr\u0026lt;T\u0026gt;，前提是类型U可以转换为类型T 如果没有声明拷贝构造函数，编译器会自己生成一个，而非使用通用构造函数去进行成员模板实例化 1 2 3 4 5 6 7 8 9 10 11 12 13 template \u0026lt;typename T\u0026gt; class MySmartPtr{ public: MyShartPtr(T* p): ptr(p) {} template \u0026lt;typename U\u0026gt; MySmartPtr(const MySmartPtr\u0026lt;U\u0026gt;\u0026amp; other): ptr(other.get()) {}; // 带类型兼容检查的通用构造函数，可以实现隐式类型转换（因为不带explicit） T* get() const {return ptr;} private: T *ptr; }; MySmartPtr\u0026lt;Derived*\u0026gt; dp(new Derived()); // 隐式类型转换 MySmartPtr\u0026lt;Base*\u0026gt; bp = MySmartPtr\u0026lt;Derived*\u0026gt;(new Derived()); // T=Base*, U=Derived* 参考 https://harttle.land/2015/09/13/effective-cpp-45.html 46：需要类型转换时请将模板定义为非成员函数 背景： 1 2 3 4 5 6 7 8 template \u0026lt;typename T\u0026gt; class Rational {}; template \u0026lt;typename T\u0026gt; const Rational\u0026lt;T\u0026gt; operator*(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs) {} Rational\u0026lt;int\u0026gt; oneHalf(1,2); Rational\u0026lt;int\u0026gt; result = oneHalf * 2; // Error 模板函数的调用过程： 首先推导出类型T，将函数进行实例化：此时无法从2推导得出类型T 在调用时，有的参数可能需要隐式类型转换 解决方法：将模板函数定义为类的友元，因此类模板实例化后类型T已知 如果仅仅是声明，编译器不会对友元函数进行实例化，因此需要进行定义 定义在类内部的函数是inline的，可以在类外部定义一个辅助函数（也是模板函数，但是不需要隐式类型转换） 1 2 3 4 5 6 7 8 9 10 template \u0026lt;typename T\u0026gt; class Rational; template \u0026lt;typename T\u0026gt; const Rational\u0026lt;T\u0026gt; func(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs) {} template \u0026lt;typename T\u0026gt; class Rational{ public: friend Rational\u0026lt;T\u0026gt; operator*(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs){ func(lhs, rhs); // 可以推导出类型T，而且不需要进行隐式类型转换 } } 47： 请使用traits classes表现类型信息 使用Traits的特点： 可以同时支持自定义类型和基础类型 在编译期就获取信息 C++中的Traits类可以在编译期提供类型信息，是通过Traits模板及其特化来实现的 C++标准库中提供了不同的Traits：iterator_traits,char_traits,numeric_limits等（以iterator_traits为例）\n背景：容器与算法通过迭代器联系在一起，算法中可能需要知道迭代器的类型、迭代器中元素的类型，由此有不同的处理方法 比如算法advance可以让一个迭代器移动n步（负数则反向移动） 迭代器有五种：其中随机访问迭代器可以直接使用+=操作 C++提供了五个类标识迭代器类型：input_iterator_tag，output_iterator_tag，forward_iterator_tag，bidirectional_iterator_tag，random_access_iterator_tag 传入的参数也可能是基本类型的指针 1 2 3 4 5 6 7 8 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ // 判断迭代器类型 if(iter is random access iterator) iter += d; else ... // 判断迭代器中元素类型 if(iter.value_type is MyVector) cout\u0026lt;\u0026lt;\u0026#34;MyVector\u0026#34;\u0026lt;\u0026lt;endl; } 分析： 如果IterT是类类型，因此可以在类中携带数据成员，表示迭代器类型和元素类型 但是IterT也可能是基本类型的指针类型，无法在其中携带信息 Traits技法：使用Traits可以通过一个模板类间接获取IterT的相关信息 1 2 template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits; Traits是C++中一种编程惯例，允许在编译期得到类型的信息 traits是一个用来携带信息的很小的类，需要实现两个部分： traits中的类型可能是用户自定义的类型， 自定义类型中需要实现相应的迭代器，对具体的类型信息起一个通用的别名 traits中包装相应的信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 template \u0026lt;typename T\u0026gt; class MyVector{ // 自定义类 public: class iterator{ // 自定义类中的迭代器 public: using value_type = T; using iterator_category = my_random_access_iterator_tag; }; }; // iterator_traits可以获取迭代器（或指针类型）的元素类型和迭代器类型（指针类型视为随机访问迭代器） template \u0026lt;typename IterT\u0026gt; struct iterator_traits{ // IterT是类类型 using iterator_category = typename IterT::iterator_category; using value_type = typename IterT::value_type; }; traits中的类型可能是基本数据类型，遵循相同的名称，包装一下相应的信息 1 2 3 4 5 template \u0026lt;typename IterT\u0026gt; struct iterator_traits\u0026lt;IterT*\u0026gt;{ // 特化版本：IterT是基本类型，IterT是基本类型的指针 using iterator_category = my_random_access_iterator_tag; // 指针可以使用+=操作，因此视为随机访问迭代器 using value_type = IterT; }; 使用 不好的写法：使用typeid在运行时判断类型 但是IterT类型在编译期就可以确定，对象iter的类型需要在运行时确定 更严重的问题：静态类型检查（编译期必须确保所有源码都有效，即使是不会执行的源码） ^826df6 比如即使迭代器不是my_random_access_iterator_tag类型，编译期也会进入if语句测试该迭代器是否支持+=运算，不支持的话编译报错 1 2 3 4 5 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ if( typeid(typename std::iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(my_random_access_iterator_tag) ) iter += d; } 推荐实现方法：根据不同的类型创建不同的重载方法（worker），然后在一个master函数中调用，依据traits类型进行重载调用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ // 将IterT中迭代器类型和元素类型萃取出来 std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category).name()\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::value_type).name()\u0026lt;\u0026lt;std::endl; // 错误使用：如果iter是指针类型，则IterT为基本类型，无iterator_category属性 // std::cout\u0026lt;\u0026lt;typeid(IterT::iterator_category).name()\u0026lt;\u0026lt;std::endl; doAdvance(iter, d, typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category()); // 最后默认初始化一个iterator_category的对象，进行重载匹配，调用对应的函数 } // 随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_random_access_iterator_tag){ iter += d; } // 前向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_forward_iterator_tag){ assert(d \u0026gt;= 0 \u0026amp;\u0026amp; \u0026#34;d must be not less then 0\u0026#34;); while(d--) ++iter; } 测试代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;cassert\u0026gt; // using namespace std; struct my_random_access_iterator_tag { // my_random_access_iterator_tag() { std::cout\u0026lt;\u0026lt;\u0026#34;my_random_access_iterator_tag ctor\u0026#34;\u0026lt;\u0026lt;std::endl; } }; struct my_forward_iterator_tag{ // my_forward_iterator_tag() {std::cout\u0026lt;\u0026lt;\u0026#34;my_forward_iterator_tag\u0026#34;\u0026lt;\u0026lt;std::endl;} }; template \u0026lt;typename T\u0026gt; class MyVector{ // 自定义类 public: class iterator{ // 自定义类中的迭代器 public: using value_type = T; using iterator_category = my_random_access_iterator_tag; }; }; // iterator_traits可以获取迭代器（或指针类型）的元素类型和迭代器类型（指针类型视为随机访问迭代器） // 输入：使用类类型的迭代器或指针类型进行实例化 // 输出：萃取出元素类型和迭代器类型 template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits{ // IterT是类类型 using iterator_category = typename IterT::iterator_category; using value_type = typename IterT::value_type; }; template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits\u0026lt;IterT*\u0026gt;{ // 特化版本：IterT是基本类型，IterT是基本类型的指针 using iterator_category = my_random_access_iterator_tag; // 指针可以使用+=操作，因此视为随机访问迭代器 using value_type = IterT; }; // std双向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, std::bidirectional_iterator_tag){ if(d \u0026gt; 0) while(d--) ++iter; else while(++d) --iter; } // std随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, std::random_access_iterator_tag){ iter += d; } // 自定义随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_random_access_iterator_tag){ iter += d; } // 自定义前向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_forward_iterator_tag){ assert(d \u0026gt;= 0 \u0026amp;\u0026amp; \u0026#34;d must be not less then 0\u0026#34;); while(d--) ++iter; } template \u0026lt;typename IterT, typename DistT\u0026gt; void myAdvance(IterT\u0026amp; iter, DistT d){ // 将IterT中迭代器类型和元素类型萃取出来 std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category).name()\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::value_type).name()\u0026lt;\u0026lt;std::endl; // 错误使用：如果iter是指针类型，则IterT为基本类型，无iterator_category属性 // std::cout\u0026lt;\u0026lt;typeid(IterT::iterator_category).name()\u0026lt;\u0026lt;std::endl; // std::cout\u0026lt;\u0026lt; (typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(std::bidirectional_iterator_tag)) \u0026lt;\u0026lt;std::endl; // 不好的写法： // 静态类型检查，即使iter不是随机访问迭代器，也会进入if语句块内进行检查 // if( typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(std::random_access_iterator_tag) ) // iter += d; doAdvance(iter, d, typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category()); // 最后默认初始化一个iterator_category的对象，进行重载匹配，调用对应的函数 } int main(){ int a[10]; for(int i = 0; i \u0026lt; 10; ++i) a[i] = i+1; int* p = \u0026amp;a[0]; myAdvance(p, 2); std::cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;std::endl; std::list\u0026lt;int\u0026gt; lst{1,2,3,4,5,6,7,8,9,10}; std::list\u0026lt;int\u0026gt;::iterator it = lst.begin(); myAdvance(it, 2); std::cout\u0026lt;\u0026lt;*it\u0026lt;\u0026lt;std::endl; return 0; } 48： 认识模板元编程 模板元编程（template metaprogramming，TMP）：编写模板，执行于编译期，生成具象化的代码 优点：可以将很多工作从运行期转移到编译期 一些错误可以提前发现 运行时更高效：可执行文件体积小，运行期短，内存需求少 避免了[[ch07-模板与泛型编程#^826df6|静态类型检查]]的问题 缺点：编译时间变长 模板元编程 图灵完备 循环由递归实现 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch07-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/","summary":"41： 了解隐式接口与编译期多态 面向对象中的类设计时需要考虑显式接口和运行时多态，而模板编程中需要考虑隐式接口和编译器多态 如果函数的形参是普通","title":"[Effective Cpp Notes] Ch07 模板与泛型编程"},{"content":"32：确定你的public继承构造出is-a关系 public继承的意思是，子类是一种特殊的父类（is-a关系） 子类必须涵盖父类每一个特点，必须无条件继承父类所有特性和接口 否则没有is-a关系，不应该使用public继承 因为很多时候凭生活经验判断，可能会错误判断为具有is-a关系，但是子类可能没有父类的某个特性 程序设计没有银弹 33：避免覆盖继承而来的名称 背景：父类中有多个重载的虚函数（同名），子类只重写了其中一个，会导致子类中父类的其他重载函数不可见 根本原因：如果子类重写了父类的重载函数的一部分，在进行名字查找中，可以在相应的静态类型（子类）中查找到名字，但是类型无法匹配 避免方法： 对于父类的重载方法，子类要么全部重写，要么一个都不重写 使用using声明 使用转交函数（forwarding function）？ 34：区分接口继承与实现继承 public继承可以分为函数接口继承和函数实现继承 基类中声明纯虚函数，派生类只继承其接口，且派生类需要提供实现 从代码层面提醒派生类主动实现其接口，即使纯虚函数在基类中也可以有实现（派生类也需要显式指明需要使用基类中的实现） 基类中声明虚函数，派生类继承其接口和缺省实现 基类中声明普通函数，派生类继承其接口和实现（好的编程习惯是不对子类方法进行重写） 35：考虑virtual函数以外的其他选择 通常面向多态的做法： 将接口设置为virtual的 通过Non-Virtual Interface(NVI)来实现template method模式 将接口Func的真正实现函数onFunc设置为private virtual的 基类中的private virtual方法，通过public继承到派生类，派生类可以进行重写 将接口Func设置为public non-virtual的，在Func中调用onFunc non-virtual的接口Func就称为virtual onFunc的wrapper 优点：在接口Func中调用onFunc前后，可以前置和后置的工作 缺点：在某些场景的继承体系中，virtual函数必须调用基类的版本，因此virtual函数必须是protected甚至public的，此时无法使用NVI strategy模式 基于Function Pointers的strategy模式 直接在构造函数中传入一个函数指针，用于实现多态 进一步的，可以基于C++11的std::function来实现strategy模式，在构造函数中传入一个可调用对象 古典的strategy模式：将函数指针替换为类指针，使用该类中的成员函数 优点：同一种类型可以使用不同的方法进行计算，而且可以在运行期变更使用的函数 缺点：函数指针只能访问public成员，否则只能弱化封装性，将外部函数声明为友元 36：绝不重写继承而来的non-virtual函数 从语法上看 虚函数执行的是动态绑定，非虚函数执行的是静态绑定 如果有多态调用的需求，设置为虚函数 从设计上看 public继承意味着一种is-a关系，子类是一种特殊的父类，不变性（父类的共性）凌驾于特异性（子类的个性）之上 重写public继承而来的non-virtual表示子类修改了父类的特性，违背了is-a关系，造成了设计上的矛盾 37：绝不重写继承而来的(虚函数的)缺省参数值 虚函数执行的是动态绑定，但是缺省参数值是静态绑定 因此可能执行的是动态类型版本的虚函数，但是缺省参数值是静态类型版本虚函数的，没有使用动态类型版本的缺省参数值，极易引起误会 缺省参数值采用静态绑定是为了提高运行时效率，这样可以在编译期将参数确定，而非得到运行时 解决方法： 如果使用虚函数，则采用相同的缺省参数值 使用Non-Virtual Interface(NVI)代替虚函数 将接口Func设置为public non-virtual的（因此不期望被重写），并带有缺省参数，因此不管怎么继承，缺省参数值都是相同的 将接口Func的实现逻辑onFunc设置为private virtual的，Func中将缺省参数传递给onFunc，调用动态版本的虚函数 38：通过复合构造出has-a关系或“根据某物实现出” 复合：一个类作为另一个类的数据成员 当复合发生在应用域内的对象之间时，表现出has-a的关系 比如Person类中有一个Address类 当复合发生在实现域内的对象之间时，表现出“根据某物实现出”的关系 比如使用List类模拟实现出一个Set类 39： 明智而审慎地使用private继承 private继承的特点： 如果派生类private继承自基类，则从派生类无法转换到基类 但是如果派生类public继承自基类，则派生类可以slice（切掉）转换为基类 private继承的意义：“根据某物实现出” 仅仅是为了让派生类使用基类中的某些方法，派生类与基类没有直接意义上的联系 private继承的使用：当需要进行“根据某物实现出”的时候 能用复合，就不要用private：绝大多数private继承的场合都可以使用“public继承+复合”进行代替 使用private继承： 比如想在Widget的派生类中，不定义OnTick方法，即使使用private继承，在Widget的派生类中仍然可以重新定义OnTick方法（类似NVI中方法） 同时Widget编译时必须依赖Timer 1 2 3 4 5 6 7 8 9 10 // 使用private继承 class Timer{ public: virtual void OnTick() const; }; class Widget: private Timer{ private: virtual void OnTick() const; // override } // Widget的派生类中仍有OnTick方法 使用复合： 在Widget的派生类中，可以没有OnTick方法（同C++11对成员函数使用final） 可以将WidgetTimer定义移出Widget，从而Widget编译时不需要Timer 1 2 3 4 5 6 7 8 9 10 11 12 class Timer{ public: virtual void OnTick() const; }; class Widget{ private: class WidgetTimer: public Timer{ public: virtual void OnTick() const; }; WidgetTimer timer; }; 使用private继承的情况：空白基类最优化（Empty Base Optimization，EBO） 40： 明智而审慎地使用多重继承 多重继承中可能遇到歧义调用，需要指明调用哪个基类中的接口 即使同名接口一个在基类中是public的，一个是private的（不会被调用），也会发生歧义 因为C++首先会找到最佳匹配函数，之后才会验证其可用性，如果两个同名的函数匹配程度相同，则发生二义性 遇到菱形继承时，使用虚继承，且尽量少的在虚基类中携带数据 多重继承的使用场景：public继承自某个抽象基类，private继承自某个协助实现的基类 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch06-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/","summary":"32：确定你的public继承构造出is-a关系 public继承的意思是，子类是一种特殊的父类（is-a关系） 子类必须涵盖父类每一个特点，必","title":"[Effective Cpp Notes] Ch06 继承与面向对象设计"},{"content":"26：尽可能延后变量定义式的出现时间 原因一：程序前面部分可能有if判断、异常处理等，可能不会运行到后面部分 原因二：直接构造的效率高于默认构造+赋值 原因三：变量可能在循环中使用，变量定义在循环内部而非循环前面，可以避免将变量的作用域扩大；除非对循环部分的性能有要求。 27：尽量少做转型动作 三种风格的转型： C语言风格：(T)expression 函数风格：T(expression) C++风格： const_cast\u0026lt;T\u0026gt;(expression)：去除const属性 dynamic_cast\u0026lt;T\u0026gt;(exprssion)：将指向为基类的指针转型为指向派生类的指针，可能耗费重大运行成本 尽量少使用 reinterpret_cast\u0026lt;T\u0026gt;(expression) static_cast\u0026lt;T\u0026gt;(expression)：最常用 28：避免返回handles指向对象内部成分 handles：引用、指针、迭代器 避免返回指向内部对象的handles，返回一个成员变量的副本 增加可封装性 帮助const成员函数的行为像一个const 将发生”dangling handles“的可能性降到最低（当临时对象析构后，也就无法通过handle获取对象内部的成员） 29：为“异常安全”而努力是值得的 异常安全的含义：当异常被抛出时 不泄露资源：使用RAII 不发生数据败坏 异常安全的函数提供三种不同级别的保证： 基本承诺：不发生数据败坏，但是不保证程序状态 强烈保证：程序状态不变（即程序回复到”调用函数之前“的状态） 通过RAII和调换代码顺序实现 或者通过copy and swap实现：创建副本资源并进行操作，所有操作完成后，使用一个不会抛出异常的swap将副本与当前资源进行交换 不抛掷承诺：总能完成功能，作用域内置类型上的所有操作都提供nothrow承诺 强烈保证有时无法实现 异常安全保证具有木桶效应 30：透彻了解内联的里里外外 inline最初只是针对编译器的优化建议，而非强制；是否内联由优化等级所控制，与是否内联无关\n声明： 隐式声明：将函数定义与类内部（但不是一种好的编程风格） 显示声明：inline 内联函数通常被置于头文件中，因为内联大部分情况下时编译期行为 inline必须放在函数定义前 从实现上看，inline放在函数声明前不起作用 从编程风格看，应该严格区分声明与定义，而且用户不需要、也没有必要知道该函数是否内联 inline只是对编译器的一个申请，不是强制命令 31：将文件间的编译依存关系降到最低 pimpl idiom（pimpl：pointer to implementation）设计思想： 原来main class包含类的具体实现逻辑 现在将main class中具体实现逻辑，放到一个实现类Impl中，在private中添加一个指向Impl的指针 因此main class只是提供接口，实现类Impl负责实现接口，”类的接口与实现分离“ 背景：即使只是改动类的实现，而不改变类的接口，这样所有包含该类的源码都要重新编译 根本原因在于，编译器在编译期必须知道对象的大小，如果不知道类的定义，就无法为对象分配内存 方法一：提供句柄类，用”声明的依存性“替换”定义的依存性“ 原来：假设1000个文件依赖于Person.h，这1000个文件都要重新编译链接 1 2 3 4 5 6 7 8 // Person.h class Person{ public: std::string name() const; private: std::string mName; } // 假设在Person.cpp中，略微修改了std::string Person::name()的实现，1000个文件需要全部重新编译 现在：只需要修改PersonImpl的具体实现，重新编译这一个文件即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Person.h class PersonImpl; // PersonImpl声明 class Person{ public: std::string name() const; private: PersonImpl *pImpl; } // Person.cpp #include \u0026#34;Person.h\u0026#34; #include \u0026#34;PersonImpl.h\u0026#34; std::string Person::name(){ return pImpl-\u0026gt;name(); // 调用实现类中同名函数 } // PersonImpl.h class PersonImpl{ // PersonImpl与Person有相同的public函数，且Person的private数据成员移动到了PersonImpl的private部分 public: std::string name() const; private: std::string mName; } // PersonImpl.cpp #include \u0026#34;PersonImpl.h\u0026#34; std::string PersonImpl::name() {return mName;} 方法二：将句柄类定义为抽象类 基类中定义一个工厂方法，返回动态类型为派生类，静态类型为基类的指针 因此修改派生类中的方法的实现逻辑，不会影响到基类，”类的接口与实现分离“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // Person.h class Person{ public: Person(); virtual std::string name() const; static std::shared\u0026lt;Person\u0026gt; create(const std::string\u0026amp; name); virtual ~Person(); }; // Person.cpp #include \u0026#34;Person.h\u0026#34; #include \u0026#34;RealPerson.h\u0026#34; std::shared\u0026lt;Person\u0026gt; Person::create(const std::string\u0026amp; name){ return std::shared\u0026lt;Person\u0026gt;(new RealPerson(name)) } // RealPerson.h class RealPerson: public Person{ public: RealPerson(std::string\u0026amp; name): mName(name) {}; virtual std::string name() const; virtual ~RealPerson(); private: std::string mName; } 参考 https://www.zhihu.com/question/52832178/answer/192499529 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch05-%E5%AE%9E%E7%8E%B0/","summary":"26：尽可能延后变量定义式的出现时间 原因一：程序前面部分可能有if判断、异常处理等，可能不会运行到后面部分 原因二：直接构造的效率高于默认构造","title":"[Effective Cpp Notes] Ch05 实现"},{"content":"18：让接口容易被正确使用，不易被误用 函数接口传参，使用者可能理解错误或不小心传错 将函数参数封装为新的类型，比如封装新的年月日类，而非直接传入数字 限制类型内可以进行的操作 比如添加const限制，比如item3 尽量使自定义类型和内置类型的行为保持一致 消除使用者的资源管理责任 比如直接返回一个智能指针，而非返回一个raw指针 19：设计class犹如设计type 设计类时，考虑的问题：\n如何创建以销毁：如何实现构造函数和析构函数 初始化与赋值的区别：如何实现构造函数和赋值操作符 类对象传值：如何实现拷贝构造函数 成员类型的合法值：在构造函数和赋值操作中进行检查 继承关系的约束：基类的相关虚函数、成员函数是否需要被声明为virtual 是否允许由别的类转换而来：如何写转换构造函数 哪些操作符和函数是合理的 哪些操作符和函数应该拒绝 成员给哪些用户使用：成员的访问控制权限 新类型的未声明接口是什么 是否有必要将类一般化为类模板 这个新类型是否真的需要 20：传参时，尽量传常量引用而非传值 优点： 减少一次对象的复制 避免对象切割（比如形参是基类，实参是派生类），同时实现多态 使用传值的情况：内置类型，STL迭代器，函数对象 21：函数返回值尽量不要为引用 禁止在函数中返回一个指向局部变量的指针或引用 不要在函数中返回一个动态分配的对象 不要在可能多次调用的函数中返回一个局部静态变量 错误返回引用的例子： 返回栈空间中局部变量的引用：函数返回后，栈上相应对象被销毁，因此未定义 返回堆空间中局部变量的引用：虽然函数返回后不会释放对象，但是函数返回赋值的变量占有了堆空间的资源，而且极易容易忘记释放（因为一般也基本不会考虑对返回值进行delete），造成内存泄露 返回静态变量的引用：当多次调用该函数返回静态变量的引用时，静态变量只有一个，例子 C++11中可以使用移动语义，减少拷贝带来的消耗 22：将成员变量声明为private 将成员变量声明为public的缺点： 缺乏语法一致性：访问public成员变量，可以直接访问或者调用成员函数 对成员变量处理缺少准确控制：将成员变量设置为private的，可以提供setter/getter函数来控制其读写权限 不利于封装：在成员变量发生变化时，可以在相关函数中通知其他变量，从而进行相应修改 23：宁以non-member、non-friend替换member函数 功能颗粒度较高的函数设置为类外的函数，而非封装为public成员函数\n背景：public成员函数可分为两类： 功能颗粒度较低的函数：public/protected成员函数，内部直接访问private成员 功能颗粒度较高的函数：public/protected成员函数，内部由若干个public成员函数集成而来 尽量将功能颗粒度较高的函数封装为类外的函数： 优化类的封装性：如果封装为public函数，本来希望该函数只是public函数的集成，但是这样没法在代码层面体现出来 允许我们从更多维度组织代码结构，提供更大的包裹弹性：比如将不同public成员函数封装为不同功能的外部函数 优化编译依赖关系：比如不同的public成员函数可以封装为不同功能的外部函数，这些外部函数分别放在不同文件中，但是属于同一个命名空间中；这样使用时，需要哪个功能，就只需要包含该文件即可 24：若所有参数皆需要类型转换，请为此采用non-member函数 如果希望运算符的任意操作数可以发生隐式类型转换，则应该将运算符重载为非成员函数（比如友元）\n背景：运算符可以重载，重载为成员函数呢，还是重载为非成员函数呢？ 规定：如果运算符是成员函数，则它的第一个运算对象不会发生隐式类型转换 因为编译器根据第一个运算对象的类型，确定调用的运算符是属于哪一类的 比如：z = x * y等价于z = x.operator*(y)，x不会发生隐式类型转换 25：考虑写出一个不抛出异常的swap函数 如果Widge是一个类，可以在std命名空间中实现std::swap\u0026lt;T\u0026gt;的Widge全特化版本，同时在Widge中实现类内的swap函数以修改private成员的值 1 2 3 4 5 6 7 8 9 10 11 class Widget{ public: void swap(Widget\u0026amp; other){ // member swap using std::swap; // default swap // 调用std::swap进行private成员的处理 } } namespace std{ template\u0026lt;\u0026gt; // std::swap特例化版本 void swap\u0026lt;Widge\u0026gt; (Widget\u0026amp; a, Widget\u0026amp; b) { a.swap(b);} } 如果Widge是一个类模板 不能偏特例化一个函数模板 1 2 3 4 namespace std{ template\u0026lt;typename T\u0026gt; // non-member swap void swap\u0026lt;Widget\u0026lt;T\u0026gt;\u0026gt; (Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} // 编译报错 } 但是可以偏特例化一个类模板，添加一个重载版本 但是不要在std命名空间中添加新东西 1 2 3 4 namespace std{ template\u0026lt;typename T\u0026gt; void swap(Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} } 解决方法：置于一个新的命名空间中 1 2 3 4 5 6 7 namespace WidgetStuff{ template\u0026lt;typename T\u0026gt; class Widget{ ... }; template\u0026lt;typename T\u0026gt; void swap(Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} } 因此，如果想使得Widget专属版swap在尽可能多的语境下被调用，需要 在Widget中提供一个public swap函数（不可抛出异常），内部调用std::swap 同时可能需要同时实现两个版本： Widget所在命名空间WidgetStuff中，实现一个nom-member swap，内部调用Widget::swap 如果Widget是一个类而非类模板，在std中特化std::swap，内部调用Widget::swap C++11之后，std::swap改用std::move实现，所以几乎不存在性能缺陷 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch04-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/","summary":"18：让接口容易被正确使用，不易被误用 函数接口传参，使用者可能理解错误或不小心传错 将函数参数封装为新的类型，比如封装新的年月日类，而非直接传","title":"[Effective Cpp Notes] Ch04 设计与声明"},{"content":"13：以对象管理资源 资源获取即初始化（RAII）：使用析构函数确保资源被释放 复制时使用移动语义，移交资源的所有权 背景：使用动态内存分配时，很容易忘记delete，尤其是程序在中间退出（比如if判断后return） RAII（Resource Acquisition Is Initialization）资源获取即初始化： 资源的有效期与持有资源的对象的生命周期严格绑定（即获取资源的时候要通过构造函数初始化） 对象独占资源 即让编译器在每个退出的分支上，对象都进行析构，从而释放资源 使用模板更加方便 移交所有权 背景：如果两个指针同时指向一个资源，会析构两遍；因此RAII类独占资源（类似unique_ptr） 在RAII类中，将拷贝相关的函数设置为=delete，RAII无法进行拷贝 因此只能通过移动构造函数使用std::move进行移交所有权 如何把RAII类作为函数的参数 值传递：各位caller，我不要ownership了，请拿走 非const引用传递：拿不拿走都行，提前商量好（不推荐） const引用传递：可以拿走用一下，但是ownership还是我的 右值引用：同第二条，无法确定caller是否拿走了ownership C++98与C++11 C++98中std::auto_ptr类似于C++11中std::unique_ptr，但是std::unique_ptr不允许所有权被转移 C++98中std::tr1::shared_ptr类似于C++11中std::shared_ptr，weak_ptr只是拥有资源的使用权而非所有权，因此不占用引用计数，可以解决环状引用的问题 梳理：RAII作为一种管理资源的方式（或思想），早期使用auto_ptr作为解决方案，C++11之后使用unique_ptr和move语义作为解决方案 参考： 现代C++学习—— 什么是RAII 14：在资源管理类中小心copying行为 复制RAII对象必须一并处理资源的copy行为\ncopy行为的不同情况： 大部分情况下，对RAII对象的复制操作本身就不合法 对底层资源使用引用计数法（shared_ptr） 复制底层资源（行为像值，进行深拷贝） 转移资源所有权（unique_ptr） 15：在资源管理类中提供对原始资源的访问 将RAII对象转换为对资源的直接访问 通过显示转换：提供一个get()函数返回智能指针内部的原始指针 通过隐式转换 像使用原始指针一样使用智能指针，比如智能指针一样可以使用-\u0026gt;访问成员 直接访问原始指针：在RAII类内实现返回原始指针的类型转换运算符 16：成对使用new和delete时要采取相同形式 new一个对象，使用delete释放；new一个数组，使用delete []进行释放 delete []表示知道释放的是数组，读取数组元素数量，从而多次调用析构函数 尽量避免对数组使用typedef，此时在delete时很容易出现混淆：用delete还是delete[]，可以的话可以使用std::vector等容器 17：以独立语句将new的对象置入智能指针 背景：编译器可能对单一语句中的执行顺序进行重新调整 1 2 3 4 5 6 7 8 9 10 int priority() {} void func(std::shared_ptr\u0026lt;MyResource\u0026gt; sp, int priority) {} func(std::shared_ptr\u0026lt;MyResource\u0026gt;(new MyResource), priority()); /* 该语句的执行顺序可能是： MyResource* tmp_ptr = new MyResource; int priority = priority(); std::shared_ptr\u0026lt;MyResource\u0026gt; sp = std::shared_ptr\u0026lt;MyResource\u0026gt;(tmp_ptr); */ 如果int priority = priority();执行失败，则tmp_ptr指向的临时资源无法被释放，发生内存泄漏 根本原因是：资源被创建和资源被转换成资源管理对象有时间差，中间可能有干扰 解决方法：以独立语句将new的对象置于智能指针中，因为编译器无法对跨语句的操作进行调整 1 2 std::shared_ptr\u0026lt;MyResource\u0026gt; sp(new MyResource); func(sp, priority()); ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch03-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/","summary":"13：以对象管理资源 资源获取即初始化（RAII）：使用析构函数确保资源被释放 复制时使用移动语义，移交资源的所有权 背景：使用动态内存分配时，很","title":"[Effective Cpp Notes] Ch03 资源管理"},{"content":"05：了解C++默默编写并调用了哪些函数 如果没有自定义相应拷贝控制成员，而且需要使用该拷贝控制成员，则编译器进行合成 有时编译器不会进行合成，因为一些操作非法 1 2 3 4 class MyClass {}; MyClass m1; // 生成默认构造函数和析构函数 MyClass m2(m1); // 生成复制构造函数 m2 = m1; // 生成赋值构造运算符 默认构造函数和析构函数 作用：调用{基类和non-static成员变量}的构造函数和析构函数 当自定义构造函数后，编译器就不会自动生成构造函数 生成的析构函数是non-virtual的，除非基类的析构函数是virtual的 复制构造函数 赋值构造运算符 自动生成赋值构造运算符的条件是，相关操作必须合法 比如成员变量是const或引用，则不能进行赋值 比如基类中赋值构造运算符是private的，则派生类中无法调用父类相应的赋值构造运算符对父类成员进行赋值 06：若不想使用编译器自动生成的函数，就该明确拒绝 在声明中将拷贝控制成员标记为=delete，将不会自动生成该拷贝控制成员\n背景：有时不希望类具有拷贝等行为（语义要求） 三种方法：将不需要自动生成的拷贝控制成员 在private中进行定义 虽然类外部无法访问，但不是绝对安全，可以在成员函数和友元中使用 写为空函数体，使其在链接过程中报错 在基类中声明为private 这样即使在成员函数和友元中使用相应拷贝控制成员，也会因为无法拷贝控制相应基类成员，从而将报错从链接期提前到编译期 在声明中标记为=delete 07：为多态基类声明virtual析构函数 声明多态性质的基类的析构函数为virtual的\n背景：当delete一个指向派生类的基类指针时，只会调用non-virtual的基类析构函数，派生类中成员无法释放 只有当类中至少包含一个除析构函数外的virtual函数时（多态性质），才将析构函数声明为virtual的 为了保持可移植性 如果该类不包含virtual函数，则通常该类不会作为基类 将基类析构函数声明为pure virtual函数，从而将基类构造为抽象基类（避免了考虑将其他哪个函数声明为pure virtual函数） 所有的STL容器都不包含virtual析构函数，因此不要将STL容器作为基类 因为STL容器设计不是用来作为基类，不带有多态语义要求，只有多态性质的基类才需要声明一个virtual析构函数 不是所有基类都带有多态性质 08：别让异常逃离析构函数 析构函数不要抛出异常，但是析构函数中可以使用try catch进行异常处理 C++11中，默认将析构函数声明为noexcept，防止在析构函数中抛出异常 try语句块中抛出异常时，会将作用域中对象依次调用析构函数，然后进入catch语句块中 如果此时调用的析构函数中继续报错，则core dumped 可以在析构函数中使用try catch捕获异常，或者重新设计接口，使得防止抛出异常的函数在析构函数中被调用 09：绝不在构造和析构过程中调用virtual函数 不要再构造/析构函数（及其调用的函数中）中调用virtual函数，因为这样虚函数不会呈现多态\n当派生类中的基类部分被构造时，其调用的虚函数只会调用基类中的版本，不会调用派生类中的版本，即不会呈现多态 从安全性角度看，因为此时派生类部分还未构造，使用派生类的虚函数版本可能产生未定义的行为，所以C++规定使用基类的版本 从原理角度看，在构造基类部分时，对象的类型实际上是基类类型 当派生类中的基类部分被析构时，同样不会呈现多态 从安全性角度看，此时派生类部分已经析构，调用派生类的虚函数版本产生未定义的行为 从原理角度看，此时对象为基类类型 构造函数/析构函数内调用的函数，也要保证其中不调用虚函数 10：令operator=返回一个reference to *this 令赋值运算符返回一个*this的引用\n11：在operator=中处理自我赋值 进行重新排列赋值或者copy and swap\n背景：有时可能很隐蔽的进行了自赋值的操作，特别是类管理资源时，很可能被意外delete掉 进行重新排列赋值：先保存当前资源副本，然后new，最后delete原来的资源；可以保证异常安全性，而且identity test没有必要 1 2 3 4 5 6 MyClass\u0026amp; operator= (const MyClass\u0026amp; rhs){ Resource* tmp = MyResource; MyResource = new Resource(); // 如果new失败，则当前资源不会被释放 delete tmp; // new成功 return *this; } copy and swap 12：复制对象时勿忘记其每一个成分 派生类复制时，不要忘记将基类部分也复制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; class Base{ public: Base(int id): base_id(id) {} Base(const Base\u0026amp; b): base_id(b.base_id) {} Base\u0026amp; operator= (const Base\u0026amp; b) { base_id = b.base_id; return *this;} private: int base_id; }; class Derived: public Base{ public: Derived(int id, string name): Base(id), myname(name) {} Derived(const Derived\u0026amp; d): Base(d), myname(d.myname) {} // 将派生类直接赋值给基类，派生类被切掉 Derived\u0026amp; operator= (const Derived\u0026amp; d){ Base::operator=(d); // 调用基类operator= myname = d.myname; return *this; } private: string myname; }; ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch02-%E6%9E%84%E9%80%A0%E6%9E%90%E6%9E%84%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/","summary":"05：了解C++默默编写并调用了哪些函数 如果没有自定义相应拷贝控制成员，而且需要使用该拷贝控制成员，则编译器进行合成 有时编译器不会进行合成，","title":"[Effective Cpp Notes] Ch02 构造、析构、赋值运算"},{"content":"01 视C++为一个语言联邦 C++高效编程守则视状况而变化，取决于你使用C++的哪一部分\nC++支持面向过程、面向对象、面向函数、泛型编程、元编程，因此可以将C++视为一个由相关语言组成的联邦而非单一语言（各个方面的编程范式不太相同）： C：有指针、数组，没有模板、重载和异常 Object-Oriented C++：类、封装、继承、多态、虚函数 Template C++：模板元编程 STL： 编程范式（或者编程技巧）的区别： 对于C而言，传值比传引用更加高效 对于Object-Oriented C++而言，常量引用传递往往更好（可以传递左值、右值） 对于Template C++而言，模板往往不知道处理的对象是什么类型 对于STL而言，迭代器和函数对象是基于C的指针，所以此时应该选择值传递 02：尽量以const,enum,inline替换#define 尽量使用编译器操作代替预处理器操作： 对于常量，尽量使用const对象或enum来替换#define 对于形似函数的宏，最好改用inline替换#define 尽量使用编译器操作代替预处理器操作 #define是在预处理阶段进行替换，宏的名字不会出现在符号表中。 对于常量，尽量使用const对象或enum来替换#define 两个典型场景： 定义常量指针 定义class专属常量，比如const static成员 类内static成员可以进行【声明时初始化】，虽然不是定义（即没有分配空间），但是只要不取地址，此时也可以使用该变量 如果类内static成员进行【声明时初始化】，而且需要取地址，则需要在类外对变量进行定义 1 2 3 4 class Widget{ const static int val = 0; }; const int Widget::val; // 由于const，无法进行赋值 对于形似函数的宏，最好改用inline替换#define 虽然使用宏本身少了一次调用过程，但是有时即使加上括号，结果也不正确 1 2 3 4 5 #define CALL_WITH_MAX(a, b) f((a) \u0026gt; (b) ? (a) : (b)) int a = 5, b = 0; CALL_WITH_MAX(++a, b); // a 累加了一次 CALL_WITH_MAX(++a, b + 10); // a 累加了两次 使用inline可以保证正确性，并且可以使用模板 参考 https://github.com/XiaotaoGuo/Effective-Cpp-Reading-Note/blob/master/1.AccustomingYourselfToCpp/02.PreferConstsEnumsInlinesToDefine.md 03：尽可能使用const 声明为const可以帮助编译器检测错误 const成员函数默认遵循bitwise constness，但是编写程序时应该使用logical constness，必要时将成员声明为mutable来保证可以修改 const和non-const成员函数有实质等价的实现，令non-const版本调用const版本可以避免代码重复 const和指针：顶层const与底层const const和STL：const迭代器是顶层const，const_iterator是底层const const和函数： 函数返回值和函数形参尽量声明为const的，有助于编译器定位相关报错 比如将比较运算符==误写为赋值运算符= 成员函数声明为const的 使得成员函数更容易被理解（这个成员函数不能修改成员），而且此时形参往往也是const引用 一个const成员函数，一个non-const成员函数，可以进行重载 const对象调用const版本成员函数，普通对象调用non-const版本成员函数 常量性转移 背景：const成员函数与non-const成员函数中间逻辑相同，可能存在大量的重复代码，一个方法是将重复的代码写成函数放在private中 更好的办法是，让non-const成员函数调用const成员函数（如果反过来，const成员函数调用non-const成员函数，不能保证对象不被修改） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class TextBlock{ public: const char\u0026amp; operator[] (std::size_t pos) const{ // do something return text[pos]; } char\u0026amp; operator[] (std::size_t pos) { return const_cast\u0026lt;char\u0026amp;\u0026gt;( static_cast\u0026lt;const TextBlock\u0026amp;\u0026gt;(*this) // *this是TextBlock\u0026amp;, 强转加上const [pos] // const TextBlock\u0026amp;调用operator[]，否则TextBlock\u0026amp;调用operator[]一直重复调用自己 ); } private: std::string text; } mutable：使得成员变量即使在const成员函数中也可以被修改，主要是为了实现logical constness 背景：bitwise constness与logical constness bitwise constness：成员函数不应该修改任何non-static成员变量（const成员函数的默认方式） 编译器容易实现，只需要寻找成员变量的赋值操作 logical constness：允许成员函数修改成员变量，对于使用者而言，可以体现出constness即可 比如一个指针成员变量，按照bitwise constness，限定指针为顶层的，但是却无法保证不修改所指对象 参考 https://github.com/XiaotaoGuo/Effective-Cpp-Reading-Note/blob/master/1.AccustomingYourselfToCpp/03.UseConstWheneverPossible.md 04：确定对象被使用前已被初始化 内置类型对象一定要进行手动初始化 构造函数中最好使用初始化列表对成员变量进行初始化，而非在函数体中进行赋值 为了避免跨编译单元的初始化顺序问题，尽量以local static对象代替non-local static对象 内置类型变量的初始化 内置类型变量（即使是类中的内置类型成员变量）是否会初始化，取决于其在内存中的位置（堆空间？栈空间？） 自定义类对象的初始化 初始化与赋值的区别 赋值：比如在构造函数函数体中进行“赋值” 非内置类型的成员变量的初始化发生在进入构造函数之前，每个成员变量的default构造函数被自动调用，构造了两次（默认构造一次，复制构造一次） 但是内置类型的成员变量不会自动初始化，此时无区别 初始化：比如在构造函数初始化列表中 此时相当于只调用了一次成员变量的构造函数（赋值构造） 如果是const或者是引用，此时不能被赋值，只能进行初始化 变量初始化顺序 在初始化列表中，编译器按照父类-\u0026gt;子类的顺序进行成员变量初始化，但尽量还是与成员声明顺序保持一致 不同编译单元内定义的non-local static对象的初始化顺序 一些情况下，不同编译单元内的non-local static对象的初始化顺序有要求，但是C++没有明确定义（比如要求先FileSystem中tfs初始化，后Diectory中tdr初始化） 将每个 non-local static 对象移至自己的专属函数内（变成 local static 对象） ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch01-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFc++/","summary":"01 视C++为一个语言联邦 C++高效编程守则视状况而变化，取决于你使用C++的哪一部分 C++支持面向过程、面向对象、面向函数、泛型编程、元编程","title":"[Effective Cpp Notes] Ch01 让自己习惯C++"},{"content":"contact me at: zhangqingannn@gmail.com\n","permalink":"https://qinganzhang.github.io/about/","summary":"contact me at: zhangqingannn@gmail.com","title":"About"},{"content":"1. linux入门 1.1 实用程序 man：查询联机手册\n1 2 man (section) name # section:1命令，2系统调用，3库函数，5配置文件（因为可能有同名的） man -k regexp # 用正则匹配 date：获取时间和日期\n1 date \u0026#34;+%Y-%m-%d %H:%M:%S Day %j\u0026#34; # 格式控制字符串必须以+号开头 bc：计算器\n1 bc -l # 类似于ipython的交互式界面 重定向\n1 2 3 ls -l \u0026gt; filelist.txt # 输出重定向 sort \u0026lt; filelist.txt # 输入重定向 ls -l \u0026gt;\u0026gt; filelist.txt # 追加内容 管道\n1 ls -l | sort # 将ls的stdout作为sort的输入 more, less：逐屏显示（文件或输出），less可以向上翻页但是more不行\n1 less -Nm # fb翻页，du翻半页，gG第一/最后一行，v编辑，/?向下或上搜索字符串(nN上一个下一个) cat：列出文件内容；od：逐字节打印\n1 2 cat -n test.txt cat \u0026gt; file.txt # 没有命令行参数，从stdin获取输出，直到Ctrl-D，将内容写入文件 head, tail\n1 2 3 head -n 20 file.txt # 显示前20行 hand -n -20 file.txt # 除了尾部20行，其余算头并显示 tail -f file.txt # 实时打印文件尾部追加的内容 tee：三通，将stdin输出到stdout，同时写入文件中\n1 ls -lh | tee out.txt wc\n-w：字计数 -l：行计数 1 2 ps -ef | wc -l # 查看当前进程总数 ls | wc -w # 查看当前文件夹下文件个数 sort：\n-r：降序 -o：结果覆盖原文件 -n：按照数字而非字符串排序 tr str1 str2：替换字符串，将stdin中str1的字符替换为str2的字符，然后标准输出\n1 cat file.txt | tr \u0026#39;[a-z]\u0026#39; \u0026#39;[A-Z]\u0026#39; # 将file.txt文件中小写字母替换为大写字母 unique：筛选文件中重复的行\n1.2 了解系统状态 who：确定谁在系统中\n1 2 tty # 输出当前终端设备文件名 who am i # 输出当前终端上的登录用户 uptime：已开机时间\n1 当前时间 开机时间 用户数量 CPU负载（1，5，15分钟内有几个进程在等待调度运行） top：列出资源占用排名靠前的进程\n1 2 3 4 top -d 1 -n 5 # delay=1, 运行5次 当前时间 开机时间 用户数量 CPU负载 任务（进程） PID USER PR NI VIRT进程虚拟地址空间 RES驻留内存数（占用物理内存数） SHR共享内存数 %CPU %MEM TIME+占用CPU的时间 ps：查询进程状态，列出当前终端上启动的进程\n-e：列出系统中所有进程 -f：以full格式列出 -l：以long格式列出 1 UID PID PPID C（最近几秒占用CPU情况） PRI优先级 SZ进程逻辑地址空间 WCHAN进程在何处睡眠 TTY终端名字 TIME累计占用CPU时间 CMD free：了解内存使用情况\n1 内存总量 已使用内存 空闲内存 共享内存 缓冲使用的内存 现在实际可以使用的内存 vmstat：了解系统负载\n1 2 vmstat 1 -Sm # 每一秒更新一次 最关注的是cpu使用率，us=user, sy=system, id=idle, wa=wait for disk IO 2. 正则表达式 2.1 元字符 [正则表达式](https://www.runoob.com/regexp/regexp-tutorial.html)与文件名通配符规则不同 .：匹配任意单字符\n*：匹配前面单字符0次或任意多次\n[：方括号内的字符为集合，表示其中任意一个，方括号内的. * \\ 表示自己，[ ][ ]表示左右中括号的两个字符，-表示一个区间（如果在最后则不表示区间）\n\\\n^：在中括号内时开头表示补集，[^a-z]表示匹配任一非小写字母（如果不在中括号内开头则不表示补集），在正则表达式开头时表示首部的限制（不在首部则不表示此限制）\n$：在正则表达式尾部时表示尾部的限制（不在尾部则不表示此限制）\n2.2 正则表达式拓展 ()：分组 |：逻辑或 +：匹配前面单字符1次或任意多次 ?：匹配前面单字符0次或1次 {m,n}：匹配前面的单字符m到n次 {m}：匹配前面的单字符m次 {m,}：匹配前面的单字符至少m次 \\d：数字， \\D：非数字，\\s：空白符（包括换行）， \\S：非空白符（不包括换行）， \\w：数字字母下划线（相当于 [A-Za-z0-9_]） 2.3 常用命令 grep -n 模式 文件名列表\n-F：按字符串搜索（同fgrep）\n-G：基本正则语法，默认\n-E：拓展正则语法（同egrep）\n-n：显示行号\n-o：提取匹配的部分\n1 2 grep -n \u0026#39;main\u0026#39; *.cpp # 从文件中筛选 ps -ef | grep -n \u0026#39;^zhang\u0026#39; # 从输入中筛选 sed：利用正则表达式处理文本（替换、删除等）\n1 sed \u0026#39;s/^zhang/ZHANG/g\u0026#39; # 将开头为zhang的替换为ZHNAG，s表示替换，用/划分不同的部分，g表示如果有多个符合则全部替换 awk：逐行扫描进行条件判断，满足条件执行动作\n3. 文件编辑 3.1 vim常用操作 3.2 常见问题 vim编辑结束后Ctrl+S：Linux进入了流量控制状态，Ctrl+Q流量控制解除\nCtrl+Z导致进程挂起（进程还在但是处于Stopped状态）：使用jobs命令查看当前Stopped的进程，使用%1将1号作业恢复到前台运行\nbackspace无法使用：Ctrl+H或者stty erase ^H\nLinux和Windows的文本文件存储格式不同（行尾不同），dos2unix/unix2dos转换\n4. 目录管理 4.1 系统目录 /etc：配置文件 /tmp：临时文件 /var：系统运行时要改变的数据（比如日志） /bin：系统常用命令（eg：ls、cp、cat） /usr/bin：常用命令（eg：ssh，ftp，make， gcc，git） /sbin, /usr/bin：系统管理员专用命令 /dev：设备文件 /usr/include：C语言头文件 /lib, /usr/lib：C语言链接库文件，静态链接库（.a文件)和动态链接库（.so文件，共享的目标代码，多个.o文件的集成，广泛使用） ldd：用来查看程序运行时所需的共享库 4.2 文件通配符 command后面跟着的是参数或文件通配符，shell进行替换，而正则表达式不进行替换 元字符 *：匹配任意长度的文件名字符串（包括空串），当.作为开头或是包含/时，必须显示匹配 ?：匹配任一单字符 []：集合，匹配其中任一字符 ~：当前用户主目录 .：当前目录 /：根目录，斜线/，反斜线\\ 4.3 常用命令 ls\n-F：如果是目录，名字后面带/，如果是可执行文件，名字后面带*，如果是链接文件，名字后面带@，普通文件无标记（现在文件都用颜色表示）\n-l：\n第一个字符为文件类型，-普通文件，d目录文件，l符号链接文件，c字符设备文件，b块设备文件，p管道文件\n访问权限（文件所有者、同组用户、其他用户）\n文件链接数\n文件所有者名字和组名\n文件大小（单位为字节，如果是目录则列出目录表大小不是目录大小）\n最后修改日期和时间，文件名\n-d：列出目录自身的信息\nls *：递归一层列出\n-a：列出所有文件\ncp：复制\ncp file1 file2：将file1复制到file2（如果file2不存在则创建，如果存在则覆盖） cp -r dir1 dir2：如果dir2不存在则复制dir1并改名为dir2，如果dir2存在则将dir1复制到dir2下 cp file1 file2 dir：将file1，file2复制到dir目录 -u：增量拷贝，便于备份目录 mv：移动\nmv file1 file2：相当于将file1改名为file2 mv file1 file2 dir：要求dir存在 mv dir1 dir2：如果dir2不存在则相当于改名，如果dir2存在移动dir1到dir2下 rm\n-r递归删除， -i删除前确认， -f强迫删除只读文件\n--后参数被shell认为是处理对象而不是命令选项\nmkdir和rmdir\n-p：自动创建路径中不存在的目录 touch：将文件最后一次修改时间设置为当前时间（如果文件不存在，则创建文件）\nfind：遍历目录树， find 查找范围 条件 动作\n条件\n-name wildcard：文件名与wildcard匹配，wildcard加单引号，wildcard可以是正则表达式 -regex pattern：整个路径名与pattern匹配 -type：f普通文件，d目录，l符号链接文件，c（char），b（block），p（pipe） -size +-n ：指定文件大小（大于+，默认等于，小于-），单位是c（字符），b（块，512字节），k，M，G，默认b -mtime +-n：文件是最近n天内修改的 -newer file：文件修改时间比file还新 !：非，前后要有空格， 默认是与 \\( 条件1 -o 条件2 \\)：或，因为()是shell的特殊符号 动作\n-print：打印查找的文件路径名\n-exec：对查找到的目标执行命令，在-exec之后和分号之前作为一条命令，{}表示文件路径名\n1 2 find . -type f -name \u0026#39;utils.*\u0026#39; -exec ls -lh {} \\; find . ! -newer file.txt \\( -name \u0026#39;*.c\u0026#39; -o -name \u0026#39;*.h\u0026#39; \\) -exec grep -n -- --help {} /dev/null \\; # 查找早于file.txt的.c或.h文件，并且在检索到的文件(用{}表示)中查找包含--help的内容，通过grep添加两个文件（{}和/dev/null）来显示查找到的内容是在哪一个文件中 -ok：类似-exec，在执行命令前需要确认\nxargs：批量处理文件，常用于先列出文件然后再xargs批处理\n1 2 find . -name \u0026#39;*.c\u0026#39; -print | grep -n --help # 每找到一个文件都要创建一个进程来grep find . -name \u0026#39;*.c\u0026#39; -print | xargs grep -n --help # 找到所有文件后，只创建一个进程来批处理(grep)这些找到的文件，将标准输入追加到参数列表后面,效率高 tar：tar c/t/x vzj f my.tar filelist\n必选参数 c：tar cvf my.tar filelist将filelist中文件打包到my.tar中 t：tar tvf my.tar查看my.tar中有什么文件 x：tar xvf my.tar解包，此时不需要压缩算法 f：指定设备文件名（即.tar文件） 可选参数 v：verbose z：gzip压缩，快，常gz后缀 j：bzip2压缩，压缩率高，常bz2后缀 gzip, gunzip; bzip2, bunzip2：压缩解压缩\ndu：du -d 1 -h显示文件大小，类似windows\n-d：递归深度 5. 文件管理 5.1 运行时获取信息 配置文件 环境变量：env打印当前环境变量，PATH是可执行文件的查找路径，CLASSPATH是类库查找路径，使用export来添加环境变量 命令行参数 交互式键盘输入 5.2 文件系统 文件系统命令\nmkfs：创建文件系统\nmount, umount：安装、卸载文件系统\ndf ：查看文件系统空间空间\n文件系统结构\n引导块：启动系统\n专用块：管理快（或超级块），存放文件系统的管理信息\ni节点区：每个文件一个i-node，包括索引、指针和文件信息\n文件存储区：目录表（文件名和i-node指针）和文件内容\n5.3 链接 硬链接：目录项指定的“文件名 i-node”映射关系\n1 ln file.txt lnk # 创建file.txt的硬链接lnk，删除lnk时对应i-node的link数减一，仅限于同一个文件系统中的普通文件 软链接（符号链接）：创建一个“符号链接文件”，里面存储路径（如果时相对路径，则相对于该符号链接文件）\n1 ln -s file.txt lnk # 创建file.txt的软链接lnk 5.4 可执行文件 程序文件：二进制 脚本文件：第一行指定解释程序，在运行中由解释程序创建一个进程进行解释执行 5.5 权限 目录权限：实际上是对目录表的权限，无读权限则无法ls，无写权限则无法创建、删除文件等（但文件可能可以修改），执行权限表示分析路径名中可以检索该目录 chmod [ugoa][+-=][rwxst] file u=user, g=group, o=other, a=all, 6. Shell 6.1 shell 命令解释器，交互式方式下替换、转义、内部外部命令，非交互式方式下编写脚本程序批量处理 6.2 bash启动方式 注册shell，启动时自动执行\n（用户级）：~/.bash_profile\n（系统级）：/etc/profile\n退出时，自动执行\n（用户级）：~/.bash_logout\n（系统级）：/etc/bash.bash.logout\n交互式shell，启动时自动执行\n（用户级）：~/.bashrc\n（系统级）：/etc/bash.bashrc\n脚本解释器：\n新创建子进程，在子进程中执行脚本 bash \u0026lt; test.sh：无法携带命令行参数 bash test.sh ..：-x参数便于调试和观察 chmod u+x test.sh; ./test.sh .. 在当前shell中执行 chmod u+x test.sh; . test.sh .. 6.3 别名 在.bashrc中添加一个别名\n1 alias lls = \u0026#34;ls -lh\u0026#34; 6.4 重定向 输入重定向\n\u0026lt;：从file中获取输入\n\u0026lt;\u0026lt;：从shell脚本中获取输入\n1 2 3 4 5 6 7 8 9 cat \u0026lt;\u0026lt; WORD Now: `date` WORD # WORD是定界符，之间内容进行替换并执行获取输入 cat \u0026lt;\u0026lt; \u0026#39;WORD\u0026#39; Now: `date` WORD # 当定界符有单引号时，之间内容不做替换 \u0026lt;\u0026lt;\u0026lt;：从命令行获取信息作为标准输入\n1 base64 \u0026lt;\u0026lt;\u0026lt; \u0026#39;test\u0026#39; 输出重定向\n\u0026gt;：覆盖，stdout重定向\n\u0026gt;\u0026gt;：追加，stdout重定向\n2\u0026gt;：将句柄2（stderr）重定向（句柄1是stdout）\n2\u0026gt;\u0026amp;1：将句柄2重定向到文件描述符1指向的文件，放在命令最后\n1 gcc test.c \u0026gt; test.err 2\u0026gt;\u0026amp;1 管道|将前一命令的stdout作为后一命令的stdin，同样可以使用2\u0026gt;\u0026amp;1\n1 gcc test.c \u0026gt; test.err 2\u0026gt;\u0026amp;1 | less 6.5 设置 set -u：当引用一个未定义的变量时，产生一个错误 set +u：当引用一个未定义的变量时，视为一个空字符串 set -x：打印出shell替换后的命令和参数，常用于观察命令经过shell替换后哪里错误 set +x：取消set -x 6.6 常用命令 echo：打印命令行参数\n-e：转义打印 printf：类似C语言\n1 printf \u0026#34;home:%s\\n\u0026#34; $HOME read：获取用户输入\n6.7 环境变量 子进程继承父进程的环境变量，以后再不影响\n使用export将局部变量转为环境变量 PATH：命令查找路径，不要将.放入PATH，PATH以:分隔路径 env：列出环境变量 set：列出环境变量、局部变量、函数定义 6.8 替换 文件名生成替换：遵循文件通配符规则\n变量替换：$var\n命令替换：以命令的stdout进行替换， `````` ````(反撇号)或者 $()\n1 2 now = `date` now = $(date) 6.9 语法 6.9.1 变量 shell先替换，再执行 变量都是字符串，可以修改 赋值语句等号两边不能有空格（否则会认为是参数），右侧字符串如果有特殊字符需要用双引号 引用变量：$var或${var}，引用未定义变量认为是空字符串 内部变量：位置参数 $0, $1, $2：第一个命令行参数（脚本文件本身的名字），第二个命令行参数，第三个命令行参数 $#：命令行参数的个数 $*：相当于\u0026quot;$1 $2 $3 ...\u0026quot;将整体作为一个参数 $@：相当于\u0026quot;$1\u0026quot; \u0026quot;$2\u0026quot; \u0026quot;$3\u0026quot; ... 将变长的命令行参数传递给其他命令 shift n ：位置参数的移位操作，位置参数顺次向前移动n个位置 6.9.2 元字符 空格，tab：命令行参数分隔符\n回车：运行命令\n\u0026gt;\u0026lt;|：重定向与管道（还有||）\n;：一个内多个命令（还有;;）\n\u0026amp;：后台运行（还有\u0026amp;\u0026amp;）\n$：引用变量\n````` ：反撇号用于命令替换，出现元字符注意转义，可以嵌套但要转义`\\\\` 、` ````\n1 year=`expr \\`date \u0026#39;+%Y\u0026#39;\\` - 10 ` 文件通配符：*[]?\n()：用于定义shell函数或在子shell中执行一组命令\n\u0026quot;：除了$和````` ，其他的特殊字符都不转义，里面只能有四种转义：`\\\u0026quot;` 、 `\\$`、 ` ````、 \\\\\n'：都不转义，中间不能有单引号（可以拆分成多段）\n1 2 3 4 5 在*.conf文件中匹配\u0026#39;192.168.x.x\u0026#39;结尾 pattern: \u0026#39;192\\.168\\.[0-9.]*\u0026#39;$ grep \\\u0026#39;\u0026#39;192\\.168\\.[0-9.]*\u0026#39;\\\u0026#39;\u0026#39;$\u0026#39; *.conf # 使用单引号 grep \u0026#34;\u0026#39;192\\\\.168\\\\.[0-9.]*\u0026#39;\\S\u0026#34; *.conf # 使用双引号 grep \\\u0026#39;192\\\\.168\\\\.\\[0-9.]\\*\\\u0026#39;\\$ *.conf # 只使用转义,不被引号包括的字符串 6.9.3 条件判断 逻辑判断\n命令的返回码是0，则命令执行成功\n$?输出上一个命令的返回码，用管道连接时以最后一个命令的返回码为准\n\u0026amp;\u0026amp; ||：与，或，可以短路\n1 2 cmd1 \u0026amp;\u0026amp; cmd2 # cmd1执行失败就不执行cmd2 cmd1 || cmd2 # cmd1执行成功就不执行cmd2 检测命令：test或[(是一个命令而非词法符号，最后一个参数必须是])\n文件特性检测：\n-f普通文件，-d目录文件，-r可读，-w可写，-x可执行，-ssize\u0026gt;0\n1 2 test -r myfile.txt \u0026amp;\u0026amp; echo readable [ -r myfile.txt] \u0026amp;\u0026amp; echo readable 检测命令是否执行成功\n比较\n字符串比较：shell中有三种字符串\nstr1 = str2或str1 != str2等号两边一定要有空格\n整数的比较\n-eq=，-ne!=， -gt\u0026gt;， -lt\u0026lt;， -ge\u0026gt;=， -le\u0026lt;=\n逻辑运算\n! 非，-o或， -a与\n命令组合：经常命令检测之后执行多条命令\n{}：在当前shell中执行，命令组合最后有分号\n1 [ -d $DIR ] \u0026amp;\u0026amp; { cd ..; ls -l; ps; } | less ()：在子进程中执行，命令组合最后无分号\n1 [ -d $DIR ] $$ ( cd..; ls -l; ps ) | less 条件结构\n1 2 3 4 5 6 7 if condition then list elif condition then list else list fi 6.9.4 表达式运算expr 运算类型：()，五种算术运算，六种关系运算，\u0026amp; |与或， :正则 注意运算符的转义 :正则：expr str : pattern 从最左字符开始尽量匹配，最终输出匹配的长度 使用的是基本正则语法，但是\\+ \\? \\|表示匹配一个或多个，匹配0个或1个，或（两端任选其一） 使用\\( \\)，将其中匹配的内容提取出来 6.9.5 循环结构 while\n1 2 3 while condition do list done for\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 for name in word1, word2, ... do list done # 或者 for name do list done # 相当于 for name in $1, $2, ... do list done for i in `seq 1 255` # 相当于for i in range(1,256) break n：跳出n层循环\ncontinue\nexit val：结束脚本执行，返回值为val\n6.9.6 其他 eval：将参数先进行变量替换或加工，然后将结果作为程序来执行 ","permalink":"https://qinganzhang.github.io/posts/linux%E7%AC%94%E8%AE%B0/","summary":"1. linux入门 1.1 实用程序 man：查询联机手册 1 2 man (section) name # section:1命令，2系统调用，3库函数，5配置文件（因为可能有同名的） man -k regexp","title":"Linux笔记"}]