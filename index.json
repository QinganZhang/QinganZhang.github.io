[{"content":"Abstract Transformer模型架构在自然语言处理、计算机视觉、强化学习等领域表现出了强大的能力，已经成为当前深度学习很多模型的核心，当前发展迅速的大模型更加凸显出这一点。由于Transformer较高的复杂度，限制了其在很多场景中的应用。因此，为了提高模型的高效性，针对Transformer的改进层出不穷。本文从模型算法的角度出发，关注于模型推理的场景，从不同层次梳理当前提高模型效率的方法，包括设计复杂度更低的注意力机制、提出更加高效的网络设计、进行模型压缩和优化的方法，并针对每一种方法进一步做了分类和总结，并选取具有代表性的方法进行说明。本文最后探讨了Transformer未来可能的发展方向。\n1. Introduction 近年来，深度学习发展迅速，尤其是以Transformer为核心的结构，构成了当前深度学习架构的核心，在计算机视觉、自然语言处理等领域，SOTA的模型均以Transformer架构为核心，而且当前诸如ChatGPT等大模型，核心同样是基于RLHF的Transformer，显示出了Transformer强大的能力。\n但是，受限于Transformer相对于序列长度平方的计算复杂度，在图片、视频等需要长序列的场景下，相对于传统的CNN架构，Transformer仍不够有效，无法得到有效的应用。Transformer的平方复杂度来源于注意力机制，因此，许多研究关注于改进注意力机制，降低注意力机制的复杂度，提出新的注意力机制。除此之外，不同的Transformer架构被提出，这些架构在Vanilla Transformer架构上做出改进来提高计算和访存效率，这可以归结为efficient attention或efficient Transformer网络架构的设计。\n除此之外，为了进一步降低Transformer模型的复杂度，提高模型的推理速度，efficient Transformer的网络架构还可以使用一些模型压缩的方法，比如剪枝、量化、蒸馏、神经架构搜索（NAS）等，这些方法可以在基本保持模型效果的同时，降低模型复杂度，减小模型大小，进一步加速模型的推理。\n需要说明的是，efficiency是一个比较宽泛的用词，包括data-efficiency, model-efficiency（efficient architecture），training-efficiency，inference-efficiency。其中data-efficiency一般指充分利用、挖掘数据，从小规模数据中进行学习；model-efficiency侧重于降低模型的复杂度或是参数量；training-efficiency指使用更少的资源（或提高资源利用效率）、使用更少的时间来进行训练；inference-efficiency通常也被成为模型推理加速，它针对训练好的模型，尽可能提高模型的推理速度、吞吐量等。本综述中只涉及到model-efficiency，并介绍一些针对Transformer的模型压缩方法。\nBlog: Efficient Deep Learning 高效深度学习\n2. Model Efficiency Model efficiency主要侧重于提出新的架构，或者改善现有架构，从而降低模型复杂度或参数量。不同于训练场景只关注于模型的参数量，在推理场景中，模型在访存、计算等方面同样需要高效，2.1节说明了在推理场景中模型所关注的几种不同的efficiency。为了能够量化的来比较模型在推理时的efficiency，2.2节总结了一些评估模型推理性能的指标。\n2.1 Kinds of Efficiency 模型的高效是一个相对的概念，但是有几个发展方向是确定的，比如高效的模型一般具有一下几个特征：模型中存在较多的计算密集型算子而非访存密集型算子（有助于充分发挥硬件性能），模型计算复杂度尽量低（可以应用于更加广泛的场景），模型参数量尽量少（可以减少存储空间和内存的占用），受限于模型的结构、应用的场景，在应用中需要先对这几个方向进行分析，然后才能够做进一步的分析和优化。\n2.1.1 Memory Efficiency 访问内存的开销是影响模型推理速度的一个关键因素。Transformer中许多操作，比如频繁的reshape，element-wise相加，归一化等操作，这些操作或算子是访存密集型的，即大部分时间花费在访存上，而计算耗时占比很小，此时模型推理速度主要受到内存带宽限制。减少模型推理过程在访存上的时间开销，就是提高memory efficiency。\nBlog: 深度学习模型大小与模型推理速度的探讨\n2.1.2. Computation Efficiency 模型的computation efficiency往往指的是模型的算法复杂度低。特别的，针对Transformer而言，当序列长度序列较小时，此时模型的计算开销主要集中在FFN模块，计算复杂度近似地线性于序列长度。但是在很多使用Transformer的场景中，比如图片、视频等场景中，输入序列长度较大。此时，模型的计算开销会集中于自注意力层，产生相对于序列长度平方的复杂度，限制了Transformer在很多场景中的应用。\nBlog: Efficient Transformers\nPaper: Attention is all you need 中FFN与Attention复杂度对比\n2.1.3 Parameter Efficiency Parameter Efficiency主要指的是模型的轻量化和较少的参数量。使用参数量较少的模型，可以减少模型在磁盘上存储的空间和模型加载后内存的占用。需要注意的是，随着大模型的发展，受限于大模型训练的成本，大模型的微调技术PEFT（Parameter-efficient fine-tuning）发展迅速。PEFT旨在最小化微调参数的数量和计算复杂度，以减少大模型微调的成本，来提高模型在新任务上的性能。这里所说的Parameter Efficiency更加类似于模型轻量化的概念。\n2.2 Metrics 设计神经网络架构的主要考虑因素之一就是效果和成本的权衡。一般情况下，一个模型的参数量越多，计算量越大，模型的容量越大，该模型的效果就越好。但是，不同模型在不同硬件平台上的推理效果往往无法直接比较。因此，在比较模型推理性能时，经常会使用一些指标，从不同角度对模型的推理性能进行比较。\n2.2.1 计算量 计算量是评价模型efficiency最常用的指标，包括很多文献进行对比时，常常会将计算量和参数量作为最重要的比较依据。计算量是模型所需的计算次数，模型的整体计算量等于模型中每个算子的计算量之和。衡量计算量主要有两个指标：\nFLOPs（Floating Point Operations，浮点计算次数）：计算量一般用OPs（Operations，计算次数）来表示，由于最常用的格式为float32，因此也常被写作为FLOPs。\nMACs（Multiply-Accumulate Operations，乘加累计操作数）：1个MACs包括一个乘法操作与一个加法操作，大约相当于2FLOPs。在很多硬件上，Multiply-Accumulate可以使用单独一个指令完成，而且很多对tensor的操作也是Multiply-Accumulate操作。FLOPs通常用于模型的理论上计算量的分析，MACs更加贴近真实的计算量。\nMultiply–accumulate_operation from wiki\n2.2.2 参数量 参数量是模型中参数的总和，直接反应了模型在磁盘中存储的大小。虽然参数量并不直接影响推理性能，但是参数量一方面会影响内存占用，另一方面会影响程序初始化时间。而且，在某些场景下，参数量是很重要的指标。比如在嵌入式或移动端场景下，磁盘空间极其有限，此时往往会对模型的参数量有比较严格的限制。在这种情况下，除了在设计时减少参数量，还可以通过压缩模型权重的方式进一步降低打包后模型的大小，但是这样会带来解压缩开销，会在一定程度上增加程序初始化的时间。\n2.2.3 访存量 访存量往往是最容易被忽略的指标，但它对推理性能有着极大的影响。访存量是指模型推理时所需访问内存的数据量，反应了模型对存储带宽的要求。访存量有时也称作MAC（Memory Access Cost）或者MOPs（Memory Operations），一般用Bytes（或KM/MB/GB）来表示，即模型需要读取/写入多少Bytes的内存数据。和计算量一样，模型整体访存量等于模型各个算子的访存量之和。\n2.2.4 运行速度 运行速度是衡量模型efficiency最有效的指标，但是需要基于相同的硬件平台进行对比，而且，即使使用相同的硬件平台，使用不同的软件环境、使用流水线的效率等因素也对最终的推理速度有极大的影响，所以往往在实践中难以直接进行比较。运行速度主要有两种形式进行反应：\n吞吐量（Throughput）：在单位时间内处理的样本个数，相当于可以并行处理的任务量，充分利用流水线可以极大提高模型推理的吞吐量。 延迟（Latency）：通常指单个样本或单个batch处理完成的时间，相当于串行处理一个任务所需要的时间。相对于吞吐量，流水线无法减少延迟。因此，对于需要实时推理的模型而言，需要考虑延迟而非提高吞吐量。 [Paper: THE EFFICIENCY MISNOMER]\n需要注意的是，使用单个指标对模型进行评估往往会导致不全面的结论，甚至评价指标无法真实地比较模型在硬件上的推理速度。比如在下图中，相较于其他网络，在保持类似精确度的情况下，EfficientNet具有相对较小的计算量（GFLOPs）和参数量（Million Parameters），但是模型的推理速度并没有相对于其他模型很明显的提升，甚至有时其他模型推理速度更快一些。虽然如此，但是固定某些指标进行比较，仍是一个相对公平的方法。而且通过分析模型的推理瓶颈，可以针对性的提升模型的某些指标，从而加速推理。\nPaper: THE EFFICIENCY MISNOMER Figure5\n2.3 Find the Bottleneck 不同的模型具有不同的特征，即使同一个模型的不同部分也有不同的特征，比如某些部分是计算密集性的，有些部分是访存密集型的，这里选取Bert和GPT-2两个典型的模型进行分析。\n为了综合衡量计算密集型与访存密集型，通常使用算数强度（arithmetic intensity，也称计算密度，计算强度，计算访存比等）来表示。算数强度表示从内存加载的每个字节可以进行的浮点运算的数量，反映了程序相对于访存而言计算的密集程度，可以通过计算量FLOPs除以访存量来计算得到。RoofLine模型是基于算数强度，来评估程序在硬件上能达到性能上界的模型，即给定一个硬件资源的限制（算力、内存带宽），模型在该硬件上可以达到的最大计算速度。\n当模型的计算密度较小时，访存相对较多，计算相对较少，模型性能主要受到内存带宽限制，此时模型是访存密集型的。反之如果模型的计算密度较大，访存相对较少，计算相对较多，模型性能主要受到硬件算力的限制，此时模型是计算密集型的。一般而言，模型的计算密度越大，越有可能提升硬件的计算效率，充分发挥硬件性能。对于访存密集型算子，推理时间跟访存量呈线性关系，而对于计算密集型算子，推理时间跟计算量呈线性关系。\nBlog: 深度学习模型大小与模型推理速度的探讨\n[Paper: Roofline: An Insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures]\nBERT是Encoder-only的模型，而GPT-2是Decoder-only的模型，如图a所示，这个区别导致两类模型的计算密度差异很大，而两种不同大小的BERT模型的计算密度差异反而不是很大。究其原因，是由于Decoder模型中，每次都是逐个token输入并解码，导致实际矩阵乘法退化为矩阵与向量的乘法，数据重用有限，使其更容易受到内存带宽的限制。因此，如图b所示，当使用高算力的硬件进行推理性能测试时，以BERT-Base的推理时间为基准，尽管相对于BERT-Base，GPT-2具有更少的计算量，但是由于访存量的激增，导致计算密度变低，最终在实际推理时，推理延时远远慢于BERT-Base。因此，针对模型进行优化时，需要综合不同的指标，分析模型的特点，找到模型的瓶颈，从而进行针对性的优化，才能对最终的推理性能有较大提升。\nBlog: LLM Inference CookBook\n[Paper: Full Stack Optimization of Transformer Inference: a Survey] Figure 6 9\n3. Efficient Transformer 虽然当前很多SOTA模型都是基于Transformer，而且很多大模型也都是以Transformer为基础，但是由于Transformer相对于输入序列的平方的复杂度，使得在很多需要长序列的场景中，比如处理图片、视频时受到很大的限制，因此很多方法被提出来改善模型的复杂度，比如降低模型的时间复杂度，减少模型的参数量，设计更适合于硬件的模型来减少访存等。本章节从三个不同角度来讨论使得模型在设计上更加高效的方法。\n3.1 Efficient Attention 注意力机制作为Transformer的核心，它使得模型可以捕捉全局信息，进行长距离建模。但是注意力机制最核心的操作是进行矩阵相乘，由于词向量维数一般固定且不是很大，可以认为是常数，因此时间复杂度可以认为是输入序列长度的平方。本节讨论一些方法，侧重于改善注意力机制的时间复杂度，并根据核心思想进行分类和总结。\nBlog: Transformers大家族——Efficient Transformers: A Survey\nBlog: 「ArXiv2020」【Efficient Transformers: A Survey】论文笔记（更新中）\nBlog: Efficient Transformers: A Survey\nBlog: 进击的Transformer \u0026mdash; 一文介绍Efficient Transformers\nFixed Patterns\n将注意力机制从全局变为局部，限制注意力机制的范围，从而降低复杂度。根据限制的范围和形式，可以分为blockwise pattern， strided pattern，compressed pattern。\nBlockwise pattern将输入序列切成多个block，只在每个block内部进行注意力机制的计算，显著降低了计算复杂度，比如Blockwise Attention、Local Attention等。但是这样简单的切割会导致序列不连贯，缺乏block之间的信息交互，注意力机制能力有限。虽然很简单，但是确实后续很多改进的基础。\nStrided pattern采用滑动窗口的形式，每个token与周围相邻的几个token计算注意力，即按固定间隔进行注意力机制的计算。比如，Sparse Transformer使用类似strided形式的滑动窗口，LongFormer使用类似dilated形式的滑动窗口。相较于Blockwise pattern，考虑到自然语言很多情况下都是局部相关性较高，因此在一个窗口范围内计算注意力可能不会丢失太多信息。\nCompressed pattern则是先通过卷积、池化等CNN操作进行下采样，从而有效减小序列长度，将输入序列转换到固定的模式，降低计算注意力机制的复杂度。\nBlockwise attn: Blockwise Self-Attention for Long Document Understanding\nLocal attn: Image Transformer\nSparse Trans: Generating Long Sequences with Sparse Transformers\nLongFormer: Longformer: The Long-Document Transformer\nCombination of Patterns\n对于输入的token，可以在不同维度、不同区域上组合使用不同的注意力机制，从而学习到更好的特征。比如，Sparse Transformer将一半的注意力头使用strided pattern，另一半注意力头使用local pattern。类似的，在Axial Tranformer中不是像多数注意力模块一样先将多维输入展平，而是每次沿着特征图的单个维度计算自注意力，然后组合多个维度的特征图以得到覆盖全局感受野的特征图。\nAxial Trans: Axial Attention in Multidimensional Transformers\nLearnable Patterns\nLearnable pattern是对fixed pattern的拓展，fixed pattern是提前规定好一些区域，在这些区域中进行注意力，而learnable pattern则是引入可学习参数，让模型自己找到计算注意力的区域，即以数据驱动的方式指导模型的学习过程。比如Reformer引入基于哈希的相似度度量方法来将输入进行切割，Routing Transformer对token向量进行k-means聚类，从而将整体序列分割为多个子序列。因此，从最后注意力计算的角度看，Learnable pattern与fixed pattern是一致的，都是通过将整体序列进行切分，只在子序列中计算注意力，不同的只是子序列的划分方式是提前确定的还是模型学习得到的。\nReformer: Reformer: The Efficient Transformer\nRouting Trans: Efficient Content-Based Sparse Attention with Routing Transformers\nNeural Memory\nNeural memory类似于compressed pattern中先压缩再计算注意力的想法，Set Transformer中第一次使用了这种方法。具体而言，就是初始化k个untrainable向量（k\u0026laquo;n），n个token embedding和这k个trainable向量计算注意力，压缩得到k个向量，然后k个向量再和n个向量计算注意力还原得到n个向量，达到抽取输入序列特征的目的。这k个untrainable向量就可以理解为memory，用于处理临时上下文信息。\nSet Trans: Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks\nLow-Rank\nLow-rank通过矩阵压缩或矩阵近似来降低计算注意力的复杂度。假设$N$是序列长度，$d$是向量维度，$k$是矩阵压缩的超参数。在Linformer中观察到，经过softmax计算之后得到的$N \\times N$的attention score矩阵是不满秩的，这意味着不需要一个完整的attention score矩阵，可以使用一个$N \\times k$的矩阵来近似$N \\times N$的attention score矩阵，同时需要将$N \\times d$的key和value向量映射到$k \\times d$维空间，由于$k$是固定的超参数，因此将注意力机制的复杂度降低到了线性级别。\nLinformer: Linformer: Self-Attention with Linear Complexity\nKernels\nBlog: 线性Attention的探索：Attention必须有个Softmax吗？\nLinear Trans: Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention\n之前的一些研究中提到制约注意力机制性能的关键因素是其中的softmax操作，Scaled-Dot Attention其实就是对value做加权平均，未来得到attention score，就必须先对query和key进行运算。但是，以核函数变换的形式可以得到一个更加通用的注意力机制的数学表达，通过将相似性度量拆分，可以实现注意力机制线性的复杂度（原来的相似度计算中，指数操作的存在使得query，key，value的矩阵操作无法使用结合律）。由于通过kernel方法计算得到的是注意力矩阵的一种近似形式，因此核方法也可以认为是一种特殊的low-rank方法。\nRecurrence\nRecurrence实际上也是fixed pattern中blockwise的一种延申，本质上仍是对输入序列进行区域划分， 只是它进一步对划分后的block做了一层训练连接，通过这样的层级关系就可以把一个长序列的输出得到更好的表征。Transformer-XL使用segment-level recurrence，将上一个segment的状态缓存下来，然后再计算当前segment的时候重复使用上一个的隐藏状态，虽然加快了推理速度，但是由于需要进行缓存，是一种空间换时间的方案。\nTransformer-XL: Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context\n3.2 Efficient Architecture Design 除了改善Transformer中注意力机制的复杂度，修改Transformer中其他部分可能同样有效。实际上，比如针对Bert-Base而言，从参数量的角度看，模型总的参数量约为104MB，其中多头注意力机制部分的参数量大约为27MB；从计算量和访存量的角度看，即使针对较长的序列而言，多头注意力机制部分也只是占了整个模型计算量/访存量的一半左右。因此，设计更加高效的网络架构，同样可以提高模型运行时的性能。同样，本节根据不同模型架构的设计思路和特点进行分类总结。\nBlog: Hydra Attention: Efficient Attention with Many Heads翻译\nBlog: 一文懂“NLP Bert-base” 模型参数量计算\n[Paper: Full Stack Optimization of Transformer Inference: a Survey] Table 3\n增加感受野\n通过增加感受野，模型可以处理更加高分辨率的图像，但同时需要尽量降低额外带来的计算量。Efficient-ViT使用MobileNetV2中的MBConv作为基本块，使用线性注意力机制替代传统注意力机制，并且在前馈神经网络中使用可变形卷积。EdgeNeXt与之相似，它使用分裂的深度转置注意力模块（Split Depth-wise Transpose Attention， SDTA）来替代传统的多头注意力机制，SDTA将输入通道分成多个通道组，利用深度可分离卷积和跨通道的自注意力来有效增加模型的感受野。\n[Paper: EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation]\n[Paper: EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications]\n[Paper: MobileNetV2: Inverted Residuals and Linear Bottlenecks]\n使用池化层\n通常在注意力机制之后使用池化层，来减少推理延迟。NextViT交替使用卷积块和注意力块，其中卷积块由多头卷积注意力和MLP构成，卷积块主要使用了多头自注意力机制，但是注意力机制中key和value都先经过了一个池化层。PoolFormer总结了一种成为MetaFormer的通用架构，通过使用不同的Token-Mixer可以获得不同的具体架构，当Token-Mixer被修改为一个简单的池化层时，PoolFormer以极少的参数同样获得了与其他模型相似的准确度。\n[Paper: Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios]\n[Paper: MetaFormer Is Actually What You Need for Vision]\n使用局部特征\nLeViT再次将充分使用CNN的局部特征，尤其是首先通过卷积来得到低分辨率的特征图，然后通过修改注意力模块进行特征图的下采样。MobileViT网络主要使用MobileViT块和MBConv块堆叠而成，其中MobileViT块负责进行全局信息与局部信息的交互，其中将特征图通过卷积层进行局部建模得到局部信息，然后将局部信息的特征图基于注意力机制进行全局建模，最后进行残差连接。\n[Paper: LeViT: a Vision Transformer in ConvNet’s Clothing for Faster Inference]\n[Paper: MobileViT: Light-Weight, General-Purpose, and Mobile-Friendly Vision Transformer]\n保持维度一致性\n相对于多头注意力机制角度的计算量对于推理延迟的影响，特征维度一致性对推理延迟同样甚至有更大的影响，比如网络中存在大量低效的reshape操作，反复调整特征的维度，会极大影响推理的速度。EfficientFormer提出了一种维度一致性的设计，将网络分成一个特征图为四维的部分和一个特征图为三维的部分，网络从patch embedding开始，首先进入四维特征图部分，最后进入三维特征图部分。在四维特征图部分，主要通过卷积结构为主；在三维特征图部分，此时网络结构中加入注意力机制和MLP结构。最终四维和三维分区的长度是通过网络架构搜索得到的。\n[Paper: EfficientFormer: Vision Transformers at MobileNet Speed]\n并行网络\n一些模型可以并行的执行特定的层，从而加快推理速度。比如Mobile-Former的两个并行分支分别提取局部和全局信息，通过双向桥接进行信息的双向融合。MixFormer基于并行分支设计，将局部自注意力和通道分离卷积两个分支进行交互，并且根据不同分支上操作共享参数的维度不同，使用双向交互模块融合不同维度的信息，针对每个分支提供互补的信息来进一步学习到更好的特征。\n[Paper: Mobile-Former: Bridging MobileNet and Transformer]\n[Paper: MixFormer: Mixing Features across Windows and Dimensions]\n3.3 Efficient Efforts 除了针对注意力机制和Transformer的架构进行改进，通用的模型压缩同样可以提高Transformer的推理性能，同时保持模型精度或将模型精度的下降控制在一个合理范围内。模型压缩主要包括剪枝、蒸馏、量化等。其中，剪枝和蒸馏可以减少模型参数量，量化可以提高模型的访存效率，而且不同的方法可以是正交的，即可以先进行模型的剪枝，再进行模型的量化。许多研究提出了不同的方法来进行Transformer模型的压缩，本节简单进行介绍。由于在自然语言处理领域和计算机视觉领域中，模型压缩的方法可能略有不同，本节更加侧重于视觉方面的模型压缩方法。\n此外，由于Transformer的广泛应用，为了提高模型的推理性能，在设计模型架构时有时需要将硬件也纳入考虑，比如考虑到硬件限制的网络架构搜索，软硬件协同设计等，虽然本综述不涉及硬件的描述，但是本节最后介绍一种针对GPU的新型注意力机制FlashAttention，通过优化注意力机制算法的访存过程，来显著提高模型的运行速度、降低所需内存，同时保持对结果不变和对用户的透明。\n3.3.1 Pruning 剪枝方法基于lottery ticket假设，即模型中只有小部分参数起到了核心作用，其他的大部分参数都是无效参数或是不重要的参数，可以去除掉，在减小模型参数量的同时，保持模型原有的精度。剪枝可以分为结构化剪枝与非结构化剪枝。非结构化剪枝允许修建任何参数，定位参数中接近于0的参数，将这些参数归零，使得权重矩阵稀疏化。虽然非结构化剪枝可以极大减少模型参数，但是由于硬件的限制，很多场景中无法完全发挥非结构化剪枝的效果。结构化剪枝是粒度较大的剪枝，修剪模型中结构化的部分，比如权重的整行，多头注意力中不需要的注意力头，多层Transformer中不需要的若干层等。由于存在一定限制，结构化剪枝的模型压缩率较小，但是更加适合于硬件运行。\n考虑到Transformer中大部分的计算量是在多头注意力（MSA）和前馈神经网络（FFN）部分，为了简Transformer的结构，Vision Transformer Pruning（VTP）是第一个专门用于Vision Tranormer的剪枝方法。VTP首先使用L1稀疏正则化进行训练，VTP获取每一个Transformer block中Dimension的重要性分数，然后对分数较低的Dimension进行裁剪，这样大量的不重要的Dimension将会被裁剪，最后进行微调。不同于VTP主要关注于通道维度的冗余，PS-ViT方法关注于patch层面的冗余，通过计算patch对于最终分类特征的重要性得分来判断每个patch的有效性，同时保证信息一致性，显著降低了计算量并保持了原始模型的精度。NViT在剪枝时将模型的推理时间纳入考虑，通过重分配使用的参数，进行全局结构性剪枝。后续模型分别针对剪枝范围和粒度、剪枝方法、剪枝过程等做出改进，进一步提高模型的推理性能。\n[Paper: THE LOTTERY TICKET HYPOTHESIS: FINDING SPARSE, TRAINABLE NEURAL NETWORKS]\n[Paper: Vision Transformer Pruning]\n[Paper: Vision Transformer with Progressive Sampling]\n[Paper: NViT: Vision Transformer Compression and Parameter Redistribution]\n3.3.2 Distillation 蒸馏是指用教师模型来指导学生模型训练，通过蒸馏的方式让学生模型学习到教师模型的知识。在模型压缩中，教师模型是一个提前训练好的复杂模型，而学生模型则是一个规模较小的模型。由训练好的教师模型，在相同的数据下，通过将教师网络对该样本的预测值作为学生模型的预测目标指导学生模型学习。通过教师模型的指导，让学生模型学习教师模型的泛化能力，以达到或媲美教师模型的准确度。\n在计算机视觉领域，DeiT在ViT的基础上，提出了一种专门针对Transformer的蒸馏方法，将distillation token与原始的class token同时加入网络，同时对损失函数进行相应的变化，显著减小了模型训练时间和训练所需的数据量。Mainfold Distiallation方法考虑了视觉Transformer的特点，在模型中间层引入了patch层级的细粒度监督信号，它是一种基于内积计算特征空间的流形结构表示，通过约束学生模型与教师模型的特征空间具有相似的流形结构，可以更好的将教师模型的知识迁移到学生模型中。TaT中进一步考虑到，由于教师模型和学生模型在结构上的异构型，直接对比像素级别的特征图可能导致不对齐的问题，因此使用注意力机制来隐式对齐语义，并提出一种近似的方法来改善方法的复杂度。\n[Training data-efficient image transformers \u0026amp; distillation through attention]\n[Learning Efficient Vision Transformers via Fine-Grained Manifold Distillation]\n[Knowledge Distillation via the Target-aware Transformer]\n3.3.3 Quantization 量化的基本思想即使用低精度、低比特的数据类型来代替原本的浮点数据类型，可以量化参数权重，也可以量化激活值，不但显著减小了模型的体积，更为重要的意义是优化了模型在运行时的访存，相较于单个指令的计算，访存耗时要远高于计算，因此可以显著加速模型推理。量化最核心的挑战在于使用更低精度的权重的同时保持模型精度尽可能少的降低。量化主要分为两大类，训练后量化（Post-Training Quantization，PTQ）和量化感知训练（Quantization-Aware Training，QAT）。训练后量化是将训练好的模型中的参数或激活值量化为低精度类型的数值类型，虽然使用简单，但是模型精度精度下降一般要高于量化感知训练。量化感知训练在训练过程中模拟量化过程，进而在更新参数时考虑量化产生的误差，虽然量化感知训练得到的量化模型精度下降较低，但是因为需要重新训练，所以开销较大，在实际使用中需要进行权衡使用。\n虽然在卷积神经网络中可以相对简单的使用量化，但是将量化应用于Transformer存在一些挑战。Transformer激活值范围较大，很难使用低精度数据类型表示。传统的卷积神经网络会将异常的离群值截断，但是在Transformer中，这样的离群值有助于深层网络中形成特定的注意力模式，直接截断会改变网络的特性和精度，如果不截断会导致数值分辨率降低，而且注意力机制中存在一些难以量化的算子，进一步导致Transformer模型难以量化。PTQ4ViT提出了使用孪生均匀量化方法来解决激活值范围大的问题，同时为了获得最优的量化参数（而非局部最优），使用Hessian引导度量来评估不同的标定因子，从而以较小的成本提高校准准确率，最终达到了近乎无损的量化效果。针对部分算子难以量化的问题，FQ-ViT中使用Power-of-Two Factor（PTF）来量化LayerNorm，使用Log-Int-Softmax（LIS）来量化softmax，并使用4位量化和BitShift来进行简化，这也是第一个实现Transformer无损全量化的工作。\n[Understanding and Overcoming the Challenges of Efficient Transformer Quantization]\n[PTQ4ViT: Post-Training Quantization Framework for Vision Transformers with Twin Uniform Quantization]\n[FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer]\n3.3.4 FlashAttention FlashAttention是一种对标准注意力机制进行加速的算法，减少了对HBM（High Bandwidth Memory，通常用于GPU显存）的访问，而且它的训练和推理过程的结果和标准注意力机制完全相同，对用户透明，并且显著减小了标准注意力机制的运行时间和所需内存。\nFlashAttention主要从两个方面减少注意力机制的HBM的访问。首先在计算softmax时，FlashAttention可以在不访问整个输入的情况下计算softmax reduction，将输入分割成块，在输入块上多次传递，从而以增量的方式计算softmax reduction。其次，在传统注意力机制中，需要将$QK^T$的计算结果$S$和$softmax(S)$后的计算结果$P$分别存储到显存中，FlashAttention对此做出改进，在反向传播中不存储中间注意力矩阵，避免从显存中读取和写入中间结果矩阵。通过分块写入到HBM中去，存储前向传递的 softmax 归一化因子，在后向传播中快速重新计算片上注意力，这比从HBM中读取中间注意力矩阵的标准方法更快。即使由于重新计算导致 FLOPS 增加，但因为减少了HBM访问，导致运行速度更快并且使用更少的显存（序列长度线性）。\n此外，最新的研究SCFA进一步进行拓展，使得FlashAttention可以计算稀疏注意力，特别是针对Hash-based Attention和Query/Key-Dropping Based Attention，都得到了显著的推理加速。\nBlog: 论文分享：新型注意力算法FlashAttention\n[Paper: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness]\n[Paper: Faster Causal Attention Over Large Sequences Through Sparse Flash Attention]\n4. Discussion on Future Research Transformer虽然有很强的建模能力，但是由于其中注意力机制具有序列长度平方的复杂度，限制了Transformer在很多场景中的使用。在未来的工作中，仍然可能会有很多工作对efficient attention、efficient transformer、模型压缩的不同方面进行改进。除此之外，本文观察到另外两个方向未来可能有进一步的发展。\n4.1 Early Exit 虽然当前很多研究关注于大模型在大量数据上的有效训练，但是经过训练的模型在实际使用中仍然速度较慢，特别是大模型作为基础设施时，越来越多的关注集中于提高模型的推理速度上。从模型来分析，很多大语言模型都是自回归模型，需要根据前面的单词递推的预测下一个单词，这个过程不能并行化，而且考虑到大模型庞大的参数量，整个推理过程需要大量的计算与较高的延迟。\n在推理时，有些单词的预测比较轻松，可能在比较浅层的网络中就可以预测出正确的结果，不用计算到最后一层就可以正确预测，即提前退出（early exit），有的单词就需要较多的计算才能预测，但是很多模型在推理时针对这两种情况使用了相同的计算量。有一些工作已经初步在这方面进行了尝试，比如CALM，不是等待所有解码器层完成，而是尝试在某个中间层之后更早地预测下一个单词。 为了决定是进行某个预测还是将预测推迟到后面的层，测量模型对其中间预测的置信度。 只有当模型有足够的信心预测不会改变时，才会跳过其余的计算。\n[Paper: Confident Adaptive Language Modeling]\nBlog: 基于动态提前退出的预训练模型推理加速简介\n4.2 Alternatives to Attention 虽然注意力机制对于Transformer而言至关重要，但是由于其较高的复杂度，一些研究开始寻找注意力机制的替代而非单纯改进注意力机制。在AFT模型中，同样有类似于标准的点积注意力算法，同样由查询向量Q，被查向量K，内容向量V相互作用而成。但不同的是，AFT中的K和V首先与一组学习得到的位置偏差（position bias）结合，然后再进行同位元素对应相乘（element-wise multiplication）。这一新操作的内存复杂度、文本规模、特征维度都是线性的。当前一个较新的尝试是Hyena。Hyena将时域卷积和频域卷积作为一个组合，通过递归进行多次来增大表达能力，其全局卷积网络达到了超越Transformer建模的效果。\n[Paper: An Attention Free Transformer]\n[Paper: Hyena Hierarchy: Towards Larger Convolutional Language Models]\n5. Conclusion 在本综述中，从推理的角度出发，对efficient transformer进行了粗粒度的调研、分析与总结，并且相对侧重于计算机视觉方面的研究。首先介绍模型不同角度的efficiency和评价efficiency的量化指标。然后从模型算法的角度，从不同层次分析了当前提高模型效率的方法，比如设计复杂度更低的注意力机制，更加高效的网络设计，模型压缩和优化等方法，并针对每种方法进一步做了分类和总结，选取代表性的方法进行具体说明。最后，简单讨论了一些efficient transformer未来可能的发展方向，比如早退机制、注意力机制的替代品等。\n6. More Reading Large Transformer Model Inference Optimization\nThe Transformer Family Version 2.0\nEfficient transformers: Survey of recent work\nBert/Transformer模型压缩与优化加速\n","permalink":"https://qinganzhang.github.io/posts/a_survey_of_efficient_transformer_on_inference/","summary":"Abstract Transformer模型架构在自然语言处理、计算机视觉、强化学习等领域表现出了强大的能力，已经成为当前深度学习很多模型的核心，当前发展迅","title":"A survey of Efficient Transformer on Inference"},{"content":"1. tmux简单介绍 xshell等工具SSH远程登录服务器时，终端窗口（显示界面）和会话（用户与服务器的交互命令）是绑定的，关闭窗口会话也随之结束。tmux可以将窗口和会话分离，关闭窗口后，会话不终止，下次重新打开窗口可以继续绑定上次的会话。\n界面说明：\n左下角，方括号中为会话编号或名称，后面是窗口编号和名字，星号*表示当前所处窗口\n2. 常用命令 2.1 会话管理 新建会话\n1 2 tmux # 会话编号自动从0开始 tmux new -s \u0026lt;session-name\u0026gt; # 自定义会话名称 将会话与窗口分离：Ctrl+b d或者tmux detach\n查看会话：tmux ls\n接入会话： tmux attach -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;\n杀死会话：tmux kill-session -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;\n退出会话：Ctrl+b d\n切换会话：tmux switch -t \u0026lt;session-name\u0026gt;/\u0026lt;session-id\u0026gt;或者Ctrl+b s\n重命名会话：tmux rename-session -t \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt;或者Ctrl+b $\n2.2 窗口（window）管理 新建窗口：tmux new-window -n \u0026lt;window-name\u0026gt;或者Ctrl+b c 切换窗口： tmux select-window -t \u0026lt;window-name\u0026gt;/\u0026lt;window-id\u0026gt; Ctrl+b p/n切换上一个/下一个窗口 Ctrl+b l：在两个窗口之间来回切换。 Ctrl+b \u0026lt;window-id\u0026gt;切换指定窗口 Ctrl+b w从列表中选择窗口 当前重命名窗口：tmux rename-window \u0026lt;new-name\u0026gt;或者Ctrl+b , 关闭当前窗口：Ctrl+b \u0026amp; 2.3 窗格（pane）管理 划分窗格：\n左右划分Ctrl+b % 上下划分Ctrl+b \u0026quot; 切换选中窗格：\nCtrl+b \u0026lt;方向键\u0026gt; 切换到下一个窗格Ctrl+b o\t切换到上一个窗格Ctrl+b ;\n交换窗格：\n与上一个窗格交换位置Ctrl+b {\t与下一个窗格交换位置Ctrl+b }\n关闭窗格：\nCtrl+b x\n调整窗格：\nCtrl+b Ctrl+\u0026lt;方向键\u0026gt;：按方向调整窗格大小\nCtrl+b z：当前窗格全屏显示（临时），再用一次复原\nCtrl+b !：将当前窗格拆分为独立的窗口\n其他：\nCtrl+b q：显示窗格编号\nCtrl+b [：进入翻屏模式，实现上下翻页\n2.4 其他 Ctrl+b ?：帮助命令 tmux list-keys列出所有快捷键和对应的tmux命令 3. 参考资料 Tmux 使用教程-阮一峰\nLinux 终端复用神器 Tmux 使用详解，看完可以回家躺平了～\n","permalink":"https://qinganzhang.github.io/posts/tmux%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","summary":"1. tmux简单介绍 xshell等工具SSH远程登录服务器时，终端窗口（显示界面）和会话（用户与服务器的交互命令）是绑定的，关闭窗口会话也随之","title":"Tmux简单使用"},{"content":"1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从energy看 访存消耗energy远多于计算（200倍） 浮点数运算消耗energy多于int8类型（十几倍），因此量化有助于keep efficient 2. 数值类型（浮点数） FP32：1+8+23 FP16：1+5+10，通常使用在混合精度训练中 BF16：1+8+7，直接将FP32进行截断，方便直接进行转换 TF32：1+8+19，保留了FP32的范围（8位范围）与FP16的精度（10位精度），用于TensorCore中 FP24： 3. 量化基础 K-Means-based Quantization\n原理：权重进行kmeans聚类（每个类别cluster视为一个模式），每个cluster对应一个浮点数，构成一个codebook（lookup table），权重矩阵中保存的是codebook中的索引 微调过程：给定权重矩阵对应的梯度矩阵，将梯度矩阵按照模式进行分组（对应不同的cluster），每组梯度进行求和，再更新codebook中对应cluster的浮点数 效果： 从pruning ratio看：剪枝+量化同时使用，可以获得更小的pruning ratio（量化后再微调一下，有助于恢复精度） 从准确率看：剪枝+量化准确率与只进行量化差不多 优化：霍夫曼编码 将更频繁的权重使用更短的编码表示（但是这样会导致权重矩阵中各个元素大小不一❓） 特点：量化后存储的是低比特，但是计算仍然是浮点数（只是节省了存储，但是访存翻倍❓） Linear Quantization\n原理：直接进行映射，相当于线性的codebook，权重矩阵中存储的是量化值，运算时先反量化到浮点数范围、再使用不同的量化参数量化到int8 $$ 量化：\u0026amp;uint \u0026amp;=\u0026amp; round( \\frac{float}{scale} + offset) \\ 反量化：\u0026amp;float \u0026amp;=\u0026amp; (uint - offset) * scale $$\ntricks：\n公式中的很多部分可以pre-compute\nscale的浮点乘法可以转换为定点小数的位移\n详见Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference 第2.2章\n神经网络量化入门\u0026ndash;基本原理\n量化推理是如何把scale转换为定点运算的\n分类\n对称量化 非对称量化（由于补码负数比正数多一个，因此区分两种模式，构造成左右对称的形式，不同框架可能使用不同的mode） full range mode：正数128加进来 restricted range mode：负数-128去掉 特点：量化后存储的是int8，计算中也是int8\n4. 量化种类 4.1 Post-Training Quantization(PTQ) 权重量化Weight Quantization：减小模型大小\nPer-tensor vs Per-channel\nWeight Equalization\n背景：\nPer-tensor量化简单，但是由于channel之间range差异较大，导致效果很差 Per-channel量化效果较好，但是需要特殊硬件支持❓ 目标：make weight ranges similar (or equalize the weight range), so that per-tensor quantization can be applied（既想要per-tensor的简单，又想要per-channel的效果） 原理：positive scaling equivariance伸缩等价性\n对于conv、fc和relu，满足：\n$$f(s x) = s f(x), where \\quad s \\gt 0 $$\n方法：对于连续的两个卷积层，第一个卷积层乘上一个scale，第二个卷积核对应通道除以一个scale，这样与原来是等价的，但是调整了第一个卷积核的range；然后逐渐连续地调整\n后量化训练-Data free quantization\nAdaptive Rounding\n背景：\n看似符合直觉的round-to-nearest其实精度并不是最优的\n因为并非每个单独的weight的量化损失越小越好，weight之间存在相互影响\n方法：Adaptive地决定weight量化时将浮点数转到最近右定点还是最近左定点❓\nAdaRound解读\n激活值量化Activation Quantization：减小内存占用\n目标：由于激活值无法提前确定，因此要找到激活值的$r_{min}, r_{max}$\nDuring Training\nEMA\n在训练时使用exponential moving averages (EMA)来得到$r_{min}, r_{max}$ $$ \u0026amp;\\hat{r} ^ {(t)} _ {max, min} = \\alpha r ^ {(t)} _ {max, min} + (1 - \\alpha) \\hat{r} ^ {(t-1)} _ {max, min} \\ \u0026amp;其中 \\hat{r} ^ {(t)} _ {max, min} 是EMA激活值范围， \\ \u0026amp;r ^ {(t)} _ {max, min} 是 epoch=t时的激活值范围 $$\nQuantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference 3.1段\nUse calibration after training\n统计calibration中每个sample的$r_{min}, r_{max}$，然后取平均\nACIQ\n基本思想：最小化激活值X与量化值Q（X）的MSE，具体假设原始激活值的分布，展开求导 $$ \\mathop{min}\\limits_{|r|_{max}} \\mathbb{E} \\left[ (X - Q(X))^2 \\right] $$\nCNN后量化方法：ACIQ\nPost training 4-bit quantization of convolutional networks for rapid-deployment\n缺点：需要假设原始的激活值浮点分布（因为需要密度函数）\nKL-divergence based\n基本思想：使用KL散度来衡量量化的信息损失（原始激活值的分布与量化后的分布）\nTensorRT INT8量化原理与实现（非常详细） 第七部分\n偏置量化Bias Quantization\n背景：权重量化之后，权重分布会产生一个shift。一方面希望量化误差尽量小，另一方面希望量化误差的期望为0（但并非如此）\n后训练量化——Data free quantization 中Bias Correction，可以看到蓝色的量化误差明显左偏\n方法：\n如果当前有数据：全精度和量化模型分别跑一遍，bias减去这个量化误差，注意对于每一个卷积层或全连接层都要跑一遍 如果当前没有数据： 4.2 Quantization Aware Training(QAT) K-means-based Quantization 微调\nSTE方法：\n想法：权重信息经过伪量化操作，来模拟产生量化误差，反向传播的梯度信息跳过伪量化节点直接更新原始权重，相当于更新权重信息考虑到了量化误差、梯度下降进行优化\n过程：\n拿到训练好的模型\n在权重、激活值、输入输出等（对应权重量化与激活值量化）前面插入伪量化节点（将浮点权重量化再反量化，模拟推理时的量化）\n一开始伪量化节点中量化参数是怎么来的？\n在微调的forward过程中，顺便计算出量化参数：\n如果是针对权重的量化：直接统计权重中的最小值、最大值，从而计算量化参数 如果是针对激活值的量化：使用指数移动平均EMA来更新量化参数 前向推理，模拟量化的过程\n反向传播：正常更新权重（权重是浮点类型），相当于梯度信息跳过了伪量化节点\n神经网络量化入门\u0026ndash;量化感知训练\n量化感知训练（Quantization-aware-training）探索-从原理到实践\n再读《神经网络量化白皮书》- 0x04 训练时量化(QAT)\nLSQ方法：在反向传播时可以更新量化参数\n量化训练之可微量化参数—LSQ\n5. 低比特量化 Binary Quantization Ternary Quantization Mixed-Percision Quantization 参考：\nMIT 6.S965 韩松课程 05 闲话模型压缩之量化（Quantization）篇 ","permalink":"https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/","summary":"1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener","title":"量化基础"},{"content":"Java编译技术分析 ​\tJava程序在运行时首先需要进行前端编译，传统的方法是将Java字节码进行解释执行。为了提高性能，JIT编译通过分层编译热点代码，结合诸多优化方法，在很多场景中性能得到显著的提高。在云原生的场景中，JIT方法面临冷启动的局限，因此AOT受到越来越多的关注。Java AOT是近几年较新的一个Java编译方法，GraalVM Native Image是当前一个主流的实现方法，它将Java字节码编译为平台相关的二进制代码，将Java的动态编译转变为静态编译，以适应云原生等场景。在文章最后将JIT与AOT进行了简单的对比。\n1. 传统Java编译和运行 1.1 Java编译 ​\t编译一般是指将高级程序设计语言转换为计算机硬件能识别的机器语言，以便计算机进行处理和实现人类的易读性，而解释是指将源代码逐条转换为目标代码并逐条运行的过程。针对Java语言而言，Java程序运行的过程中同时包括编译与运行，第一个阶段是在编译阶段，将Java代码编译成Java字节码，这个过程通常叫做前端编译，比如使用Oracle的javac编译器进行编译；第二个阶段是在运行时，通过JVM将Java字节码逐条运行。Java编译主要在第二个阶段有不同的类型，比如JIT和AOT，这两种方法会在后续进行介绍。第一个阶段的转换过程大体与其他编程语言类似，下面简单进行介绍。\n​\t前端编译主要是将源代码转换为中间代码的过程，大体分为以下几个过程。首先通过词法分析分析出句子中各个单词的词性或者词类，将程序划分为词法单元（即Token）。接下来通过语法分析从上面输出的Token流中识别出各类短语，并构造语法分析树。然后进行语义分析，手机标识符的属性信息，同时进行语义检查，最后生成中间代码。各种编程语言的前端编译大体类似。\n1.2 Java运行 ​\t经过传统的Java编译后，得到了Java字节码，即Class文件，Java字节码由操作码和操作数组成，Java通过Java字节码实现了平台无关性，一次编写，到处运行。当使用java命令运行Class文件时，相当于启动了一个JVM进程，JVM中的执行引擎（中的解释器）将平台无关的字节码转换为机器码。JVM采用基于栈的结构，同样分为堆和栈。比如我们现在运行到了 main 方法，就会给它分配一个栈帧。当退出方法体时，会弹出相应的栈帧。\n2 Java即时编译（JIT） 2.1 JIT运行过程 ​\t传统的Java运行过程是JVM解释器逐条代码翻译运行Java字节码，所以在性能上Java通常不如C++这类编译型语言。为了优化Java的性能，根据“二八定律”（少部分代码占据了程序的大部分运行时间），JVM在解释器之外引入了即时（Just In Time）编译器：当程序运行时，解释器首先发挥作用，代码可以直接执行。随着时间推移，即时编译器逐渐发挥作用，把越来越多的代码编译优化成本地代码，来获取更高的执行效率。解释器这时可以作为编译运行的降级手段，在一些不可靠的编译优化出现问题时，再切换回解释执行，保证程序可以正常运行。\n​\t使用JIT后，Java代码的执行过程分为两个部分。第一步同样是进行前端编译，转换成Java字节码。第二部分中，在程序解释运行的过程中，部分代码在一定时间内调用或循环次数超过一定的阈值后，该段代码被认为是热点代码，JIT会编译热点代码并存入codeCache中。当下次要执行该段代码时，直接从codeCache中读取执行，以此来提升运行的性能。简单说，JIT就是将代码经过预热之后，将热点代码进行编译，整体的执行过程大致如 图 1 JIT编译过程 所示。\n图一 JIT编译过程 2.2 分层编译 ​\tJIT大体分为两个部分或两种模式：C1编译模式与C2编译模式，分别对应了两种不同的编译器：Client Compiler和Server Compiler。Client Compiler（或C1编译器）注重启动速度和局部的优化，Server Compiler更关注全局的优化，性能更好但是编译时间也更久。\n​\t具体来说，C1编译器会对字节码进行以下的优化：进行局部简单可靠的优化（比如方法内联、常量传播等），将字节码构造成高级中间表示（HIR，HIR与平台无关，通常采用图结构），将HIR转换为低级中间表示（LIR）、C2编译器会进行一些全局性的、更激进的优化（比如循环变换等）。从JDK9开始，C2编译模式除了Server Compiler，还可以选择Graal编译器，该编译器会进行分支预测、虚函数内联等优化，相对Server Compiler优化更加激进，峰值性能更好。\n​\tC1编译器和C2编译器和解释器可以相互进行组合，即分层编译。Java7开始引入了分层编译的概念，对于需要快速启动的，或者一些不会长期运行的服务，可以采用编译效率较高的C1；长期运行的服务，或者对峰值性能有要求的后台服务，可以采用峰值性能更好的C2。分层编译将JVM的执行状态分为了五个层次（如 图二 常见编译路径 中横向阶段）：\n​\t0层：解释执行\n​\t1层：执行不带profiling的C1代码\n​\t2层：执行仅带方法调用次数和循环回边执行次数profiling的C1代码\n​\t3层：执行带所有profiling的C1代码\n​\t4层：执行C2代码\n​\t其中profiling就是收集能够反映程序执行状态的数据。其中最基本的统计数据就是方法的调用次数，以及循环回边的执行次数\n根据实际中不同层次进行组合的情况，常用的有五种路径或组合方式（如 图二 常见编译路径 中纵向路径）：\n​\t路径①：编译的一般情况，热点方法从解释执行到被3层的C1编译，最后被4层的C2编译。\n​\t路径②：如果方法比较小（比如Java服务中常见的getter/setter方法），3层的profiling没有收集到有价值的数据，JVM就会断定该方法对于C1代码和C2代码的执行效率相同，在这种情况下，JVM会在3层编译之后，放弃进入C2编译，直接选择用1层的C1编译运行。\n​\t路径③：如果C1编译器忙碌，就在解释执行过程中对程序进行profiling ，根据信息直接由第4层的C2编译。\n图二 常见编译路径 ​\t路径④：如果C2编译器忙碌，因为C1阶段运行速度快，这时方法会被2层的C1编译，然后再被3层的C1编译，以减少方法在3层C2的执行时间。\n​\t路径⑤：如果编译器做了一些比较激进的优化，比如分支预测，在实际运行时发现预测出错，这时就会进行反优化，重新进入解释执行\n​\t总的来说，C1的编译速度更快，C2的编译质量更高，分层编译的不同编译路径，也就是JVM根据当前服务的运行情况来寻找当前服务的最佳平衡点的一个过程。从JDK 8开始，JVM默认开启分层编译。\n2.3 编译优化 ​\tJIT会对正在运行的服务进行一系列的优化，包括字节码解析过程中的分析，根据编译过程中代码的一些中间形式来做局部优化，还会根据程序依赖图进行全局优化，最后才会生成机器码。下面简要介绍一些常用的优化方法。\n2.3.1 方法内联 ​\t方法内联，是指在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。JIT大部分的优化都是在内联的基础上进行的，方法内联是即时编译器中非常重要的一环。\n​\tJava服务中存在大量getter/setter方法，如果没有方法内联，在调用getter/setter时，程序执行时需要保存当前方法的执行位置，创建并压入用于getter/setter的栈帧、访问字段、弹出栈帧，最后再恢复当前方法的执行。内联了对 getter/setter的方法调用后，能将对getter、setter的访问优化成单一内存访问。\n​\t内联是JIT提升性能的主要手段，但是虚函数使得内联是很难的，因为在内联阶段并不知道他们会调用哪个方法。C2编译器会优化单个实现方法的虚函数调用，但是无法优化多个实现方法的虚函数调用。\n2.3.2 逃逸分析 ​\t逃逸分析是一种确定指针动态范围的静态分析，它可以分析在程序的哪些地方可以访问到指针。JIT会对新建的对象进行逃逸分析，判断对象是否逃逸出线程或者方法。根据逃逸分析的结果进行诸如锁消除、栈上分配以及标量替换的优化。\n​\t锁消除即如果JIT能够证明锁对象不逃逸，那么对该锁对象的加锁、解锁操作没就有意义，可以进行锁消除。\n​\t栈上分配是如果逃逸分析能够证明某些新建的对象不逃逸，那么JVM完全可以将其分配至栈上，并且在new语句所在的方法退出时，通过弹出当前方法的栈桢来自动回收所分配的内存空间。这样一来，我们便无须借助垃圾回收器来处理不再被引用的对象。在Hotspot虚拟机中，并没有进行实际的栈上分配，而是使用了标量替换这一技术，编译器会在方法内将未逃逸的聚合量分解成多个标量，以此来减少堆上分配。\n3 Java提前编译（AOT） ​\tJIT会对正在运行的服务进行一系列的优化，包括字节码解析过程中的分析，根据编译过程中代码的一些中间形式来做局部优化，还会根据程序依赖图进行全局优化，最后才会生成机器码。下面简要介绍一些常用的优化方法。\n3.1 背景 ​\tJIT编译经过不断的发展，在某些情况下性能甚至可以编译型语言相比，但是冷启动开销较大（即需要经过虚拟机初始化后才能达到可用状态，再经过程序预热才能达到最佳性能）的问题是JIT难以解决的一个问题，这个问题在某些情形下显得尤为重要。比如云原生场景下，Serverless 服务本身执行时间短，Serverless 应用强调微服务架构，服务的粒度小，耗时短。与短暂的应用执行时间相比，冷启动的开销耗时所占比重增大，甚至可能比程序执行时间还要长，因此冷启动对应用的影响也到了不可忽视的程度。\n3.2 运行过程与分析 ​\tJava AOT与C++的编译过程比较类似，它首先仍需要将Java程序进行前端编译，转换为Java字节码。然后使用静态编译器将字节码编译为平台相关的二进制可执行代码，最后执行。\n​\t相较于JIT，Java AOT（Ahead Of Time）是一个近年来较新的解决方案，GraalVM Native Image是Oracle官方首推的AOT解决方案，它摈弃了JVM，将Java像C++一样编译成机器代码来执行。GraalVM是Oracle在2019年推出的新一代UVM（通用虚拟机），它在HotSpotVM的基础上进行了大量的优化和改进，主要提供了两大特性：多语言支持（可以在GraalVM中无缝运行多种语言）与高性能（提供了一个高性能的JIT引擎和SubstrateVM）。下面简单介绍一下这个特定的Java AOT方案。\n​\tNative Image 是一种将 Java 代码提前编译为独立可执行文件（称为Native executable）的技术，即Native Image是基于GraalVM的AOT。Native Image的输入是整个应用的所有组件，包括应用本身的代码、各种依赖的库、JDK库、以及Substrate VM（Substrate VM是一个包含内存管理、线程调度等的运行时系统），然后会进行三个步骤（如 图三 Native executable构建过程 所示）：\n图三 Native executable构建过程 3.3 动态特性 ​\tSubstrate VM除了实现内存管理、线程映射等底层能力之外，还需要以静态的方式实现Java的动态特性，以保持JDK接口层面的兼容性和功能的等价性。例如反射是Java中使用非常广泛的动态特性，Substrate VM通过预执行、编译时和运行时三个阶段的配合对其实现了有条件的静态化支持。\n​\t静态分析无法得到反射的目标，所以静态分析得到的可达代码中缺少了反射的目标类、函数和域。Substrate VM需要用户在编译时额外提供关于反射的信息——被称为元数据配置，以帮助Substrate VM编译出正确的程序。元数据配置可以由用户手动编辑，但是考虑到在实际项目中手工编辑是不现实的，所以Substrate VM提供了native-image-agent，可以在挂载在应用程序上，将运行过程中遇到的所有反射都记录下来自动生成静态编译需要的配置文件。将通过agent得到配置的过程称为预执行，预执行时不但记录了反射信息，还记录了序列化、动态类加载和动态代理等动态特性的数据。\n​\t解析出来这个配置文件以后，就可以知道反射什么东西了，将反射的东西注册上去，也就是将可达性的范围进行了扩张，也就扩大了编译的范围。有了配置提供的反射数据，编译时一方面将反射目标注册为可达，扩大了代码可达范围；另一方面将反射调用替换为直接调用，使得在运行时可以在原本用反射调用的位置实现了直接调用。\n3 不同编译方法的对比和应用 ​\t传统的单纯解释方法已经逐渐淘汰，现在主流的方法是基于JIT的编译方法，因此下面主要讲JIT与AOT进行对比。\n​\tJIT吞吐量高，有运行时性能加成，程序运行更快，并可以做到动态生成代码等，但是相对启动速度较慢，并需要一定时间和调用频率才能触发 JIT 的分层机制。AOT内存占用低，启动速度快，可以无需 runtime 运行，直接将 runtime 静态链接至最终的程序中，但是无运行时性能加成，不能根据程序运行情况做进一步的优化，而且对动态特性的支持是有限的，部分Java的机制不再适用，且与平台相关。\n​\t总的来说，JIT与AOT是面向于不同场景下的编译方法。在传统服务器部署的场景中，应用执行时间足够长，冷启动问题就被淡化了，而且还可以提前将服务预热准备好，以最好的状态迎接用户的服务请求，因此可以充分发挥JIT的性能。而Serverless 服务本身执行时间短。Serverless 应用强调微服务架构，服务的粒度小，耗时短。与短暂的应用执行时间相比，冷启动的开销耗时所占比重增大，甚至可能比程序执行时间还要长，因此冷启动对应用的影响也到了不可忽视的程度，此时使用AOT更合适。\n","permalink":"https://qinganzhang.github.io/posts/java%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/","summary":"Java编译技术分析 ​ Java程序在运行时首先需要进行前端编译，传统的方法是将Java字节码进行解释执行。为了提高性能，JIT编译通过分层编","title":"Java编译技术分析"},{"content":"编程模型 线程组织层次 grid 网格\n由一个内核函数启动所产生的所有线程统称为一个网格(grid)\ngrid size和block size都是三维结构，dim3类型\n数据类型dim3是基于uint3定义的：\n比如在主机端配置核函数grid size和block size时，数据类型为dim3类型，此时变量可以进行修改 比如核函数在运行时，在设备端查询grid size和block size时，此时数据类型为uint3，此时变量已经固定无法修改 三维网格grid_size(gridDim.x, gridDim.y, gridDim.z) 三维线程块block_size(blockDim.x, blockDim.y, blockDim.z) thread block 线程块\n一个grid可以分为很多个thread block，由blockIdx定位 线程块大小（block size，每个block中线程数量）为1024 warp（thread）\n一个thread block中包含很多thread，每相邻的32个（warpSize）thread组成一个warp 每个thread可以由线程块idblockIdx和线程idthreadIdx唯一确定，同样也是三维结构 函数 核函数 核函数配置：\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, shared_memory_size, stream\u0026gt;\u0026gt;\u0026gt;\n核函数的启动都是异步的，host只是启动（或launch）核函数\n可以使用cudaDeviceSynchronize进行显式同步，或者进行隐式同步 核函数的语法相关：\n返回类型必须是 void 必须使用限定符 __glolbal__，也可以加上 c++ 限定符（比如static）； 核函数支持 c++ 的重载机制； 核函数不支持可变数量的参数列表，即参数个数必须确定； 一般情况下，传给核函数的数组（指针）必须指向设备内存（“统一内存编程机制”除外）； 核函数不可成为一个类的成员（一般以包装函数调用核函数，将包装函数定义为类成员）； 在计算能力3.5之前，核函数之间不能相互调用；之后，通过“动态并行”机制可以调用； 有时启动的线程数量多于数组元素个数，因此通常使用if语句进行控制\n设备函数 核函数可以调用不带执行配置的自定义函数，即设备函数。\n函数执行空间标识符（函数类型限定符）：确定一个函数在哪里被调用，在哪里被运行：\n区分变量类型限定符：__device__全局内存，__shared__共享内存，__constant__常量内存，__managed__统一内存\n__global__修饰的函数称为核函数，一般由主机调用、在设备中执行； __device__修饰的函数称为设备函数，只能被核函数或其他设备函数调用、在设备中执行； __host__修饰主机端的普通 c++ 函数，在主机中被调用、在主机中执行，一般可以省略； 相关语法：\n设备函数可以有返回值 不能同时用 __global__ 和 __device__ 修饰函数（即一个函数不能同时是核函数和设备函数） 不能同时用 __global__ 和 __host__ 修饰函数（即一个函数不能同时是核函数和主机函数） 可以同时用 __host__ 和 __device__ 修饰函数，从而减少代码冗余，此时编译器将分别在主机和设备上编译该函数，生成两份不同的机器码 可以通过 __noinline__ 建议编译器不要将一个设备函数当作内联函数； 可以通过 __forceinline__ 建议编译器将一个设备函数当作内联函数。 内存模型 执行模型 并行方式 指令级并行：如果某个warp中两条指令相互独立，则可以依次发射，进行指令级并行 线程并行方式：SIMT SIMD：比如向量运算指令 一个线程可以同时处理多个数据，但是当前只使用一个ALU。比如使用ARM指令拓展NEON中的向量加指令，可以同时进行四个int的相加 多个数据使用使用相同的指令一起执行 SIMT 从硬件上看，所有的core有各自的执行单元（与SIMD共用一个ALU不同） 从软件上看，每个线程都有自己的指令计数器、寄存器，因此每个线程可以有自己独立的执行路径 尽管一个warp中的所有线程在相同的程序地址上同时开始执行，但是单独的线程仍然可能有不同的行为 warp并行方式：SM上同一个线程块的多个warp，通过大量的core实现并行，通过调度和流水线实现并发和并行 执行模型 host启动核函数，GPU异步执行\nGPU根据运行配置，GPU将启动的核函数作为一个grid，并划分为线程块\n一个线程块分配到一个SM执行，多个线程块可以分配到同一个SM执行，但是一个线程块无法分配到多个SM 线程块划分为warp\n由于资源和硬件限制，并非所有的warp都可以同时执行，因此warp可以分类：\n资源和硬件限制：\n限制了运行的warp的最大数量\nSM限制：每个SM、每个block的最大共享内存大小\n寄存器限制：每个SM、每个block、每个thread的最大寄存器数量\n每个SM中resident block、resident warps、resident threads的最大数量\n寄存器和共享内存都是以256个或字节为单元进行分配的\n限制了每个时钟周期发射的warp的数量：比如一个warp scheduler如果只有一个issue slot，则只能从warp slots中发生一个warp\nactive warp：进入到warp slots中的warp（另一种说法是，当寄存器和共享内存分配给线程块，该线程块内的warp处于活跃状态） stalled warp：阻塞的warp 造成阻塞的情况：正在取指，依赖内存指令的访存结果，依赖于之前指令的执行结果，pipeline正在忙，同步barrier eligible warp：符合条件的warp（32个cuda core可用于执行，数据已经就绪），可以运行的warp selected warp：选定的warp，当前正在运行的warp inactivate warp 由于计算资源是在warp之间分配的，且warp的整个生命周期都在片上（上下文常驻SM），所以warp的上下文切换是非常快速的\n而CPU中寄存器数量很有限，进行需要保护和切换上下文 参考\nwarp scheduler 隐藏延迟：如果warp scheduler在指令周期的每个时钟周期都有一些可以发射的指令，则最大化硬件利用率。通过流水线，来隐藏延迟\n同一个线程中的指令使用流水线来进行指令级并行 两类指令： 算数指令：使用ALU，延迟小（大约10~20个时钟周期） 算数指令隐藏延迟的目的是使用全部的计算资源\n算数运算的并行可以表示为：隐藏算数指令延迟所需要的操作数量\n所需的指令数量=延迟 $\\times$ 吞吐量/32 吞吐量是每个SM每个时钟周期的操作数量，由于SIMT，一个指令对应32个线程的操作，因此指令的吞吐量=（操作数量）吞吐量/32 理论上所需active的warp数量=延迟 $\\times$ 吞吐量/32，还是延迟$\\times$ warp_scheduler数量，不是很清楚\n比如有4个warp scheduler，一个算数指令的耗时或延迟是8个周期，则为了完全隐藏延迟，最少需要32个active的warp；如果warp表现出指令并行性，则需要的active的warp数量更少\n内存指令：使用LD/ST，延迟较大（大约400~800个时钟周期） 内存指令隐藏延迟的目的是使用全部的带宽 内存操作的并行可以表示为：每个周期内隐藏内存延迟所需的字节数 $$所需active的warp数量=\\frac{\\frac{访存延迟(周期)}{内存频率(周期/s)} \\times 带宽(GB/s)}{每个线程访问的数据量(B) \\times 32} $$ 辨析： 传统CPU流水线：每个硬件部件（译码单元，ALU等）当前运行的，属于不同的指令，隐藏的是整个指令从取指到写回的整个过程。独立的算数指令的流水线也与此类似。 CPU通过cache来隐藏延迟，而GPU通过计算来隐藏延迟 算数指令的流水线：在一个SM中，warp之间运行的是不同的指令，因为GPU指令相对CPU而言较慢，所以隐藏的是GPU指令的运行时间 内存指令的流水线：若干个SM中的所有core，使用流水线，从而隐藏访存延迟 内存延迟的时候，计算资源core正在被别的warp使用，这两种延迟使用的是不同的硬件资源，但是遵循相同的原理 一方面，隐藏延迟需要足够多的活跃的warp，数量越多，隐藏越好；另一方面，warp的数量又受到资源和硬件的限制，不能过多 warp占用率：CUDA Occupancy Calculator\nwarp占用率=$\\frac{SM中活跃的warp的数量}{SM最大支持warp数量}$ nvcc编译时，添加编译选项--ptxas-options=-v，可以统计共享内存和寄存器的使用量 高占用率不一定有高性能，但是低占用率不利于隐藏延迟 占用率限制因素： 资源限制：共享内存和寄存器限制 硬件设计限制：每个SM的最多block数、warp数、thread数 权衡 如果每个线程块中线程太少，线程块数量变多，容易受到每个SM中最多block数的限制，导致占用率低 如果每个线程块中线程太多，每个线程块中warp数量变多，线程块数量减少，容易受到每个线程寄存器/共享内存的限制，剩余的一些warp没法组成一个线程块，导致占用率变低 参考 https://blog.csdn.net/weixin_44444450/article/details/118058031 一个占用率计算例子：https://blog.csdn.net/wd1603926823/article/details/108871290 https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P2/ 避免分支 一个warp中的if语句如果在运行时判断产生分支，会导致一个warp中对应的线程依次执行相应路径，其他线程等待（或是假运行），相当于每个代码块都跑了一遍，分支数量越多，性能越差\n如果if中没有产生分支，则不用考虑 比如for循环中包含了if判断，则很可能 可以将分支粒度调整为warp大小的倍数，使得一个warp中执行同一个路径，不同warp间可以执行不同路径，比如(tid/warpSize)%2进行奇偶交错 独立线程调度机制中，每个线程有自己的程序计数器和寄存器，此时SIMT如何运行？不是很清楚\nmetric：不是很清楚\nBranch Efficiency is a measure of how many branches diverged. 100% means no branches diverged. When a branch diverges the warp thread active mask is reduce to be less than 32 so the execution is not as efficient. In addition the branch may have to be executed multiple times based upon the number of ways the branch diverged. Control Flow Efficiency is a measure of how many threads in a warp were active for each instruction. Unless you launch a non-multiple of 32 threads this will be 32 threads or 100%. This number will be less than 100% if the code diverges. 参考\nWhat does a high branch efficiency and low control flow efficiency indicate 循环展开 循环展开：在一次循环中，完成多次循环的任务，从而减少循环的迭代次数\n减少了循环判断次数（减少指令消耗） 循环内部可以有更多独立的操作，有利于流水线 例子：reduce中循环展开\n首先一个线程累加多个数据：shrink 收益：线程数量减半（指数减少） 代价：多了一次（或若干次）访存，但是可以使用流水线隐藏延迟 然后折半reduce的过程 要求此时数组长度必须为2的幂次，因此可以写成模板、在编译期判断 最后是一个warp中的reduce过程：此时计算的线程数量\u0026lt;=32， 不仅没有了循环判断，而且读写过程可以充分使用流水线 动态并行 优点：\n让复杂的kernel变得有层次，比如实现递归核函数 可以等到执行的时候再创建执行配置，利用GPU硬件调度器和加载平衡器动态的调整以适应数据驱动或工作的负载 缺点：\n运行效率更低 过程\n子grid被父thread启动，必须在对应的父thread，父thread block，父grid结束之前结束。所有的子grid结束后，父thread，父thread block，父grid才能结束 如果父thread调用子grid时没有显式同步，则运行时保证，父thread与子grid隐式同步 需要仔细考虑内存竞争的问题 编译时需要加上-lcudadevrt --relocatable-device-code true\n--relocatable-device-code true表示生成可重新定位的代码 参考 # CUDA编程第三章: CUDA执行模型 ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%92%8C%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B/","summary":"编程模型 线程组织层次 grid 网格 由一个内核函数启动所产生的所有线程统称为一个网格(grid) grid size和block size都是三维结构，dim3类","title":"[cuda-learning-notes] 硬件抽象和执行模型"},{"content":"内存模型 全局内存 对全局内存变量的理解：\n从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局内存变量 一个经常会发生的错误就是混用设备和主机的内存地址：主机代码不能直接访问设备变量，设备也不能直接访问主机变量 对全局内存的读写\n如果是读操作，有三种部分的访问方式： L1缓存，L2缓存，DRAM （禁用L1缓存）L2缓存，DRAM Fermi之后都是默认禁用L1 禁用L1缓存的原因是，L1缓存被用作缓冲从寄存器中溢出的数据 只读缓存，L2缓存，DRAM 如果是写操作，则无法被缓存，只经过device层次的L2缓存，没有命中再访问DRAM ==不是很清楚== 编程模型 动态全局内存： 1 2 3 4 5 double *d_x; cudaMalloc((void**)(\u0026amp;d_x), 100*sizeof(double)); // d_x改变为指向设备全局内存的指针 double *h_x; h_x = (double*)malloc(100*sizeof(double)); // h_x是指向主机内存的指针 cudaMemcpy(d_x, h_x, 100*sizeof(double), cudaMemcpyHostToDevice); 静态全局内存： 如果静态全局变量是一个变量（而非数组类型）：此时主机中不可以直接给静态全局内存变量赋值，可以通过 cudaMemcpyToSymbol() 和 cudaMemcpyFromSymbol() 拷贝。 （一个例外：固定内存） 1 2 3 4 5 6 7 8 9 __device__ double d; // 从设备端来看，d直接就是设备全局内存上的变量；从主机端来看，d是一个指针，但是不知道其指向哪里 double h = 0.0; cudaMemcpyToSymbol(d, \u0026amp;h, sizeof(double)); // H2D cudaMemcpyFromSymbol(\u0026amp;h, d, sizeof(double)); // D2H // 因为使用cudaMemcpy需要得到d的地址，而主机端无法直接操作设备端的变量。如果非要使用cudaMemcpy: double *dptr; cudaGetSymbolAddress((void**)(\u0026amp;dptr), d); // 因为主机无法对全局内存变量d取地址，只能使用函数间接得到其地址dptr cudaMemcpy(dptr, h, 100*sizeof(double), cudaMemcpyToDevice); 如果静态全局变量是一个数组，可以使用cudaMemcpy： 1 2 3 __device__ double d_x[100]; // d_x[]直接就是设备全局内存上的数组，d_x是其地址 double h_x[100]; cudaMemcpy(d_x, h_x, 100*sizeof(double), cudaMemcpyHostToDevice); 优化 全局内存访问速度慢，往往是一个 CUDA 程序的性能瓶颈。 优化目标：\n对齐合并的内存访问，减少带宽浪费 足够的并发内存操作，隐藏内存延迟 全局内存的对齐合并访问 访问粒度：\nL1的缓存粒度为128字节（可以禁用L1缓存，只使用L2缓存） L2的缓存粒度为32字节 只读缓存也可以缓存全局内存中的数据，缓存粒度为32字节 使用__ldg()函数将全局内存缓存到只读缓存中 如果编译器能够判断一个全局内存变量在整个核函数的范围内都可读，则自动使用__ldg()函数进行缓存，但是对于全局的写入，没有相应的函数 可以使用__restrict__修饰指针，表示该指针专门用来访问特定的数组（该指针不是别名），nvcc使用只读缓存进行加载 内存对齐：\n一次数据传输中，从全局内存转移到 L2 缓存的一片内存的首地址一定是 32 的整数倍。 使用cuda runtime api（比如cudaMalloc）分配的内存的首地址至少是256字节的整数倍 内存事务：从核函数发起请求，到硬件相应返回数据这个过程\n内存事务可以分为1段，2段，4段 比如全局内存写入时，经过L2缓存，缓存粒度为32字节，此时一次内存事务可以写入1段32字节，2段64字节，4段128字节，其他字节数量只能组合得到 全局内存的访问模式：\n对齐的：内存事务的首地址是缓存粒度的整数倍 合并的（coalesced）：一个warp对全局内存的访问都在一个缓存粒度中（一个warp对全局内存的访问导致最少数量的数据传输），或者可以理解为缓存利用率 合并度=$\\frac{warp请求的字节数}{由该请求导致的所有数据传输的字节数}$ 几种常见的内存访问模式：（以一维的grid和一维的block为例）\n理想的内存访问：顺序的合并访问，合并度=100% 1 2 3 4 5 void __global__ add(float *x, float *y, float *z){ int n = threadIdx.x + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); 乱序的合并访问：访问是交叉的，但仍是合并的，合并度=100% 1 2 3 4 5 6 7 void __global__ add_permuted(float *x, float *y, float *z){ int tid_permuted = threadIdx.x ^ 0x1; // 交换两个相邻的数 // 比如：threadIdx.x=0, tid_permuted=1; threadIdx.x=1;tid_permuted=0; int n = tid_permuted + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add_permuted\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); 不对齐的非合并访问（地址错位） 如果使用L1 cache，访问粒度为128字节，速度快，但是带宽利用率更低 如果不使用L1 cache，访问粒度为32字节，速度慢，但是带宽利用率更高，从而可以提高总线的整体利用率 1 2 3 4 5 6 7 8 void __global__ add_offset(float *x, float *y, float *z){ int n = threadIdx.x + 1 + blockIdx.x * blockDim.x; z[n] = x[n] + y[n]; } add_offset\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); // 对于某个thread block，有32个线程 // 假设数组x，y，z首地址都是256字节的倍数，而一次访存至少32字节 // 由于地址错位，需要进行五次访存，合并度=128/(5*32)=80% 跨越式非合并访问 如果使用L1 cache，访问粒度为128字节，合并度很低（而且出现频繁的缓存失效和替换） 如果不使用L1 cache，访问粒度为32字节，合并度稍微提升 1 2 3 4 5 6 7 8 void __global__ add_stride(float *x, float *y, float *z){ int n = blockIdx.x + threadIdx.x * gridDim.x; z[n] = x[n] + y[n]; } add_stride\u0026lt;\u0026lt;\u0026lt;128, 32\u0026gt;\u0026gt;\u0026gt;(x, y, z); // 对于0号线程块(blockIdx.x=0)，将访问：0， 128， 256， 384 ... 等位置 // 即stride=gridDim.x=128 // 合并度=128/(32*32)=12.5%，触发32次访存，每次访存32字节 广播式非合并访问 1 2 3 4 5 6 7 void __global__ add_broadcast(float *x, float *y, float *z){ int n = threadIdx.x + blockIdx.x * blockDim.x; z[n] = x[0] + y[n]; } // 合并度=4/32=12.5% // 虽然合并度低，但是整个过程只进行了一次访存 // 其实更适合使用常量内存 定量衡量核函数的有效带宽 带宽：\n理论带宽：硬件限制 有效带宽：核函数实际达到的带宽，$有效带宽=\\frac{(读字节数+写字节数)\\times 10^{-9}}{运行时间}$ 吞吐量：单位时间内操作的执行速度，比如说FPS或（流水线）每个周期完成都少个指令，不仅取决于有效带宽，而且与带宽的利用率、是否命中缓存有关 比如数据经常命中缓存，此时吞吐量就可能超过有效带宽 例子：使用全局内存进行方阵转置，\n准备工作：测量有效带宽的上限和下限 测量有效带宽的上限：对A按行合并读取，对B按行合并写入 1 B[nx + ny * N] = A[nx + ny * N]; 测量有效带宽的下限：对A按列交叉读取，对B按列交叉写入 1 B[ny + nx * N] = A[ny + nx * N]; 测试：code部分如果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const int TILE_DIM = 32; const int N = 100; typedef double real; __global__ void copy(const read *A, real *B, const int N){ const int nx = threadIdx.x + blockIdx.x * TILE_DIM; const int ny = threadIdx.y + blockIdx.y * TILE_DIM; /* code */ } const dim3 block_size(TILE_DIM, TILE_DIM); // 每个thread block中TILE_DIM*TILE_DIM个线程，每个元素对应一个线程 // 此时一个线程块中32*32个线程，少于1024的限制 const dim3 grid_size((N + TILE_DIM - 1) / TILE_DIM, (N + TILE_DIM - 1) / TILE_DIM); // grid的维度 copy\u0026lt;\u0026lt;\u0026lt;grid_size, block_size\u0026gt;\u0026gt;\u0026gt;(A, B, N); 将A的一行转成B的一列：\n1 2 if(nx \u0026lt; N \u0026amp;\u0026amp; ny \u0026lt; N) B[ny + nx * N] = A[nx + ny * N]; 对于A的读取是顺序的，对于B的写入是非顺序的 将A的一列转成B的一行：更快\n1 2 if(nx \u0026lt; N \u0026amp;\u0026amp; ny \u0026lt; N) B[nx + ny * N] = A[ny + nx * N]; 对于A的读取不是顺序的，对于B的写入是顺序的 分析：\n如果对A按行读取（将A的一行转成B的一列），对A按行读取是合并的，写入过程（交叉写入）不缓存\n如果对B按行写入（将A的一列转成B的一行），对A按列读取是交叉的，写入过程（合并写入）不缓存，应该更慢\n但是实际上第二种方式更快，原因在于L1缓存命中率 对A按行读取，每个warp读取$32\\times4B=128B$，正好是一次L1缓存的访问粒度，相当于每次访问，L1缓存命中率都为0，数据从全局内存拿到L1缓存后，后续这些数据又不再使用。因此，总体来看L1缓存命中率=0 对A按列访问，第0个warp中每个线程此时都L1缓存没有命中，此时会有32次128B的访存，然后数据拿到L1缓存中，后面第1~31个warp中线程都可以命中L1缓存。因此，总体来看缓存命中率=$\\frac{31}{32}$=0.96875 可能是对A按列访问由于L1缓存命中率高，隐藏延迟更好，总体耗时更短，==不是很清楚== 若不能满足读取和写入都是合并的，一般应该尽量做到合并写入\n结构体数组和数据结构体 结构体数组（Structure of Array，SoA）：一个结构体，其中成员是数组\n1 2 3 4 5 struct SoA{ int a[N]; int b[N]; }; struct SoA myStruct; 数组结构体（Array of Structure, AoS）：一个数组，每个元素都是一个结构体\n1 2 3 4 typedef struct element { int a, b; } Aos; Aos array[N]; CUDA中普遍倾向于SoA（结构体数组）因为这种内存访问可以有效地合并 其他 增加每个线程中执行独立内存操作的数量，减少核函数发射的数量\n对于IO密集型的核函数，每个线程多处理一点数据（而非原来只处理一个数据） 比如reduce中，每个线程可以先累加多个数据，然后再进行两两数据的折叠相加 对核函数的运行配置进行调整，提升SM占用率\n提升SM占用率会更好隐藏访存延迟吗？==不是很清楚== 参考：Better Performance at Lower Occupancy 参考\nhttps://mp.weixin.qq.com/s/t4T7u4SqajH8db0Essedog 常量内存 常量内存属于全局内存，只有64KB 核函数的参数通过常量内存传递，且限定4KB 常量内存通过Read-Only Data Cache进行缓存，而且读取到的数据可以广播给warp中的其他线程 因为是只读的，因此常量内存必须在全局空间内、所有核函数之外进行声明，且必须在kernel启动前由host进行初始化（比如使用cudaMemcpyToSymbol来进行初始化） 纹理和表面内存 纹理内存专门为那些存在大量空间局部性的内存访问模式设计，可以充分利用空间局部性（比如插值、滤波等操作） 纹理内存驻留在全局内存中，经过只读纹理缓存进行缓存 寄存器 一个寄存器有32bit（4B）的大小，一些常用内建变量存放在寄存器中 核函数中定义的不加任何限定符的变量一般就存放在寄存器中，不加任何限定符的数组可能存放在寄存器中，或者放在局部内存中（即寄存器溢出，会对性能造成很大影响） 核函数前显式说明来帮助编译优化：__launch_bounds_(maxThreadaPerBlock, minBlocksPerMulitprocessor) maxThreadaPerBlock：线程块内包含的最大线程数 minBlocksPerMulitprocessor：可选参数，每个SM中预期的最小的常驻线程块数量 寄存器只能被一个线程可见，因此每个线程都有一个变量的副本，而且该变量的副本可以值不同 局部内存 将寄存器放不下的变量、索引值不能再编译时就确定的数组，都存放在局部内存中（编译器进行判断） 局部内存是全局内存的一部分，因此使用时延迟较高 对于计算能力2.0以上的设备，局部内存可能会存储在L1缓存或L2缓存上 共享内存 主要作用： 减少核函数中对全局内存的访问次数，实现高效的线程块内部的通信 优化对全局内存的访问模式，尤其是针对全局内存的跨越式非合并访问，提高带宽利用率 共享内存一般和L1缓存共享64KB片上内存，可以进行配置 按设备进行配置 1 2 3 4 5 6 7 cudaDeviceSetCacheConfig(cudaFuncCache cacheConfig); /* 参数 cudaFuncCachePreferNone: no preference(default) cudaFuncCachePreferShared: prefer 48KB shared memory and 16 KB L1 cache cudaFuncCachePreferL1: prefer 48KB L1 cache and 16 KB shared memory cudaFuncCachePreferEqual: prefer 32KB L1 cache and 32 KB shared memory */ 不同核函数自动配置 1 cudaFuncSetCacheConfig(const void* func, enum cudaFuncCache cacheConfig); // 配置核函数func对应的共享内存大小 编程模型 静态分配：__shared__ float mat[5][5]; 动态分配： 函数内声明方式：extern __shared__ double arr[]; 动态共享内存只支持一维数组 核函数的执行配置中，第三个参数为每个线程块中动态共享内存的字节数：\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, sizeof(float) * block_size\u0026gt;\u0026gt;\u0026gt; 同步：__syncthreads进行线程块的同步 优化 缓存 L1和L2缓存：缓存局部内存和全局内存的数据\n每个SM都有自己的L1缓存，但是L2缓存是所有SM共用的 可以配置是否使用L1缓存 CPU的L1缓存考虑了时间局部性（LRU算法）和空间局部性，GPU的L1缓存只有空间局部性，没有时间局部性（频繁访问一个一级缓存的内存位置不会增加数据留在缓存中的概率） CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有 与CPU读写都缓存不同，GPU只会针对读过程进行缓存，写过程不缓存 每个SM都有一个只读常量缓存\n使用__ldg()函数显示将数据通过只读数据缓存进行加载 GPU不是很强调缓存（not dependent on large caches for performance），因为当指令或数据miss时，由于warp切换速度快，所以旧切换warp；即用计算而非cache来隐藏延迟\n内存管理 常规数据传输函数 cudaMalloc函数：cudaError_t cudaMalloc(void **address, size_t size);\n示例： 1 2 double *d_x; cudaMalloc((void**)\u0026amp;d_x, 100); // \u0026amp;d_x的类型为double** 参数说明： address是在分配设备内存的指针 注意事项： ==一个经常会发生的错误就是混用设备和主机的内存地址==：主机代码不能直接访问设备变量，设备也不能直接访问主机变量 因为该函数的功能是改变指针d_x的值（即改变d_x指向的位置，将一个指向内存地址的指针赋值给d_x），而非改变d_x所指内容的值，因此只能传入指针d_x的地址，即指针的指针 原来d_x是主机上的一个指针，cudaMalloc之后改变为指向设备全局内存的指针，本质上是GPU地址在内存中的虚拟映射地址 cudaMemset函数：cudaError_t cudaMemset(void * devPtr,int value,size_t count)\ncudaFree函数：cudaError_t cudaFree(void* address)\n设备内存的分配和释放非常影响性能，尽量重用 CUDA允许在核函数内部使用malloc/free 分配/释放全局内存，但是一般会导致较差的性能 cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind)\n主机端的内存默认是可分页的，如果进行数据拷贝，此时CUDA分配不可分页的固定内存，将可分页内存中的数据复制其中，然后再从固定内存中拷贝数据到显存 如果主机端的内存是可分页的，使用虚拟内存，当该页面被换出到交换区时，设备此时无法访问或者进行控制 cudaMemcpyToSymbol函数和cudaMemcpyFromSymbol函数\nsymbol是一个驻留在全局或常量内存空间中的变量 cudaMemcpy 的异步版本 cudaMemcpyAsync\ncudaError_t cudaMemcpyAsync(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind, cudaStream_t stream) 使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（使用cudaMallocHost或cudaHostAlloc），从而防止在程序执行期间物理地址被修改 如果将可分页内存传递给cudaMemcpyAsync，则会导致同步传输 固定内存：\ncudaError_t cudaMallocHost(void **devPtr, size_t count); cudaError_t cudaFreeHost(void *ptr); 固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。 固定内存有更高的读写带宽，但是分配过多的固定内存可能会降低主机系统的性能，同时固定内存分配和释放的代价更高。通常, 当传输数据量\u0026gt;=10M时, 使用固定内存是更好的选择 零拷贝内存\n在零拷贝内存中，主机和设备可以直接访问对方的变量，原理是将host内存直接映射到设备内存空间上，使得设备可以通过DMA的方式访问host的锁页内存 cudaError_t cudaHostAlloc(void **pHost, size_t size, unsigned int flags) cudaHostAllocDefault：与cudaMallocHost函数行为一致 cudaHostAllocPortable：返回能被所有CUDA上下文使用的固定内存，而不仅是执行内存分配的那一个，分配portable memory，适用于主机多线程，让控制不同GPU的主机端线程操作同一块portable memory，实现GPU线程间通信 cudaHostAllocMapped：分配mapped memory，可以在kernel中直接访问mapped memory中的数据，不必再内存和显存之间进行数据拷贝，即zero-copy功能 cudaHostAllocWriteCombined：分配write-combined memory，提高从CPU向GPU单向传输数据的速度，不使用CPU的L1、L2 cache，将cache资源留给其他程序使用，在PCI-E总线传输期间不会被来自CPU的监视打断 将多次写操作写到固定内存的buffer中，将多次写合并；但实际上性能会比普通的write-back更糟糕, 主要是由于其没有使用cache, 而是直接写回内存 零拷贝内存虽然不需要显式的将主机的数据复制到设备上，但是设备也不能直接访问主机端的数据，需要通过cudaHostGetDevicePointer函数主机上的地址，然后才能通过pDevice访问主机上的零拷贝内存 cudaHostGetDevicePointer(void **pDevice, void *pHost, unsigned int flags); flags设置为0 如果使用统一内存，则无须使用cudaHostGetDevicePointer 使用零拷贝内存需要注意同步主机和设备之间的内存访问 零拷贝内存适合用于少量的数据传输 统一内存 发展：\n统一寻址（Unified Address）：Fermi架构中提出了统一的地址空间，将全局内存、局部内存、共享内存放在一个地址空间中 统一虚拟地址(UVA)：CUDA 4（开普勒架构，麦克斯韦架构）引入，将CPU和GPU的内存映射到统一的虚拟地址上，可以使用指针访问对方的地址 统一内存(UM)：CUDA 6（帕斯卡架构之后）引入，实现了一个CPU和GPU之间的内存池 对于第一代统一内存，主机与设备不能并发访问统一内存。因此，在主机调用核函数之后，必须加上一个同步函数（比如cudaDeviceSynchornize），确保核函数对统一内存的访问已经结束，然后才能主机访问统一内存变量 对于第二代统一内存，主机与设备可以并发访问统一内存 语法相关：\n统一内存在device中当作全局内存来使用，必须由主机来定义或分配内存，不能在设备端（核函数或__device_函数中）进行。因此，在核函数中由malloc分配的堆内存不属于同一内存，因而如果CPU需要访问，需要手工进行移动 同一个程序中可以同时使用统一内存和非统一内存 统一内存的分配\n动态分配：cudaError_t cudaMallocManaged(void **devPtr, size_t size, unsigned flags = 0); 参数flags默认为cudaMemAttachGlobal，表示分配的全局内存可以由任何设备通过任何CUDA流访问 静态分配：__device__ __managed__修饰，而且只能是全局变量 超量分配：\n编译选项：-DUNIFIED cudaMallocManaged申请内存只是表示预定了一段空间，统一内存的实际分配发生在第一次访问预留的内存时 优化使用统一内存的程序\n可以手动给编译期一些提示，避免数据缺页、内存抖动，保持数据局部性等，可以使用cudaMemAdvice和cudaMemPrefetchAsync cudaError_t cudaMemPrefetchAsync(const void *devPtr, size_t count, int dstDevice, cudaStream_t stream) 在CUDA流中将统一内存缓冲区devPtr内count字节的内存迁移到设备dstDevice（cudaCpuDeviceId表示主机的设备号）中的内存区域，从而防止或减少缺页异常，提高数据局部性 尽可能多的使用cudaMemPrefetchAsync 优势：\n简化编程 编程更简单：比如之前多GPU，针对某一个数据使用零拷贝内存，每个设备都需要有对应的一个指针，容易混乱（针对零拷贝的改进） 方便代码移植 支持更完整的C++语言要素：比如核函数参数可以使用引用，可以直接使用拷贝构造函数而不用手工进行拷贝或进行很多重载 可能会提供比手工移动数据更好的性能，比如可能会将某部分数据放置到离某个存储器更近的位置 可以进行超量分配，超出GPU显存的部分可以放在主机内存中（但是反过来不行） ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","summary":"内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局","title":"[cuda-learning-notes] 内存模型"},{"content":"CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start, 0)); // 将事件start关联到指定的流0 cudaEventQuery(start); // 强制刷新 cuda 执行流，因为WDDM模式下，CUDA流中的操作显式提交到一个软件队列中（TCC模式不用） // 此处不能使用CHECK，因为它可能返回cudaErrorNotReady，但是又不代表程序出错 // run code. CHECK(cudaEventRecord(stop, 0)); CHECK(cudaEventSynchronize(stop)); // 强制同步，让主机等待cuda事件执行完毕。 float elapsed_time = 0; CHECK(cudaEventElapsedTime(\u0026amp;elapsed_time, start, stop)); // 计算 start 和stop间的时间差（ms）。 CHEKC(cudaEventDestroy(start)); CHEKC(cudaEventDestroy(stop)); CUDA流 CUDA流：由主机发出的、在一个设备中执行的CUDA操作序列\nkernal_func\u0026lt;\u0026lt;\u0026lt;grid_size, block_size, 0, stream\u0026gt;\u0026gt;\u0026gt;(params); 一个CUDA流中各个操作的次序是由主机控制的，但是来自于两个不同CUDA流中的操作顺序无法确定 任何CUDA操作都存在于某个CUDA流中，要么是默认流（也成为空流），要么明确指定的流 相关函数\ncudaError_t cudaStreamCreate(cudaStream_t *stream); cudaError_t cudaStreamDestory(cudaStream_t stream); cudaError_t cudaStreamSynchronize(cudaStream_t stream); 同步等待一个流中的所有操作完成 cudaError_t cudaStreamQuery(cudaStream_t stream); 查询一个流中的操作是否全部完成，不会阻塞；若是，则返回 cudaSuccess; 否则，返回 cudaErrorNotReady。 Stream对并行性的影响 调度队列的个数： 单调度队列：虽然Fermi架构支持最多16个流，但是实际调度过程中，所有的流被塞进同一个调度队列，当选中一个操作执行时，runtime会查看操作之间的依赖关系，如果当操作依赖于前面的操作，而且由于只有一个调度队列，因此调度队列阻塞（后面所有操作都等待，即使这些操作来自不同的流） Hyper-Q：最多32个调度队列和32个流 多个流的操作的发射顺序 左边将多个流以DFS方式发射，右边将多个流以BFS方式发射 以DFS方式发射时，流的发射顺序对并行性有影响 每种资源都有一个队列 每个流内部很可能有依赖关系 比如先发射Stream1，后发射Stream2： 比如先发射Stream2，后发射Stream1： 每个操作操作具体占用的资源大小差异对并行性也有影响 使用流隐藏延迟 在默认流中重叠主机和设备计算 一些cuda runtime api具有隐式同步的效果（比如cudaMemcpy函数），会导致主机阻塞等待 核函数的调用是非阻塞的 用多个流重叠多个核函数的执行 制约加速比的因素：（假设每个CUDA流都执行相同规模的计算） GPU的计算资源（SM数量，每个SM最多允许的线程数量） 当CUDA流较少时，增加CUDA流的数量，总耗时只是略微增加，加速比线性增加，此时加速比没有饱和 当CUDA流的个数到达瓶颈，继续增加CUDA流的数量时，总耗时线性增加，加速比饱和 单个GPU中能够并发运行的核函数个数的上限 比如此时能够并发运行的核函数上限为32，Tesla K40有15个SM，每个SM最多允许2048个线程 比如此时一个核函数开1024线程，理论上最多并发运行的核函数$=\\min{ \\frac{15\\times2048}{1024}, 32}=30$，此时限制因素为GPU的计算资源 比如此时一个核函数开128线程，理论上最多并发运行的核函数$=\\min { \\frac{15 \\times 2048}{128}, 32 }=32$，此时限制因素为并发运行核函数的上限 参考 《CUDA编程：基础与实践》 用多个流重叠核函数的执行与数据传递 将数据与相应操作分成若干份，每个流中依次进行操作，形成流水线 理论上最大加速比为3（假设H2D,KER,D2H运行时间相同） 同步 核函数（或grid）之间的同步 背景：连续发射两个核函数，其调度行为未知 使用cuda graph显示指定核函数调度顺序（？不确定） 相关函数 cudaDeviceSynchronize：阻塞host端，直到所有的kernel调用完毕 原理是device设置了cudaDeviceScheduleBlockingSync标志，将host线程阻塞 在device中使用 cudaDeviceSynchronize已经被逐渐废弃 cudaStreamSynchornize：阻塞host端，直到流中的kernel调用完毕 cudaSetDeviceFlags：记录标志，作为活动的host线程执行device代码时使用的标志 cudaLaunchKernel：在CPU端使用\u0026lt;\u0026lt;\u0026lt;\u0026gt;\u0026gt;\u0026gt;launch核函数时，实际上调用的是该函数，launch核函数到GPU上执行 线程块（或Block）内部的同步 barrier：__syncthreads()同步Block内所有线程 注意死锁问题：__syncthreads必须能被块内所有线程访问到，即不要将__syncthreads放到if-else语句中 __syncthreads的变种：syncthreads_xxx(int predicate) 与__syncthreads相同，但是有一个额外的功能： predicate是一个条件表达式，该变种函数对所有线程评估predicate： __syncthreads_or：如果有任意一个线程的predicate值非零，返回非零 __syncthreads_and：如果对所有线程的predicate值非零，返回非零 __syncthreads_count：统计所有线程中predicate值非零的线程数量 应用：last-block guard确定最后一个线程块（编号最后的线程块未必是最后运行结束的） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 __device__ int counter = 0; __device__ bool lastBlock(int* counter){ // 方法一： __shared__ int last; // 表示当前已经调度发射了多少个线程块 __threadfence(); // 确保之前计算的结果已经写入内存，对所有线程块可见 if(threadIdx.x == 0) // 每个块中第一个线程维护last的值 last = atomicAdd(counter, 1); // 原子更新全局内存中的变量，将更新后的值返回到共享内存中 __syncthreads(); // 块内所有线程同步，有必要。如果没有线程块内同步，则一个线程块内对last的访问有的是新值，有的是旧值，但是又必须要求一个线程块内部的last值都相同。注意没有保证不同的线程块之间是同步的 return last == gridDim.x-1; } __device__ bool lastBlock(int* counter){ // 方法二： __threadfence(); int last = 0; // 寄存器变量 if(threadIdx.x == 0) last = atomicAdd(counter, 1); // 块内线程不需要完全同步 return __syncthreads_or(last == gridDim.x-1); // 仍需要使用__syncthreads_or，因为一个线程块内部，只有0号线程的last是用来维护计数的。因此只要0号线程计算完即可确定当前线程块是否为最后一个 } 线程块（或Block）之间的同步 全局锁+原子操作 线程块内选一个代表，通过维护锁变量，代表先进行同步，从而线程块同步\n1 2 3 4 5 6 7 8 9 __device__ volatile int g_mutex; // 全局锁变量 __deviec__ void __gpu_sync(int goalVal){ int tid_in_block = threadIdx.x * blockDim.y + threadIdx.y; if(tid_in_block == 0){ // 每个线程块中的0号线程 作为线程块的代表 atomicAdd((int*)\u0026amp;g_mutex, 1); while(g_mutex != goalVal){ /* Do nothing */} // 死循环，直到g_mutex到达goalVal的值 // 这里，goalVal个线程块之间达成同步 } } 无锁方法 将块间同步转换为块内同步 为每个线程块分配一个同步变量，形成一个数组Arrayin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 __device__ void __gpu_sync(int goalVal, volatile int* Arrayin, volatile int* Arrayout){ int tid_in_block = threadIdx.x * blockDim.y + threadIdx.y; // 线程在block中的id int nBlockNum = gridDim.x * gridDim.y; // block数量 int bid = blockIdx.x * gridDim.y + blockIdx.y; // 线程块id if(tid_in_block == 0) // 每个线程块的0号线程，基于自己线程块的索引，更新Arrayin数组 Arrayin[bid] = goalVal; // 0号线程块进行控制 if(bid == 0){ // 将块间同步转换为线程块0号内部的块内同步 if(tid_in_block \u0026lt; nBlockNum) { // 0号线程块中，每个线程控制一个线程块 while(Arrayin[tid_in_block] != goalVal) { /* Do nothing */} } __syncthreads(); // 0号线程块内进行同步。 // 0号线程块执行到这里，表示所有线程块已经完成初始化Arrayin数组 if(tid_in_block \u0026lt; nBlockNum) Arrayout[tid_in_block] = goalVal; } if(tid_in_block == 0){ // 每个线程块的0号线程 while(Arrayout[bid] != goalVal) { /* Do nothing */} } __syncthreads(); // 同步所有块内线程 } 内存fence 背景：CUDA 编程模型假定了一种弱顺序(weakly-ordered)一致性的内存模型 内存一致性（memory consistency）：访存操作在全局中生效（或观察到的）顺序问题， 是指令集所规范的，是软硬件接口的一部分 缓存一致性（cache coherence）：同一个地址在不同的缓存中一致性问题，是完全的硬件实现策略，程序员无关，是集成电路设计者考虑的东西。 内存fence：读写操作可能进行重排or优化，添加fence之后，fence之前的op一定比fence之后的op先执行。即抑制编译器重排、抑制乱序。 内存fence：The CUDA programming model assumes a device with a weakly-ordered memory model. Memory fence functions can be used to enforce a sequentially-consistent ordering on memory accesses. volatile：声明一个变量，防止编译器优化，防止这个变量存入缓存，如果恰好此时被其他线程改写，那就会造成内存缓存不一致的错误，所以volatile声明的变量始终在全局内存中。 内存fence只会影响自己线程中内存操作的顺序，保证自己的数据fence后能够被其他线程安全的访问，并不能像__syncthreads那样保证内存操作对于同block中的其他线程可见 相关函数 __threadfence_block()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对block内所有线程可见。 __threadfence()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对grid内所有线程可见。 __threadfence_system()：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对system（CPU+GPU）内所有线程可见。 参考： CUDA内存栅栏（Memory Fence）理解 warp同步 warp内（inter-warp）同步 barrier：__syncwarps()同步一个warp中的线程\n线程束内函数都有 _sync 后缀，表示这些函数都具有隐式的同步功能。\n线程束表决函数（warp vote functions） unsigned __ballot_sync(unsigned mask, int predicate)：如果线程束内第n个线程参与计算（旧掩码）且predicate值非零，则返回的无符号整型数（新掩码）的第n个二进制位为1，否则为0 int __all_sync(unsigned mask, int predicate)：线程束内所有参与线程的predicate值均非零，则返回1，否则返回0 int __any_sync(unsigned mask, int predicate)：线程束内所有参与线程的predicate值存在非零，则返回1， 否则返回0 线程束匹配函数（warp match functions） 线程束洗牌函数（warp shuffle functions）：最后一个参数表示逻辑上的warp大小 T __shfl_sync(unsigned mask, T v, int srcLane, int w = warpSize)：参与线程返回标号为 srcLane 的线程中变量 v 的值。该函数将一个线程中的数据广播到所有线程。 T __shfl_up_sync(unsigned mask, T v, unsigned d, int w=warpSize)：标号为t的参与线程返回标号为 t-d 的线程中变量v的值，t-d\u0026lt;0的线程返回t线程的变量v。该函数是一种将数据向上平移的操作，即将低线程号的值平移到高线程号。 例如当w=8、d=2时，2-7号线程将返回 0-5号线程中变量v的值；0-1号线程返回自己的 v。 T __shfl_down_sync(unsigned mask, T v, unsigned d, int w=warpSize)：标号为t的参与线程返回标号为 t+d 的线程中变量v的值，t+d\u0026gt;w的线程返回t线程的变量v。该函数是一种将数据向下平移的操作，即将高线程号的值平移到低线程号。 例如当w=8、d=2时，0-5号线程将返回2-7号线程中变量v的值，6-7号线程将返回自己的 v。 T __shfl__xor_sync(unsigned mask, T v, int laneMask, int w=warpSize)：标号为t的参与线程返回标号为 t^laneMask 的线程中变量 v 的值。该函数让线程束内的线程两两交换数据。 线程束矩阵函数（warp matrix functions） 例子：使用warp shuffle函数进行规约：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void __global__ reduce_shfl(const real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; // tid从0到blockDim.x const int bid = blockIdx.x; const int n = tid + bid * blockDim.x; extern __shared__ real s[]; // 比如大小128 s[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; const unsigned FULL_MASK = 0xffffffff; __syncthreads(); // 线程块同步函数 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt;= 32; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s[tid] += s[tid + offset]; __syncthreads(); } real y = s[tid]; for(int offset = 16; offset \u0026gt; 0; offset \u0026gt;\u0026gt;= 1) y += __shfl_down_sync(FULL_MASK, y, offset); // 线程tid返回线程tid+offset中寄存器变量y的值 if(tid == 0) atomicAdd(d_y, y); } 协作组 协作组（cooperative groups）:提供了线程块以上级别的同步\nthread_group\n协作组编程模型中最基本的类型，是线程块级别的协作组 成员函数： void sync()，同步组内所有线程；（相当于__syncthreads函数） unsigned size()，返回组内总的线程数目，即组的大小； unsigned thread_rank()，返回当前调用该函数的线程在组内的标号（从0计数） bool is_valid()，如果定义的组违反了任何cuda限制，返回 false，否则true thread_block继承于thread_group_base\u0026lt;T\u0026gt;，thread_group_base\u0026lt;T\u0026gt;继承于thread_group\ndim3 group_index()，返回当前调用该函数的线程的线程块指标，等价于 blockIdx； dim3 thread_index()，返回当前调用该函数的线程的线程指标，等价于 threadIdx； this_thread_block()：初始化一个thread_block对象 tiled_partition() ：将一个thread_block划分为若干片（tile），每片构成一个thread_group 1 2 3 4 5 6 7 #include \u0026lt;cooperative_groups.h\u0026gt; using namespace cooperative_groups; // 相关变量和函数定义在该命名空间下 // namespace cg = cooperative_groups; // 取别名 thread_block g = this_thread_block(); // g相当于一个之前的线程块，这里将其包装为一个类型 thread_group myWarp = tiled_partition(g, 32); // 将thread_block划分为thread_group thread_group g4 = tiled_partition(myWarp, 4); // 可以将thread_group进一步细分 thread_block_tile\n使用模板，在编译期划分 线程块片（thread block tile） 1 2 thread_block_tile\u0026lt;32\u0026gt; g32 = tiled_partition\u0026lt;32\u0026gt;(this_thread_block()); thread_block_tile\u0026lt;32\u0026gt; g4 = tiled_partition\u0026lt;4\u0026gt;(this_thread_block()); 线程块片具有额外的函数（类似线程束内函数）：\nunsigned ballot(int predicate); int all(int predicate); int any(int predicate); T shfl(T v, int srcLane); T shfl_up(T v, unsigned d); T shfl_down(T v, unsigned d); T shfl_xor(T v, unsigned d); 与一般的线程束不同，线程组内的所有线程都要参与代码运行计算；同时，线程组内函数不需要指定宽度，因为该宽度就是线程块片的大小。 例子：使用协作组进行规约：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void __global__ reduce_cp(const real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; // tid从0到blockDim.x const int bid = blockIdx.x; const int n = tid + bid * blockDim.x; extern __shared__ real s[]; // 比如大小128 s[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; __syncthreads(); // 线程块同步函数 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt;= 32; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s[tid] += s[tid + offset]; __syncthreads(); } real y = s[tid]; thread_block_tile\u0026lt;32\u0026gt; g = tiled_patition\u0026lt;32\u0026gt;(this_thread_block()); for(int i = g.size() \u0026gt;\u0026gt; 1; i \u0026gt; 0; i \u0026gt;\u0026gt;= 1) y += g.shfl_down(y, i); // 使用协作组的成员函数与使用warp shuffle函数具有等价的执行效率 if(tid == 0) atomicAdd(d_y, y); } more\nhttps://www.zhihu.com/question/586453330/answer/3232856921 原子操作 两类原子函数： atomicAdd_system：将原子函数的作用范围拓展到所有节点（host和device） atomicAdd_block：将原子函数的作用范围缩小至一个线程块 一个特殊的原子函数：atomicCAS，所有其他原子函数都可以使用它来实现 相关语法： 原子函数的返回值都是原来的旧值 原子函数都是__device__函数，只能在核函数中使用 原子函数操作的地址可以位于全局内存，也可以位于共享内存 原子操作开销与是否存在竞争相关，且参与竞争者越少，开销越小 例子：使用原子函数进行规约 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void __global__ reduce_shared(real *d_x, real *d_y, const int N){ const int tid = threadIdx.x; const int bid = blockIdx.x; const int n = blockIdx.x * blockDim.x + threadIdx.x; extern __shared__ real s_y[]; // 动态共享内存 s_y[tid] = (n \u0026lt; N) ? d_x[n] : 0.0; // 将全局内存中的数据拷贝到线程块对应的共享内存中 __syncthreads(); // 保证一个线程块中的同步，但是不能保证不同线程块之间的同步 for(int offset = blockDim.x \u0026gt;\u0026gt; 1; offset \u0026gt; 0; offset \u0026gt;\u0026gt;= 1){ if(tid \u0026lt; offset) s_y[tid] += s_y[tid + offset]; __syncthreads(); } if(tid == 0) atomicAdd(\u0026amp;d_y[0], s_y[0]); // 使用原子操作，将结果累加到d_y[0] } ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/","summary":"CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start, 0)); //","title":"[cuda-learning-notes] 流和同步"},{"content":"工具 nvidia-smi -L：显示设备名称，精简信息\n-q -i 0：显示0号设备详细状态信息\n-q -i 0 -d MEMORY：从详细状态信息中提取某类信息（比如MEMORY、COMPUTE、UTILIZATION等）\n部分字段含义：\nGPU-util：For a given time period, it reports what percentage of time one or more GPU kernel(s) was active (i.e. running). nvidia-smi Volatile GPU-Utilization explanation? Nsight System(nsys) nsys profile ./hello_world\n--trace cuda\n--gpu-metrics-device 0\n--stats true\n如何检测achieved_occupancy活跃线程束比例， gld_throughput内存利用率\nhttps://face2ai.com/CUDA-F-3-3-%E5%B9%B6%E8%A1%8C%E6%80%A7%E8%A1%A8%E7%8E%B0/\nhttps://zhuanlan.zhihu.com/p/589120507\nnvprof是旧的分析工具，不支持8.0以上的GPU，其功能拆分给nsys和ncu\nnsys nvprof：统计cuda api和cuda kernel的耗时和相关配置 ncu --metrics：统计得到metrics Nsight Compute(ncu) 几种常规用法：很可能需要sudo权限 分析某几个指标：ncu --metrics ncu --query-metrics可以列出分析的指标 得到profile的全部信息：ncu --set full --import-source yes --target-processes all -o profile_file --set full：profile全部信息 ncu --list-sets可以查看支持的section，每个section是一些metric的集合 --import-source yes：在服务器端跑出profile，然后copy到本地gui中进行查看 -o \u0026lt;output_file_name\u0026gt; metrics metrics：performance counter，性能统计的指标\nmetrics structure\npeak rete：每个counter都有两类peak rete burst rate：the maximum rate reportable in a single clock cycle sustained rate：the maximum rate achievable over an infinitely long measurement period metrics entities counter：直接从GPU而来的统计量 每个counter都有四个sub-metrics，叫做roll-ups sum，avg，min，max 有一些可以从counter roll-ups计算而来的sub-metrics 比如.peak_sustained ratio：有三个sub-metrics pct，ratio，max_rate throughputs：标识一个portion接近peak rate的程度，有四个sub-metrics 比如.pct_of_peak_sustained_active ncu的metrics与nvprof的metrics不相同，存在一定的对应关系。常用的对应关系 nvprof ncu 说明 achieved_occupancy sm__warps_active.avg.pct_of_peak_sustained_active gld_throughput l1tex__t_bytes_pipe_lsu_mem_global_op_ld.sum.per_second gst_throughput l1tex__t_bytes_pipe_lsu_mem_global_op_st.sum.per_second gld_efficiency smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct gst_efficiency smsp__sass_average_data_bytes_per_sector_mem_global_op_st.pct gld_transactions l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum gst_transactions l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum gld_transactions_per_request l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_ld.ratio gst_transactions_per_request l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_st.ratio shared_efficiency smsp__sass_average_data_bytes_per_wavefront_mem_shared.pct shared_load_throughput l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.per_second shared_load_transactions l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum shared_store_throughput l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second shared_store_transactions l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second inst_per_warp smsp__average_inst_executed_per_warp.ratio 比如if分支优化之后，分支减少，inst_per_warp会减少很多 metrics命名规则和对应实体\n其他\n常见报错：Error: ERR_NVGPUCTRPERM - The user does not have permission to access NVIDIA GPU Performance Counters on the target device. 官方解决方法：# NVIDIA Development Tools Solutions - ERR_NVGPUCTRPERM: Permission issue with Performance Counters 自己在/etc/modprobe.d下touch nvidia-restrict-profiling.conf并写入options nvidia NVreg_RestrictProfilingToAdminUsers=0，然后重启 参考\nnvprof的metric与ncu的metric的对应关系 ncu的metric中命名规则和说明 nvprof的metric的说明 nvprof的metric的说明（中文博客） cuda-memcheck CUDA 提供了 CUDA-MEMCHECK 的工具集，包括 memcheck, racecheck, initcheck, synccheck.\ncuda-memcheck --tool memcheck [options] app-name [options] 对于 memcheck 工具，可以简化为：\ncuda-memcheck [options] app-name [options] 实战 二维矩阵相加进行profile：https://face2ai.com/CUDA-F-3-3-%E5%B9%B6%E8%A1%8C%E6%80%A7%E8%A1%A8%E7%8E%B0/\nreduce使用全局内存进行profile逐步优化：https://face2ai.com/CUDA-F-3-5-%E5%B1%95%E5%BC%80%E5%BE%AA%E7%8E%AF/\n","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E5%92%8Cprofile/","summary":"工具 nvidia-smi -L：显示设备名称，精简信息 -q -i 0：显示0号设备详细状态信息 -q -i 0 -d MEMORY：从详细状态信息中提取某类信息（比如MEMORY、CO","title":"[cuda-learning-notes] 工具使用和profile"},{"content":"CUDA编译链和兼容性 兼容性 CPU与GPU的区别\nCPU只有少量的计算核心，有更多晶体管用于数据缓存和流程控制， GPU有大量计算能力较弱的计算核心，用于控制和缓存的晶体管较少 GPU系列：\nTesla系列：使用ECC内存，用于科学计算。后来也叫Data Center GPUs。 Quadro系列：专业级，用于OpenGL、CAD等需要高精度计算的场景。后来也叫Workstation GPUs。 GeForce系列：消费级，用于游戏和计算，但是没有ECC Tegra系列：移动处理器 Jetson系列：嵌入式 GPU架构、计算能力与对应系列\n计算能力（Compute Capability）决定了GPU硬件支持的功能，反映了设备支持的指令集及其他规范，也称SM version，注意GPU计算能力不等价于计算性能 架构 计算能力Compute Capability 发布时间 Tesla系列 Quadro系列 GeForce系列 Jetson系列 Tesla X = 1 2006 Fermi X = 2 2010 Kepler X = 3 2012 Kepler K系列 Quadro K系列 GeForce 600/700系列 Tegra K1 Maxwell X = 5 2014 Maxwell M系列 Quadro M系列 GeForce 900系列 Tegra X1 Pascal X = 6 2016 Pascal P系列 Quadro P系列 GeForce 10系列 Tegra X2 Volta X = 7 2017 Tesla V系列 - TITAN V AGX Xavier Turing X.Y = 7.5 2018 Tesla T系列 Quadro RTX系列 GeForce 16系列，GeForce 20系列 AGX Xavier Ampere X = 8 2020 Tesla A系列 RTX A系列 GeForce 30系列 Ada Lovelace X.Y = 8.9 2022 L4、L40 RTX Ada系列 GeForce 40系列 Hopper X = 9 2022 H100 - CUDA开发平台 CUDA 提供两个编程接口 CUDA driver API：low-level CUDA (driver) library由NVIDIA driver安装，比如常用的共享库libcuda.so，对应头文件为cuda.h，里面提供的API称为CUDA driver API 同时可以看到NVIDIA driver的版本：find / -name libcuda.* NVIDIA driver同时包含了nvidia-smi命令，可以看到NVIDIA driver的版本，以及当前NVIDIA driver支持的最高CUDA版本（向下兼容） 或者使用函数cudaDriverGetVersion(int* driverVersion) CUDA runtime API：high-level CUDA Runtime library由CUDA Toolkit安装，比如常用的共享库libcudart.so，对应头文件为cuda_runtime.h，里面提供的API称为CUDA runtime API cuda_runtime_api.h是纯C版本，cuda_runtime.h是C++版本 离线安装的CUDA工具包会默认携带与之匹配特定的驱动程序 CUDA Toolkit中同时包含了一些工具比如编译器nvcc，nvcc -V显示的CUDA版本是runtime API版本 cuda driver API版本（即驱动支持的最高cuda版本）应该高于cuda runtime API版本（即当前安装的cuda toolkit版本） 或者使用函数cudaRuntimeGetVersion(int *runtimeVersion) 注意不要将GPU计算能力与CUDA (driver/runtime)版本混淆 参考 # CUDA Driver VS CUDA Runtime # cuda 的driver API 和 runtime API 编译相关 编译过程 编译过程 编译device code 首先将预处理之后的C++ code经过CICC compiler编译成PTX code PTX可以视为虚架构的汇编，虚架构体现了应用程序对GPU计算能力的要求，版本尽量低，因此可以适用于更加广泛的GPU架构 再使用ptxas (PTX optimizing assembler)，根据实架构，将PTX code编译成cubin二进制机器码 .cubin：CUDA device code binary file (CUBIN) for a single GPU architecture 将PTX code和cubin放到fatbin.c文件中 .fatbin：CUDA fat binary file that may contain multiple PTX and CUBIN files 编译host code 将预处理之后的C++ code，使用cudafe++将host和device部分分离 分离后的host代码，结合device code部分得到的fatbin.c文件，进行编译 在host code看来，device code其实就是一段数据。 对每一个.cu文件都执行单独的host code和device code编译 链接： 使用nvlink将所有.o目标文件中的device code重新链接到一个cubin文件中，并通过fatbinary转换为.fatbin.c文件 将.fatbin.c文件，结合一些其他的文件，编译得到device code最终对应的目标文件 将host code的目标文件和device code最终的目标文件链接起来，得到最终的可执行文件 使用\n需要选项 -arch=compute_XY 指定一个PTX虚拟架构的计算能力，虚架构版本：Virtual Architecture Feature List\nArchitecture 虚架构 实架构 Maxwell compute_50，compute_52，compute_53 sm_50，sm_52，sm_53 Pascal compute_60，compute_61，compute_62 sm_60，sm_61，sm_62 Volta compute_70，compute_72 sm_70，sm_72 Turing compute_75 sm_75 Ampere compute_80，compute_86，compute_87 sm_80，sm_86，sm_87 Ada Lovelace compute_89 sm_89 Hopper compute_90，compute_90a sm_90，sm_90a 需要选项 -code=sm_ZW 指定一个真实架构的计算能力，实架构版本：GPU Feature List\nCUDA二进制兼容性只能保证局限在相同大版本计算能力的架构中 实架构的计算能力必须大于等于虚架构的计算能力 如果希望编译出来的文件能在更多的GPU上运行，可以使用-gencode同时指定多组计算能力，生成多个PTX版本代码，例如：\n1 2 3 -gencode arch=compute_35, code=sm_35 -gencode arch=compute_50, code=sm_50 -gencode arch=compute_60, code=sm_60 此时，编译出来的可执行文件将包含3个二进制版本，在不同架构的GPU中运行时会自动选择对应的二进制版本 -code=可以指定虚架构，此时将进行即时编译，只会包含PTX代码 如果在运行期间找不到当前架构的二进制版本代码，则使用即时编译\n即时编译推迟cubin的生成，将PTX代码在runtime内编译成cubin然后执行，因为runtime时已经知道当前运行在哪种GPU架构中，因此可以直接生成 缺点是增加了程序的启动延迟，但是可以使用编译缓存来缓解 默认cuda以whole program compilation mode来编译\nreference and more reading\n# Matching CUDA arch and CUDA gencode for various NVIDIA architectures # CUDA 编译与 NVVM IR 笔记 # 银河系CUDA编程指南(2.5)——NVCC与PTX # NVCC编译流程+中间文件+GDB调试cuda程序初探 nvcc文档 # CUDA编译过程 nvcc编译选项 -g：在host端生成调试信息 -G：在device端生成调试信息。如果-dopt未指定，则关闭编译优化。 -lineinfo：为device端生成行号，同时将source information嵌入到可执行文件中 -dopt：如果-G没有指定，则-dopt=on，允许device端代码编译优化。如果-G指定，enables limited debug information generation for optimized device code 常用编译命令：\nnvcc -lineinfo -arch=compute_86 -code=sm_86 或者alias mynvcc='nvcc -lineinfo -arch=compute_86 -code=sm_86' 架构发展 Overview Tesla G80 SP（Streaming Processor）：scalar ALU for a single CUDA thread ALU执行是流水线化的，即一项操作会被分为X个步骤由X个组件去处理，每个步骤都耗费1周期。虽然一条指令要X周期才能执行完，但对于每个组件只要1周期就执行完了，所以每个周期都能送入一份数据进ALU。 SP的频率是调度单元（以及外部纹理单元等）的2倍，所以在调度单元看来，是需要2周期去消化1条指令。 SM（Streaming Mulitprocessor）：每个线程块分配到一个SM上 SM的频率是GPU频率的两倍 scoreboarding 作用：在指令发射阶段，检查待发射的指令是否与正在执行但尚未写回寄存器的指令之间存在数据相关。三种数据相关： 大致原理：scoreboard为每个warp寄存器分配一个bit来记录相应寄存器的写完成状态，\n如果后序指令不存在数据相关，则进入流水线 如果存在数据相关，通过检查标识位，后续指令就会stall而无法发射，此时可以切换其他warp的指令进行调度 参考\n# ILP——指令级并行2：记分牌（Scoreboard）技术 通用图形处理器设计3.5 Fermi 以GF100为例，架构： 特点 第三代流式多处理器（SM） 每个SM有32个CUDA核心，比GT200多4倍 双精度浮点峰值性能比GT200提高8倍 两个warp调度器，可以同时调度和分发指令给两个独立的warp 64KB RAM，可供共享内存和L1缓存配置化划分使用 第二代并行线程执行ISA（Instruction Set Architecture指令集架构） 统一地址空间，完全支持C++（比如虚函数、new/delete等） 针对OpenCL和DirectCompute进行了优化 完全支持IEEE 754-2008 32位和64位精度 具有64位扩展的完整32位整数路径 内存访问指令支持向64位寻址的过渡 通过预测提高性能 Predication enables short conditional code segments to execute efficiently with no branch instruction overhead 改进的内存子系统 具有可配置L1和统一L2高速缓存的NVIDIA Parallel DataCacheTM层次结构 之前Tesla架构没有L1、L2 cache 支持ECC内存的第一款GPU 大大提高原子内存操作性能 NVIDIA GigaThread引擎 应用程序上下文切换速度提高了10倍 并发内核执行 无序线程块执行 双向可重叠的内存传输引擎 SM SM架构：有4个执行端口 core 每个CUDA处理器都有完全流水线化的整数算术逻辑单元（ALU）和浮点单位（FPU） LD/ST单元 每个SM有16个Load/Store单元，允许16个线程每个时钟周期计算源和目的地址，支持将每个地址的数据读取和存储到缓存或DRAM中 SFU dual warp scheduler 每个SM有两个warp scheduler和两个instruction dispatch unit，每个周期可以同时issue和execute两个warp warp scheduler：选择warp Instruction Dispatch Unit：将指令发送到对应的端口（16个core、或16个LD/ST、或4个SFU中） 由于SP（或者core）的频率是调度单元的2倍，因此调度单元一个周期选择一个warp，一个周期内2倍频率的core连续两次在half-warp上执行 由于SFU只有4个，因此一个warp在SFU中计算需要消耗8个周期，但是此时它不阻塞调度 由于warp之间独立运行，因此warp scheduler不需要检查指令流中的依赖关系 大多数指令可以这样同时dual issue，两个整数指令、两个浮点指令或混合发出整数、浮点、加载、存储和 SFU 指令；但是双精度指令不支持dual dispatch with any other operation G80/GT200/Fermi对比 ISA Fermi是第一个支持PTX2.0的架构 PTX2.0统一了各种内存空间的寻址 GigaThread 两级thread scheduler thread scheduler：将线程块调度和分配到SM，GigaThread warp scheduler：将warp调度和分配到执行单元 特点： 应用程序上下文切换速度更快 concurrent(并发) kernel执行：（感觉下面的图画得有些confused？） 同一应用程序上下文的不同kernel可以并行在GPU上执行 不同应用程序上下文的kernel可以顺序执行 Kepler GK110/210是Kepler架构中高端型号，用于科学计算，因此主要以这两种型号为基础来介绍kepler架构。总体架构：15个SMX SMX 架构 SMX中的core的频率与主GPU频率相同，以增大面积为代价，降低功耗 warp scheduler 4个warp scheduler和8个instruction dispatch unit warp scheduler中调度的warp，对应的2个instruction dispatch unit可以在一个周期分配给该warp两个独立的指令 两个指令中允许双精度指令与其他指令dual dispatch kepler架构针对warp scheduler在降低功耗方面的优化：从硬件的动态调度转向编译器辅助的静态调度 Fermi用硬件scoreboard来记录寄存器的使用信息，从而确定指令之间的依赖关系 硬件scoreboard就是记录各个组件（寄存器、执行单元）当下的情况，并自动根据指令涉及的操作数、ALU去匹配。 到了Kepler架构，因为指令的执行周期是可以预计的，所以调度信息其实在编译期就能确定了。于是ISA就做了更改，每7条指令为一组，附加一段调度信息（Control Code），把因为数据依赖需要等待的cycle数记录进去。硬件上许多动态调度的模块被砍掉了，节省了功耗。 访存指令的延迟依旧是没法预计的，因为不知道有没有cache miss，所以遇到访存指令势必需要一个等待数据就绪的同步过程，可以借助软件scoreboard来完成。 软件scoreboard可以看作是预分配几个信条量，有依赖关系的指令会显式声明对哪几个信号量做操作，这样一来要记录维护的信息变少了，逻辑也简单了。同时软件scoreboard没有dependency check，一方面可以将这部分卸载到编译器，另一方面考虑到dependency不多 cache\nKepler的L1 Cache是用来为reg spill或者stack data服务的，即访存数据其实并不会缓存在L1里。 对于那些readonly的global memory，允许借用Tex Cache shuffle指令：warp可以读取来自warp内其他线程中任意排列的值，因此节省了共享内存\nDynamic Parallelism Hyper-Q 之前架构中只有一个CPU与GPU的工作分配器（CWD）之间的硬件工作队列，多个流复用一个队列，可能造成虚假的依赖性 现在有32个硬件工作队列 Grid Management Unit 为了支持动态并行，需要改变对grid的管理 NVIDIA GPUDirect 可以实现 GPU 与其他设备（例如网络接口卡 (NIC) 和存储设备）之间的直接通信和数据传输，但是中间数据不经过CPU Maxwell 以GM204为例，4个GPC，每个GPC有4个SMM 特点 更高效的SM（Maxwell SM，也称SMM）：core数量减少但是效率增加 指令调度提升 所有核心的SMM功能单元都分配给特定的调度器，没有共享单元。 每个分区中的core数量是32，warp scheduler方便调度 支持双发射（两个独立的指令，比如一个计算一个访存），也支持单发射（此时正好调度到一个warp） 现有代码的占用率增加：每个SM上active的block数量翻倍 减少算数指令延迟 更大的专用共享内存： 每个SMM有64KB的共享内存，4个processing block共享；但是每个线程块只能用48KB L1缓存专职服务于texture，L2缓存大小激增 快速的共享内存原子操作 支持动态并行：Kepler只在高端GPU中支持，Maxwell在低功率芯片中也支持 SMM Pascal 以GP100为例，6个GPC，每个GPC有5个TPC，每个TPC有2个Pascal SM（但是P100有56个SM） 架构 SMP 每个SM有64个core 每个SM中寄存器数量保持不变，因为SM数量更多，所以总的寄存器数量也变多 每个SM中共享内存从GM200的96KB下降到64KB，但是因为SM数量更多，因此共享内存总量更大 每个SM中有32个双精度FP64 CUDA core 支持FP16 有专用的共享内存（64KB/SM），L2 cache进一步增大 Unified Memory Compute preemption 计算抢占：允许在GPU上运行的计算任务在指令级别粒度上被中断 在Pascal架构之前： 仅仅在线程块粒度可以被中断 如果GPU上同时运行计算任务和显示任务，则长时间的计算可能会使得显示任务变得不响应和非交互 Pascal中 支持计算抢占，因此显示任务会保持流畅运行 同时，计算抢占允许在单个GPU上交互式调试kernel 硬件结构 内存从原来的GDDR5更换到HBM NVLink：可以GPU之间连接，也可以CPU和GPU之间连接 通过NVLink连接的GPU，程序可以直接访问另一个GPU的显存 Volta 以V100为例，有6个GPC，每个GPC有7个TPC，每个TPC有2个SM\nSM和Tensor Core core的变化：允许FP32和INT32操作同时执行\n原来SM是core（ALU+FPU）+DPU的结构，因此FP32与INT32无法同时运行 由于ALU都是流水线化、分阶段的，因此虽然ALU和FPU可以同时运行，但是可能处于不同阶段 现在SM是FP32+FP64+INT的结构，分离了ALU和FPU 因此FP32与INT32可以同时运行 而且FP32和INT32可以满吞吐运行 对于1个warp共32个线程，交给16个单元去执行的话，要像G80等架构提到的那样占用连续的两个周期来完成issue。不过在第二个周期，dispatch unit可以继续发射指令到其他单元，比如INT32。两者交错起来，就正好能达到满吞吐。 虽然增加了1周期的延迟，但是Volta大多数指令延迟都从6个周期降低到4个周期，总体还是快 意义：很多程序具有执行指针算术（整数内存地址计算）与浮点计算相结合的内部循环，流水线循环的每次迭代都可以更新地址（INT32指针算术）并为下一次迭代加载数据，同时在FP32中处理当前迭代。 Tensor Core\n每个tensor core在每个时钟周期内，可以执行64个浮点FMA操作（4*4*4的GEMM） 每个tensor core执行浮点FMA操作：D=A*B+C enhanced L1 data cache and shared memory\nInstruction Cache 原来SM中有一个Instruction Cache，每个processing block中有一个Instruction Buffer 现在SM中有一个L1 Instruction Cache，每个processing block中有一个L0 Instruction Cache 提高了L1 data cache的带宽，降低了其延迟 共享内存 将共享内存和L1 data cache整合起来，一共128KB，其中共享内存可以分配到96KB 纹理内存、全局内存都会经过L1 data cache 之前的GPU只有load caching，GV100中引入了write caching Independent Thread Scheduling 之前的SIMT模型\n一个warp使用一个共享的程序计数器，作用于32个线程，使用一个活动掩码，masked thread就是inactive的thread。各个分支依次执行，最后reconverge（同步） 由于divergence处理成顺序的执行，因此，来自不同区域或不同执行状态的 Warp 中的线程不能相互发送信号或交换数据，同时需要由锁或互斥锁保护的细粒度数据共享的算法很容易导致死锁 例子：比如0~3号线程在执行完A之后，需要使用到X的计算结果，此时无法实现 Volta的SIMT模型：引入独立线程调度，每个线程都有自己的程序计数器和调用堆栈 Volta的独立线程调度允许GPU放弃任何线程的执行，以便更好地利用执行资源或允许一个线程等待另一个线程生成数据，现在线程可以按照子warp粒度进行分支和重新汇聚，同时Volta中的收敛优化器仍会将执行相同代码的线程组合在一起、并行运行以达到最大效率。 可以使用CUDA 9的warp同步函数__syncwarp()来强制warp重新汇聚，因此假设了warp同步的代码不再安全 void __syncwarp(unsigned mask = 0xffffffff) 二进制位1表示对应的线程参与同步 虽然一个SM中拆分为了4个processing block，每个processing block16个FP32/INT32，而且每个线程都有自己的PC和stack，看起来half-warp在1个周期内可以直接调度和dispatch到一个processing block；但是每次调度仍然是一个warp（32个线程），消耗2个周期（1个周期调度到1个processing block，2个周期将完整的warp调度完毕）。 前面的方法会增加调度硬件的复杂性，而且这种运行时的动态信息会改变各个组件的可用情况，也可能会破坏编译器静态调度的预设状态。 例子1：可以实现warp内部细粒度的同步 例子2：分支间交错执行，可以掩盖stall 独立线程调度使得假设了warp同步的代码不再安全，比如此时在执行Z的时候，一个warp中的32个线程没有reconverge（同步），而是保持原来的branch执行 这是因为调度程序必须保守地假设Z可能会产生其他分叉执行分支所需的数据，如果是这种情况，自动强制重新汇聚将不安全。 此时需要使用__syncwarp()强制汇聚，可以提高SIMT效率 因此，从CUDA 9开始，原来的warp shuffle指令__shfl都变成了deprecated，推荐使用__shfl_sync，里面加入了mask参数 例子3：无饥饿算法，多线程环境下双向链表插入节点 Volta的独立线程调度确保即使线程T0当前持有节点A的锁，同一warp中的另一个线程T1也可以成功等待锁变得可用，而不会妨碍线程T0的进展。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 __device__ void insert_after(Node *a, Node *b) { Node *c; lock(a); lock(a-\u0026gt;next); c = a-\u0026gt;next; a-\u0026gt;next = b; b-\u0026gt;prev = a; b-\u0026gt;next = c; c-\u0026gt;prev = b; unlock(c); unlock(a); } 缺点：增加了寄存器负担，单个线程的程序计数器一般要占用两个寄存器 参考 https://www.zhihu.com/question/290660113 https://developer.nvidia.com/blog/inside-volta/ https://zhuanlan.zhihu.com/p/186192189 Multi-Process Service(MPS) MPS：实现多个计算应用程序共享GPU时的性能提升和隔离\n特点\n保证服务质量：限制每个应用程序只使用GPU资源的一部分，从而降低或消除排队阻塞 独立地址空间：不同应用程序进行地址隔离 发展\nVolta之前都是通过软件方法，使用时间片的方式Time-slice scheduling 从Kepler GK110 GPU开始，NVIDIA引入了基于软件的Multi-Process Service（MPS）和MPS Server，MPS Server允许将多个不同的CPU进程（应用程序上下文）组合成单个应用程序上下文并运行在GPU上，从而实现更高的GPU资源利用率。 对于Pascal，CUDA Multi-Process Service是一个CPU进程，它代表已经请求和其他GPU应用程序同时共享执行资源的GPU应用程序。该进程充当中介，将工作提交到GPU内部的工作队列中以进行并发内核执行。 Volta MPS： Server CUDA Context管理GPU硬件资源，多个MPS Clients会将它们的任务通过MPS Server传入GPU Volta MPS对MPS server的关键部分使用硬件加速，使得MPS客户端能够直接将工作提交到GPU内部的工作队列中，同时将MPS客户端的最大数量从Pascal上的16增加到Volta上的48 Volta MPS旨在将GPU共享在单个用户的应用程序之间，并不适用于多用户或多租户用例 如果其中一个运行出错，则可能导致运行的任务都失败，即Volta MPS不提供客户端之间的致命故障隔离。 应用：\nNo Batching的推理场景中，允许许多单独的单个推理任务同时提交到GPU，提升GPU利用率 支持linux下的统一内存， 在GPU执行时，之前的MPS client都是运行在一个单独的地址空间，与访问独立CPU进程内存不兼容 Hyper-Q与MPS\nHyper-Q：多流优化，同一个应用程序下多个stream中，没有依赖的操作可以并行执行 MPS：同时并行运行多个应用程序，多个应用程序共享同一个GPU context more reading and reference\nMULTI-PROCESS SERVICE # 教你如何继续压榨GPU的算力 https://asphelzhn.github.io/2019/04/14/tensor_09_MPS/ https://blog.csdn.net/cleanarea/article/details/112691820 Cooperative Groups(CG) 协作组是CUDA 9引入的新特性，允许自定义线程通信的粒度 # CUDA 编程模型之协作组（Cooperative Groups） # CUDA协作组详解\nTuring 以TU102为例，有6个GPC，每个GPC有6个TPC，每个TPC有2个SM SM 添加了独立的integer datapath，可以与浮点数指令同时运行 Uniform Register：将共享内存、texture cache、memory load cache（L1 data cache？）重新设计，统一到一起 第二代Tensor Core 添加了INT8和INT4精度模式，增强了推理性能 支持DLSS（Deep Learning Super Sampling） 实时光线追踪、渲染管线、RT Core、DLSS等图像相关 Ampere 以GA100为例，有8 GPCs, 8 TPCs/GPC, 2 SMs/TPC\nSM 第三代Tensor Core Tensor Core Sparsity利用2:4的细粒度结构化稀疏性，使得吞吐量翻倍 稀疏矩阵定义：2:4稀疏矩阵，即每个四元组中有两个非零值 过程：使用稠密权重进行训练，然后进行细粒度结构化剪枝，最后通过额外的训练步骤对剩余的非零权重进行微调。 具体而言，A100使用Sparse MMA(Matrix Multiply-Accumulate)指令，跳过对带零值的输入进行计算，从而使 Tensor Core 的计算吞吐量翻倍 支持所有数据类型：FP16、BF16、TF32、FP64、INT8、INT4 和 INT1，且比V100有进一步的加速效果 如果不使用Tensor Core，默认使用FP32；如果使用Tensor Core，则默认使用TF32 支持FP16/FP32、BF16/FP32混合精度，且两种混合精度速度一样快 TF32一方面保持了FP16的精度，另一方面保持了FP32的范围，因此很适合训练 memory方面的改进 Data sharing improvements： 数据可以在一个warp中32个线程共享，原来Volta只能在8个线程之间共享 因此节省了寄存器和带宽 同时，A100 Tensor Core将矩阵乘法指令的k维变为原来的4倍 表格中的数据怎么来的？Nvidia tensorCore 计算过程 Data Fetch improvement 新的异步拷贝指令可以直接将数据从全局内存（通常是DRAM和L2缓存）中加载到共享内存中，绕过L1缓存和寄存器 原来Volta中，数据先经过L1缓存读取到寄存器，然后再写到共享内存中 异步拷贝指令与异步barrier搭配使用：异步拷贝完成后，通过异步barrier通知程序拷贝完成 Compute Data Compression Combined L1 cache and shared memory L1 data cache和共享内存整合到一起，一共192KB FP32和INT32可以同时运行、且满吞吐运行（与Volta与Turing架构相同） L2 cache improvement\n设计改进 Residency Control：ping-pong buffer（或称double buffer） ping-pong buffer常驻于L2缓存上，减少对内存的写回，保持L2中数据重用 比如推理场景中，权重分段轮流装载到L2缓存上，让计算与权重装载并行。此时，多batch可以共用更多的权重 总结 Multi-Instance GPU(MIG) 背景：Volta MPS虽然支持多个应用程序同时运行，但是可能一个应用程序占用太多内存带宽或是L2缓存，对其他应用程序造成影响\nMIG MIG可以将每个A100 划分为最多7个GPU Instance，每个instance可以为client（虚拟机、容器、进程等）提供定义的服务质量和故障隔离 每个instance由若干个GPU slices组成，GPU slices的结构 Sys Pipe：GigaThread Engine的一部分 一个GPC（7个TPC，14个SM） 一个L2 slice group（包括10个L2 cache slices） 对一部分frame buffer memory的访问 每个instance内部可以再细分为compute instance compute instance可以自行配置和封装计算资源，默认每个instance创建一个compute instance，因此该compute instance使用该instance的全部资源 每个compute instance包括一个Sys Pipe和若干个GPC，所有共享一个compute instance的应用程序共享一个Sys Pipe，每个compute instance都可以单独进行上下文切换 每个compute instance都支持MPS，MPS client的最大数量与compute instance大小成正比 应用场景：\nMulti-Tenant Single Tenant, Single User：一个用户运行多个GPU应用程序 Single Tenant, Multi-User：比如对外部提供AI服务 CUDA Advances Task Graph Acceleration\n背景：对于深度学习等应用场景，有iterative structure（即same workflow is executed repeatedly） 以前只能在每个iteration中，CPU重新提交任务到GPU。尤其是很多小的kernel在整个运行过程中，launch、init等开销占了相当一部分时间。 现在定义一个task graph（若干个操作、相应依赖关系和一些内存操作），可以define-once/run-repeatedly，即先将多个kernel预先构建为一个task graph，然后CPU一次性launch，减少了launch、init的时间 kernel的执行流程可以分为三个步骤：launch，grid initialization，kernel execution 加速原理： launch optimization：submit multiple work items to the GPU in a single operation execution dependency optimization：可以优化复杂的graph（比如workflow fork and re-join，在一个fork分支中可以有多个dependency） 异步数据拷贝和异步barrier：memcpy_asnyc\n异步数据拷贝： memcpy_asnyc：从global memory到shared memory的异步数据拷贝 cudaMemcpyAsync：从CPU memory到GPU global memory的异步数据拷贝 异步barrier：arrival和wait是分开的 arrival：最快线程到达barrier wait：等待其他线程（或者最慢的线程）到达barrier 普通的barrier由于各线程快慢不一，中间有idle；异步barrier中间原来idle的部分现在进行其他independent work Controlling Data Movement to Boost Performance on the NVIDIA Ampere Architecture：两阶段的pipeline，将计算与拷贝重叠 L2 cache residency control\n两种数据： persisting data：数据重复使用，比如深度学习场景，或生产者-消费者场景 streaming data：数据只使用一次 L2 cache中专门留出一部分给persisting data使用，persistent access优先访问这部分，具体见Device Memory L2 Access Management 参考\n# NVIDIA GPU A100 Ampere(安培) 架构深度解析 # CUDA效率优化之：CUDA Graph # NV Ampere GPU架构学习与思考 Ada Lovelace cuda core数量增加 第四代Tensor Core Hopper FP8 Transformer Engine Hopper white paper\n参考 https://mp.weixin.qq.com/s/qakvAfNV4KkmNa3P56i-dQ 江南泣相关（翻译）博客和对应white paper NVIDIA GPU的一些解析（一）的相关解读 ","permalink":"https://qinganzhang.github.io/posts/cuda-learning-notes/gpu%E6%9E%B6%E6%9E%84%E5%8F%91%E5%B1%95%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%BC%96%E8%AF%91/","summary":"CUDA编译链和兼容性 兼容性 CPU与GPU的区别 CPU只有少量的计算核心，有更多晶体管用于数据缓存和流程控制， GPU有大量计算能力较弱的计算","title":"[cuda-learning-notes] GPU架构发展、兼容性和编译"},{"content":"1. 查看 1.1 移动光标 w/W, b/B移动到下一单词、上一单词的开头，e/E移动到下一单词的结尾，大写空格分割，小写非字母分割 $, ^行尾 行首，0行间第一个字符 Ctrl+f/b翻页，Ctrl+d/u翻半页，Ctrl+e/y上下滚动一行 数字+方向键移动多次（数字+cmd执行多次cmd） gg, G文件首尾 50%移动到文件50%的位置，:50移动到第50行，.表示当前行号，$表示最后一行的行号 /pattern正则匹配查找，n/N上下跳转 光标移动到括号上时，使用%进行括号配对 1.2 文件编码 :set fileencoding查看当前文件编码 :e ++enc=utf-8使用utf-8重新打开文件 1.3 显示 :set nu, :set nonu显示/不显示行号，在~/.vimrc中设置set nu持久化设置 Ctrl+G显示当前状态 1.4 分屏 打开 vim -O file1 file2 打开多个文本（-O垂直分屏，-o水平分屏） :vs file在当前vim中打开file的垂直分屏，:sp file在当前vim中打开file的水平分屏 Ctrl+w v/s复制当前屏为相同垂直分屏或水平分屏 :new newfile在vim中创建新文本并创建分屏 切换 Ctrl+w+w切换下一个 Ctrl+w+h/j/k/l，hl左右，jk上下 改变位置 Ctrl+w Shift+h/j/k/l，当前屏左上下右移动 改变大小 Ctrl+w Shift+|水平加宽，Ctrl+w Shift+_垂直加宽，Ctrl+w =重置大小 Ctrl+w n +增加高度n，Ctrl+w n -减少高度n，Ctrl+w n Shift+\u0026lt;界线左移n，Ctrl+w n Shift+\u0026gt;界线右移n 关闭 Ctrl+w c关闭当前分屏 Ctrl+w o只保留当前分屏 2. 编辑 2.1 进入编辑模式 i光标处插入，a光标右边插入，o,O下面、上面另起一行，I,A行首尾插入 2.2 简单编辑 2.2.1 选中：v v, V, Ctrl+v字符、行、块选中 可以结合w/W, b/B, e/E 结合text object 2.2.2 text object 包括范围和文本对象，可以结合各种操作使用 范围：i：inner,a：around 文本对象：w：word，s：sentence，各种括号引号 2.2.3 删除和剪切：d 删除将内容复制到匿名寄存器中（即剪切），可以使用黑洞寄存器\u0026quot;_避免剪切内容\n不剪切的删除（将删除内容复制到黑洞寄存器中，相当于不保存）：\u0026quot;_cmd，其中cmd是删除相关的命令，eg：\u0026quot;_x\n使用键盘映射实现更简便的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;在~/.vimrc中,将删除映射为不剪切的删除，剪切映射为删除命令前加前缀\u0026#34; let mapleader = \u0026#34;,\u0026#34; nnoremap x \u0026#34;_x nnoremap X \u0026#34;_X nnoremap d \u0026#34;_d nnoremap dd \u0026#34;_dd nnoremap D \u0026#34;_D vnoremap d \u0026#34;_d vnoremap dd \u0026#34;_dd \u0026#34;\u0026lt;leader\u0026gt;是前缀，通过mapleader设定\u0026#34; nnoremap \u0026lt;leader\u0026gt;x \u0026#34;\u0026#34;x nnoremap \u0026lt;leader\u0026gt;X \u0026#34;\u0026#34;X nnoremap \u0026lt;leader\u0026gt;d \u0026#34;\u0026#34;d nnoremap \u0026lt;leader\u0026gt;dd \u0026#34;\u0026#34;dd nnoremap \u0026lt;leader\u0026gt;D \u0026#34;\u0026#34;D vnoremap \u0026lt;leader\u0026gt;d \u0026#34;\u0026#34;d vnoremap \u0026lt;leader\u0026gt;dd \u0026#34;\u0026#34;dd 在~/.vimrc中输入:source ~/.vimrc使设定生效\n在vim中输入:map查看当前的键盘映射\nD, d$删除光标至行尾，dd删除当前行\nx删除当前字符，daw删除单词及后面的空格，diw删除单词，结合text object\n:m,nd删除m-n行\ns删除字符并插入，S清空行并插入\n先选中，然后x删除选中部分，D删除选中行\n2.2.4 复制：y yy复制当前行，:m,ny复制m-n行到剪贴板 结合text object 2.2.5 粘贴：p p，P粘贴到光标处/后 m,ncok复制m-n行到k行下一行 m,nmk移动m-n行到k行下一行 2.2.6 搜索 /pattern匹配，n, N下一个上一个匹配对象 *, #匹配下一个，上一个相同的单词 2.2.7 替换：c 结合text object r单字符替换，R字符串替换 [range]s/pattern/replace/[flags] [range]：%(全文)，.，m,n，m [flags]：g全局替换，c替换前询问，不写默认替换首个 2.2.8 撤销重做 u撤销 Ctrl+r重做 2.2.9 批量注释 方法一： 注释：Ctrl+v选择，Shift+i进入编辑模式，输入插入的字符比如#，再两次Esc 取消注释：Ctrl+v选择，x或d删除（就是选择然后删除） 方法二：正则替换 注释：:m,ns/^/#/g 取消注释：:m,ns/^#//g（替换成空白） 2.2.10 其他 J将当前行下面的行合并到当前行 3. 其他 3.1 优质Blog 完全用Vim工作 ","permalink":"https://qinganzhang.github.io/posts/%E5%B8%B8%E7%94%A8vim%E6%93%8D%E4%BD%9C/","summary":"1. 查看 1.1 移动光标 w/W, b/B移动到下一单词、上一单词的开头，e/E移动到下一单词的结尾，大写空格分割，小写非字母分割 $, ^行尾 行首，0行间第一个字","title":"常用vim操作"},{"content":"Git配置相关 （全局）配置：如果是局部配置，每个仓库都需要进行配置\n1 2 3 4 5 6 7 8 # 设置全局配置 # git config --global user.name \u0026#34;zhangqingan\u0026#34; # git config --global user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --global https.proxy http://127.0.0.1:7890 # git config --global https.proxy http://127.0.0.1:7890 # 清除全局配置 # git config --global unset user.name # git config --global unset user.email 如果是针对仓库的局部配置\n1 2 3 git config --local user.name \u0026#34;zhangqingan\u0026#34; git config --local user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --local --list 生成密钥对\n1 2 3 4 ssh-keygen -t rsa -C \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # 并且后续生成密钥的位置自定义，注意win上这里是一个目录，linux上是文件名 ssh-keygen -l -f key # 查看密钥的contents（SHA256+comments） 添加私钥\n1 2 3 4 # ssh-agent bash ssh-add private_key # 将私钥添加到本地 ssh-add -l # 查看当前添加的私钥 ssh agent详解\n修改配置文件：修改~/.ssh/config\n1 2 3 4 5 Host github(bupt) User QinganZhang HostName ssh.github.com IdentityFile /home/zqg/.ssh/github/bupt Port 443 # or 22 reference and more reading\nGit多用户配置 如何为Git设置代理 相关概念 顶层概念：\nWorkspace：工作区，本地的工作目录 Repository：包含.git目录的工作区，其中.git为版本库，其中保存了stage暂存区、第一个分支main、指向main的指针HEAD Index/Stage：暂存区 Remote：远程仓库 底层概念：from missing semester中的Git\n文件称为Blob对象（数据对象），目录称为tree，每个commit即为一个对文件和目录的快照的指针（保存了当前的整个仓库，或者说追踪最顶层的树）\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 文件就是一组数据 type blob = array\u0026lt;byte\u0026gt; // 一个包含文件和目录的目录 type tree = map\u0026lt;string, tree | blob\u0026gt; // 每个提交都包含一个父辈，元数据和顶层树 type commit = struct { parent: array\u0026lt;commit\u0026gt; // 一个commit可能有多个parent author: string message: string snapshot: tree // 追踪最顶层的树 } 对象可以是文件、目录或者commit，对象通过SHA-1哈希进行按名存取（文件和目录好说，但是commit就不好访问了，因此统一使用SHA-1哈希）\n1 2 type object = blog | tree | commit objects = map\u0026lt;string, object\u0026gt; 为了方便好记，使用引用来指向最近一次的commit，而不是来记一串哈希值。因此，分支就是可变的引用，而标签就是绑定到特定commit的引用，HEAD指向当前的commit\n1 references = map\u0026lt;string, string\u0026gt; 因此，Repository保存的就是对象和引用。\n前面说commit是一个对文件和目录的快照，是通过向暂存区进行若干次操作，确认保存操作的结果，即形成一个快照\n其他概念：\ntrack/untrack：文件或目录是否纳入到git的版本控制范围内 基础操作 常用操作 git init -b main：创建.git文件夹，将当前目录变成一个仓库，默认分支为main\ngit add：将文件添加到暂存区（stage），相当于创建了快照，否则文件就是untracked的\ngit diff：比较当前工作区和暂存区快照之间的差异，即修改之后还没有暂存起来的变化内容 git commit -m \u0026quot;comment\u0026quot;：将暂存区的修改提交到分支（多次add之后进行一次commit），commit就是一个快照\ngit diff --staged：比较暂存区快照和最近一次commit之间的差异 git commit -a -m \u0026quot;comment\u0026quot; ：将所有跟踪过的文件暂存起来一起提交，跳过了git add步骤 git status：查看当前文件夹中文件的状态\ngit rm --cached \u0026lt;file\u0026gt;：取消对file的跟踪\ngit diff：\ngit diff命令，官方文档 git diff输出结果解读 git diff输出中 \\ No newline at end of file的含义 git log：查看commit历史，最近的排在最上面\n-p (--path)：显示每次提交所引入的差异（按补丁的格式输出） 补丁：即两次文件的差异 --stat：显示每次提交的简略统计信息 --ptetty：设置输出模式，可以自定义输出格式 --decorate：查看各个分支当前所指向的对象 --graph： -n：限制输出长度 --since, --until --grep：搜索提交说明中的关键字 -S：pickaxe选项，接受一个字符串，搜索那些添加或删除了该字符串的提交 -- path：输出某些文件或目录的历史提交，注意这个参数是放在最后的（因此用两个短线隔开） 版本控制 版本回退\ngit reset --hard HEAD^：返回到最近一次commit HEAD指向最近一次的commit，HEAD^和HEAD^^分别表示上一个commit和上上个commit git reset --hard commitId：返回到特定的commit git log --pretty=oneline ：显示所有提交过的commit，不包括已经回退的commit记录 怎么才能看懂git log的线 git reflog：显示所有提交过的commit，包括回退的操作，比如回退之后又反悔了，需要使用reflog来找到新版本对应的commit id 撤销修改\n如果只是在本地工作区修改了，还没有git add：git restore \u0026lt;file\u0026gt;或者git checkout -- \u0026lt;file\u0026gt; 如果在本地工作区修改之后，已经git add：git restore --staged \u0026lt;file\u0026gt;或者git reset HEAD \u0026lt;file\u0026gt; 如果已经git commit，则进行版本回退 重新提交：如果上一次commit完成后，发现漏了些文件，此时先git add，然后使用git commit --ament，这样只会有一次提交，后一次的提交会覆盖前一次的提交\n远程库 对远程库的操作实际上都是对远程库中远程分支的操作，默认远程库为origin，远程分支为 与当前本地仓库分支 同名的远程分支\n远程库的几种使用场景：\n克隆别人的仓库：git clone默认只有main分支，使用git checkout -b dev origin/dev在本地创建dev分支，并且与远程的dev分支关联起来\n自己在GitHub上新建一个仓库，然后clone下来进行开发\n自己在本地目录下，先git init创建本地仓库，然后将本地仓库与远程仓库关联起来：git remote add \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt;\n\u0026lt;url\u0026gt;支持多种协议，\u0026lt;shortname\u0026gt;即代表了该url\n一般远程库的名字就叫origin\n可以关联多个远程库，比如本地仓库关联一个共有的和一个私有的仓库\n查看远程库信息：git remote -v\n远程库可能有多个 获取远程库的更新：\ngit fetch \u0026lt;remote\u0026gt;：只会将远程库的更新下载到本地仓库，不会自动进行合并 git pull：如果当前分支设置了跟踪远程分支，则git pull会拉取更新，并自动进行合并。如果有冲突，需要手动解决冲突。 详解git pull和git fetch的区别 将本地库的内容推送到远程库：git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt;\n默认remote是origin，默认将本地分支推送到远程的同名分支上 git push -u origin main：第一次push时，远程库是空的，此时不但会将本地库的内容推送到远程库，而且将本地的main分支和远程库的main分支关联起来 如果他人先于你push到远程，你的push会被拒绝，此时需要拉取更新，手动修改冲突的部分，合并之后才能再push 查看某个远程仓库：git remote show \u0026lt;remote\u0026gt;\n远程仓库重命名：git remote rename old-name new-name\n解除本地和远程库之间的关联关系：git remote rm origin\n分支管理 分支是指向commit的可变指针，默认名字为main，main分支在每次提交时都自动向前移动\nHEAD是一个指向当前所在的本地分支的指针（可以想象为当前分支的别名）\n基本操作 注意这些操作都是在本地仓库的\n创建分支：git branch dev\n--merged：查看哪些分支已经合并到当前分支 --no-merged：查看所有包含未合并工作的分支（即没有汇聚到当前分支的那些分支） 重命名当前分支：git branch -M newname\n切换分支：git checkout dev\n创建并切换分支：git checkout -b dev或者git switch -c dev\n合并指定分支到当前分支：git merge dev\n如果当前分支main和待合并分支dev存在冲突，此时进行了合并，但是没有创建一个新的commit，需要先解决冲突，再手动进行commit，解决冲突就是手动将git merge失败的文件手动进行编辑，可以使用git status查看unmerged的文件，然后使用git merge --continue继续合并过程。 Git官方文档-3.2分支的新建与合并 Git冲突详细处理步骤及案例 如何避免Git冲突 git解决冲突（超详细图文版及常用命令） 因此使用分支时应该在main分支中生成多个dev分支，最后选择合适的dev分支进行合并，而非直接在main分支上进行修改 默认合并分支时使用Fast forward模式，此时删除分支之后，会丢掉分支信息。如果禁用fast forward模式（--no-ff），git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息 fast forward模式的含义：比如dev是master的直接后继，即master之后没有分叉，此时将dev merge到master上时，直接移动master的指针即可 查看分支：git branch\n-vv：列出每一个分支正在跟踪的远程分支，以及ahead和behind信息 如果需要查看最新的信息，则需要更新远程的信息，git fetch --all; git branch -vv 删除分支：git branch -d dev\n如果当前分支还没有被合并，而且需要删除当前分支，需要使用git branch -D dev强行删除 远程分支 远程跟踪分支是远程分支状态的引用，相当于书签。比如远程仓库命名为origin，拉取该仓库的main分支，因此本地就将对应的commit叫做origin/main，在本地仓库同样有一个main分支，比如本地进行多个commit会ahead of origin/main。Git官方文档-3.5远程分支\n比如当拉取本地没有的、位于远程的新的分支b时，本地只会有一个不可修改的origin/b指针，本地不会自动生成一份可编辑的副本。因此，需要使用git merge origin/b将远程分支b合并到本地当前分支，或者git checkout -b b origin/b将远程分支拉取到本地的新分支b上（如果本地仓库没有分支b，而且远程分支只有一个叫做b的分支，则一个快捷方式为：git checkout b） 修改或设置跟踪的上游分支 ：git branch -u origin/b 删除远程分支：git push origin --delete b 这个操作只是从服务器上移除这个指针，实际物理删除需要等到过一段时间git服务器进行垃圾回收时，因此误删通常是容易恢复的 最佳实践-修复Bug 背景：比如main分支上有一个bug，但是当前在dev分支上，而且针对dev的工作还没有完成（即当前不能commit到dev分支，从而清空status） 大致流程为： 使用git stash将当前工作区保存起来，此时工作区恢复到最近一次commit时的状态 然后修复bug：先切换到main分支，创建修复bug的分支，修复bug，然后再合并到main分支，同时也需要将修复bug这个commit合并到其他dev分支，切换到dev分支，然后git cherry-pick git cherry-pick commit_id：复制一个特定的commit到当前分支（相当于在dev分支上将修复bug的操作重新进行commit，因此生成的commit id和在main分支上的commit id不同） 修复完bug再恢复当前工作区 查看暂存的工作区：git stash list 恢复暂存的工作区： git stash apply：恢复之前保存的工作区，但是保存的工作区内容还在stash中，需要使用git stash drop进行删除。可以恢复指定的工作区：git stash apply stash{0} git stash pop：恢复工作区的公式，也将保存在stash中的内容删除 Rebase 用来将一组commit按照顺序（即某一分支上的commit）合并到一个特定的commit后面（即另一个分支的最后）\n万能公式：git rebase --onto \u0026lt;base\u0026gt; \u0026lt;start\u0026gt; \u0026lt;end\u0026gt; 变基原则：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，则不要进行变基 参考 Git官方文档-3.6变基 万能公式来源：强烈推荐：git rebase有哪些用法？elpie-kay的回答 标签管理 标签就是指向commit的指针，但是分支可以移动，标签不能移动\n在关键commit节点，使用commit id不方便，因此标签绑定到该commit id\n打标签：git tag v1.0\n在某个特定的commit上打tag，并添加说明：git tag -a v1.0 -m \u0026quot;comments\u0026quot; commitId 这里说的标签指的是轻量标签（某个特定提交的引用），附注标签指的是上面添加的说明 查看所有标签：git tag\n标签不是按照时间顺序列出，而是按照字母排列列出 查看标签信息：git show v1.0 删除标签：git tag -d v0.9可以删除本地标签\n删除远程标签时，先从本地删除，然后使用从远程删除。从远程删除： 第一种方法：git push origin :refs/tags/v0.9（即将冒号前面的空值推送到远程） 第二种方法：git push origin --delete v0.9 推送标签到远程：git push origin v1.0\n默认情况下git push不会将标签推送到远程仓库上 一次性推送所有标签到远程：git push origin --tags 检出标签：git checkout \u0026lt;tag\u0026gt;，即将HEAD移动到指向某个标签，此时仓库处于detached HEAD状态\n自定义Git 忽略特殊文件.gitignore 一些.gitignore模板\n虽然某个文件可以匹配到gitignore的规则，但是需要强制添加：git add -f myfile\n或者某个文件应该可以添加但仍然被忽略了，说明gitignore规则有问题，找出对应的规则条目：git check-ignore -v myfile\n在线生成gitignore文件：Gitignore Online Generator\n配置别名 几个例子：\ngit config --global alias.st status\ngit config --global alias.unstage 'restore --stage'：将add到暂存区的修改撤销掉\ngit config --global alias.last 'log -1'：显示最后一次提交信息\ngit config --global alias.lg \u0026quot;log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset' --abbrev-commit\u0026quot;：自定义git log显示\n删除别名时，只需要在仓库的配置文件.git/config或是用户的配置文件.gitconfig的[alias]段落中，删除掉特定的行即可\n工作流 向一个项目贡献 提交准则 提交不应包含trailing whitespace。git apply应用补丁时会检测空白错误,默认情况下,尾部空白,包含空白的空行,初始tab缩进之后紧跟的空白字符会被认为是错误。参考\n在git apply patch时，应该先git diff --check，将会找到可能的whitespace errors并列出来 By default, trailing whitespaces (including lines that consist solely of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors.\n—— from git-diff\n让每个commit解决一个问题，不要多个问题混在一个commit中\n重视写commit message\n一个好的commit message模板 私有开发项目 Git文档中一个私有开发项目的例子\n私有管理团队 多个开发者在feature分支上工作，只有整合者才能将feature分支merge到master分支\nGit文档中一个私有管理团队的例子\n派生的公开项目 先fork公开项目，然后自己进行修改，最后通过Pull Request请求合并\nGit文档中一个派生的公开项目的例子\n通过邮件的公开项目 使用git format-patch生成mbox文件，它将每一个提交转换为一封电子邮件，其中保留了所有的提交信息。最后通过git send-email发送补丁。\n维护项目 在主题分支中工作 应用来自邮件的补丁 使用git apply应用补丁 补丁是通过git diff生成的，可以对补丁进行检查git apply --check git apply要么全部应用补丁，要么全部不应用，不会部分应用补丁 git apply之后，需要手动暂存并提交 使用git am应用补丁（推荐） 补丁是通过git format-patch生成的，此时补丁中包含了作者信息和commit message，因此更加推荐 git am是为了读取mbox文件而构建的，mbox是一种用来在单个文本文件中存储一个或多个电子邮件消息的简单纯文本格式 git am会自动创建一个新的提交，作者信息和提交消息来自于mbox文件，并自动应用mbox指向的补丁 如果发生冲突，则同样需要手动进行修改，然后暂存，再git am --resolved继续应用下一个补丁 git生成patch和打patch 检出远程分支 背景：别人fork了自己的仓库，并且在某个分支上进行了修改，想提交贡献，此时我得到了它的仓库的URL和对应的分支 如果想与他人建立长期的合作交流：将其仓库添加为远程仓库，fetch到本地并在本地checkout到该分支，进行测试 如果别人只是偶尔提供一个贡献 直接pull到本地（不会将该URL添加为远程仓库），然后切换分支并进行测试 或者使用电子邮件来接受patch（或者使用托管服务） 确定引入了哪些东西 检查main分支未包含的commit，比如检查某个分支contrib上引入的修改：git log contrib --not main\n如果想具体查看contrib分支上相对于原来main，到底有什么区别（即diff），使用git diff main...contrib，即对contrib分支的最新提交和两个分支的最近共同祖先进行比较（注意三个点）\n因为在进行contrib分支上的工作时，main分支可能同时继续向前，diff比较时的main分支应该为原来的位置，即为contrib和现在main分支的最近共同祖先 将贡献的工作整合进来 合并工作流：将主题分支合并到main分支，然后删除主题分支\n如果项目很重要，可以使用两阶段循环合并，即维护两个长期分支（main和develop分支），新代码首先合并到develop分支，打标签发布时才将main分支更新到稳定的develop分支 为了保持线性的提交历史，可以在 main分支上对贡献来的工作进行变基而不是直接合并。另一种类似效果的方式是，提取分支的补丁，然后应用到当前分支上\nRerere：重用已记录的冲突解决方案，是一种简化冲突解决的方法。当启用 rerere 时，Git 将会维护一些成功合并之前和之后的镜像，当 Git 发现之前已经修复过类似的冲突时， 便会使用之前的修复方案，而不需要你的干预。\n发布 为发布打标签 生成一个构建号 创建一个归档文件 制作提交简报 基于Github的工作流 常见问题 ssh -T git@github.com 连接超时 示例：\nssh -T git@github.com的含义：\n解决方法：\n如果使用ssh协议：修改HostName或者修改Port\n在.ssh文件夹下的config文件中修改：参考\n1 2 3 4 Host github.com HostName ssh.github.com User xxx IdentityFile xxx 如果使用https协议：参考\n","permalink":"https://qinganzhang.github.io/posts/git%E7%AC%94%E8%AE%B0/","summary":"Git配置相关 （全局）配置：如果是局部配置，每个仓库都需要进行配置 1 2 3 4 5 6 7 8 # 设置全局配置 # git config --global user.name \u0026#34;zhangqingan\u0026#34; # git config --global user.email \u0026#34;zhangqingannn@bupt.edu.cn\u0026#34; # git config --global https.proxy http://127.0.0.1:7890 # git config --global","title":"Git笔记"},{"content":"[toc]\ntags：【双指针】，【前缀和】，【原地哈希】\n【好题】，【不会】，【重要】\n方法 双指针 前后定长双指针 前后快慢双指针 左右双向双指针 611.有效三角形的个数 方法一：二重循环a、b，对c进行二分查找（查找最后一个满足a+b\u0026lt;c的c） 方法二：遍历c，左右双指针表示a(nums[i])和b(nums[j])，参考 if(nums[i] + nums[j] \u0026gt; c) ，此时有j-i个三角形，j向左走（i向右走无用） if(nums[i] + nums[j] \u0026lt;= c) ，此时有0个三角形，i向右走（j向左走无用） 11.盛最多水的容器：盛水体积只取决于左右两隔板的高度（木桶理论） 区别于接雨水，雨水可能分布在不连续的凹陷处 两分支双指针 165.比较版本号 滑动窗口 904. 水果成篮\n基于双指针的滑动窗口 必须使用滑动窗口保证水果是连续的，如果只使用哈希表，则可能出现中间有中断的情况 76. 最小覆盖子串：代码\n对t统计词频，得到相同的两个ump：tump和tmp_ump 只移动右指针，找到s中第一个包含t的区间 移动右指针的过程中，逐步递减并erasetmp_ump中的元素，直到tmp_ump为空，此时就找到了s中第一个包含t的区间，同时维护区间的词频win_ump 窗口进行移动：将c=s[left++]从win_ump中减一，同时左指针向右移动了一位， 如果此时win_ump[c] \u0026gt;= tump[c]，说明c不在t中，或者c是t中是多余重复的，因此continue 如果此时win_ump[c] \u0026lt; tump[c]，说明c是t中的，需要右指针向右移动，再次找到c字符，因此得到了新的窗口 技巧：可以s+=' '，避免最后跳出循环还要移动左指针， 3.无重复字符的最长子串 【重要】\n1004.最大连续1的个数Ⅲ\n两种思路 复杂的代码：维护窗口内0的数量，但同时也分情况讨论左右断点的情况 简洁的代码：找出一个最长的子数组，该子数组中最多有k个0，因此只需要维护窗口内0的数量即可 数组【二刷】 模拟题 498.对角线遍历：i+j==level\n48.旋转图像\n最重要的是找到原来(i,j)位置的元素，旋转之后在什么位置（(j,n-i-1)） 矩阵变换的方法也是从上面的对应关系来的 先转置(j,i)，再水平翻转(j,n-i-1) 或者先垂直翻转(n-i-1,j)，再转置(j,n-i-1) 54.螺旋矩阵 和 59. 螺旋矩阵 II\n按圈遍历，设定四个逐步减小的边界 每圈遍历中，判断新到达的位置是否超出边界，若是则改变方向 (二分)查找 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 假设v非递减 int find_first_ge(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回第一个\u0026gt;=target的元素的索引（lower_bound） int left = 0, right = v.size(), mid = -1; while(left \u0026lt; right){ mid = left + (right - left) / 2; if(v[mid] \u0026gt; target) right = mid; // target is in left part else if(v[mid] \u0026lt; target) left = mid + 1; // target is in right part else right = mid; // v[mid] == target, } return left; // now left == right } int find_first_gt(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回第一个\u0026gt;target的元素的索引（upper_bound） int left = 0, right = v.size(), mid = -1; while(left \u0026lt; right){ mid = left + (right - left) / 2; if(v[mid] \u0026gt; target) right = mid; else if(v[mid] \u0026lt; target) left = mid + 1; else left = mid + 1; // difference } return left; } int find_last_le(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回最后一个\u0026lt;=target的元素的索引 return find_first_gt(v, target) - 1; // 即第一个\u0026gt;target的元素的前一个位置 } int find_last_lt(vector\u0026lt;int\u0026gt;\u0026amp; v, int target) { // 返回最后一个\u0026lt;target的元素的索引 return find_first_ge(v, target) - 1; // 即第一个\u0026gt;=target的元素的前一个位置 } 240.搜索二维矩阵Ⅱ 方法一：从右上开始，按照搜索二叉树的逻辑查找 方法二：每行进行一次二分查找 162.寻找峰值 方法一：分治，类似归并排序，递归找最大值 方法二：类似二分查找，判断nums[mid]与nums[mid+1]的大小关系（即判断中点是上坡还是下坡），从而修改左右索引 原理是因为开始时left和right都是最小值，此后mid部分永远是高点 细节：在函数体中，left与right不相等，因此mid永远不会等于right，同时left与right是左闭右闭，代码 搜索旋转排序数组系列：是否有重复数字 33.搜索旋转排序数组：首先二分找到分界点，然后在左边或者右边再次进行二分（此时范围是有序的） 81.搜索旋转排序数组Ⅱ：尝试将问题转换到33.搜索旋转排序数组，我的题解 154.寻找旋转排序数组中的最小值Ⅱ 排序 快排：在partition时，如果选left作为pivot，则需要先移动右边的指针，原理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void qSort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int left, int right){ // [left, right] if(left \u0026gt;= right) return ; if(left+1 == right){ if(nums[left] \u0026lt;= nums[right]) return ; else {swap(nums[left], nums[right]); return ;} } // 左中右，取中间大小的值，放在最左边 int begin = left, end = right, mid = (left + right) / 2; int pivot = max(min(nums[left], nums[right]), nums[mid]); if(nums[right] == pivot) swap(nums[left], nums[right]); else if(nums[mid] == pivot) swap(nums[left], nums[mid]); // 注意元素是覆盖的 while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; nums[right] \u0026gt;= pivot) --right; nums[left] = nums[right]; while(left \u0026lt; right \u0026amp;\u0026amp; nums[left] \u0026lt;= pivot) ++left; nums[right] = nums[left]; } // now: left == right nums[left] = pivot; // 缩小中轴范围，尤其针对重复元素多的数组 while(left \u0026gt; begin \u0026amp;\u0026amp; nums[left] == nums[left-1]) --left; while(right \u0026lt; end \u0026amp;\u0026amp; nums[right] == nums[right+1]) ++right; qSort(nums, begin, left-1); qSort(nums, right+1, end); } 归并排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 归并排序需要辅助数组，因为前后两个有序数组是连着的， void mergeSort(vector\u0026lt;int\u0026gt;\u0026amp; out, int begin, int end, vector\u0026lt;int\u0026gt;\u0026amp; in){ // [begin, end) if(begin \u0026gt;= end || begin+1 == end) return ; int mid = (begin + end) / 2; mergeSort(out, begin, mid, in); // [begin, mid) mergeSort(out, mid, end, in); // [mid, end) // now left part and right part are all sorted, merge them into out int i = begin, j = mid, k = begin; while(i \u0026lt; mid \u0026amp;\u0026amp; j \u0026lt; end){ if(in[i] \u0026lt;= in[j]) out[k++] = in[i++]; // stable else out[k++] = in[j++]; } while(i \u0026lt; mid) out[k++] = in[i++]; while(j \u0026lt; end) out[k++] = in[j++]; // copy out back to in for(int s = begin; s \u0026lt; end; ++s) in[s] = out[s]; } 堆排序\n第一种方法：数组原地构建最大堆，数组原地进行排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void heapSort(vector\u0026lt;int\u0026gt;\u0026amp; nums){ buildMaxHeap(nums); int len = nums.size(); for(int i = len-1; i \u0026gt;0; --i){ swap(nums[0], nums[i]); // 将最大堆的首元素（最大元素）放在数组后面位置 adjust(nums, 0, --len); // 首元素变了，因此需要调整，同时堆的长度减一 } } void buildMaxHeap(vector\u0026lt;int\u0026gt;\u0026amp; nums){ int n = nums.size(); for(int i = n/2-1; i \u0026gt;= 0; --i){ // n/2-1是最后一个非叶节点，依次向上检测和调整每个非叶节点 adjust(nums, i, n); } } void adjust(vector\u0026lt;int\u0026gt;\u0026amp; nums, int idx, int len) { // 当前节点的索引为idx，在[0, len)范围内是最大堆 while(idx * 2 + 1 \u0026lt; len){ int leftSon = idx * 2 + 1; int rightSon = idx * 2 + 2; int largeIdx = idx; // largeIdx指向{根节点，左孩子，右孩子}中较大的值 if(leftSon \u0026lt; len \u0026amp;\u0026amp; nums[leftSon] \u0026gt; nums[idx]) largeIdx = leftSon; if(rightSon \u0026lt; len \u0026amp;\u0026amp; nums[rightSon] \u0026gt; nums[largeIdx]) largeIdx = rightSon; if(largeIdx != idx){ swap(nums[idx], nums[largeIdx]); idx = largeIdx; }else break; } } 第二种方法：数组构建最小堆，依次弹出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 手写堆 class minHeap{ private: vector\u0026lt;int\u0026gt; heap; int len = -1; public: minHeap(vector\u0026lt;int\u0026gt;\u0026amp; nums): heap(nums) { len = heap.size(); // build minHeap for(int i = n/2-1; i \u0026gt;= 0; --i) adjust(i); } void adjust(int idx){ while(idx * 2 + 1 \u0026lt; len){ int leftSon = idx * 2 + 1; int rightSon = idx * 2 + 2; int largeIdx = idx; // largeIdx指向{根节点，左孩子，右孩子}中较大的值 if(leftSon \u0026lt; len \u0026amp;\u0026amp; heap[leftSon] \u0026gt; heap[idx]) largeIdx = leftSon; if(rightSon \u0026lt; len \u0026amp;\u0026amp; heap[rightSon] \u0026gt; heap[largeIdx]) largeIdx = rightSon; if(largeIdx != idx){ swap(heap[idx], heap[largeIdx]); idx = largeIdx; }else break; } } int top() { return heap[0];} // return min value void pop() { swap(heap[0], heap[--len]); adjust(0); } }; // 或者调用优先队列 vector\u0026lt;int\u0026gt; heapSort(vector\u0026lt;int\u0026gt;\u0026amp; nums){ priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; for(int n: nums) pq.push(n); vector\u0026lt;int\u0026gt; ans; while(!pq.empty()) {ans.push_back(pq.top()); pq.pop();} return ans; } 179.最大数\n巧妙的自定义排序规则：a+b\u0026lt;b+a 215.数组中的第k个最大元素 【重要】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 int findKthLargest(vector\u0026lt;int\u0026gt;\u0026amp; nums, int begin, int end, int k){ // [begin, end), 快排逻辑 if(begin+1 == end) return nums[begin]; if(begin+2 == end){ if(k == begin) return max(nums[begin], nums[begin+1]); if(k == begin+1) return min(nums[begin], nums[begin+1]); } int left = begin, right = end-1; // [left, right] int pivot = nums[left]; while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; nums[right] \u0026lt;= pivot) --right; nums[left] = nums[right]; while(left \u0026lt; right \u0026amp;\u0026amp; nums[left] \u0026gt;= pivot) ++left; nums[right] = nums[left]; } int mid = left; // now left == right nums[mid] = pivot; if(k-1 == mid) return pivot; else if(k-1 \u0026lt; mid){ while(mid \u0026gt; k-1 \u0026amp;\u0026amp; nums[mid] == nums[mid-1]) --mid; return findKthLargest(nums, begin, mid+1, k); // 注意这里还是传入[begin, mid+1)而非[begin, mid)，因为经过while优化，此时mid可以退到和begin位置相同 } else{ // k-1 \u0026gt; mid while(mid \u0026lt; k-1 \u0026amp;\u0026amp; nums[mid] == nums[mid+1]) ++mid; return findKthLargest(nums, mid, end, k); // 注意这里还是传入[mid, end)而非[mid+1, end) } } 剑指40.最小k个数：快排逻辑\n套路题 14.最长公共前缀 按行比，按列比，都行 209.长度最小的子数组 方法一：贪心+双指针 方法二：前缀和+二分 细节较多：前缀和是inclusive的还是exculsive的（这里用的是exculsive的），二分找的是第一个大于val的位置 剑指21.调整数组顺序使奇数位于偶数前面 如果不需要保持奇数/偶数内部的相对顺序，左右双指针向内走 169.多数元素 投票法：维护一个元素值value和计数值cnt，数组元素等于value时累加cnt，不等于value时递减cnt，当cnt==0时更新value 可以保证最后众数的cnt至少为1 128.最长连续序列 哈希表unordered_map\u0026lt;int, bool\u0026gt;（bool表示是否使用过该数字），元素往前往后分别试探 31.下一个排列 ： 题解 与556.下一个更大元素Ⅲ相同 从后往前遍历，找到一个最长的后缀，这个后缀是逆序的（即该后缀从前往后看递减，从后往前看递增） 该最长后缀前面一个元素nums[idx]，是小于最长后缀的第一个元素的 在该最长后缀中，找到最后一个\u0026gt;nums[idx]的元素nums[pos]，然后交换（因此最长后缀又变长了一位） 最后reverse[idx+1, end)，因此数组前面部分不动，后面部分得到了下一个排列 综合 560.和为K的子数组：【前缀和】+【哈希表】 通过前缀和可以将区间和转换为两个点的查询 通过哈希表记录遍历过的位置的前缀和（value是特定前缀和的计数） 现在已知一个点和中间差值，通过哈希找到另一个点 区别209.长度最小的子数组 字符串 模拟 415.字符串相加 43.字符串相乘 443.压缩字符串 6.Z字形变换 468.验证IP地址：先判断有.还是:，然后根据.或者:分割之后，逐段判断 7.整数反转：用字符串表示数字 166.分数到小数：首先注意符号问题，然后注意能否整除，最后逐次*10模拟竖式除法 套路 翻转字符串的妙用：局部翻转后再整体反转（或反过来），达到子串位置颠倒的效果\n151. 反转字符串中的单词\nLCR 182. 动态口令\nKMP系列\n实现strStr 链表【二刷】 206. 反转链表\n注意递归写法\n1 2 3 4 5 6 7 ListNode* reverseList(ListNode* head) { // 递归，返回反转链表的头 if(head==nullptr || head-\u0026gt;next==nullptr) return head; // 当前是空节点，或者是最后一个节点 ListNode* newHead = reverseList(head-\u0026gt;next); // 已经将head-\u0026gt;next部分的链表处理完毕 head-\u0026gt;next-\u0026gt;next = head; head-\u0026gt;next = nullptr; return newHead; } 迭代写法1：遍历，修改相邻节点的指针指向\n迭代写法2：创建虚拟头节点，进行头插法（遍历链表，插入到虚拟头节点之后）\n142. 环形链表 II 【好题】\n快慢指针可以判断有环 如何找到这个环的入口 148.排序链表\n递归方法：（自顶向下的）归并排序，时间复杂度O(n logn)，空间复杂度O(logn) 迭代方法：自底向上的归并排序，时间复杂度O(n logn)，空间复杂度O(1) 143.重排链表 【好题】\n先快慢指针寻找中点，然后后半段链表原地反转，最后两个链表合并 23.合并K个升序链表\n最小堆：priority_queue\u0026lt;ListNode*, vector\u0026lt;ListNode*\u0026gt;, decltype(cmp)\u0026gt; pq; 445.两数相加Ⅱ\n一种方法是反转链表，另一种是使用栈进行计算 LRU缓存 【好题】\n两点注意： 设置dummyHead与dummyTail，可以避免专门判断head与tail是否为空（因为是双向链表，所以要设置头尾两个dummyNode） 在Node中需要同时包含key和value，因为当删除某个node时，需要知道其对应的key，从而删除哈希表中对应的表项 递归 递归写法代码量一般比较少，也比较优雅，尤其在没有头节点的情况下避免对头节点另外判断\n138.随机链表的复制\n21.合并两个有序链表\n哈希表【二刷】 有时可以直接使用数组进行哈希，有时需要使用map（unordered_map）或set（unordered_set）进行哈希，注意如果键无法进行哈希，则无法使用unordered_map或unordered_set（比如vector容器就没有hash方法，不能作为unordered_map或unordered_set的键）\n202.快乐数：使用哈希表空间复杂度为O(n)，将其视为快慢指针此时空间复杂度为O(1)\nn数之和系列：给定n数之和\n给定一个数组，要求返回其中一个元组下标：哈希\n1. 两数之和 给定一个数组，要求返回所有元组下标：先排序，外层遍历，内层左右指针向中移动，根据当前三数之和确定左指针还是右指针移动，同时注意跳过相同的数字\n15. 三数之和\n18. 四数之和：注意四数之和可能超过int的范围\n给定多个数组，要求返回元组的个数：哈希\n454. 四数相加 II 【原地哈希】\n例题：LCR 120.寻找文件副本：可能有多个重复数字，返回任意其一\n调整数组为nums[i]==i，如果将i写入到nums[i]时发现原来已经nums[i]==i，说明i就是重复数字 方法：通过交换实现调整 442.数组中重复的数据：数字出现1或2次，返回所有出现两次的数字\n287.寻找重复数：只有一个重复数，返回之；但是不能修改原数组\nFloyd判圈 268.丢失的数字：只有一个缺失的数字，返回之\n41.缺失的第一个正数 ：首先要判断数字是否在[0,n]的范围内\n总结：虽然原地哈希的核心部分都是判断当前位置j的元素j=nums[i]为索引时，是否已经写入j?=nums[j]，但是中间很多细节略微不同\n974.和可被K整除的子数组：前缀和+哈希表\n前缀和实际上是前缀和的取模，使用哈希表记录模和其计数 12.整数转罗马数字\n哈希表记录数字到字符串的映射，注意使用map\u0026lt;int, string, greater\u0026lt;int\u0026gt;\u0026gt;将key从大到小排列 栈与队列【二刷】 用栈模拟队列：一个输入栈，一个输出栈 用队列模拟栈：只需要一个队列，将元素进行循环弹入弹出 优先队列 注意优先队列如何自定义比较顺序 栈 基本计算器Ⅱ：遇到加减法入栈（即栈内都进行加法运算），有两种不太相同的写法：比如a+b*c\n方法一：暂存数字。比如解析+时，暂存的是数字a，此时可以入栈；比如解析*时，暂存的是数字b（运算符前面的数字），此时先不能入栈，需要继续向后解析完c之后，更新暂存的数字 方法二：暂存数字前的运算符，更简洁。比如解析b时，当前暂存的运算符是+（数字前面的运算符），因此遇到新的运算符*时，根据需要出栈入栈 技巧：将a+b*c处理成a+b*c+0，且开始时暂存的运算符是+ 394.字符串解码：【重要】\n方法一：【双栈】写法，数字栈与string栈 字符串出栈时，每个元素需要先reverse，连起来字符串之后要再次reverse（因为出栈是逆序的，每个元素内部有时顺序的） 数字栈使用stack\u0026lt;int\u0026gt;，string栈使用deque\u0026lt;string\u0026gt;进行模拟，方便最后进行出栈 方法二：递归写法 全局的索引idx，函数传参string和重复数量cnt 如果遇到[，则进入递归；如果遇到]，则退出递归 递归就是顺着累加字符串，不需要reverse 678.有效的括号字符串：\n方法一：【双栈】 括号一个栈st，星号一个栈star_st，栈内存放下标 括号按照传统方法出入栈，星号直接入星号栈 在遍历完成之后，括号栈依次出栈， 如果当前是(，需要保证star_st.top()大于(的下标 如果当前是)，需要保证star_st.top()小于)的下标（极其注意需要当前star_st.top()可能大于)的下标，需要while依次出栈，与上面逻辑不同） 方法二：贪心 维护未匹配的(的数量可能的最大值和最小值，遇到星号时，最小值减一，最大值加一 如果最大值\u0026lt;0，则字符串无效 遍历完成后，只有最小值=0时，字符串才可能有效 最小栈 参考\n方法一：【双栈】 一个普通栈，一个最小栈（用来记录最小值） 如果当前元素==minStack.top()，也要push/pop最小栈 方法二：使用一个栈，并维护当前最小值minVal 入栈：如果当前元素\u0026lt;=minVal，则先将minVal入栈，然后再将当前元素入栈，同时更新minVal的值；否则直接入栈 技巧：minVal初始值设定为最大值 方法三：使用一个栈 每次入栈元素为当前元素-minVal -\u0026gt; st.top()，如果结果是负数，说明minVal需要更新minVal=当前元素 每次出栈或top，如果栈顶元素是正数，则原来的元素=minVal+st.top()；如果栈顶元素是负数，则说明当前minVal经过更新变得更小，原来的元素=minVal，复原原来的minVal=原来的元素(即旧的minVal)-st.top() 单调队列 239. 滑动窗口最大值 方法一：大根堆，维护一个大根堆，里面存放数组索引，但是比较方法是按照对应元素大小进行比较，出队列时肯定是当前最大元素，而且可以判断该元素是否在窗口范围内 最坏情况如果是一个递增序列，每次push都是log(i)的复杂度，总的复杂度为sum(log(i))=O(n log(n)) 方法二：单调队列，维护一个递增的deque，里面存放数组索引，从后面pop_back可以比较当前元素与队尾元素，保持队列递增；从前面pop_front可以保持元素位于窗口范围内 最坏情况是O(n) 单调栈 739. 每日温度：从左往右，找到第一个比当前元素大的元素\n单调递增栈（从栈顶到栈底递增，栈顶元素为已经遍历过部分的最小值），如果当前元素nums[i]大于栈顶元素nums[top]，则从左往右nums[top]第一个比它大的元素是nums[i]\n496. 下一个更大元素 I：单调栈+哈希表\n503. 下一个更大元素 II：朴素想法是将循环数组展开，但是可以相同的单调栈代码跑两遍（第二遍继续使用第一遍剩下的单调栈）\n42. 接雨水 【重要】\n方法一：单调栈，从栈顶到栈底递增（反映到柱子上就是往下的台阶）\n横着接水：如果当前元素height[i]高于栈顶的柱子H=height[st.top()]，则栈顶的柱子H为最低高度，pop之后的栈顶为左边比H更高的位置，当前位置i为右边比H更高的位置，横着按层累加 时间复杂度O(n)，空间复杂度O(n) 方法二：双指针\n竖着接水：维护左右边历史最高柱子，往中间移动的过程中： 如果右边低，当前水位最高只能按照低的来，ans += rightHeight - height[right--] 左边同理 时间复杂度O(n)，空间复杂度O(1) 方法三：两个数组，分别从左向右和从右向左记录当前最高水位，也是竖着接水\n84. 柱状图中最大的矩形 【重要】\n单调栈，从栈顶到栈底递减（反应到柱子上就是往上的台阶）\n找每个柱子左右两边第一个低于该柱子的位置：如果当前元素height[i]低于栈顶的柱子H=height[st.top()]，有： i-1位置的柱子一定不低于H pop之后的栈顶位置+1一定不低于H（注意与接雨水的细微区别） 因此可以算面积 时间复杂度O(n)，空间复杂度O(n)\n技巧：在原来height数组开头height.insert(heights.begin(), 0)，在结尾height.push_back(0)，可以保证最后栈中无元素\n85.最大矩形\n每行统计高度，因此每行跑一个84. 柱状图中最大的矩形 时间/空间复杂度均为O(mn) 402. 移掉 K 位数字\n单调栈：从栈底到栈顶递增，同时维护栈的顺序和k\u0026gt;0 优先队列 347.前K个高频元素：小根堆，遍历过程中逐步弹出堆顶，剩下的就是高频元素\n注意优先队列的写法：\n1 2 auto cmp = [](pair\u0026lt;int, int\u0026gt;\u0026amp; p1, pair\u0026lt;int, int\u0026gt;\u0026amp; p2){return p1.second \u0026gt; p2.second;}; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, decltype(cmp)\u0026gt; pq(cmp); 手写堆\n二叉树【二刷】 遍历 DFS 递归写法：\n确定递归函数的参数和返回值 确定终止条件 确定单层递归的逻辑 迭代写法：\n道理：当前arrive（或access）的节点，未必就是要add进数组的节点\n前序：第一次arrive的节点，就是add进数组的节点 中序：第二次arrive的节点，就是add进数组的节点 前序：空节点不入栈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; v; stack\u0026lt;TreeNode*\u0026gt; st; if(root == nullptr) return v; st.push(root); while(!st.empty()){ TreeNode* now = st.top(); st.pop(); v.push_back(now-\u0026gt;val); if(now-\u0026gt;right) st.push(now-\u0026gt;right); if(now-\u0026gt;left) st.push(now-\u0026gt;left); } return v; } 中序：空节点可以入栈，使用now指向当前arrive的节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 vector\u0026lt;int\u0026gt; inorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; v; stack\u0026lt;TreeNode*\u0026gt; st; TreeNode* now = root; while(now != nullptr || !st.empty()){ // 比如中间-\u0026gt;可能now指向空指针，此时stack不能为空 // -\u0026gt;可能stack为空，但是now指向右节点 // 最后now指向某个节点的右空树，且stack都出栈已经为空，此时就是结束 if(now == nullptr){ now = st.top(); st.pop(); // st.top()是第二次访问，可以add进数组 v.push_back(now-\u0026gt;val); now = now-\u0026gt;right; } else{ // now != nullptr st.push(now); now = now-\u0026gt;left; } } return v; } 后序：可以按照【根右左】的顺序遍历，然后reverse（即左右根）\nBFS 迭代写法：注意是否要分层；如果不用分层，则不用计算每层的size，更简单一些\n递归写法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; levelOrder(TreeNode* root) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; vv; bfs(root, vv, 0); return vv; } void bfs(TreeNode* root, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; vv, int depth){ if(root == nullptr) return ; if(vv.size() == depth) vv.push_back(vector\u0026lt;int\u0026gt;()); vv[depth].push_back(root-\u0026gt;val); if(root-\u0026gt;left) bfs(root-\u0026gt;left, vv, depth+1); if(root-\u0026gt;right) bfs(root-\u0026gt;right, vv, depth+1); } 199.二叉树的右视图：注意递归的写法，将深度和当前数组的size比较 二叉树 222.完全二叉树的节点个数 【好题】\n如何判断满二叉树？向左递归深度==向右递归深度 完全二叉树中，某个节点左子树和右子树中，至少有一个是满二叉树，参考 复杂度分析： 每次递归需要计算当前节点的高度，O(log n) 最多需要调用“树的高度”次，O(log n) 相乘，O(log n) * O(log n) 110.平衡二叉树\n注意二叉树节点【深度】和【高度】的差异 高度：该节点到叶子节点的最长，求高度适合用前序遍历 深度：根节点到该节点的路径，求深度适合用后序遍历 112.路径总和\n注意分辨递归什么时候有返回值 不用完整搜索整棵二叉树，找到其中一条路径即可，需要返回值（比如本题），比如if判断当前节点后直接返回。或者说遍历的思维 需要完整搜索整棵二叉树，或者说二叉树与回溯的结合 需要返回值（比如递归求深度） 不需要返回值 124.二叉树中的最大路径和 【好题】，【不会】\n递归写法 236.二叉树的最近公共祖先 【好题】\n递归方法： 后序遍历：分别在左右子树中找p和q的最近公共祖先，然后根据找到的情况进行处理 如果子树递归返回nullptr，说明子树不包含p或者q 如果子树递归返回非nullptr，说明子树包含p、或q、或pq 理解返回值：返回值是以root为根的子树中，p或q的最近公共祖先，如果该子树不包含p或者q，则返回nullptr 如果root==p || root==q，则当前root至少为一个节点祖先，另一个节点可能在这个子树上，也可能不在这个子树上，但至少返回root 如果当前root为根的子树，没有p或者q（左右子树都是nullptr），只能返回nullptr 如果当前root为根的子树，左右子树分别有p和q，则root为最近公共祖先，返回root 如果当前root为根的左子树或右子树其中一个，同时有p和q，则只能将其最近公共祖先向上返回 迭代方法：使用map记录子节点到父节点的映射，再使用一个map记录p到root的路径，最后q向上回到root过程中找到最近同时访问的节点 543.二叉树的直径\n维护一个计算每个节点最大深度的递归函数deepest 在计算节点左右子树的过程中，更新树的直径 662.二叉树最大宽度：中间nullptr也算\npair\u0026lt;TreeNode*, unsigned long long\u0026gt;保存节点和其id，×2得到其左节点id，×2+1得到其右节点id，最后id相减 116.填充每个节点的下一个右侧节点指针\n常规方法：使用队列进行迭代 递归方法：递归函数中传入两个节点指针 671.二叉树中第二小的节点：root是最小的，遍历一遍，比root大的其中最小的\n区分572.另一棵树的子树 和 LCR 143.子结构判断(这个题目关于空节点本身没有说清楚)\n863.二叉树中所有距离为K的结点\n遍历一遍得到子节点到父节点的map，从而变树为图，然后dfs 297.二叉树的序列化与反序列化 【好题】\n第一种方法：使用括号表示编码（BNF编码）进行序列化，使用递归函数进行反序列化，代码 BNF编码：比如postOrder BNF编码(左)(右)(根) 反序列化时，递归函数中需要使用栈，从而确定左右子树在字符串中的范围 第二种方法：使用逗号表示编码按照层序遍历进行序列化，使用迭代方法进行反序列化，代码 序列化方式与leetcode样例给出方式相同，不需要特殊表示换层 反序列化同样使用队列，字符串遍历的过程中入栈出栈 第三种方法：使用逗号表示编码进行序列化，使用递归函数进行反序列化，代码 序列化表示形式与第二种方法相同，但是好像只能使用前序遍历 如果使用中序/后序，字符串中第一个元素解码后是nullptr，在反序列化的递归函数中第一个元素就直接返回，不会处理后面的字符串了 如果使用前序，字符串中第一个元素肯定不为nullptr，可以递归下去 反序列化过程需要维护一个全局的索引，从而在不同的递归函数之间确定当前处理的元素的位置 652.寻找重复的子树\n使用基于后序遍历的二叉树序列化，模板类似297.二叉树的序列化与反序列化中第一种方法，但是序列化格式可以简化 在后序遍历进行序列化的过程中，同时维护unordered_map\u0026lt;string, pair\u0026lt;TreeNode*, int\u0026gt;\u0026gt;的映射 二叉搜索树 98.验证二叉搜索树 530.二叉搜索树中的最小绝对差 501.二叉搜索树中的众数\n原理：二叉搜索树中序遍历是有序的 可以是递归写法：维护一个全局变量，记录上一个节点的指针pre 可以是迭代写法：中序迭代写法 98.验证二叉搜索树极易想成简单左右子树判断，但此时根节点和右子树的左孩子的关系是无法判断的，只能中序遍历判断有序 450.删除二叉搜索树中的节点 【好题】\n对比递归方法与迭代方法：都是五种情况 迭代方法：小心删除根节点时的特判 递归方法：使用root-\u0026gt;left或root-\u0026gt;right接受返回值，避免记录pre节点（同时也避免了删除根节点时pre==nullptr的判断） LCR 174.二叉搜索树的第k大节点\n中序倒序，维护全局变量的计数器 426.将二叉搜索树转换为有序的双向链表\n递归函数返回有序双向链表的头 LCR 152.验证二叉搜索树的后序遍历序列\n注意是二叉搜索树，因此可以确定根与左右子树，从而递归判断 第二种方法：单调栈+后序逆序，代码，参考，不太会 比如当前是根节点（栈顶） 如果下一个节点大于栈顶元素，则在右侧，因此入栈 如果下一个节点小于栈顶元素，则出栈（该节点在其祖先节点的右边），找到其祖先节点，后序节点应该都在该祖先节点的左边 假设有一个极大的虚拟根节点，整棵树都在其左边 99.恢复二叉搜索树\n遍历过程中，记录这两个节点，参考 综合 437.路径总和Ⅲ 【好题】，【二叉树】+【前缀和】+【回溯】\n递归方法：以每个节点为root（O(n)），再计算包含root时的路径数量（O(n)），复杂度O(n^2)\n前缀和：在前序遍历的过程中，记录当前节点的前缀和，并遍历过的节点的前缀和保存到map中（value是特定前缀和的个数）\n根据当前前缀和和root-\u0026gt;val，可以得到当前分支上符合要求的路径的个数 当当前root返回时，当前的前缀和也需要从map中复原 回溯 回溯\n思路：二叉树/多叉树的递归遍历\n视为二叉树的话，每个元素选择或不选，每个dfs中有两条路径 视为多叉树的话，在每个for循环中进行选择，注意选择之后的回溯复原就表示没有选择当前元素，然后可以选择后面的元素 写法：数组直接作为全局变量，进行多叉树的遍历时使用一个startIdx来表示当前搜索数组的位置\n细节问题：\n使用startIdx还是从0开始 能否对数组排序？ 能，如果需要去重，维护一个全局的used数组 used数组的索引，表示nums的下标（一般是这个），还是nums元素的值 不能，如果需要去重，则每一层应该维护一个局部的set 组合问题：从N个数中选k个数，有几种选法\n77.组合：模板题 216.组合总数Ⅲ：直接在for循环中进行剪枝 17.电话号码的字母组合：使用字符串数组（或者二维数组）来进行数字到字符串的对应 39.组合总和： 40.组合总和Ⅱ：使用used数组进行去重，初始化used=false： 当数组中相邻两个元素相等且used=true时，表示这两个元素在同一个树枝上（在一个分支上），此时不用去重（即组合内部使用了相同的元素） 当数组中相邻两个元素相等且user=false时，表示这两个元素在递归的同一层（同一树层上），此时表示后面会有相同的组合出现，因此需要去重（continue） 切割问题：一个字符串不同切割方式，有几种方式\n131.分割回文串：逐个分割每个元素进行判断，同样是递归的树形结构 93.复原IP地址：感觉写成三叉树的递归方式，而非是for循环的递归方式更直观和易于理解 三叉树方式：从当前位置开始的子串，分别作为一个字符、两个字符、三个字符进行匹配 子集问题：N个数中相关子集的个数\n78.子集：递归的树形结构的所有节点 90.子集Ⅱ：理解“树枝去重”与“树层去重”的逻辑，对于相同的数字，前面的可以选或不选，后面的必须不能选 491.递增子序列：同样需要去重，但不能使用全局的used数组来去重 90.子集Ⅱ中数组是有序的，可以保证相同的数字都是挨着的， 491.递增子序列中数组无序，如果按上面的方式，只能保证相同的连着的数字是去重的，相同的不挨着的数字会重复，因此只能每一层维护一个局部的used数组，动态判断该数字之前是否出现过 排列问题：N个数的不同排列方式\n46.全排列：\n方法一：使用used数组记录该数字是否使用过，仔细考虑for循环和回溯（回退）的过程 方法二：使用swap和startIdx，每次减小排列的规模 47.全排列Ⅱ：对比491.递增子序列\n332.重新安排行程：\n错误理解和写法：每个机场只到一次（因此使用一个数组记录该节点是否到过） 正确理解：所有路径都走且只走一次（可能比如北京到上海有好几张票，都要使用，因此使用unordered_map\u0026lt;string, map\u0026lt;string, int\u0026gt;\u0026gt;来进行建图，然后dfs,回溯更新int的值） 棋盘问题：\n51.N皇后：画出搜索的树形结构，dfs中逐层放置皇后 37.解数独： 二维的递归，注意最外层for循环的是数组/棋盘，而不是各种可能性或组合（即选或不选） 判断合法性时，只是判断当前元素是否行、列、方格重复 贪心 区间贪心 55. 跳跃游戏：维护一个当前可以跳跃到的最右边界 45.跳跃游戏Ⅱ 435.无重叠区域 当有重叠区域时，更新右端点right = min(right, v[1]);的含义：如果重叠，使得右端点最小 如果旧的right更小，则移除掉新来的区间 如果新来的区间v[1]更小，则移除原来的区间 452.用最少数量的箭引爆气球 对比435.无重叠区域 按照每个点的start进行排序，当前重叠范围为[start, right]，start递增，维护逐渐缩小的重叠区间right = min(right, points[i][1]) 两个维度贪心 406.根据身高重建队列：先从高到低排队，再插队，复杂度O(n^2) 上下坡 376.摆动序列 方法一：贪心，也就是统计一共有几次变化 方法二：带空间优化的动规，up[i], down[i]为以nums[i]为结尾（最后一个是上升或下降）的摆动序列长度 135.分发糖果：正着统计上坡，反着统计上坡 122.买卖股票的最佳时机Ⅱ：直接累加上坡的差值 134.加油站：找剩余油量的前缀和中最小的位置 动态规划 总结 动规五部曲：\n确定dp数组的含义和下标的含义 确定递推公式 确定dp数组的初始化 确定遍历顺序 举个例子 单纯动规 直接寻找/使用最优子结构 97.交错字符串\n91.解码方法\n最优子结构好找（相当于递推），只是中间判断有点多 139.单词拆分\n322.零钱兑换\n343.整数拆分\n221.最大正方形\n子结构需要从三个方向考虑 使用滚动数组优化，注意有斜向上的依赖，需要使用一个变量记录 576.出界的路径数：题目一般，就像递推\n931.下降路径最小和\n120.三角形最小路径和\n剑指 Offer 47. 礼物的最大价值 同 64.最小路径和\n剑指Ⅱ 091.粉刷房子\n174.地下城游戏\n从右下到左上的动规 823.带因子的二叉树\n01背包 494.目标和：要装满背包，有几种方法 注意，0可以特殊处理，也可以不用特殊处理 416.分割等和子集： 给定背包容量，能不能装满这个背包 方法一：dp[j]就表示背包容量为j时，能否将背包装满 方法二：视为标准01背包，物品价值和重量相等，最后看容量为j的背包里最大价值 1049.最后一块石头的重量Ⅱ 1049.最后一块石头的重量Ⅱ： 首先转换成标准01背包：分成两堆石头，一堆小，一堆大，让小的那堆尽量接近一半 474.一和零：给定背包容量，装满背包最多有多少个物品 注意背包是二维的（长对应0的数量，宽对应1的数量） 排列数与组合数 377.组合总和Ⅳ：算组合数 22.爬楼梯：进阶版爬楼梯（每次可以爬[1 - m]个台阶）其实是一个完全背包下计算组合数的问题 参考 打家劫舍系列 198.打家劫舍： 不要硬套01背包，01背包只是动规中很套路的一个模板；除了直接题目可以直接套模板，剩下的还是要具体分析出来递推公式 213.打家劫舍Ⅱ 拆环为链，拆分成两种情况，各跑一遍 337.打家劫舍Ⅲ：树形DP 每个节点有一个状态数组 在后序遍历中，得到左右子树的状态，更新当前节点的状态 买卖股票的最佳时机系列 121.买卖股票的最佳时机\ndp数组表示持有/不持有股票，第0天持有即买入 划分状态 首先为什么标准01背包不需要针对每个背包的容量分成两种状态的数组？ 动规原理是最优子结构，标准01背包中物品之间是相互独立的，不存在某件放入a物品后必须放入b物品这样的关联 其次为什么打家劫舍问题也不需要针对每一间房屋分成两种状态的数组？ 首先可以分，而且公式写出来也很清晰，在比如树形DP中还必须要分 但是打家劫舍中，只是相邻两个房屋之间有关联，公式中可以直接将关联表示出来 买卖股票中为什么必须要分成两种状态的数组？ 因为买卖股票的两天之间的关联不是固定的 买卖股票中还需要注意两种状态的定义：是持有/不持有，而非买入/卖出 什么是状态？ 第i天进行第j笔交易，是持有还是不持有 注意如何保证只买入一次？区别122.买卖股票的最佳时机Ⅱ 加上手续费相同714.买卖股票的最佳时机含手续费 122.买卖股票的最佳时机Ⅱ\n123.买卖股票的最佳时机Ⅲ\n每天有多种状态：第i天进行第j笔交易，是持有还是不持有\n有一个技巧可以将空间复杂度降到O(1)，参考\n188.买卖股票的最佳时机Ⅳ 同理\n309.最佳买卖股票时机含冷冻期\n细化状态（比如不持有股票可以细分为今天卖出还是维持原来不持有的状态） 画出状态转移图 序列问题 递增序列/数组 300.最长递增子序列 LIS\n更像是记忆化搜索或者递推，而非动规\n对比674.最长连续递增序列（或者可称为最长递增数组？），是否连续决定是否内部要使用一个for循环找到比当前元素小的位置\n可以使用贪心+二分实现更低的复杂度\n贪心：d[len]表示长度为len的LIS，末尾元素的最小值，最小值越小越好\n二分：d[]数组单调递增\n1 2 3 4 5 6 7 8 9 // d[len]:长度为len的LIS，末尾元素的最小值 if(nums[i] \u0026gt; d[len]) d[++len] = nums[i]; else{ // 二分查找：find max l, nums[i] \u0026gt; d[l] // 因此d[l+1]找到一个更小的末尾元素nums[i]：d[l+1]\u0026gt;nums[i]\u0026gt;d[l] d[l+1] = nums[i]; } return len 参考\n673.最长递增子序列的个数\n使用贪心+树状数组实现O(nlogn)的复杂度，参考 354.俄罗斯套娃信封问题\n先排序，w正排，h倒排（保证相同w时，大h不能包含小h） 通过排序将二维LIS转换为一维的LIS 368.最大整除子集\n与LIS方法差不多 重复数组、公共序列、子数组/序列问题 718.最长重复子数组\n使用滚动数组进行优化：代码 内层逆序：之所以逆序，一是因为不将物品重复放入，二是因为可能依赖是斜向上的，逆序可以直接访问未更新之前的数值 也可以使用顺序，不过要将原来未更新之间的数值记录下来 其实是这个题目对遍历顺序没有要求，因为if中dp依赖左上旧值，else中dp直接是0 其他题目中，else中可能需要用到刚才更新过的值，因此只能从前向后遍历 1143.最长公共子序列 和 1035.不相交的线\n使用滚动数组进行优化：使用两个数组来回调替，或者直接记录依赖的旧值 53.最大子数组和\n遇到数组和第一直觉总是前缀和，但是这个题目使用动规很简单 392.判断子序列\n可以使用双指针 使用动规：状态转移方程很类似 dp可以表示相同序列的长度 dp也可以是bool数组，表示s[0, i]是否为t[0, j]的子序列 使用滚动数组优化二维数组时，注意将初始化方式从原来的二维情况下转换到一维情况下，比如当i=0时容易记起初始化，但是i=1,2,3\u0026hellip;之后，dp[0]或者dp数组开头几个数字就容易忘记初始化，代码 115.不同的子序列\n代码模板是392.判断子序列，只是递推公式需要多考虑一下 字符串操作 583.两个字符串的删除操作 动规方式1：先求出最长公共子序列，再相减 动规方式2：dp直接表示删除的最小步数，逻辑相同 注意原来使用二维数组时，有一定初始化方式；使用一维数组进行优化时，dp[0]很容易忘记初始化，代码 712.两个字符串的最小ASCII删除和 72.编辑距离 当word1[i]与word2[j]不相同时，如果进行插入和删除，只需要考虑将word1[i]当前字符插入或删除 牛客NC35 编辑距离二 有O(nlogn)的算法吗？？？ 回文相关 647.回文子串：【好题】，分析 有时dp数组的含义并不是直接求什么，定义什么 如果$dp[i][j]$表示$s[i:j]$内的回文子串的数量，当s[i]==s[j]时，此时无法判断$s[i+1:j-1]$是否为回文串，由此无法确定递推公式中是否要+1，错误代码 $dp[i][j]$表示$s[i:j]$是否为回文串，在递推公式之后根据true or false进行累加，正确代码 5.最长回文子串 516.最长回文子序列 注意看是子序列（不必连续）还是子串（必须连续） 这个回文动规中，dp的含义，就是求什么定义什么 1312.让字符串成为回文串的最少插入次数 其他 152.乘积最大子数组：【好题】，也是分状态，但是其中另一个状态隐含在题目中，需要分析，很巧 第一次几乎完全不会 32.最长有效括号 动规+单调队列 1696.跳跃游戏： 模板题 14253带限制的子序列和：【好题】 比1696在动规上多了一点 图论 DFS与BFS 797.所有可能的路径：DFS+回溯\n200.岛屿数量：DFS，BFS模板题\n1020.飞地的数量：第一阶段原地修改原来的二维数组标记，第二阶段再次遍历\n130.被围绕的区域：原地修改二维数组标记\n827.最大人工岛：保存中间计算结果（岛屿面积），避免重复计算\n首先遍历，每个岛屿进行编号，同时使用map记录id到岛屿面积的映射 对于水块，上下左右累加岛屿面积 127.单词接龙：\n单词个数n，单词长度m\n方法一：BFS内部，对单词进行遍历，找到相邻的单词，最坏情况复杂度O(nnm) 方法二：BSF内部，对当前单词逐字母进行替换，判断替换后的单词是否在词表中，复杂度O(26*n) 并查集 并查集：一个用数组表示的森林\n当存在u-\u0026gt;v的有向边时，添加到并查集：father[v] = u; // v的father是u 1971.寻找图中是否存在路径：模板题\n数学 模拟 9.回文数： 空间复杂度O(1)的方法：原来数字取模除十的过程中，与反转后的数组比较大小 172.阶乘后的零：实际上就是找因子5的个数 位运算 常用技巧：对于int n\n获取n的最低位的1：n \u0026amp; (-n) 将n的最低位1变为0：n \u0026amp; (n-1) 191.位1的个数：\n循环检查二进制位：if(n \u0026amp; (1 \u0026lt;\u0026lt; i)) ++cnt lsb翻转：n \u0026amp; (n-1)结果为将n的二进制lsb变为0，因此：while(n) {n \u0026amp;= (n-1); ++cnt;} 136.只出现一次的数字：数组异或，原理是异或具有交换律\n137.只出现一次的数字Ⅱ：\n对于32位int，统计每一个bit中1的个数cnt，如果cnt无法整除3，则只出现一次的数字在当前bit为1，ans |= (1 \u0026lt;\u0026lt; i) 260.只出现一次的数字Ⅲ：分组异或\nxorsum一定不为0，否则所有数字都出现两次，假设两个出现一次的数字为a和b xorsum的最低有效位lsb，则一定是a的lsb=1，b的lsb=0（或反过来） 出现两次的数字，其lsb一定相同；因此根据这个lsb可以将所有数字分成两类，分别进行异或 其他 快速幂 470.用Rand7()实现Rand10()：拒绝采样 注意不能直接使用rand7() * rand7()，因为其中元素概率不完全相同，比如14的概率是2/49，1的概率是1/49，6的概率是4/49 视为行列索引：row=rand7(); col=rand7(); c = (row-1)*7 + col;，这样每个元素等概率 设计 705.设计哈希集合：基于vector\u0026lt;list\u0026lt;int\u0026gt;\u0026gt;的链地址法 706.设计哈希映射：基于vector\u0026lt;list\u0026lt;pair\u0026lt;int,int\u0026gt;\u0026gt;\u0026gt;的链地址法 380.O(1)时间插入、删除和获取随机元素： 一个vector用来获取随机元素 一个unordered_map\u0026lt;int, int\u0026gt;用来记录val到idx的映射 208.实现Trie（前缀树） 类似二叉树，Trie本身就是一个node，里面有vector\u0026lt;Trie*\u0026gt; children(26, nullptr)表示26叉树 Trie节点中包含一个属性isEnd，如果当前节点表示字符串的最后一个字符，则当前节点的下一个节点的isEnd=true 包含一个辅助函数Trie* searchPrefix(string prefix)，返回prefix字符串结尾的下一个节点 继续刷 142.环形链表Ⅱ\n124.二叉树中的最大路径和 437.路径总和Ⅲ\n4.寻找两个正序数组的中位数\n85.最大矩形\n28.找出字符串中第一个匹配项的下标：KMP模板\n","permalink":"https://qinganzhang.github.io/posts/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/","summary":"[toc] tags：【双指针】，【前缀和】，【原地哈希】 【好题】，【不会】，【重要】 方法 双指针 前后定长双指针 前后快慢双指针 左右双向双指针 611.有效","title":"Leetcode刷题记录"},{"content":"指令集架构 指令集 说明了操作种类、指令格式（操作码和地址码，地址码个数，操作码定长与拓展）、寻址方式、地址空间大小和寄存器个数等。简单可以理解为汇编指令用01表示。\nCPU位数=CPU中寄存器的位数=数据总线宽度\n硬件厂商开发某种指令集的CPU，需要该指令集专利持有者进行授权\n比如ARM公司自己的研发指令集叫ARM指令集，对外授权（同时ARM公司还进行微架构的授权）\n一些大型公司都获得ARM公司针对ARM指令集的授权，开发兼容ARM指令集的不同的微架构\n比如Intel授权AMD可以生产兼容x86指令集的CPU 编译：高级语言翻译成特定ISA的机器码\n参考\n关于CPU、指令集、架构、芯片的一些科普 复杂指令集CISC x86：在1978年的Intel 8086 CPU（16位）指令集基础上，发展而来的一些列指令集的泛称\n桌面级CPU一般都是x86的，兼容8086指令集 IA-32(x86,i386)：Intel将16位的x86拓展为32位的IA-32，但是由于IA-32的统治地位，x86也一般指IA-32的CPU\nIntel 80386是第一款i386 CPU（第一款IA-32架构的CPU） i386，i486：即Intel 80386， Intel 80486 Pentium（i586）：Intel 80586 Pentium Pro（Pentium Ⅱ，i686）：Intel 80686 此后，x86成为一些列架构的泛称，不限于16位，32位，64位 IA-64：1994年Intel推出的与x86完全无关的新架构（也不兼容之），基于显式并行指令运算（EPIC）的64位指令集架构\n2001年发布第一款基于IA-64的CPU，叫Itanium安腾，IA-64也称为Intel Itanium 但是由于软件环境的缺乏和AMD的竞争，导致市场不好 x86-64(x64)：1999年，AMD推出x86-64架构（简称x64），是对IA-32(x86)的兼容和拓展\n2003年AMD发布的一款基于x86-64的CPU，x86-64也称为AMD64\n后来Intel也用AMD64架构，称为IA-32e(IA-32 extension)，后来又叫Intel64\nx86-64, x64, AMD64, Intel64, IA-32e(IA-32 extension)基本是一个东西\n苹果公司和 RPM 包管理员以 x86-64 或 x86_64 称呼此 64 位架构。甲骨文公司及 Microsoft 称之为x64。BSD 家族及其他 Linux 发行版则使用 amd64，32 位版本则称为i386（或 i486/586/686），Arch Linux 用x86_64 称呼此 64 位架构。\nx86,x64,x86-64,amd64,arm指令集架构之间的关系中x86 架构发展\n参考\ni386、i486、i586、 i686、 x86、x86_64、x64、amd_64详解【写的很好】 精简指令集RISC ARM ARMv3~ARMv7都是32位 ARMv8：向前兼容32位指令，同时 AArch64：64位执行状态，使用全新的ARM 64位指令集 AArch32：32位执行状态 RISC-V：伯克利发明的一种基于RISC的开源指令集架构 一文看懂RISC-V MIPS PowerPC 微架构 微架构：硬件电路（或CPU单个核心core）的结构和实现 CPU研发能力一般指的是独立的微架构研发能力，是否使用自行研发的指令集关系不大 研发兼容的指令集可以没有获得授权，指令集的研发不是很难，但是之后获得授权后才能合法销售 微架构的设计细节是保密且复杂的 SoC（System on Chip）封装相对简单 商业模式 之前在PC时代，CPU研发厂商自己的微架构只有自己用 后来在智能设备时代，ARM公司将自己的微架构出售，其他厂商可以拿来组装，比如Cortex系列核心 由于ARM公司的成功，ARM公司针对PC领域发布了ARM v8 64位指令集 以前ARM适合低功耗的场景，随着技术进步，指令集对微架构的影响越来越小 指令集的选择：倾向于选择软件生态良好的指令集 以前获得指令集的授权很困难，主要通过技术交换的形式（指令集多授权一家，就多一个对手） 后来ARM对指令集授权略微放松 参考： 指令集、微架构、手机芯片(Soc)及ARM的介绍(偏硬件科普) 计算机架构 冯.诺伊曼架构：程序和指令存储在一起 哈佛架构：程序和指令分开存储 比如单片机（51单片机，STM32单片机），Cortex-M系列 现代处理器架构一般指令和数据共享存储，但是CPU内部缓存分开 特别介绍：ARM ARM商业发展 由于商业需要，1985年，Acorn公司基于RISC，自研CPU（包括指令集和微架构），称为ARM（Acorn RISC Machine），型号命名为ARM1（对标80286）\n后来，Acorn公司和苹果公司联合成立了一家叫ARM（Advanced RISC Machines）的公司，开启新的产品策略：授权\n传统商业模式：\nIDM(Integrated Design and Manufacture)：从设计，到制造、封装测试以及投向消费市场一条龙全包，比如Intel 无工厂模式Fabless：自己设计，制造交给代工厂，比如AMD，NVIDIA Foundry：只做代工 使用层级授权（处理器授权）：只能买来已经封装好的CPU，不能更改原来设计，可以配置的地方不多 内核层级授权（POP授权）：以一个内核（或IP核）为基础然后在加上自己的外设 架构层级授权：授权使用ARM指令集，可以修改指令集，但是比较贵 比如华为基于ARMv8，自研达芬奇架构 后来ARM公司越来越成功，苹果公司逐渐卖掉其股份，开发ipod（基于ARM指令集）。\n2007年，苹果公司发布iphone，基于ARM指令集 2008年，谷歌发布Android系统，也是基于ARM指令集 2016年，ARM公司被软银集团收购\n参考\n如何看待观点「华为没有核心技术，因为芯片用的是ARM（安谋）架构，一旦被停止授权，就会做不出芯片」？ 【推荐】到底什么是Cortex、ARMv8、arm架构、ARM指令集、soc？一文帮你梳理基础概念【科普】 ARM处理器 一般处理器就是指CPU\n但是ARM处理器指的是单个核（或IP核，或内核），因为厂商可以在IP核上进一步封装，最终CPU不尽相同\nIP核，全称知识产权核（英语：intellectual property core），是在集成电路的可重用设计方法学中，指某一方提供的、形式为逻辑单元、芯片设计的可重用模组。IP核通常已经通过了设计验证，设计人员以IP核为基础进行设计，可以缩短设计所需的周期。\n参考：\narmv7-A系列0 - arm 处理器架构发展史中的处理器到底指的是什么 到底什么是Cortex、ARMv8、arm架构、ARM指令集、soc？一文帮你梳理基础概念【科普】中的ARM内核与架构 指令集、微架构、手机芯片(Soc)及ARM的介绍(偏硬件科普) 指令集架构：\nARMv1~ARMv9（可以有一定的变种比如ARMv8-A） ARMv8是首款64位的ARM指令集 处理器架构\nARMv3~ARMv6： ARM6, ARM7, ARM9, ARM11系列 ARMv7及以后 Cortex-A：大型嵌入式系统（手机） Cortex-R：实时处理器 Cortex-M：单片机 参考：\nARM基础教程 | ARM命名规则\nARM 命名规则——指令架构、CPU的历史回顾\n参考：\nARM体系架构概述\nAndroid 简介 Android是一个开源的，基于Linux的移动设备操作系统，主要使用于移动设备\n谷歌在2007年发布了第一个测试版本的 Android 软件开发工具包（SDK），第一个商业版本的 Android 1.0，则发布于2008年9月。\nAndroid 应用程序一般使用 Android 软件开发工具包，采用 Java 语言来开发。\n版本 Android版本（版本代号）\n每个Android 版本对应一个Android SDK，可以类比JDK Android API版本：有利于设置和解决兼容性问题\nAndroid API级别官方说明\nAndroid版本和 Android API level的对应关系\nAndroid NKD\n工具链 背景：\n使用GCC编译，很多时候需要手动链接（只有标准库才默认链接） 当需要链接的文件很多时，一来每次在命令行中写一遍繁琐容易出错，二来无法使用增量编译 Makefile 背景：make命令根据编译规则进行编译，而且可以进行增量编译，makefile用于写编译规则\n简要语法：\n阮一峰make教程 简明make教程 GNU make/Makefile 简明实用教程 语法笔记\nmake：即制作出某个指定的文件（默认makefile中第一个文件）\n越是接近目标文件的命令，就越是要写在前面。因为程序是按照递归的方式进行依赖文件查找的，看到第一行有一个没见过的依赖文件，就往下一行进行查找，以此类推。 核心概念：目标target，前置条件prerequisite，命令command\n伪目标的使用\n伪目标是一个命令，且没有前置条件：比如clean，显式使用内置目标名指定为伪目标，主要用于执行命令\n伪目标是一个文件，但是前置条件有多个，且没有命令：比如生成多个文件\nCMake 背景： 当工程很大的时候，手写Makefile也不简单 Makefile与平台相关，无法实现跨平台 cmake：跨平台的项目管理工具，自动生成makefile文件，然后make构建 手写CMakeLists.txt文件，cmake生成Makefile，然后再make构建 cmake简要语法 指令大小写无关，变量大小写相关\n可以使用双引号将文件名或目录名包含其中\nadd_executable：将源文件编译成可执行文件\nadd_library：将源文件编译为库文件\n在构建时，静态库和动态库重名会导致后面的构建失败，参考 SET_TARGET_PROPERTIES：同时构建同名的静态库和动态库 aux_source_directory(\u0026lt;dir\u0026gt; \u0026lt;variable\u0026gt;)：将dir目录下所有源文件的文件名存放到variable变量中\nadd_subdirectory：包含一个子目录，该子目录中也有一个CMakeLists.txt文件和代码文件，它们也会被处理，同时可以指定编译输出（包含编译中间结果）的路径\nlink_directories：添加共享库搜索目录\nCMAKE_LIBRARY_PATH：设置库文件搜索目录，这不是cmake变量（需要在bash中设置），通过FIND_LIBRARY找到相应库文件 target_link_libraries(\u0026lt;target\u0026gt; \u0026lt;items\u0026gt;)：为库或可执行文件加入库链接\ninclude_directories：添加头文件搜索目录\nCMAKE_INCLUDE_PATH：设置头文件搜索目录，这不是cmake变量（需要在bash中设置），通过find_path找到相应头文件 target_include_directories：在编译目标文件时指定头文件\nfind_系列\nfind_package：加载外部库到项目中 configure_file：默认定义了一些编译选项的值\noption：添加编译选项（更准确是代码中的宏定义）\n变量\n创建变量：set()，获取变量的值：${variable}，调用环境变量：$ENV{} 追加变量的值：set(SRC_LIST ${SRC_LIST} test.cpp) PROJECT_NAME PROJECT_BINARY_DIR、CMAKE_BINARY_DIR：编译路径，当前工程的二进制路径（即编译产物会存放到该路径，一般为build所在路径） PROJECT_SOURCE_DIR、CMAKE_SOURCE_DIR：工程根目录，即顶层CMakeLists.txt文件的路径 EXECUTABLE_OUTPUT_PATH：编译生成的可执行文件的路径 LIBRARY_OUTPUT_PATH：编译生成的共享库文件的路径 最佳实践 项目配置 在源文件同级目录下建立目录build，在build中 cmake ..：将cmake得到的中间文件保存在build文件夹中，需要重新构建直接删除文件夹 make：构建，可以使用make clean清除中间文件，重新构建 ","permalink":"https://qinganzhang.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84%E7%A7%91%E6%99%AE%E5%92%8C%E6%A2%B3%E7%90%86/","summary":"指令集架构 指令集 说明了操作种类、指令格式（操作码和地址码，地址码个数，操作码定长与拓展）、寻址方式、地址空间大小和寄存器个数等。简单可以理解","title":"计算机架构科普和梳理"},{"content":"本地搭建博客 本地环境：windows10\n使用主题：PaperModX\n安装过程 安装Go并配置环境\n下载prebuilt版本的hugo\n注意hugo有普通版本和extended版本，最好使用extended版本，因为在使用PaperModX主题时，需要使用到extended版本（但是PaperMod主题使用普通版本就可以） 新建站点：hugo new site myblog\n下载主题：在myblog/themes/下git clone git@github.com:reorx/hugo-PaperModX.git\n也可以使用git submodule的方式添加主题，此时方便进行版本控制和管理 本地配置 myblog/下的配置文件参考sulvblog\u0026rsquo;s config.yaml和PaperModX example\u0026rsquo;s config.yaml进行配置，自己慢慢调吧（papermodx在papermod的基础上添加了一些特性，比如侧边目录）\n个人主要进行的修改有：\n在archetypes/posts.md中设定默认的meta内容 修改为posts、archive、search、tags、categories、about六个menu，其中posts、categories、tags在content下为目录，archive、search、about在content下为md文件 在文件夹下创建_index.md文件可以在里面添加Front Matter，用来设置当前文件夹下的meta信息 在配置时留意是posts还是post，是archive还是archives 加入数学公式的支持 但是当使用带有/begin{} /end{}的多行公式，或者多行公式中含有若干下划线时，此时可能无法正确渲染，我的解决办法是将没有正确渲染的多行数学公式放在\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;标签对中，这样在网页博客和本地typora中都可以正常显示。考虑到平时不怎么写复杂的多行数学公式，因此手动修改也不多。 在Hugo中优雅地使用数学公式中，博主的方法三自己编译一份加入了goldmark数学插件的hugo版本，但是注意编译过程中gcc版本不宜过高（我的gcc原来是8.1.0，编译不过，后来改到5.1.0，编译通过）。但是最终使用好像针对原生latex的多行公式支持不足（？不确定，可能是自己后面配置不正确？），最后没有使用这个方案 调整了主页中Welcome部分的高度，在themes/hugo-PaperModX/assets/css/common/main.css的.first-entry中min-height修改为80px 调整了页面中内容的宽度（原来侧边留空感觉有点多，可以适当减小），themes/hugo-PaperModX/assets/css/common/main.css的.main.post中添加right: 60px; 在themes/hugo-PaperModX/assets/css/common/post-single.css中调整h1~h6标题的高度 内容管理 写文章：hugo new posts/文章名称.md，注意写对md文件的路径\n本地预览：hugo server -D在localhost:1313上进行预览\n-D表示draft: true的内容在预览时展示 有时将draft改为false，使用hugo server进行预览时，对应文章没有出现，此时关掉PowerShell重开一个，重新运行一下命令 构建：hugo会将构建的网站内容保存到public文件夹中，默认只会向public中添加内容，而不会删除外部不存在但是public中还存在的文件\nhugo -F --cleanDestinationDir表示每次生成的public都是全新的，会覆盖原来的 --theme指定主题，--baseURL=\u0026quot;xxx\u0026quot;指定url 将内容发布到GitHub Pages上 将public文件夹转换为git库：\n进入到public文件夹，git init -b main 生成的默认主分支名字为main 将git库关联到远程库：\ngit remote add origin git@github.com:QinganZhang/QinganZhang.github.io.git 检查是否关联成功：cat .git/config 如果[remote \u0026quot;origin\u0026quot;]信息正常显示，说明本地git库已经成功关联到远程库 将修改commit到本地库\n1 2 3 git status # 查看当前修改状态 git add . # 添加所有修改过的文件，也可以只添加某个文件 git commit -m \u0026#34;add a new post\u0026#34; # 将修改push到远程库\ngit push -u origin main --force 报错： error: src refspec main does not match any 本地的branch为master，但是远程库默认branch是main，先将本地branch的名字修改为main git branch -m master main 报错： ! [rejected] main -\u0026gt; main (fetch first) 提交冲突，远程库和本地库不一致。通常出现在初始化仓库有readme而本地没有等情况。参考 git pull --rebase origin main 查看是否部署成功\n网页样式（css）丢失，但是内容还在，浏览器F12控制台报错：Failed to find a vlid digest in the 'integrity' attribute for source 'xxx.css' with computed SHA-256 integrity '***'. The resource has been blocked. （关键词：”integrity“）\n尝试方法一：解决 hugo 中关于 integrity 的错误，仍然出现原来的错误\n尝试方法二：解决Hugo无法加载css文件，仍然出现原来的错误，而且第一遍文章会覆盖在h1标题Posts上，\n最终方法：在themes/hugo-PaperModX/layouts/partial/head.html中，将\n1 2 3 4 5 6 {{- if not site.Params.assets.disableFingerprinting }} {{- $stylesheet := $stylesheet | fingerprint }} \u0026lt;link crossorigin=\u0026#34;anonymous\u0026#34; href=\u0026#34;{{ $stylesheet.RelPermalink }}\u0026#34; integrity=\u0026#34;{{ $stylesheet.Data.Integrity }}\u0026#34; rel=\u0026#34;preload stylesheet\u0026#34; as=\u0026#34;style\u0026#34;\u0026gt; {{- else }} \u0026lt;link crossorigin=\u0026#34;anonymous\u0026#34; href=\u0026#34;{{ $stylesheet.RelPermalink }}\u0026#34; rel=\u0026#34;preload stylesheet\u0026#34; as=\u0026#34;style\u0026#34;\u0026gt; {{- end }} 注释掉，只保留\u0026lt;link crossorigin=\u0026quot;anonymous\u0026quot; href=\u0026quot;{{ $stylesheet.RelPermalink }}\u0026quot; rel=\u0026quot;preload stylesheet\u0026quot; as=\u0026quot;style\u0026quot;\u0026gt;这一行。猜想可能是与使用的主题相关，但是暂时没有找到使用相同主题类似错误的信息。\n更多参考：Hugo - Failed to find a valid digest in the \u0026lsquo;integrity\u0026rsquo; attribute for resource - The resource has been blocked - Host on Github\n使用GitHub Actions自动构建博客 使用上面的方式（手动构建），在本地写好博客之后，然后使用hugo在本地构建好静态博客，生成public目录，最终是将public目录push到GitHub仓库，构建静态博客。\n还有一种方式，看起来更加高级，那就是基于GitHub Action自动构建博客。大致流程为：在本地写好博客之后，直接push到远程GitHub仓库，在远端而非本地构建博客。这个方式只是节省了自己使用hugo手动进行构建的这一步，但是如果当自己手工进行操作的步骤比较繁琐且固定时，使用GitHub Action自动化就很方便了。\n在实际配置过程中，这里使用了两个仓库。一个是private的myblog仓库，本地写好博客后就push到这个myblog仓库；另一个仓库是public的、作为GitHub Pages的仓库，myblog仓库使用GitHub Action自动进行构建，将最终得到的public文件就放到这个仓库中。下面简要介绍基于Github Action自动构建博客的过程，着重介绍与上面手动构架不同的地方。\n具体过程：\n在Github远程新建一个仓库，比如命名为myblog\n在本地使用hugo新建站点时（比如hugo new site myblog），在本地myblog目录下git init -b main，并且使用git remote add将本地的myblog目录关联到远程myblog仓库\n注意之前手动构建的方式中，是在public目录下git init，并关联到远程仓库的，而且该远程仓库即为Github Pages 在下载主题时，可以直接git clone源码，也可以使用git submodule的方式将主题作为子项目添加进来\n注意git submodule的子模块和原来的主模块是两个单独的项目，所以进入到子模块和主模块中进行git操作，是针对不同仓库的。Git Submodules介绍 但是这里想将主题添加进来，自己进行一些修改，因此使用了另一种方法将主题添加进来：git subtree，这样可以直接将子项目作为主仓库的一个目录添加进来 git subtree的使用 在myblog根目录下，创建.github/workflows/deploy.yaml，个人的deploy.yaml配置文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 name: deploy on: # 表示GitHub Action的触发条件（即push） push: branches: - main # 设定触发的分支为main workflow_dispatch: # 可以在Github项目仓库的Action工具栏手动调用 # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write jobs: # 表示GitHub Action的任务，这里定义了一个build的任务 build: runs-on: ubuntu-latest # 指定GitHub Action的运行环境 env: HUGO_VERSION: 0.122.0 steps: # 其中run表示执行的命令，uses时GitHub Action中的一个插件 - name: Checkout # 使用actions/checkout插件检出GitHub仓库 uses: actions/checkout@v2 # with: # submodules: false # 同时检出子模块 # fetch-depth: 0 # 完整检出所有历史记录 - name: Setup Hugo # 使用peaceiris/actions-hugo插件来安装Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.122.0\u0026#34; # 0.122.0 extended: true - name: Build Web # 运行hugo命令生成博客的静态文件 env: HUGO_ENVIRONMENT: production HUGO_ENV: production run: hugo --gc --minify # --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v2 with: path: ./public - name: Deploy Web # 使用peaceiris/actions-gh-pages插件将静态网页部署到GitHub Pages上 uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_BLOG_TOKEN }} # 个人访问令牌 EXTERNAL_REPOSITORY: QinganZhang/QinganZhang.github.io # 部署到的GitHub Pages仓库 PUBLISH_BRANCH: main # Github Pages分支 PUBLISH_DIR: ./public # hugo静态文件的目录 commit_message: ${{ github.event.head_commit.message }} # 提交更改时使用的提交消息 # cname: ${{ secrets.DOMAIN }} # 自定义域名，默认使用github pages域名 # reference1: https://blog.csdn.net/m0_51993913/article/details/132657065 # reference2: https://blog.csdn.net/freeking101/article/details/135515958使用Github Actions自动化部署部分 # reference3: https://github.com/reorx/hugo-PaperModX/blob/master/.github/workflows/gh-pages.yml 然后生成Token，参考\n因为需要从myblog仓库推送public目录到Github Pages仓库，所以需要向myblog仓库添加身份验证凭据 最后将本地博客push到myblog远程仓库，然后myblog远程仓库下使用GitHub Actions将public目录推送到Github Pages仓库中\n其他问题：\n如何将obsidian双链转换为HTML的\u0026lt;a\u0026gt;\u0026lt;/a\u0026gt;标签对？ 目前发现的一个方案是jekyll-wililinks，但是这个方案需要使用jeklly搭建静态博客 ","permalink":"https://qinganzhang.github.io/posts/hugo+github_pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","summary":"本地搭建博客 本地环境：windows10 使用主题：PaperModX 安装过程 安装Go并配置环境 下载prebuilt版本的hugo 注意hugo","title":"Hugo+Github Pages搭建个人博客"},{"content":"41：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递 一般C++传参方式有三种： 对左值引用和右值引用分别重载，需要实现两个版本 使用万能引用，使用时可能会实例化出多个版本，传参报错可读性差 传值： 可以考虑参数使用按值传递的情况： 构造（拷贝构造或移动构造）：对于可拷贝的，移动开销低的，并且总是会被拷贝的形参而言，按值传递和按引用传递的效率很接近，而且按值传递更容易实现，还可能会生成更少的目标代码，只是略微引入了一点性能开销 按值传递的前提是移动操作的成本足够低廉，因为按值传递比按引用传递多一次移动操作 只有当形参一定会被拷贝时，才考虑按值传递；比如有时函数开始先进行if检查，即使没有满足if条件而跳出函数，也会产生形参传值构造和析构的开销 赋值（拷贝赋值或移动赋值） 有时移动操作可能比直接拷贝开销更大：因为移动操作会涉及到原来对象的析构、新对象的构造，如果新对象比原来对象小，拷贝可以直接在原对象的位置上进行（具体见参考中的密码例子，如果新密码的长度比旧密码短，则新密码直接拷贝到旧密码的位置） 参考 https://blog.csdn.net/Dong_HFUT/article/details/127054642 42：考虑置入而非插入 push_back可能会创建中间临时对象，但是emplace_back使用完美转发（直接将参数匹配到构造函数），不会创建临时对象\n多数场景下使用emplace_back比push_back高效\n要插入的值是通过构造函数插入容器，而非赋值 赋值：比如emplace到容器begin，此时需要构造临时对象，然后将其移动到begin，此时emplace没有优势 传入参数的类型和容器元素的类型不同 如果传参类型和容器元素类型相同，也就不需要产生临时对象，emplace与push相同 如果某个元素值添加重复，会使用新创建的元素值替换为原来旧的元素值 使用注意：\n资源管理 1 2 3 std::list\u0026lt;std::shared_ptr\u0026lt;Widget\u0026gt;\u0026gt; ptrs; ptrs.push_back(std::shared_ptr\u0026lt;Widget\u0026gt;(new Widget, myDeleter)); // ok，不会发生内存泄露 ptrs.emplace_back(new Widget, myDeleter); // 如果emplace_back内部、调用构造函数之前发生异常，则会发生内存泄露 原因是延迟了资源管理对象的创建 因此要么使用make_shared创建智能指针，要么先创建一个临时对象然后move到emplace中 与显式构造函数的交互 参考\nhttps://blog.csdn.net/Dong_HFUT/article/details/127073175 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch08-%E5%BE%AE%E8%B0%83/","summary":"41：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递 一般C++传参方式有三种： 对左值引用和右值引用分别重载，需要实","title":"[Effective Modern Cpp Notes] Ch08 微调"},{"content":"","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch07-%E5%B9%B6%E5%8F%91api/","summary":"","title":"[Effective Modern Cpp Notes] Ch07 并发API"},{"content":"","permalink":"https://qinganzhang.github.io/posts/effective-cpp/effective-cpp-reading-notes/","summary":"","title":"Effective Cpp Reading Notes"},{"content":"","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/effective-modern-cpp-reading-notes/","summary":"","title":"Effective Modern Cpp Reading Notes"},{"content":"31：避免默认捕获模式 闭包：lambda所创建的运行期对象 默认捕获可能导致引用悬挂 默认传引用可能导致引用悬挂 显式传引用也可能导致引用悬挂，但是可以更容易发现此处可能有引用悬挂 默认传值捕获也可能导致引用悬挂 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 std::vector\u0026lt;std::function\u0026lt;bool(int)\u0026gt;\u0026gt; filters; class Widget{ public: // void addFilter() const{ // filters.emplace_back( // [=](int value) {return value % divisor == 0;} // ); // 看似是传值捕获，不会有引用悬挂；但是lambda只能捕获作用域中的非静态局部变量，此处的divisor其实是this-\u0026gt;divisor，容易产生引用悬挂 // } // 解决方法：使用一个局部变量复制成员变量，然后使用显式的值捕获 void addFilter() const{ int divisorCopy = divisor; filters.emplace_back( [divisorCopy] (int value) {return value % divisorCopy == 0;} ); } private: int divisor; }; lambda只能捕获作用域中的非静态局部变量，无法捕获静态或全局变量 捕获表示将值拷贝到闭包类中，而lambda中使用静态或全局变量，相当于是对外部的引用，因此此时lambda不是独立的 参考 https://blog.csdn.net/Dong_HFUT/article/details/125037605 32：使用初始化捕获将对象移入闭包 C++14使用初始化捕获模式（也称广义lambda捕获）来实现移动捕获 1 2 3 4 5 struct Widget{ bool isValid() const; }; auto func = [pw = std::make_unique\u0026lt;Widget\u0026gt;()] // 左边是lambda闭包内成员名称，右边是初始化 {return pw-\u0026gt;isValid();} C++11使用std::bind间接实现移动捕获 1 2 3 4 5 6 7 struct Widget{ bool isValid() const; }; auto func = std::bind( [] (const std::unique_ptr\u0026lt;Widget\u0026gt;\u0026amp; pw) {return pw-\u0026gt;isValid();}, std::make_unique\u0026lt;Widget\u0026gt;() ); 参考 https://blog.csdn.net/Dong_HFUT/article/details/125111586 33：泛型lambda的完美转发版本 对auto\u0026amp;\u0026amp;类型的形参使用decltype，以std::forward之\n泛型lambda（C++14）：可以使用auto声明形参（即闭包类中的operator()可以使用模板实现） 1 2 3 4 5 6 7 auto f = [] (auto x) {return func(x);} // 闭包类中的operator()的大致实现：auto形参实际上是模板类型推导 class SomeCompilerGeneratedClassName{ public: template \u0026lt;typename T\u0026gt; auto operator() (T x) const {return func(x);} } 泛型lambda的完美转发版本： 1 2 3 4 5 6 7 8 9 auto f = [] (auto\u0026amp;\u0026amp; param) {return func( std::forward\u0026lt;decltype(param)\u0026gt;(param) );} // 闭包类中的operator()的大致实现 class SomeCompilerGeneratedClassName{ public: template \u0026lt;typename T\u0026gt; auto operator() (T\u0026amp;\u0026amp; param) const { return func( std::forward\u0026lt;decltype(param)\u0026gt;(param) ); } }; auto fs = [] (auto\u0026amp;\u0026amp;... params) {return func( std::forward\u0026lt;decltype(params)\u0026gt;(params)... );} // 变长参数版本 参考 https://blog.csdn.net/Dong_HFUT/article/details/125116613 34：优先选用lambda表达式，而非std::bind 对于C++11，除了个别边缘case，lambda比std::bind更有优势；C++14，lambda完全可以替代std::bind\nlambda可读性更强，更容易理解 使用std::bind需要保持参数位置，同时需要了解其实现机制 std::bind需要保持参数位置，因此使用时需要查看原来函数的声明，才能知道占位符对应的参数类型和参数含义；但是lambda形参列表很明确 std::bind默认将参数拷贝到绑定对象内部（可以使用std::ref指定传引用），但是lambda可以明确指出值捕获还是引用捕获 std::bind绑定对象的函数调用使用了完美转发机制，但是lambda可以从形参列表中清晰看出传值还是传引用 1 2 3 4 5 6 7 Widget w; Logger logger; auto f = [w, \u0026amp;logger] (CompressLevel level) { return compress(w, level, logger); } // 捕获对象：w值捕获，logger引用捕获；形参：level传值 auto g = std::bind(compress, w, std::placeholders::_1, std::ref(logger)); // 需要对应参数顺序 // 绑定对象：w值绑定（复制），logger引用绑定；形参：level使用完美转发机制 std::bind参数绑定和对象调用不是一个时间，因此可能出现逻辑错误（见参考） lambda灵活性更强 如果std::bind绑定的函数存在重载版本，则编译器无法确定使用哪个版本的重载函数 1 2 3 4 5 6 7 void func(int a); void func(int a, int b); auto f = [] (int b) { return func(0, b); } using funcType = void(int, int); auto bnd = std::bind(static_cast\u0026lt;funcType\u0026gt;(func), 0, std::placeholders::_1) lambda可以内联 因为std::bind中绑定的是函数指针，需要在运行时才能确定；但是lambda中包含函数体，可以进行内联 使用std::bind的两个场景：在C++11中 使用std::bind间接实现移动捕获（[[ch06-lambda表达式#32：使用初始化捕获将对象移入闭包|C++14支持移动捕获]]） 使用std::bind绑定参数的完美转发机制，间接多态函数对象（[[ch06-lambda表达式#33：泛型lambda的完美转发版本|C++14支持泛型lambda]]） 1 2 3 4 5 6 7 8 auto f = [callableObject] (const auto\u0026amp; param) { callableObject(param); }; class CallableObject{ public: template \u0026lt;typename T\u0026gt; void operator() (const T\u0026amp; param); }; auto g = std::bind(CallableObject(), std::placeholders::_1); // 将占位符参数完美转发到可调用对象的调用运算符中 参考 https://blog.csdn.net/Dong_HFUT/article/details/125130410 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch06-lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","summary":"31：避免默认捕获模式 闭包：lambda所创建的运行期对象 默认捕获可能导致引用悬挂 默认传引用可能导致引用悬挂 显式传引用也可能导致引用悬挂，但","title":"[Effective Modern Cpp Notes] Ch06 Lambda表达式"},{"content":"23：理解std::move和std::forward std::move：返回变量的右值引用 对const对象的移动操作会被转换为拷贝操作 因为const对象经过std::move会返回一个const右值引用，而一般函数重载的移动版本形参都是非const的右值引用，无法匹配 std::move不移动对象，而且也不保证对象一定被移动，仅仅返回对象的右值引用 1 2 3 4 5 6 template\u0026lt;typename T\u0026gt; // C++14 decltype(auto) move(T\u0026amp;\u0026amp; param) { using ReturnType = remove_reference_t\u0026lt;T\u0026gt;\u0026amp;\u0026amp;; return static_cast\u0026lt;ReturnType\u0026gt;(param); } std::forward：实现完美转发（保持对象的左值性或右值性） 通常情况下，形参总是左值，即使其类型是右值引用 std::move和std::forward只是进行类型转换，在运行时不做任何事 参考 https://blog.csdn.net/Dong_HFUT/article/details/123765869 24：区分万能引用和右值引用 万能引用和右值引用只是形式上类似，但这是两个概念\n万能引用：形式为T\u0026amp;\u0026amp;或auto\u0026amp;\u0026amp;，并且存在类型推导 函数模板参数：template \u0026lt;typename T\u0026gt; void func(T\u0026amp;\u0026amp; param); auto类型推导：auto\u0026amp;\u0026amp; val = myVal; 1 auto myFunc = [] (auto\u0026amp;\u0026amp; func, auto\u0026amp;\u0026amp;... params) {/* do something */} 右值引用 带const（不是纯粹的T\u0026amp;\u0026amp;形式）：template \u0026lt;typename T\u0026gt; void func(const T\u0026amp;\u0026amp; param); 形式是T\u0026amp;\u0026amp;，但是不存在类型推导：比如vector的push_back，但是emplace_back中参数是万能引用 1 2 3 4 5 6 7 8 template \u0026lt;typename T, typename Allocator = allocator\u0026lt;T\u0026gt;\u0026gt; class vector{ public: void push_back(T\u0026amp;\u0026amp; x); // 调用push_back时，类型T已知 template \u0026lt;typename... Args\u0026gt; void emplace_back(Args\u0026amp;\u0026amp;... args); // 参数包args的类型Args独立于T，存在类型推导，这里是万能引用 } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123773321 25：针对右值引用实施std::move，针对万能引用实施std::forward 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Widget{ // 以例子来说明 public: Widget(Widget\u0026amp;\u0026amp; rhs): name(std::move(rhs.name)), sp(std::move(rhs.sp)) {} // 形参为右值引用，将形参（左值）进行移动 template \u0026lt;typename T\u0026gt; void setName(T\u0026amp;\u0026amp; newName){ // 形参为万能引用，保持形参的左值性或右值性 cout\u0026lt;\u0026lt;\u0026#34;set new name:\u0026#34;\u0026lt;\u0026lt;newName\u0026lt;\u0026lt;endl; name = std::forward\u0026lt;T\u0026gt;(newName); // 在函数中使用move或forward时，使用的位置应该是该参数最后一次使用的时候 } Widget operator+(Widget\u0026amp;\u0026amp; lhs, Widget\u0026amp;\u0026amp; rhs){ lhs.name += rhs.name; return std::move(lhs); } template \u0026lt;typename T\u0026gt; T doNothing(T\u0026amp;\u0026amp; t) { return std::forward\u0026lt;T\u0026gt;(t); } private: string name; shared_ptr\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; sp; }; 重载setName不是一个好的设计 可能效率低：如果传入字面量，即使匹配到右值版本的函数，形参仍然会作为临时对象 如果有多个参数，需要重载$2^N$种，如果使用参数包，则无法实现 在函数中使用move或forward时，使用的位置应该是该参数最后一次使用的时候 如果函数中将形参进行处理，然后返回 传值返回：如果形参是右值引用（比如Widget operator+成员函数），使用move返回；如果形参是万能引用（比如doNothing成员函数），使用forward返回 如果返回值是函数中的局部变量，则编译器有特定的优化：RVO 返回值优化RVO（Return Value Optimization）：减少函数返回时产生临时对象，进而消除部分拷贝或移动操作 1 2 3 4 5 6 7 8 9 10 11 12 // 原来 Widget func() { return Widget(); } // 有一次默认构造，一次拷贝构造 Widget w = func(); // 再加上一次拷贝构造 // 使用RVO优化，上面过程相当于： void func(Widget\u0026amp; w) { w.Widget::Widget(); } // Widget w在外面分配空间，直接传入func中进行构造，因此只需要一次（默认）构造 // NRVO(Named Return Value Optimization)原理类似 Widget func() { Widget w; return w; // 返回对象已经具名 } 使用前提：局部对象的类型和返回值类型相同，而且局部对象就是返回值 限制场景： 返回std::move()：默认构造+移动构造 进行赋值而非初始化Widget w; w = func();：默认构造+func中的默认构造和拷贝构造 不同的分支条件下，返回不同的局部对象 参考 https://blog.csdn.net/Dong_HFUT/article/details/123946594 26：避免依万能引用类型进行重载 原因：函数匹配规则 如果模板实例化出的函数和普通重载函数都精确匹配，则优先选择普通重载函数，其次选择模板函数实例化出来的精确版本 例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Person{ public: explicit Person(int idx): _name(nameFromIdx(idx)) {} template \u0026lt;typename T\u0026gt; // 对Person(int)的重载 explicit Person(T\u0026amp;\u0026amp; name): _name(std::forward\u0026lt;T\u0026gt;(name)) {} private: std::string _name; }; short id = 1; Person p1(id); // 会调用模板实例化的版本，而非进行类型转换调用普通版本 const Person p2(id); // 这个情况极其容易混淆， Person q2(p2); // 会调用生成的拷贝构造函数（因为其实参为const Person\u0026amp;） Person q1(p1); // 会调用模板实例化的版本，而非调用生成的拷贝构造函数 // 尤其当Person作为基类，派生类在构造函数中初始化基类部分时 class SpecialPerson: public Person{ public: SpecialPerson(const SpecialPerson\u0026amp; rhs): Person(rhs) {} SpecialPerson(SpecialPerson\u0026amp;\u0026amp; rhs): Person(std::move(rhs)) {} // 这两个构造函数均使用基类Person构造函数的完美转发版本， } // 对万能引用参数的函数进行重载，不是一个好的设计 27：熟悉依万能引用类型进行重载的替代方案 放弃重载，使用不同的函数名\n但是对于构造函数就无能为力 普通函数形参为const type\u0026amp;类型\n因此传入const实参，会优先使用原来的普通版本，而非重载的万能引用版本 将形参从引用类型换成值类型：当知道肯定要复制形参时，考虑按值传递\n1 2 3 4 5 6 7 class Person{ public: explicit Person(std::string name): _name(std::move(name)) {} explicit Person(int idx): name(nameFromIdx(idx)) {} private: std::string _name; } 使用Tag分发：使用Tag对参数进行区分，进而分发到不同的函数实现\n背景：如果想使用完美转发，就必须要使用万能引用 例子： 1 2 3 4 5 6 7 8 9 10 // 两个函数实现的版本 template \u0026lt;typename T\u0026gt; void logAndAddImpl(T\u0026amp;\u0026amp; name, std::false_type) {} template \u0026lt;typename T\u0026gt; void logAndAddImpl(int idx, std::true_type) {} // 使用Tag对参数进行区分 template \u0026lt;typename T\u0026gt; void logAndAdd(T\u0026amp;\u0026amp; name) { logAndAddImpl( std::forward\u0026lt;T\u0026gt;(name), std::is_integral\u0026lt;typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026gt;() ); // 或者C++14：std::is_integral\u0026lt;typename std::remove_reference_t\u0026lt;T\u0026gt; } 如果传入true or false，到运行时才能决定 在编译阶段进行模板匹配，std::is_integral在编译阶段就可以判断类型是否为整型 约束接受万能引用的模板：std::enable_if判断\n背景：构造函数无法使用Tag分发 例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;type_traits\u0026gt; class Person{ public: explicit Person(int idx): _name(nameFromIdx(idx)) {} template\u0026lt;typename T, typename = std::enable_if_t\u0026lt; !std::is_base_of_v\u0026lt;Person, std::decay_t\u0026lt;T\u0026gt;\u0026gt; \u0026amp;\u0026amp; !std::is_integral_v\u0026lt;std::remove_reference_t\u0026lt;T\u0026gt;\u0026gt; \u0026gt; \u0026gt; // 当类型T不为Person或者其派生类，抑或T不为int型时，才会选择这个的重载版本，使用万能引用进行重载并实现完美转发 explicit Person(T\u0026amp;\u0026amp; name): _name(std::forward\u0026lt;T\u0026gt;(name)) { static_assert( std::is_constructible(std::string, T)::value, \u0026#34;Parameter name can\u0026#39;t be used to construct a std::string\u0026#34; ); // 验证类型为std::string的对象能否被类型为T的对象构造 } private: std::string _name; }; std::enable_if\u0026lt;condition\u0026gt;::type：只有满足条件的模板才会使用（C++14std::enable_if_t） std::is_same\u0026lt;T1, T2\u0026gt;::value（C++17std::is_same_v） std::is_base_of\u0026lt;T1, T2\u0026gt;::value：如果T2继承于T1，则为true；且std::is_base_of\u0026lt;T, T\u0026gt;::value==true（C++17std::is_base_of_v） std::decay\u0026lt;T\u0026gt;::type的类型与T的类型相同，忽略了引用、const、volatile（C++14std::decay_t） 权衡\n前三种方案都需要对需要调用的函数形参逐一指定其类型，后两种方案使用万能引用实现了完美转发 虽然完美转发效率更高（避免创建临时对象），但是某些对象无法实现完美转发，并且使用完美转发并编译报错时，报错信息的可读性很差 std::is_constructible可以在编译期测试一个类型的对象能否被另一个不同类型的对象（或者多个不同类型的多个对象）构造，因此可以用来验证转发函数的万能引用参数是否合法 参考\nSFINAE技术 https://blog.csdn.net/Dong_HFUT/article/details/124227488 28：理解引用折叠 几种引用折叠的应用场景： 万能引用的实例化：在模板类型推导时，可能出现“引用的引用”的情况，此时需要用到引用折叠 std::forward完美转发： 1 2 3 4 template \u0026lt;typename T\u0026gt; T\u0026amp;\u0026amp; forward(typename remove_reference\u0026lt;T\u0026gt;::type\u0026amp; param){ return static_cast\u0026lt;T\u0026amp;\u0026amp;\u0026gt;(param); } auto类型推导，decltype类型推导 typedef类型别名 参考 https://blog.csdn.net/Dong_HFUT/article/details/124517043 29：假定移动操作不存在、成本高、未使用 几种移动语义不可用、不高效的情况： 没有移动操作：编译器只有在没有用户自定义拷贝操作和析构函数时，才自动生成移动操作 移动未能更快： std:array 一般STL中容器的对象都分配在堆上，对象中有指向堆上内存的指针，因此移动操作只需要进行指针的更新、源对象的指针置空即可 但是std::array中内容分配在栈上（栈上的数组），移动操作等于复制操作 std::string std::string针对小对象有一个优化SSO（Small String Optimization），小对象直接存储在栈上而非堆上，省去动态内存分配 移动不可用：移动操作没有标记为noexcept 如果移动操作没有标记为noexcept，即使是适合使用移动操作的场景，编译器也会使用复制操作替代 源对象是左值：只有右值可以作为移动操作的源（左值可以用，但是很容易造成空悬问题） 参考 https://blog.csdn.net/Dong_HFUT/article/details/124577258 30：熟悉完美转发的失败情形 完美转发的含义：不仅转发对象，而且转发其特征（左值、右值、const、volatile） 完美转发的失败情形 列表初始化 1 2 3 4 5 6 7 8 void f(const std::vector\u0026lt;int\u0026gt;\u0026amp; v) {} template \u0026lt;typename T\u0026gt; void fwd(T\u0026amp;\u0026amp; param) {} f({1,2,3}); // ok fwd({1,2,3}); // 编译报错：无法推断出T的类型 auto il = {1,2,3}; fwd(il); // T=initializer_list\u0026lt;int\u0026gt; 0或NULL作为空指针 0或NULL会被推导为int型而非空指针类型，因此完美转发后得到的类型是int，但是形参是指针类型 仅仅声明整型的静态常量数据成员 1 2 3 4 5 class Widget{ public: static cosnt int cnst = 12; // 声明而非定义，不会分配实际的存储空间，而是常量传播（直接将用到cnst的地方替换为12） }; fwd(Widget::cnst); // 编译报错：找不到cnst的定义 只声明不会分配空间，因此无法取地址，也无法使用引用，不能使用完美转发 解决方法：在类外或是对应.cpp文件中添加定义：const int cnst = 12; 函数重载和函数模板 1 2 3 4 5 6 7 8 9 10 void f(int (*pf)(int)); int func(int a); int func(int a, int b); f(func); // ok fwd(func); // 模板类型推导失败：无法确定是哪个重载版本 // 解决方法： using FuncType = int (*)(int); fwd(static_cast\u0026lt;FuncType\u0026gt;(func)); // 但是万能引用和完美转发一般是针对任意类型的，这里限定了类型，语义与实现矛盾 位域：位域只是int类型的一部分，没有一个确切地址，也就无法引用 参考 https://blog.csdn.net/Dong_HFUT/article/details/124787082 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch05-%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E7%A7%BB%E5%8A%A8%E8%AF%AD%E5%8F%A5%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/","summary":"23：理解std::move和std::forward std::move：返回变量的右值引用 对const对象的移动操作会被转换为拷贝操作 因为","title":"[Effective Modern Cpp Notes] Ch05 右值引用、移动语句和完美转发"},{"content":"18：使用std::unique_ptr管理具备专属所有权的资源 std::unique_ptr表示独占所有权，因此无法拷贝（拷贝构造、拷贝赋值是delete的），只能进行移动操作从而转移资源控制权 例外：可以从函数返回一个std::unique_ptr 1 2 3 4 5 std::unique_ptr\u0026lt;int\u0026gt; func(int x){ auto delInt = [\u0026amp;](int* p) { cout\u0026lt;\u0026lt;\u0026#34;My deleter\u0026#34;\u0026lt;\u0026lt;endl; delete p;} std::unique_ptr\u0026lt;int, decltype(delInt)\u0026gt; pInt(new int(x), delInt); return pInt; } 删除器是std::unique_ptr类型的一部分 在不定义删除器的情况下，std::unique_ptr内存占用和原始指针相同 如果自定义删除器，则std::unique_ptr内存占用会变大 std::unique_ptr可以指向数组，默认删除器为delete[]：std::unique_ptr\u0026lt;int[]\u0026gt; p(new int[5]{1,2,3,4,5}); 但是数组形式用到的场合很少，尽量使用STL std::unique_ptr可以直接隐式转换为std::shared_ptr 典型应用：针对继承体系，作为工厂函数的返回值类型 1 2 3 4 5 6 7 8 9 10 11 class Animal {}; class Dog: public Animal {}; class Cat: public Animal {}; template \u0026lt;typename... Ts\u0026gt; auto makeAnimal(AnimalType type, Ts\u0026amp;\u0026amp;... AnimalInfo){ // C++14中函数返回值可以写为auto，因此unique_ptr的删除器可以放在函数内部，否则显式写出返回类型时需要知道删除器类型，因此删除器只能写在函数外部 auto delAnimal = [](AnimalType* ptr) { makeMyLog(ptr); delete ptr; } std::unique_ptr\u0026lt;Animal, decltype(delAnimal)\u0026gt; up(nullptr, delAnimal); if(type == Dog) up.reset(new Dog(std::forward\u0026lt;Ts\u0026gt;(AnimalInfo)...)); // 参数是万能引用，这里进行完美转发 if(type == Cat) up.reset(new Cat(std::forward\u0026lt;Ts\u0026gt;(AnimalInfo)...)); // 使用reset使得指针独占资源的所有权，不能直接将原始指针赋值给智能指针 return up; // 返回unique_ptr } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123465058 19：使用std::shared_ptr管理具备共享所有权的资源 std::shared_ptr可以拷贝，通过引用计数来管理资源的生命周期 std::shared_ptr内存模型 一个std::shared_ptr大小通常为普通指针的两倍：一个指针指向资源，另一个指针指向控制块 控制块中通过原子操作维护引用计数，保存deleter（因此deleter不属于std::shared_ptr类型的一部分），保存弱计数等 std::shared_ptr的使用： 使用std::make_shared、std::unique_ptr、原始指针创建std::shared_ptr，会为资源创建一个控制块 如果资源有多个控制块，就会被多次析构，因此尽量避免使用原始指针构造std::shared_ptr 使用std::shared_ptr或std::weak_ptr创建一个std::shared_ptr，不会创建一个新的控制块 this的陷阱： 1 2 3 4 5 6 7 8 9 10 11 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal{ virtual void eat(){ eatList.emplace_back(this); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(this)); } }; struct Cat: public Animal{}; struct Dog: public Animai{}; shared_ptr\u0026lt;Animal\u0026gt; myCat(new Cat); myCat-\u0026gt;eat(); // 针对同一个对象创建了两个控制块 解决方法一：使类继承自std::enable_shared_from_this，类内部使用shared_from_this方法，搜索当前对象的控制块，如果有就不用创建控制块了，如果没有则抛出异常，因此适合于当前对象已经创建过控制块的情况 1 2 3 4 5 6 7 8 9 10 11 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal: public std::enable_shared_from_this\u0026lt;Animal\u0026gt;{ virtual void eat(){ eatList.emplace_back(shared_from_this()); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(shared_from_this())); } }; struct Cat: public Animal{}; struct Dog: public Animai{}; shared_ptr\u0026lt;Animal\u0026gt; myCat(new Cat); myCat-\u0026gt;eat(); 解决方法二：见127页，代码是自己实现的，有误 1 2 3 4 5 6 7 8 9 10 11 12 13 vector\u0026lt;shared_ptr\u0026lt;Animal\u0026gt;\u0026gt; eatList; // 追踪哪些Animal调用了eat方法 struct Animal: public std::enable_shared_from_this\u0026lt;Animal\u0026gt;{ public: template \u0026lt;typename... Ts\u0026gt; static shared_ptr\u0026lt;Animal\u0026gt; create(Ts\u0026amp;\u0026amp;... params) { return shared_ptr\u0026lt;Animal\u0026gt;(Animal(std::foward\u0026lt;Ts\u0026gt;(params)...)); } virtual void eat(){ eatList.emplace_back(shared_from_this()); // eatList.push_back(shared_ptr\u0026lt;Animal\u0026gt;(shared_from_this())); } private: Animal() {} // 构造函数 }; struct Cat: public Animal{}; struct Dog: public Animai{}; 参考 https://blog.csdn.net/Dong_HFUT/article/details/123599599 20：对于类似std::shared_ptr但是可能空悬的指针使用std::weak_ptr std::weak_ptr通常视为std::shared_ptr的辅助工具，通过std::shared_ptr构造std::weak_ptr std::weak_ptr不会影响对象的引用计数 但是std::weak_ptr没有解引用操作，必须调用lock转换为std::shared_ptr来访问对象 例子：if(shared_ptr\u0026lt;int\u0026gt; p = wp.lock()\u0026gt; cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;endl; 典型应用： 避免shared_ptr循环引用：将其中一个shared_ptr改为weak_ptr 1 2 3 4 5 6 7 8 9 10 struct A{ std::shared_ptr\u0026lt;B\u0026gt; pb; // std::weak_ptr\u0026lt;B\u0026gt; pb; }; struct B{ std::shared_ptr\u0026lt;A\u0026gt; pa; }; std::shared_ptr\u0026lt;A\u0026gt; pa = std::make_shared\u0026lt;A\u0026gt;(); std::shared_ptr\u0026lt;B\u0026gt; pb = std::make_shared\u0026lt;B\u0026gt;(); pa-\u0026gt;pb = pb; // pb和pa-\u0026gt;pb同时指向同一个对象B，引用计数为2 pb-\u0026gt;pa = pa; 带缓存的工厂方法 1 2 3 4 5 6 7 8 9 std::shared_ptr\u0026lt;const Widget\u0026gt; fastLoadWidget(WidgetID id){ static std::unordered_map\u0026lt;WidgetID, weak_ptr\u0026lt;const Widget\u0026gt;\u0026gt; cache; std::shared_ptr\u0026lt;const Widget\u0026gt; widgetPtr = cache[id].lock(); if(!widgetPtr){ // 缓存中没有 widgetPtr = loadWidget(id); // 调用原始工厂方法创建，并加入到缓存中 cache[id] = widgetPtr; } return widgetPtr; } 观察者设计模式：多个观察者（observer）对象同时监听一个主题（subject）对象，主题对象会在其发生状态改变时发出通知。主题对象不会控制其观察者的生存期，但需要确认当一个观察者对象被析构后，主题对象不会再访问它。一种合理的设计就是让每个主题对象持有指向其观察者对象的std::weak_ptr，以便在使用之前确认它是否空悬。 参考： https://blog.csdn.net/Dong_HFUT/article/details/123612236 21：优先选用std::make_unqiue和std::make_shared，而非直接使用new make函数可以传入任意集合的参数，然后完美转发给构造函数，并动态创建一个对象，返回智能指针 支持auto 避免异常：将[[ch03-资源管理#17：以独立语句将new的对象置入智能指针| effective C++ item17：以独立语句将new的对象置入智能指针]]改进为使用make函数 1 2 3 4 5 6 7 void func(shared_ptr\u0026lt;Widget\u0026gt; sp, int priority); void func(shared_ptr\u0026lt;Widget\u0026gt;(new Widget), priority); // 可能由于异常导致内存泄露 void func(make_shared\u0026lt;Widget\u0026gt;(), priority); // 不会由于异常导致内存泄露 // 如果需要自定义删除器，并且又可以避免异常 shared_ptr\u0026lt;Widget\u0026gt; sp(new Widget, myDeleter); func(std::move(sp), priority); // 直接传递一个右值，避免了修改引用计数 效率更高：make函数只需要申请一次内存（同时存储对象和控制块），但是使用shared_ptr\u0026lt;Widget\u0026gt;(new Widget)需要申请两次内存（一次对象，一次控制块） make函数的缺点： 无法自定义deleter 语义歧义：比如使用()和{}初始化vector代表不同的方式，make函数可以完美转发()，不支持完美转发{} 1 2 3 4 auto sp1 = make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(2,3); // {3,3}; shared_ptr\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; sp2(new vector{1,2,3,4,5}); auto initList = {1,2,3,4,5}; auto sp3 = make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(initList); // 不支持：make_shared\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;({1,2,3,4,5}); 不建议对自定义内存管理方式的类使用 make 函数：通常情况下，类自定义的operator new和operator delete被设计成用来分配和释放能精确容纳该类大小的内存块，但std::allocate_shared所要求的内存大小并不等于动态分配对象的大小，而是在其基础上加上控制块的大小。 若存在非常大的对象和比相应的std::shared_ptr生存期更久的std::weak_ptr，不建议使用 make 函数，会导致对象的析构和内存的释放之间产生延迟 如果只申请一块内存（make函数），如果后来shared_ptr的引用计数为0，但是weak_ptr的引用计数不为0时，对象销毁会被延长，只有当weak_ptr的引用计数为0时，控制块才被释放 如果使用new的话，可以立即销毁对象 参考 https://blog.csdn.net/Dong_HFUT/article/details/123622543 22：使用Pimpl习惯用法时，将特殊成员函数的定义放到实现文件中 PImpl技术（Pointer to Implementation，编译防火墙）：将类的实现放在另一个单独的类中，并通过不透明的指针进行访问。因此可以有效减少编译依赖。 原理：一个只声明但是不定义的类型是不完整类型，声明指向它的指针是可以通过编译的 常见错误： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // in \u0026#34;widget.h\u0026#34; #include \u0026lt;memory\u0026gt; class Widget { public: Widget(); private: struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; pImpl; }; //==================================================================================// // in \u0026#34;widget.cpp\u0026#34; #include \u0026#34;widget.h\u0026#34; #include \u0026lt;string\u0026gt; struct Widget::Impl { std::string name; }; Widget::Widget(): pImpl(std::make_unique\u0026lt;Impl\u0026gt;()){} //==================================================================================// // in \u0026#34;main.cpp\u0026#34; #include \u0026#34;widget.h\u0026#34; int main(){ Widget w; // 报错：/usr/include/c++/9/bits/unique_ptr.h:79:16: error: invalid application of ‘sizeof’ to incomplete type ‘Widget::Impl’ return 0; } 报错原因：在析构Widget w时，此时看到的Impl是不完整类型 在编译widget.cpp时没有问题：g++ -c widget.cpp -o widget.o 在编译main.cpp时出问题：g++ -c main.cpp -o main.o 没有定义Widget的析构函数，因此使用自动生成的析构函数（默认是inline的） 本来如果声明了Widget的析构函数，编译时无法进行处理，后面链接时链接到定义，运行时才能析构pImpl（因为经过链接，此时也知道Impl是完整类型） 但是正因为自动生成的析构函数是inline的，编译时就可以展开，此时析构pImpl当然看到的Impl是不完整类型（还没有链接到widget.o） 使用说明 考虑到如上报错和[[ch03-转向现代C++#17：理解特殊成员函数的生成机制|item17：理解特殊成员函数的生成机制]]，因此最好将拷贝控制成员和析构函数自定义，且声明与实现分离（防止进行内联） 为了实现PImpl技术，使用unique_ptr是最合适的，因为pImpl指针独享Impl的所有权，如果使用shared_ptr则上述报错不会出现（因为删除器不属于类型的一部分，属于控制块，不会包含删除器的代码） 参考 https://blog.csdn.net/Dong_HFUT/article/details/123704824 https://github.com/liuzengh/CppIdioms/blob/main/code/pimpl/person.cpp 实例 widget.h 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;memory\u0026gt; class Widget{ public: Widget(std::string s); Widget(const Widget\u0026amp; rhs); Widget\u0026amp; operator=(const Widget\u0026amp; rhs); Widget(Widget\u0026amp;\u0026amp; rhs); Widget\u0026amp; operator=(Widget\u0026amp;\u0026amp;); ~Widget(); std::string getName() const; private: // std::string _name; struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; pImpl; }; widget.cpp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026#34;widget.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; struct Widget::Impl{ Impl(std::string name): _name(name) {}; std::string _name; std::string getName() const {return _name;} }; Widget::Widget(std::string s): pImpl(std::make_unique\u0026lt;Impl\u0026gt;(s)) {} Widget::~Widget() {} Widget::Widget(const Widget\u0026amp; rhs): pImpl(std::make_unique\u0026lt;Impl\u0026gt;(*rhs.pImpl)) {} Widget\u0026amp; Widget::operator=(const Widget\u0026amp; rhs){ *pImpl = *rhs.pImpl; return *this; } Widget::Widget(Widget\u0026amp;\u0026amp; rhs) =default; Widget\u0026amp; Widget::operator=(Widget\u0026amp;\u0026amp; rhs) =default; std::string Widget::getName() const { return pImpl-\u0026gt;getName();} main.cpp 1 2 3 4 5 6 7 8 #include \u0026#34;widget.h\u0026#34; #include \u0026#34;iostream\u0026#34; int main(){ Widget w(\u0026#34;zhang\u0026#34;); std::cout\u0026lt;\u0026lt;w.getName()\u0026lt;\u0026lt;std::endl; return 0; } ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch04-%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","summary":"18：使用std::unique_ptr管理具备专属所有权的资源 std::unique_ptr表示独占所有权，因此无法拷贝（拷贝构造、拷贝赋","title":"[Effective Modern Cpp Notes] Ch04 智能指针"},{"content":"07：在创建对象时注意区分()和{} 初始化方式 1 2 3 4 int x1(1); int x2 = 2; int x3{3}; // 统一初始化（列表初始化） int x4 = {4}; // 和第三种方式相同 ()和=初始化的限制 ()不能用于non-static成员的初始化 不能拷贝的对象不能使用()初始化 {}初始化的优点 禁止基本类型之间的隐式窄化类型转换：比如不能使用double初始化int型变量 避免了C++复杂的语法分析：C++\u0026rsquo;s most vexing parse 1 2 3 Widget w1(10); // 传入一个实参，构造出一个对象 Widget w2(); // 本来想调用无形参的构造函数构造一个对象，但是实际上声明了一个函数 Widget w3{}; // 调用无形参的构造函数，构造出一个对象 {}的缺陷 auto类型推导中使用{}进行初始化，则auto被推断为initializer_list\u0026lt;T\u0026gt; 会优先使用形参为initializer_list\u0026lt;T\u0026gt;的构造函数，即使其他的构造函数更加匹配 只有当{}中参数无法转换为initializer_list中类型时，编译器才匹配普通函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Widget{ public: Widget() {cout\u0026lt;\u0026lt;\u0026#34;0\u0026#34;\u0026lt;\u0026lt;endl;} Widget(int i, int d) {cout\u0026lt;\u0026lt;\u0026#34;1\u0026#34;\u0026lt;\u0026lt;endl;} Widget(int i, bool d) {cout\u0026lt;\u0026lt;\u0026#34;2\u0026#34;\u0026lt;\u0026lt;endl;} Widget(initializer_list\u0026lt;int\u0026gt; il) {cout\u0026lt;\u0026lt;\u0026#34;2\u0026#34;\u0026lt;\u0026lt;endl;} Widget(const Widget\u0026amp; w) {cout\u0026lt;\u0026lt;\u0026#34;copy ctor\u0026#34;\u0026lt;\u0026lt;endl;} Widget(Widget\u0026amp;\u0026amp; w) {cout\u0026lt;\u0026lt;\u0026#34;move copy ctor\u0026#34;\u0026lt;\u0026lt;endl;} operator int() const { cout\u0026lt;\u0026lt;\u0026#34;convert to int\u0026#34;\u0026lt;\u0026lt;endl; return 1; } }; Widget w1{1, true}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，即使Widget(int i, bool d)更加匹配 Widget w2{1, 1.0}; // 编译报错，本来调用Widget(initializer_list\u0026lt;int\u0026gt; il)，但是使用{}初始化禁止窄化类型转换（存在从double到int的转换） Widget w3{w1}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)（中间先将w1转为int），即使Widget(const Widget\u0026amp; w)更加匹配（如果w1无法转换为int，则调用该构造函数） Widget w4{std::move(w1)}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，即使Widget(Widget\u0026amp;\u0026amp; w)更加匹配 // 特殊情况： Widget w4{}; // 调用Widget()，而非调用Widget(initializer_list\u0026lt;int\u0026gt; il) Widget w5{{}}; // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，而非调用Widget() Widget w6({}); // 调用Widget(initializer_list\u0026lt;int\u0026gt; il)，而非调用Widget() 使用模板创建对象时，仔细考虑使用()还是{}进行初始化 标准库函数std::make_unique和std::make_shared也面临着这个问题，它们的解决方案是在内部使用小括号，并将这个决定写进文档中，作为其接口的组成部分。 1 2 3 4 5 6 7 8 9 template \u0026lt;typename T, typename... Ts\u0026gt; void f(Ts\u0026amp;\u0026amp;... params){ // 使用可变参数模板 T localVector1(std::forward\u0026lt;Ts\u0026gt;(params)...); T localVector2{std::forward\u0026lt;Ts\u0026gt;(params)...}; } f\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(3,4); // 推断出T=vector\u0026lt;int\u0026gt;, Ts=int // localVector1: 4,4,4 // localVector2: 3,4 参考 https://blog.csdn.net/Dong_HFUT/article/details/122811753 08：优先选用nullptr，而非0或NULL 字面量0是一个int，NULL的实现为0L，可以转换为int，bool，void* nullptr可以理解为任意类型的空指针 使得重载函数的调用明确 提高代码的清晰度 使用类型推导时，nullptr可以隐式转换为任意类型指针 参考 https://blog.csdn.net/Dong_HFUT/article/details/122891898 09：优先选用别名声明，而非typedef using别名的优点： 清晰，比typedef更容易理解 可以直接对模板起别名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template \u0026lt;typename T\u0026gt; using MyAllocList = std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt;; // 如果非要使用typedef，需要包装一层 template \u0026lt;typename T\u0026gt; struct MyAllocList{ typedef std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt; type; }; template \u0026lt;typename T\u0026gt; class Widget{ MyAllocList\u0026lt;T\u0026gt; list1; // list1=std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt;,此时MyAllocList一定是一个别名 typename MyAllocList\u0026lt;T\u0026gt;::type list2; // list2=MyAllocList\u0026lt;T\u0026gt;中的std::list\u0026lt;T, MyAlloc\u0026lt;T\u0026gt;\u0026gt; // 需要使用typename显式说明MyAllocList\u0026lt;T\u0026gt;::type是一个类型，而非数据成员 } 应用：标准库的\u0026lt;type_traits\u0026gt;中提供了一整套用于类型转换的类模板 虽然C++11中仍然是使用typedef实现的，但是C++14中是使用using声明实现的 1 2 std::remove_const\u0026lt;T\u0026gt;::type // C++11中, 是一个内部包裹typedef的类模板，将T中的const属性移除 std::remove_const_t\u0026lt;T\u0026gt; // C++14中, 是一个类模板中typedef别名的别名，将T中的const属性移除 参考 https://blog.csdn.net/Dong_HFUT/article/details/122847510 10：优先选用限定作用域的枚举类型，而非不限作用域的枚举类型 无作用域限制的枚举（unscoped enums，C++98） 有时使用可能简便一点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 using UserInfo = std::tuple\u0026lt;std::string, std::string, std::size_t\u0026gt; //name, email,age enum UserInfoFields {uiName, uiEmail, uiAge}; UserInfo uInfo; auto email = std::get\u0026lt;1\u0026gt;(uInfo); // 位置1为email auto email = std::get\u0026lt;uiEmail\u0026gt;(uInfo); // 发生隐式类型转换 auto email = std::get\u0026lt;static_cast\u0026lt;std::size_t\u0026gt;(UserInfoFields::uiEmail)\u0026gt;(uInfo); // 冗余 // C++14下的辅助类:既想使用有作用限制的枚举，又不想过于啰嗦 template \u0026lt;typename E\u0026gt; constexpr auto toUType(E enumerator) noexcept { return static_cast\u0026lt;std::underlying_type_t\u0026lt;E\u0026gt;\u0026gt;(enumerator); } auto email = std::get\u0026lt;toUType(UserInfoFields::uiEmail)\u0026gt;(uInfo); 有作用域限制的枚举（scoped enums，C++11） 减少名称污染 1 2 3 4 5 enum unscopedColor{black, white}; auto black = false; // 无作用域限制的枚举，因此枚举类型暴露在{}之外 enum class scopedColor {red, blue}; auto red = false; // 有作用域限制的枚举，枚举类型限制在{}之内，因此减少名称污染 有强类型 1 2 3 4 5 enum unscopedColor{black, white}; double d1 = black; // 无作用域限制的枚举，可以发生隐式类型转换 enum class scopedColor {red, blue}; double d2 = static_cast\u0026lt;double\u0026gt;(scopedColor::red); // 有作用域限制的枚举，不会发生隐式类型转换，类型转换需要显式说明 可以前向声明：只有在指定底层类型后，才能进行前向声明 1 2 enum unscopedColor: std::uint8_t; // 没有提供默认底层类型 enum class; //默认底层类型为int 参考 https://blog.csdn.net/Dong_HFUT/article/details/122914289 11：优先选用删除函数，而非private未定义函数 背景：编译期会自动生成某些函数，但是有时不需要这些函数； C++98的做法：声明为private的，且只声明不定义（effective C++中item6） 在private中声明但是不定义，使之在链接阶段因为没有定义而报错 在基类中声明为private的，会因为无法拷贝控制派生类中的基类部分，将报错从链接期提前到编译期 C++11的做法：在声明中标记为=delete 将删除的函数声明为public的，原因是编译器先检查访问权限，再检查delete状态。如果将删除的函数声明为private的，调用删除的函数时，可能报错原因提示是private的；但是更期望的更明确的含义是这些函数是删除的 =delete可以在任意函数中进行标记，不仅仅局限于成员函数 应用： 比如可以阻止某些形参的隐式类型转换 1 2 void func(int a); void func(double) =delete; // 因此禁止double和float两种参数的调用（C++总是倾向于将 float 转换为 double） 阻止某些模板类型的实例化 1 2 3 4 5 6 7 template \u0026lt;typename T\u0026gt; void func(T* ptr); template \u0026lt;\u0026gt; void func\u0026lt;void\u0026gt;(void* ptr) =delete; struct Widget{ template\u0026lt;typename T\u0026gt; void g(T* ptr); }; template\u0026lt;\u0026gt; void Widget::g\u0026lt;void\u0026gt;(void* ptr) = delete; // 成员模板函数在类外阻止某些类型的实例化 参考 https://blog.csdn.net/Dong_HFUT/article/details/123005509 12：给意在改写的函数添加override声明 重写override需要满足的条件 基类的重写函数必须是虚函数 基类和派生类的重写函数 函数名（析构函数除外）、形参类型、函数常量性完全相同 函数引用限定符完全相同（C++11，函数引用限定符：该成员函数可以被左值对象还是右值对象调用） 返回值类型、异常规格说明兼容 将重写的函数标记为override，如果不满足重写条件则报错 参考 https://blog.csdn.net/Dong_HFUT/article/details/123008755 13：优先选用const_iterator，而非iterator C++98在容器的成员函数中对const_iterator支持有限 C++11在容器的成员函数中支持const_iterator，但是只提供了非成员的begin和end 1 2 3 4 template \u0026lt;typename Container\u0026gt; // C++11实现cbegin的方法 auto cbegin(const Container\u0026amp; container) -\u0026gt; decltype(std::begin(container)){ // auto=const Container::iterator\u0026amp; return std::begin(container); } C++14提供了非成员的cbegin和cend 尽量使用非成员的cbegin和cend，因为某些数据结构（比如数组）没有成员函数cbegin和cend，非成员的cbegin和cend更加通用 1 2 3 4 5 6 7 template\u0026lt;typename C, typename V\u0026gt; void findAndInsert(C\u0026amp; container, const V\u0026amp; targetVal, const V\u0026amp; insertVal) { using std::cbegin; using std::cend; auto it = std::find(cbegin(container), cend(container), targetVal); container.insert(it, insertVal); } 参考 https://blog.csdn.net/Dong_HFUT/article/details/123030976 14：只要函数不会抛出异常，就为其加上noexcept声明 noexcept 是函数接口的一部分，并且调用者可能会依赖这个接口。 相较于 non-noexcept 函数，noexcept 函数有被更好优化的机会。 noexcept 对于 move 操作、swap、内存释放函数和析构函数是非常有价值的。 大部分函数是异常中立的而不是 noexcept。 背景： C++98中异常规范的局限性：接口的实现一旦被修改，其异常规范可能也变化 因此C++11只需要指明接口是否可能抛出异常 优点：一个noexcept函数有更多编译优化的机会 不需要保持运行栈为解开的状态 不需要保证对象以构造顺序的逆序完成析构 应用：如果知道一个函数不会抛出异常，一定要加上noexcept noexcept属性对于移动操作、swap、内存释放函数和析构函数最有价值。C++11 STL 中的大部分函数遵循 “能移动则移动，必须复制才复制” 策略 默认noexcept函数：C++11内存释放函数和所有的析构函数都默认隐式地具备noexcept属性 析构函数未隐式地具备noexcept属性的唯一情况，就是所有类中有数据成员（包含递归的成员）的类型显式地将其析构函数声明为noexcept(false) 如果标准库使用了某个对象，其析构函数抛出了异常，则该行为是未定义的。 条件noexcept：一个函数是否为noexcept，取决于noexcept中的表达式是否为noexcept 只有被调用的低层次的函数是noexcept，高层次的调用方才是noexcept的 1 2 3 4 template \u0026lt;typename T1, typename T2\u0026gt; struct myPair{ void swap(myPair\u0026amp; p) noexcept( noexcept(swap(first, p.first)) \u0026amp;\u0026amp; noexcept(swap(second, p.second)) ); } 异常中立函数：本身不抛出异常，但是调用的函数可能抛出异常，因此不适合标记为noexcept 但是允许noexcept函数中调用没有noexcept保证的函数 通常只为宽松规约提供noexcept声明 宽松规约（wide contract，宽接口）：不带前提条件，被调用时不需要关注程序的状态，传入的参数方面没有限制，宽接口的函数永远不会出现未定义的行为 狭隘规约（narrow contract，窄接口）：带前提条件，如果违反前提条件，则结果是未定义的 调用者来保证调用时满足前提条件 如果调用时违反前提条件，则抛出异常；如果定义为noexcept的，违反前提条件结果是未定义的；相较而言，找出抛出异常的原因相对简单一些 参考 https://blog.csdn.net/Dong_HFUT/article/details/123163671 15：只要有可能使用constexpr，就使用它 constexpr对象：具备const属性，并且在编译期（和链接期）可以确定其值 const对象不能保证在编译期确定其值 constexpr函数 含义： 如果所有传入 constexpr 函数的参数都能在编译时知道，则结果将在编译时计算出来。 如果传入 constexpr 函数的参数有任何一个不能在编译期知道，则结果在运行时计算出来 使用 C++11中，constexpr函数有且只能有一条return语句；C++14无此限制 constexpr 函数被限制只能接受和返回 literal 类型（字面量，非指针和引用，自定义类型也可能是字面量类型的） C++11中，如果成员函数修改了操作的对象，或者成员函数的返回值是void的，则该成员函数无法成为constexpr的；C++14无此限制 1 2 3 4 5 6 7 8 9 10 11 class Point{ public: constexpr Point(double xVal=0, double yVal=0) noexcept: x(xVal), y(yVal) {} constexpr double getX() const noexcept {return x;} constexpr double getY() const noexcept {return y;} constexpr void setX(double newX) noexcept { x = newX;} // C++14中，移除了两条限制，因此可以设置为constexpr的 constexpr void setY(double newY) noexcept { y = newY;} private: double x, y; }; constexprt Point p1(1.0, 2.0); 参考 https://blog.csdn.net/Dong_HFUT/article/details/123172189 16：保证const成员函数的线程安全性 const成员的好处：不会修改成员变量，而且可以区分重载（const对象和非const对象调用） 保证const成员函数的线程安全性 使用std::mutex，进入临界区锁对象获取互斥量，出临界区析构锁（释放互斥量） 使用std::atomic，但是只能同步单一变量或者内存单元 std::mutex和std::atomic都是move-only的 参考 https://blog.csdn.net/Dong_HFUT/article/details/123316263 17：理解特殊成员函数的生成机制 特殊成员函数（special member function）： 一般是public、inline和novirtual的 例外：如果基类中的析构函数是virtual的，派生类中的析构函数也是virtual的 拷贝构造和拷贝赋值是两个独立的操作 移动构造和移动赋值不是独立的操作，如果声明了其中一个，编译器会阻止生成另外一个 如果显式申明一个拷贝操作，则两个移动操作不会自动生成 三法则（The Rule of Three）：如果声明了{拷贝构造函数、拷贝赋值操作、析构函数}中任意一个，则应该声明所有这三个函数，因为往往意味着类要管理某些资源 因此，如果只声明了一个析构函数，编译器应该不会自动生成拷贝操作 但实际上编译器还是可能自动生成拷贝操作（历史遗留原因，以及C++11为了兼容历史代码） 因此，只有当类中没有声明析构函数、拷贝操作、移动操作，而且需要时，编译器才会生成移动操作 如果想让编译器自动生成相关函数（即使违背了这些限制），添加=default进行标记 C++11中对特殊成员函数的生成规则： 默认构造函数：同C++98 析构函数：本质同C++98，只是默认声明为noexcept 拷贝构造函数：运行期行为同C++98（memberwise 拷贝构造 non-static 成员变量） 如果类中声明了一个移动操作，则拷贝构造函数和拷贝赋值运算符被标记为=delete的 如果类中自定义拷贝赋值运算符或析构函数，可以生成拷贝构造函数，但是已经成为被废弃的方法 拷贝赋值运算符：规则同拷贝构造函数 移动构造函数和移动赋值运算符：仅当类中不包含用户声明的拷贝操作、移动操作和析构函数时才生成 特殊情况：成员模板函数不会抑制特殊成员函数的自动生成 1 2 3 4 5 class Widget{ public: template \u0026lt;typename T\u0026gt; Widget(const T \u0026amp;rhs); template \u0026lt;typename T\u0026gt; Widget\u0026amp; operator=(const T\u0026amp; rhs); }; // 编译器仍然会生成copy和move操作，即使可以实例化得到 参考 https://blog.csdn.net/Dong_HFUT/article/details/123433559 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch03-%E8%BD%AC%E5%90%91%E7%8E%B0%E4%BB%A3c++/","summary":"07：在创建对象时注意区分()和{} 初始化方式 1 2 3 4 int x1(1); int x2 = 2; int x3{3}; // 统一初始化（列表初始化） int x4 = {4}; // 和第三种方式相同 ()和=初始化的限","title":"[Effective Modern Cpp Notes] Ch03 转向现代C++"},{"content":"05：优先选用auto，而非显式类型推断 优点一：避免变量未初始化 使用auto声明的变量未初始化，直接导致编译报错 优点二：简化变量声明（避免写一长串类型名） 优点三：声明闭包类型（lambda表达式） C++11中lambda式返回值可以使用auto，C++14中lambda式形参也可以使用auto std::function通常比起auto更大更慢，还可能导致内存消耗异常，因此实际使用时更推荐auto。 使用auto声明的、存储着一个闭包的变量和该闭包是同一类型，从而它要求的内存量也和该闭包相同 使用std::function声明的、存储着一个闭包的变量是std::function的一个实例，不管给定的签名如何，它都占有固定大小的内存，而这个大小对于其存储的闭包而言并不一定够用，如果是这样，那么std::function的构造函数就会分配堆上的内存来存储该闭包。 优点四：避免类型截断 优点五：避免类型不匹配 1 2 3 4 5 std::unordered_map\u0026lt;std::string, int\u0026gt; mp; for(auto\u0026amp; item: mp) { // auto=std::pair\u0026lt;const std::string,int\u0026gt; // 但是如果显式定义类型，很容易定义为std::pair\u0026lt;std::string, int\u0026gt;\u0026amp; } 06：当auto推导的类型不符合要求时，使用带显式类型的初始化习惯用法 隐式的代理类型可能导致auto类型推导结果不符合预期，因此应该显式声明类型 代理类：模拟和拓展某些其他类型的行为，比如智能指针，比如std::vector\u0026lt;bool\u0026gt;::reference std::vector\u0026lt;bool\u0026gt;进行了特化，与一般std::vector不同： 一般对于vector\u0026lt;T\u0026gt;的operator []操作，返回类型为T\u0026amp;；但是对于vector\u0026lt;bool\u0026gt;的operator []操作，返回类型为vector\u0026lt;bool\u0026gt;::reference（因此可能发生到bool的隐式类型转换），这是因为标准库无法返回对bit的引用 vector\u0026lt;bool\u0026gt;::reference的实现中，可能有一个指向word的指针和一个对应的offset，很可能出现难以预料的错误 1 2 3 vector\u0026lt;bool\u0026gt; func(); auto flg = func()[0]; // func()返回一个临时的右值对象，flg是vector\u0026lt;bool\u0026gt;::reference类型，然后临时的右值对象被析构 // 因为vector\u0026lt;bool\u0026gt;::reference类型中可能有一个指针，再使用flg可能出现未定义的行为 表达式模板中，计算结果可能被解析为一棵语法解析树，而非直接返回计算结果，因此实际得到的结果类型（语法解析树）可能并非期望的类型 # C++元编程之表达式模板优化数组计算 总之，对(隐形)代理类的auto类型推导往往得到的不是预期的类型，因此要么显式声明类型，要么使用static_cast强转然后进行auto类型推导 ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch02-auto/","summary":"05：优先选用auto，而非显式类型推断 优点一：避免变量未初始化 使用auto声明的变量未初始化，直接导致编译报错 优点二：简化变量声明（避免写","title":"[Effective Modern Cpp Notes] Ch02 Auto"},{"content":"01：理解模板类型推导 在模板类型推导中，引用类型参数将被视为非引用类型处理，也就是说其引用性被忽略。 - 在万能引用参数类型推导时，左值参数被特殊处理。 - 值传递形参的类型推导时，其 const 和 volatile 被忽略。 - 在模板类型推导时，数组或者函数类型被转换为指针类型，除非它们用来初始化引用。 背景：有时模板类型推导无法一下看出来T是什么类型 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(ParamType param); f(expr); // 比如实参可能是int, const int, const int\u0026amp; 类型T的推导不仅取决于expr的类型，也取决于ParamType的形式 情况一：ParamType是指针或引用，但不是万能引用 1 2 3 template \u0026lt;typename T\u0026gt; void f(T\u0026amp; param); template \u0026lt;typename T\u0026gt; void f(const T\u0026amp; param); template \u0026lt;typename T\u0026gt; void f(T* param); 情况二：ParamType是万能引用，因此可能发生引用折叠 1 template \u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp; param); 情况三：ParamType不是指针，也不是引用，因此视为值传递（实参的const/volatile性质被忽略，因为值进行了复制，形参副本不影响原来的实参） 1 template \u0026lt;typename T\u0026gt; void f(T param); 特殊情况一：传入的实参为数组类型 如果模板是情况一：推导出T为数组类型（包含类型和元素数量） 1 2 3 template \u0026lt;typename T\u0026gt; void f(T\u0026amp; param); const char name[] = \u0026#34;zhang\u0026#34;; f(name); // 推导出T=const char[6], f(const char(\u0026amp;param)[6]) 应用：比如可以在编译阶段计算数组元素个数： 1 2 template \u0026lt;typename T, std::size_t N\u0026gt; constexpr std::size_t arraySize(T (\u0026amp;)[N]) noexcept {return N;} 如果模板是情况三：将数组名视为指针，因此T是指针类型 特殊情况二：传入的实参为函数类型 如果模板是情况一：推导出T为函数引用类型 如果模板是情况三：推导出T为函数指针类型 参考： https://blog.csdn.net/Dong_HFUT/article/details/122727237 02：理解auto类型推导 一般情况下，auto类型推导和模板类型推导完全相同；但是auto类型推导会假定使用{}的列表初始化表达式是一个std::initializer_list，但是模板类型推导不会 在函数返回值或lambda式形参中使用auto，意思是使用模板类型推导而非使用auto类型推导 背景：将一个变量赋值给auto类型变量，auto是什么类型 同[[ch01-类型推导#01：理解模板类型推导|01：理解模板类型推导]]中的总体原则：将实参赋值给形参 除了一个例外：使用{}进行列表初始化 auto类型推导： 1 2 auto x = {1, 2, 3}; // auto=std::initializer_list\u0026lt;int\u0026gt;,首先推导为std::initializer_list\u0026lt;T\u0026gt;，然后再推断类型T=int auto y{2}; // auto=int 模板类型推导：不能直接将{}的列表初始化表达式推导为T=std::initializer_list\u0026lt;type\u0026gt;， 1 2 3 4 template \u0026lt;typename T\u0026gt; void f(T param); f({1, 2, 3}); // 报错：直接传入{}列表初始化的实参，模板类型推导失败 template \u0026lt;typename T\u0026gt; void g(std::initializer_list\u0026lt;T\u0026gt; initList); g({1, 2, 3}); // T=int 为什么两种行为不同的一个可能解释 1 2 3 template \u0026lt;typename T\u0026gt; void func(T\u0026amp; a, T\u0026amp; b); func(vector\u0026lt;int\u0026gt;{1,2,3}, {1,2,3}); // 左边推导出T=vector\u0026lt;int\u0026gt;, 右边如果推导出T=initializer_list\u0026lt;int\u0026gt;,则左右冲突 auto可以作为函数返回值类型、lambda式形参类型（C++14） 但是原理是模板类型推导，而非auto类型推导 参考 https://blog.csdn.net/Dong_HFUT/article/details/122740091 03：理解decltype 绝大多数情况下，decltype会得到变量或表达式的类型，而不进行修改 对于类型为T的左值表达式，除非该表达式只有一个名字，否则decltype总是返回T\u0026amp; C++14支持decltype(auto)：auto 表示类型需要推导，decltype 表示使用decltype规则进行推导 背景：给定一个名字或表达式，decltype返回其类型：原来是值/左值/右值，返回值/左值/右值 体会auto类型推导和decltype类型推导的区别 auto类型推导：将变量rhs赋值给lhs，推导出lhs的类型 decltype类型推导：返回变量rhs的类型 使用场景： 声明一个函数模板，其返回值类型取决于参数类型 1 2 template \u0026lt;typename Container, typename Index\u0026gt; auto getItem(Container\u0026amp; c, Index i) -\u0026gt; decltpye(c[i]) { return c[i]; } // 返回类型是引用T\u0026amp; 如果返回值为auto，使用auto类型推导，返回类型将不是引用 1 2 template \u0026lt;typename Container, typename Index\u0026gt; auto getItem(Container\u0026amp; c, Index i) { return c[i]; } // 返回类型是T 可以同时使用auto和deltype：auto 表示类型需要推导，decltype 表示使用decltype规则进行推导 1 2 template \u0026lt;typename Container, typename Index\u0026gt; decltype(auto) getItem(Container\u0026amp; c, Index i) { return c[i]; } // 返回类型是引用T\u0026amp; 优化与完善：为了传入右值的Container，使用万能引用，同时使用完美转发 1 2 template \u0026lt;typename Container, typename Index\u0026gt; decltype(auto) getItem(Container\u0026amp;\u0026amp; c, Index i) { return std::forward\u0026lt;Container\u0026gt;(c)[i]; } // C++14，或者C++11使用尾置返回类型 一般而言decltype返回的类型都比较直观，除了一种情况： 1 2 3 int x = 0; // decltype(x)=int // decltype((x))=int\u0026amp; 参考 https://blog.csdn.net/Dong_HFUT/article/details/122745518 https://zyfforlinux.blog.csdn.net/article/details/52658452 04：掌握查看类型推导结果的方法 在代码编辑阶段查看类型推导结果：IDE 在代码编译阶段查看类型推导结果：查看编译报错 在代码运行阶段查看类型推导结果： typeid：不同编译期实现不同，无法保证完全可靠，而且类型的引用、const、volatile等性质被忽略 Boost库的模板函数boost::typeindex::type_id_with_cvr 如果类型不包含引用、const、volatile等性质，则type_id_with_cvr与typeid返回相同 1 2 3 4 5 6 7 8 #include \u0026lt;boost/type_index.hpp\u0026gt; template \u0026lt;typename T\u0026gt; void f(const T\u0026amp; param){ using std::cout; using boost::typeindex::type_id_with_cvr; // c:const, v:volatile, r:reference cout\u0026lt;\u0026lt;type_id_with_cvr\u0026lt;T\u0026gt;().pretty_name()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; cout\u0026lt;\u0026lt;type_id_with_cvr\u0026lt;decltype(param)\u0026gt;().pretty_name()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } ","permalink":"https://qinganzhang.github.io/posts/effective-modern-cpp/ch01-%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/","summary":"01：理解模板类型推导 在模板类型推导中，引用类型参数将被视为非引用类型处理，也就是说其引用性被忽略。 - 在万能引用参数类型推导时，左值参数被特","title":"[Effective Modern Cpp Notes] Ch01 类型推导"},{"content":"49：了解new-handler的行为 new申请内存失败会抛出bad alloc的异常，此前会调用一个错误处理函数，此函数由std::set_new_handler()指定 set::set_new_handler() 接受一个错误处理函数，返回旧的错误处理函数 throw表示可能抛出的异常类型，参数为空表示不抛出任何异常 1 2 typedef void (*new_handler)(); // 无形参，返回值为void的函数指针 new_handler set_new_handler(new_handler f) throw(); 当new申请不到足够的内存时，会不断调用错误处理函数f，因此错误处理函数应该进行下面的处理之一： 提供更多可用的内存 向set_new_handler中传入一个新的错误处理函数 set_new_handler函数中传入一个空指针，因此内存分配失败时不进行处理，直接抛出异常 抛出bad_alloc的异常 不返回：调用std::abort或std::exit abort会设置程序非正常退出 exit会设置程序正常退出，当存在未处理异常时，会调用terminate，内部回调set::set_terminate设置的回调函数，默认会调用abort 类型相关错误处理 为不同的类分配对象时，使用不同的错误处理函数 重载set_new_handler和operator new，重载为static成员 可以写成模板 此处的模板参数T并没有真正被当成类型使用，而仅仅是用来区分不同的派生类，使得模板机制为每个派生类具现化出一份对应的currentHandler 这个做法用到了所谓的 CRTP（curious recurring template pattern，奇异递归模板模式），也常被用于静态多态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 template \u0026lt;typename T\u0026gt; class NewHandlerSupport { public: static std::new_handler set_new_handler(std::new_handler p) noexcept; static void* operator new(std::size_t size); ~NewHandlerSupport() {std::set_new_handler(currentHandler);} private: NewHandlerSupport(const NewHandlerSupport\u0026amp;); // 阻止拷贝构造 NewHandlerSupport\u0026amp; operator=(const NewHandlerSupport\u0026amp;); // 阻止拷贝复制 static std::new_handler currentHandler; }; template \u0026lt;typename T\u0026gt; std::new_handler NewHandlerSupport\u0026lt;T\u0026gt;::currentHandler = nullptr; template \u0026lt;typename T\u0026gt; std::new_handler NewHandlerSupport\u0026lt;T\u0026gt;::set_new_handler(std::new_handler p) noexcept { std::new_handler oldHandler = currentHandler; currentHandler = p; return oldHandler; } template \u0026lt;typename T\u0026gt; void* NewHandlerSupport\u0026lt;T\u0026gt;::operator new(std::size_t size) { NewHandlerSupport h(std::set_new_handler(currentHandler)); // 返回的函数指针初始化了一个对象h，在退出函数时，执行h的析构过程，即将原来的handle恢复 return ::operator new(size); } // 使用 class Widget: public NewHandlerSupport\u0026lt;Widget\u0026gt;{ ... }; new分配失败后，可能不会抛出异常，而是返回null，这种称为nothrow new 例子：new (std::nothrow) int[10]; nothrow new只能保证内存分配错误时不抛出异常，无法保证对象的构造函数不抛出异常 50： 了解new和delete的合理替换时机 为什么需要自定义operator new 检测使用错误：检测多次delete，检测越界 提高效率：手动维护更适合应用场景的存储策略 比如针对特定类型，增加分配和归还的速度 比如将相关对象集成到簇中（即尽量分配到一个内存页上） 收集使用的统计信息 其他原因：比如安全性（将申请到的内存初始化为0），字节对齐等 51： 编写new和delete时需固守常规 operator new需要无限循环地获取资源，如果没能获取则调用\u0026quot;new handler\u0026quot;，不存在\u0026quot;new handler\u0026quot;时应该抛出异常；\noperator new应该处理size == 0的情况；\noperator delete应该兼容空指针；\noperator new/delete作为成员函数应该处理size \u0026gt; sizeof(Base)的情况（因为继承的存在）。\n外部（非成员函数的）operator new：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void* operator new(std::size_t size) throw(std::bad_alloc){ if(size == 0) size = 1; // size=0时，返回合法的指针就说明成功分配了内存 while(true){ void *p = malloc(size); if(p) return p; // 申请失败，获得new handler，多线程需要加锁 new_handler h = set_new_handler(0); set_new_handler(h); // auto h = get_new_handler(); // C++11方式 if(h) (*h)(); // new-handler应该实现item49中描述的五种行为之一，否则，此处陷入死循环 else throw bad_alloc(); } } 成员operator new\n如果operator new是针对基类的，也就是说operator new是针对大小为sizeof(Base)的内存进行优化的 一般来说派生类不应该使用基类的operator new，因为派生类对象大小与基类对象大小一般不同 1 2 3 4 5 6 7 8 9 10 11 12 class Base{ public: static void* operator new(std::size_t size); }; void* Base::operator new(std::size_t size) { if(size != sizeof(Base)) // sizeof(Base)永远不会为0（至少为1），因为空对象至少会插入一个char return ::operator new(size); // 使用全局的operator new ... } class Derived: public Base { ... }; operator new[]与operator new有相同的参数和返回值，只需要分配一块原始内存 delete\ndelete 惯例：delete一个空指针是安全的 外部operator delete\n1 2 3 4 void operator delete(void* rawMemory) noexcept { if (rawMemory == 0) return; // 释放 rawMemory 所指的内存 } 成员operator delete 如果基类的析构函数不是虚函数，则size大小为静态类型的大小； 比如Base* p = new Derived; delete p;中，很可能派生类大小大于基类大小，因此存在内存泄露 否则size为动态类型的大小 1 2 3 4 5 6 7 8 void Base::operator delete(void* rawMemory, std::size_t size) noexcept { if (rawMemory == 0) return; if (size != sizeof(Base)) { ::operator delete(rawMemory); // 转交给标准的 operator delete 进行处理 return; } // 释放 rawMemory 所指的内存 } 52： 写了placement new也要写`palcement delete placement new：广义上指拥有额外参数的operator new 背景： 在使用new创建对象时，往往进行了两个函数的调用：一个是operator new，进行内存分配；一个是对象的构造函数 如果构造失败，此时对象没有被创建，对象无法被析构，且此时还没有拿到分配内存的地址 因此需要运行时系统进行delete，运行时系统需要知道使用的是哪一种operator new，因此调用对应的operator delete 如果没有对应的operator delete函数，则运行时系统什么都不做，导致内存泄露 当定义了placement new时，同时也要定义对应的placement delete 用户直接调用delete时，运行时系统不会将其解释为placement delete，因此还需要定义一个正常的delete 1 2 3 4 5 6 class Widget{ public: static void* operator new(std::size_t size, std::ostream\u0026amp; log) throw(std::bad_alloc); static void operator delete(void *mem, std::ostream\u0026amp; log); static void operator delete(void *mem) throw(); }; 名称隐藏：类中的名称会隐藏类外的名称，子类的名称会隐藏父类的名称 三种全局new 1 2 3 void* operator(std::size_t) throw(std::bad_alloc); // normal new void* operator(std::size_t, void*) noexcept; // placement new void* operator(std::size_t, const std::nothrow_t\u0026amp;) noexcept; // nothrow new 最佳实践： 将全局版本new在一个基类中进行重载，内部调用全局new进行实现 然后在自定义类Widget中，public继承，并使用using声明使得三种new和三种delete对Widget可见，因此同时Widget可以定义自己版本的placement new 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class StandardNewDeleteForms { public: // normal new/delete static void* operator new(std::size_t size) throw(std::bad_alloc) { return ::operator new(size); } static void operator delete(void *pMemory) throw() { ::operator delete(pMemory); } // placement new/delete static void* operator new(std::size_t size, void *ptr) throw() { return ::operator new(size, ptr); } static void operator delete(void *pMemory, void *ptr) throw() { return ::operator delete(pMemory, ptr); } // nothrow new/delete static void* operator new(std::size_t size, const std::nothrow_t\u0026amp; nt) throw() { return ::operator new(size, nt); } static void operator delete(void *pMemory, const std::nothrow_t\u0026amp;) throw() { ::operator delete(pMemory); } }; class Widget: public StandardNewDeleteForms { public: using StandardNewDeleteForms::operator new; using StandardNewDeleteForms::operator delete; static void* operator new(std::size_t size, std::ostream\u0026amp; log) throw(std::bad_alloc); // 自定义 placement new static void operator delete(void *pMemory, std::ostream\u0026amp; logStream) throw(); // 对应的 placement delete }; ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch08-%E5%AE%9A%E5%88%B6new%E5%92%8Cdelete/","summary":"49：了解new-handler的行为 new申请内存失败会抛出bad alloc的异常，此前会调用一个错误处理函数，此函数由std::set_","title":"[Effective Cpp Notes] Ch08 定制new和delete"},{"content":"41： 了解隐式接口与编译期多态 面向对象中的类设计时需要考虑显式接口和运行时多态，而模板编程中需要考虑隐式接口和编译器多态\n如果函数的形参是普通类： 普通类的显式接口由函数签名（函数名、形参类型、返回值类型）表征，运行时多态由虚函数实现 在函数进行编译时，就可以知道该普通类有哪些接口 如果函数的形参是模板类型： 模板类型的隐式接口由表达式的合法性表征（即该模板类型应该支持函数中形参调用的方法），编译器多态由模板初始化和重载函数的解析实现 在函数进行编译时，无法知道模板类型有哪些接口，因此视为鸭子类型（即传入对象支持函数中调用的方法即可） 在编译函数时当然无法确定模板类型，但是当传入实参后，内部如果调用了实参未定义的函数，同样会在编译期报错而非运行期 参考： https://www.zhihu.com/question/423699453 42： 了解typename的双重意义 在模板声明中，使用class与typename完全相同 在模板内部，typename还可以用来显式指明【嵌套从属类型名称】 背景：比如编译器无法在模板内部判断T::mem是一个static成员（默认），还是一个类型 嵌套从属类型名称：T::mem是一个依赖于模板参数T的类型 例子：模板内部typename T::age myAge = 25; typename还可以用来显式指明【嵌套从属类型名称】，可以出现在模板内部、函数形参列表，但是不可以出现在【类派生列表】和【构造函数中成员初始化列表】中 当类型名称过于复杂时，可以使用类型别名 参考 https://harttle.land/2015/09/09/effective-cpp-42.html 43： 使用模板化基类中的成员函数 背景：如果基类是一个模板类，派生类进行继承 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Buff {}; class RedBuff: public Buff {}; class BlueBuff: public Buff {}; template \u0026lt;typename T\u0026gt; // 基类 class Container { /* 假设有成员函数func() */}; //template \u0026lt;\u0026gt; // 全特化基类 //class Container\u0026lt;Buff*\u0026gt; { /* 假设没有成员函数func() */ }; // template \u0026lt;typename T=Buff*\u0026gt; // 使用默认模板实参，同全特化基类 // class Container\u0026lt;T\u0026gt; { /* 假设没有成员函数func() */ } template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { func(); } // 这里编译报错 }; 对于模板化基类，可能有特化版本，且其中可能有不同的接口 对于派生类而言，也无法确定类型T，因此C++规定派生类不在模板化基类中查找继承而来的接口 解决方法：向编译器承诺所有的特化版本都遵循模板化基类的接口（或者说使用非特化版本的模板化基类中的接口） 使用this显式指出访问基类的成员函数 1 2 3 4 5 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { this-\u0026gt;func(); } // this指针可以访问所有成员函数 }; 使用using声明 1 2 3 4 5 6 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: using Container\u0026lt;T\u0026gt;::func; // 告诉编译器，func在模板化基类中 void test() { func(); } }; 使用作用域运算符::明确指出，不推荐使用，因为如果func是虚函数，使用这种方法不会产生多态 1 2 3 4 5 template \u0026lt;typename T\u0026gt; class PlayerContainer: public Container\u0026lt;T\u0026gt; { // 派生类继承模板化基类 public: void test() { Container\u0026lt;T\u0026gt;::func(); } // 明确指出 }; 44： 将与参数无关的代码抽离模板 背景：代码膨胀 模板提供的是编译期多态，不同的类型参数会生成不同的模板 比如一个模板类接受一个类型参数T与一个非类型参数N，大部分成员都使用类型参数T，只有极少部分成员使用非类型参数N 如果使用相同的类型type、但是不同的非类型参数n进行实例化，生成的代码中大部分都相同，只有极少部分不同 抽取公共代码： 模板中生成的冗余代码是隐式的，因为模板只有一份，生成不同实例后才可能产生冗余 比如可以将与参数无关的代码（成员函数，数据成员）放入基类中，然后private继承 参考 https://harttle.land/2015/09/12/effective-cpp-44.html 45： 运用成员函数模板接受所有兼容类型 背景：假如类型参数T存在继承关系，但是模板实例化后是完全不同的两个类 比如有一个继承体系，基类Base，派生类Derived 指向派生类的指针可以转换为指向基类的指针：Base* p = new Derived(); 但是指向派生类的智能指针无法转换为指向基类的智能指针： shared_ptr\u0026lt;Base*\u0026gt; sp = make_shared\u0026lt;Derived*\u0026gt;(new Derived()); 重载构造函数 接受同一模板的其他实例的构造函数称为通用构造函数 兼容类型检查：将MySmartPtr\u0026lt;U\u0026gt;转换为MySmartPtr\u0026lt;T\u0026gt;，前提是类型U可以转换为类型T 如果没有声明拷贝构造函数，编译器会自己生成一个，而非使用通用构造函数去进行成员模板实例化 1 2 3 4 5 6 7 8 9 10 11 12 13 template \u0026lt;typename T\u0026gt; class MySmartPtr{ public: MyShartPtr(T* p): ptr(p) {} template \u0026lt;typename U\u0026gt; MySmartPtr(const MySmartPtr\u0026lt;U\u0026gt;\u0026amp; other): ptr(other.get()) {}; // 带类型兼容检查的通用构造函数，可以实现隐式类型转换（因为不带explicit） T* get() const {return ptr;} private: T *ptr; }; MySmartPtr\u0026lt;Derived*\u0026gt; dp(new Derived()); // 隐式类型转换 MySmartPtr\u0026lt;Base*\u0026gt; bp = MySmartPtr\u0026lt;Derived*\u0026gt;(new Derived()); // T=Base*, U=Derived* 参考 https://harttle.land/2015/09/13/effective-cpp-45.html 46：需要类型转换时请将模板定义为非成员函数 背景： 1 2 3 4 5 6 7 8 template \u0026lt;typename T\u0026gt; class Rational {}; template \u0026lt;typename T\u0026gt; const Rational\u0026lt;T\u0026gt; operator*(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs) {} Rational\u0026lt;int\u0026gt; oneHalf(1,2); Rational\u0026lt;int\u0026gt; result = oneHalf * 2; // Error 模板函数的调用过程： 首先推导出类型T，将函数进行实例化：此时无法从2推导得出类型T 在调用时，有的参数可能需要隐式类型转换 解决方法：将模板函数定义为类的友元，因此类模板实例化后类型T已知 如果仅仅是声明，编译器不会对友元函数进行实例化，因此需要进行定义 定义在类内部的函数是inline的，可以在类外部定义一个辅助函数（也是模板函数，但是不需要隐式类型转换） 1 2 3 4 5 6 7 8 9 10 template \u0026lt;typename T\u0026gt; class Rational; template \u0026lt;typename T\u0026gt; const Rational\u0026lt;T\u0026gt; func(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs) {} template \u0026lt;typename T\u0026gt; class Rational{ public: friend Rational\u0026lt;T\u0026gt; operator*(const Rational\u0026lt;T\u0026gt;\u0026amp; lhs, const Rational\u0026lt;T\u0026gt;\u0026amp; rhs){ func(lhs, rhs); // 可以推导出类型T，而且不需要进行隐式类型转换 } } 47： 请使用traits classes表现类型信息 使用Traits的特点： 可以同时支持自定义类型和基础类型 在编译期就获取信息 C++中的Traits类可以在编译期提供类型信息，是通过Traits模板及其特化来实现的 C++标准库中提供了不同的Traits：iterator_traits,char_traits,numeric_limits等（以iterator_traits为例）\n背景：容器与算法通过迭代器联系在一起，算法中可能需要知道迭代器的类型、迭代器中元素的类型，由此有不同的处理方法 比如算法advance可以让一个迭代器移动n步（负数则反向移动） 迭代器有五种：其中随机访问迭代器可以直接使用+=操作 C++提供了五个类标识迭代器类型：input_iterator_tag，output_iterator_tag，forward_iterator_tag，bidirectional_iterator_tag，random_access_iterator_tag 传入的参数也可能是基本类型的指针 1 2 3 4 5 6 7 8 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ // 判断迭代器类型 if(iter is random access iterator) iter += d; else ... // 判断迭代器中元素类型 if(iter.value_type is MyVector) cout\u0026lt;\u0026lt;\u0026#34;MyVector\u0026#34;\u0026lt;\u0026lt;endl; } 分析： 如果IterT是类类型，因此可以在类中携带数据成员，表示迭代器类型和元素类型 但是IterT也可能是基本类型的指针类型，无法在其中携带信息 Traits技法：使用Traits可以通过一个模板类间接获取IterT的相关信息 1 2 template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits; Traits是C++中一种编程惯例，允许在编译期得到类型的信息 traits是一个用来携带信息的很小的类，需要实现两个部分： traits中的类型可能是用户自定义的类型， 自定义类型中需要实现相应的迭代器，对具体的类型信息起一个通用的别名 traits中包装相应的信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 template \u0026lt;typename T\u0026gt; class MyVector{ // 自定义类 public: class iterator{ // 自定义类中的迭代器 public: using value_type = T; using iterator_category = my_random_access_iterator_tag; }; }; // iterator_traits可以获取迭代器（或指针类型）的元素类型和迭代器类型（指针类型视为随机访问迭代器） template \u0026lt;typename IterT\u0026gt; struct iterator_traits{ // IterT是类类型 using iterator_category = typename IterT::iterator_category; using value_type = typename IterT::value_type; }; traits中的类型可能是基本数据类型，遵循相同的名称，包装一下相应的信息 1 2 3 4 5 template \u0026lt;typename IterT\u0026gt; struct iterator_traits\u0026lt;IterT*\u0026gt;{ // 特化版本：IterT是基本类型，IterT是基本类型的指针 using iterator_category = my_random_access_iterator_tag; // 指针可以使用+=操作，因此视为随机访问迭代器 using value_type = IterT; }; 使用 不好的写法：使用typeid在运行时判断类型 但是IterT类型在编译期就可以确定，对象iter的类型需要在运行时确定 更严重的问题：静态类型检查（编译期必须确保所有源码都有效，即使是不会执行的源码） ^826df6 比如即使迭代器不是my_random_access_iterator_tag类型，编译期也会进入if语句测试该迭代器是否支持+=运算，不支持的话编译报错 1 2 3 4 5 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ if( typeid(typename std::iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(my_random_access_iterator_tag) ) iter += d; } 推荐实现方法：根据不同的类型创建不同的重载方法（worker），然后在一个master函数中调用，依据traits类型进行重载调用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 template \u0026lt;typename IterT, typename DistT\u0026gt; void advance(IterT\u0026amp; iter, DistT d){ // 将IterT中迭代器类型和元素类型萃取出来 std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category).name()\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::value_type).name()\u0026lt;\u0026lt;std::endl; // 错误使用：如果iter是指针类型，则IterT为基本类型，无iterator_category属性 // std::cout\u0026lt;\u0026lt;typeid(IterT::iterator_category).name()\u0026lt;\u0026lt;std::endl; doAdvance(iter, d, typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category()); // 最后默认初始化一个iterator_category的对象，进行重载匹配，调用对应的函数 } // 随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_random_access_iterator_tag){ iter += d; } // 前向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_forward_iterator_tag){ assert(d \u0026gt;= 0 \u0026amp;\u0026amp; \u0026#34;d must be not less then 0\u0026#34;); while(d--) ++iter; } 测试代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;cassert\u0026gt; // using namespace std; struct my_random_access_iterator_tag { // my_random_access_iterator_tag() { std::cout\u0026lt;\u0026lt;\u0026#34;my_random_access_iterator_tag ctor\u0026#34;\u0026lt;\u0026lt;std::endl; } }; struct my_forward_iterator_tag{ // my_forward_iterator_tag() {std::cout\u0026lt;\u0026lt;\u0026#34;my_forward_iterator_tag\u0026#34;\u0026lt;\u0026lt;std::endl;} }; template \u0026lt;typename T\u0026gt; class MyVector{ // 自定义类 public: class iterator{ // 自定义类中的迭代器 public: using value_type = T; using iterator_category = my_random_access_iterator_tag; }; }; // iterator_traits可以获取迭代器（或指针类型）的元素类型和迭代器类型（指针类型视为随机访问迭代器） // 输入：使用类类型的迭代器或指针类型进行实例化 // 输出：萃取出元素类型和迭代器类型 template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits{ // IterT是类类型 using iterator_category = typename IterT::iterator_category; using value_type = typename IterT::value_type; }; template \u0026lt;typename IterT\u0026gt; struct my_iterator_traits\u0026lt;IterT*\u0026gt;{ // 特化版本：IterT是基本类型，IterT是基本类型的指针 using iterator_category = my_random_access_iterator_tag; // 指针可以使用+=操作，因此视为随机访问迭代器 using value_type = IterT; }; // std双向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, std::bidirectional_iterator_tag){ if(d \u0026gt; 0) while(d--) ++iter; else while(++d) --iter; } // std随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, std::random_access_iterator_tag){ iter += d; } // 自定义随机访问迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_random_access_iterator_tag){ iter += d; } // 自定义前向迭代器版本 template \u0026lt;typename IterT, typename DistT\u0026gt; void doAdvance(IterT\u0026amp; iter, DistT d, my_forward_iterator_tag){ assert(d \u0026gt;= 0 \u0026amp;\u0026amp; \u0026#34;d must be not less then 0\u0026#34;); while(d--) ++iter; } template \u0026lt;typename IterT, typename DistT\u0026gt; void myAdvance(IterT\u0026amp; iter, DistT d){ // 将IterT中迭代器类型和元素类型萃取出来 std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category).name()\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::value_type).name()\u0026lt;\u0026lt;std::endl; // 错误使用：如果iter是指针类型，则IterT为基本类型，无iterator_category属性 // std::cout\u0026lt;\u0026lt;typeid(IterT::iterator_category).name()\u0026lt;\u0026lt;std::endl; // std::cout\u0026lt;\u0026lt; (typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(std::bidirectional_iterator_tag)) \u0026lt;\u0026lt;std::endl; // 不好的写法： // 静态类型检查，即使iter不是随机访问迭代器，也会进入if语句块内进行检查 // if( typeid(typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category) == typeid(std::random_access_iterator_tag) ) // iter += d; doAdvance(iter, d, typename my_iterator_traits\u0026lt;IterT\u0026gt;::iterator_category()); // 最后默认初始化一个iterator_category的对象，进行重载匹配，调用对应的函数 } int main(){ int a[10]; for(int i = 0; i \u0026lt; 10; ++i) a[i] = i+1; int* p = \u0026amp;a[0]; myAdvance(p, 2); std::cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;std::endl; std::list\u0026lt;int\u0026gt; lst{1,2,3,4,5,6,7,8,9,10}; std::list\u0026lt;int\u0026gt;::iterator it = lst.begin(); myAdvance(it, 2); std::cout\u0026lt;\u0026lt;*it\u0026lt;\u0026lt;std::endl; return 0; } 48： 认识模板元编程 模板元编程（template metaprogramming，TMP）：编写模板，执行于编译期，生成具象化的代码 优点：可以将很多工作从运行期转移到编译期 一些错误可以提前发现 运行时更高效：可执行文件体积小，运行期短，内存需求少 避免了[[ch07-模板与泛型编程#^826df6|静态类型检查]]的问题 缺点：编译时间变长 模板元编程 图灵完备 循环由递归实现 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch07-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/","summary":"41： 了解隐式接口与编译期多态 面向对象中的类设计时需要考虑显式接口和运行时多态，而模板编程中需要考虑隐式接口和编译器多态 如果函数的形参是普通","title":"[Effective Cpp Notes] Ch07 模板与泛型编程"},{"content":"32：确定你的public继承构造出is-a关系 public继承的意思是，子类是一种特殊的父类（is-a关系） 子类必须涵盖父类每一个特点，必须无条件继承父类所有特性和接口 否则没有is-a关系，不应该使用public继承 因为很多时候凭生活经验判断，可能会错误判断为具有is-a关系，但是子类可能没有父类的某个特性 程序设计没有银弹 33：避免覆盖继承而来的名称 背景：父类中有多个重载的虚函数（同名），子类只重写了其中一个，会导致子类中父类的其他重载函数不可见 根本原因：如果子类重写了父类的重载函数的一部分，在进行名字查找中，可以在相应的静态类型（子类）中查找到名字，但是类型无法匹配 避免方法： 对于父类的重载方法，子类要么全部重写，要么一个都不重写 使用using声明 使用转交函数（forwarding function）？ 34：区分接口继承与实现继承 public继承可以分为函数接口继承和函数实现继承 基类中声明纯虚函数，派生类只继承其接口，且派生类需要提供实现 从代码层面提醒派生类主动实现其接口，即使纯虚函数在基类中也可以有实现（派生类也需要显式指明需要使用基类中的实现） 基类中声明虚函数，派生类继承其接口和缺省实现 基类中声明普通函数，派生类继承其接口和实现（好的编程习惯是不对子类方法进行重写） 35：考虑virtual函数以外的其他选择 通常面向多态的做法： 将接口设置为virtual的 通过Non-Virtual Interface(NVI)来实现template method模式 将接口Func的真正实现函数onFunc设置为private virtual的 基类中的private virtual方法，通过public继承到派生类，派生类可以进行重写 将接口Func设置为public non-virtual的，在Func中调用onFunc non-virtual的接口Func就称为virtual onFunc的wrapper 优点：在接口Func中调用onFunc前后，可以前置和后置的工作 缺点：在某些场景的继承体系中，virtual函数必须调用基类的版本，因此virtual函数必须是protected甚至public的，此时无法使用NVI strategy模式 基于Function Pointers的strategy模式 直接在构造函数中传入一个函数指针，用于实现多态 进一步的，可以基于C++11的std::function来实现strategy模式，在构造函数中传入一个可调用对象 古典的strategy模式：将函数指针替换为类指针，使用该类中的成员函数 优点：同一种类型可以使用不同的方法进行计算，而且可以在运行期变更使用的函数 缺点：函数指针只能访问public成员，否则只能弱化封装性，将外部函数声明为友元 36：绝不重写继承而来的non-virtual函数 从语法上看 虚函数执行的是动态绑定，非虚函数执行的是静态绑定 如果有多态调用的需求，设置为虚函数 从设计上看 public继承意味着一种is-a关系，子类是一种特殊的父类，不变性（父类的共性）凌驾于特异性（子类的个性）之上 重写public继承而来的non-virtual表示子类修改了父类的特性，违背了is-a关系，造成了设计上的矛盾 37：绝不重写继承而来的(虚函数的)缺省参数值 虚函数执行的是动态绑定，但是缺省参数值是静态绑定 因此可能执行的是动态类型版本的虚函数，但是缺省参数值是静态类型版本虚函数的，没有使用动态类型版本的缺省参数值，极易引起误会 缺省参数值采用静态绑定是为了提高运行时效率，这样可以在编译期将参数确定，而非得到运行时 解决方法： 如果使用虚函数，则采用相同的缺省参数值 使用Non-Virtual Interface(NVI)代替虚函数 将接口Func设置为public non-virtual的（因此不期望被重写），并带有缺省参数，因此不管怎么继承，缺省参数值都是相同的 将接口Func的实现逻辑onFunc设置为private virtual的，Func中将缺省参数传递给onFunc，调用动态版本的虚函数 38：通过复合构造出has-a关系或“根据某物实现出” 复合：一个类作为另一个类的数据成员 当复合发生在应用域内的对象之间时，表现出has-a的关系 比如Person类中有一个Address类 当复合发生在实现域内的对象之间时，表现出“根据某物实现出”的关系 比如使用List类模拟实现出一个Set类 39： 明智而审慎地使用private继承 private继承的特点： 如果派生类private继承自基类，则从派生类无法转换到基类 但是如果派生类public继承自基类，则派生类可以slice（切掉）转换为基类 private继承的意义：“根据某物实现出” 仅仅是为了让派生类使用基类中的某些方法，派生类与基类没有直接意义上的联系 private继承的使用：当需要进行“根据某物实现出”的时候 能用复合，就不要用private：绝大多数private继承的场合都可以使用“public继承+复合”进行代替 使用private继承： 比如想在Widget的派生类中，不定义OnTick方法，即使使用private继承，在Widget的派生类中仍然可以重新定义OnTick方法（类似NVI中方法） 同时Widget编译时必须依赖Timer 1 2 3 4 5 6 7 8 9 10 // 使用private继承 class Timer{ public: virtual void OnTick() const; }; class Widget: private Timer{ private: virtual void OnTick() const; // override } // Widget的派生类中仍有OnTick方法 使用复合： 在Widget的派生类中，可以没有OnTick方法（同C++11对成员函数使用final） 可以将WidgetTimer定义移出Widget，从而Widget编译时不需要Timer 1 2 3 4 5 6 7 8 9 10 11 12 class Timer{ public: virtual void OnTick() const; }; class Widget{ private: class WidgetTimer: public Timer{ public: virtual void OnTick() const; }; WidgetTimer timer; }; 使用private继承的情况：空白基类最优化（Empty Base Optimization，EBO） 40： 明智而审慎地使用多重继承 多重继承中可能遇到歧义调用，需要指明调用哪个基类中的接口 即使同名接口一个在基类中是public的，一个是private的（不会被调用），也会发生歧义 因为C++首先会找到最佳匹配函数，之后才会验证其可用性，如果两个同名的函数匹配程度相同，则发生二义性 遇到菱形继承时，使用虚继承，且尽量少的在虚基类中携带数据 多重继承的使用场景：public继承自某个抽象基类，private继承自某个协助实现的基类 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch06-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/","summary":"32：确定你的public继承构造出is-a关系 public继承的意思是，子类是一种特殊的父类（is-a关系） 子类必须涵盖父类每一个特点，必","title":"[Effective Cpp Notes] Ch06 继承与面向对象设计"},{"content":"26：尽可能延后变量定义式的出现时间 原因一：程序前面部分可能有if判断、异常处理等，可能不会运行到后面部分 原因二：直接构造的效率高于默认构造+赋值 原因三：变量可能在循环中使用，变量定义在循环内部而非循环前面，可以避免将变量的作用域扩大；除非对循环部分的性能有要求。 27：尽量少做转型动作 三种风格的转型： C语言风格：(T)expression 函数风格：T(expression) C++风格： const_cast\u0026lt;T\u0026gt;(expression)：去除const属性 dynamic_cast\u0026lt;T\u0026gt;(exprssion)：将指向为基类的指针转型为指向派生类的指针，可能耗费重大运行成本 尽量少使用 reinterpret_cast\u0026lt;T\u0026gt;(expression) static_cast\u0026lt;T\u0026gt;(expression)：最常用 28：避免返回handles指向对象内部成分 handles：引用、指针、迭代器 避免返回指向内部对象的handles，返回一个成员变量的副本 增加可封装性 帮助const成员函数的行为像一个const 将发生”dangling handles“的可能性降到最低（当临时对象析构后，也就无法通过handle获取对象内部的成员） 29：为“异常安全”而努力是值得的 异常安全的含义：当异常被抛出时 不泄露资源：使用RAII 不发生数据败坏 异常安全的函数提供三种不同级别的保证： 基本承诺：不发生数据败坏，但是不保证程序状态 强烈保证：程序状态不变（即程序回复到”调用函数之前“的状态） 通过RAII和调换代码顺序实现 或者通过copy and swap实现：创建副本资源并进行操作，所有操作完成后，使用一个不会抛出异常的swap将副本与当前资源进行交换 不抛掷承诺：总能完成功能，作用域内置类型上的所有操作都提供nothrow承诺 强烈保证有时无法实现 异常安全保证具有木桶效应 30：透彻了解内联的里里外外 inline最初只是针对编译器的优化建议，而非强制；是否内联由优化等级所控制，与是否内联无关\n声明： 隐式声明：将函数定义与类内部（但不是一种好的编程风格） 显示声明：inline 内联函数通常被置于头文件中，因为内联大部分情况下时编译期行为 inline必须放在函数定义前 从实现上看，inline放在函数声明前不起作用 从编程风格看，应该严格区分声明与定义，而且用户不需要、也没有必要知道该函数是否内联 inline只是对编译器的一个申请，不是强制命令 31：将文件间的编译依存关系降到最低 pimpl idiom（pimpl：pointer to implementation）设计思想： 原来main class包含类的具体实现逻辑 现在将main class中具体实现逻辑，放到一个实现类Impl中，在private中添加一个指向Impl的指针 因此main class只是提供接口，实现类Impl负责实现接口，”类的接口与实现分离“ 背景：即使只是改动类的实现，而不改变类的接口，这样所有包含该类的源码都要重新编译 根本原因在于，编译器在编译期必须知道对象的大小，如果不知道类的定义，就无法为对象分配内存 方法一：提供句柄类，用”声明的依存性“替换”定义的依存性“ 原来：假设1000个文件依赖于Person.h，这1000个文件都要重新编译链接 1 2 3 4 5 6 7 8 // Person.h class Person{ public: std::string name() const; private: std::string mName; } // 假设在Person.cpp中，略微修改了std::string Person::name()的实现，1000个文件需要全部重新编译 现在：只需要修改PersonImpl的具体实现，重新编译这一个文件即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Person.h class PersonImpl; // PersonImpl声明 class Person{ public: std::string name() const; private: PersonImpl *pImpl; } // Person.cpp #include \u0026#34;Person.h\u0026#34; #include \u0026#34;PersonImpl.h\u0026#34; std::string Person::name(){ return pImpl-\u0026gt;name(); // 调用实现类中同名函数 } // PersonImpl.h class PersonImpl{ // PersonImpl与Person有相同的public函数，且Person的private数据成员移动到了PersonImpl的private部分 public: std::string name() const; private: std::string mName; } // PersonImpl.cpp #include \u0026#34;PersonImpl.h\u0026#34; std::string PersonImpl::name() {return mName;} 方法二：将句柄类定义为抽象类 基类中定义一个工厂方法，返回动态类型为派生类，静态类型为基类的指针 因此修改派生类中的方法的实现逻辑，不会影响到基类，”类的接口与实现分离“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // Person.h class Person{ public: Person(); virtual std::string name() const; static std::shared\u0026lt;Person\u0026gt; create(const std::string\u0026amp; name); virtual ~Person(); }; // Person.cpp #include \u0026#34;Person.h\u0026#34; #include \u0026#34;RealPerson.h\u0026#34; std::shared\u0026lt;Person\u0026gt; Person::create(const std::string\u0026amp; name){ return std::shared\u0026lt;Person\u0026gt;(new RealPerson(name)) } // RealPerson.h class RealPerson: public Person{ public: RealPerson(std::string\u0026amp; name): mName(name) {}; virtual std::string name() const; virtual ~RealPerson(); private: std::string mName; } 参考 https://www.zhihu.com/question/52832178/answer/192499529 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch05-%E5%AE%9E%E7%8E%B0/","summary":"26：尽可能延后变量定义式的出现时间 原因一：程序前面部分可能有if判断、异常处理等，可能不会运行到后面部分 原因二：直接构造的效率高于默认构造","title":"[Effective Cpp Notes] Ch05 实现"},{"content":"18：让接口容易被正确使用，不易被误用 函数接口传参，使用者可能理解错误或不小心传错 将函数参数封装为新的类型，比如封装新的年月日类，而非直接传入数字 限制类型内可以进行的操作 比如添加const限制，比如item3 尽量使自定义类型和内置类型的行为保持一致 消除使用者的资源管理责任 比如直接返回一个智能指针，而非返回一个raw指针 19：设计class犹如设计type 设计类时，考虑的问题：\n如何创建以销毁：如何实现构造函数和析构函数 初始化与赋值的区别：如何实现构造函数和赋值操作符 类对象传值：如何实现拷贝构造函数 成员类型的合法值：在构造函数和赋值操作中进行检查 继承关系的约束：基类的相关虚函数、成员函数是否需要被声明为virtual 是否允许由别的类转换而来：如何写转换构造函数 哪些操作符和函数是合理的 哪些操作符和函数应该拒绝 成员给哪些用户使用：成员的访问控制权限 新类型的未声明接口是什么 是否有必要将类一般化为类模板 这个新类型是否真的需要 20：传参时，尽量传常量引用而非传值 优点： 减少一次对象的复制 避免对象切割（比如形参是基类，实参是派生类），同时实现多态 使用传值的情况：内置类型，STL迭代器，函数对象 21：函数返回值尽量不要为引用 禁止在函数中返回一个指向局部变量的指针或引用 不要在函数中返回一个动态分配的对象 不要在可能多次调用的函数中返回一个局部静态变量 错误返回引用的例子： 返回栈空间中局部变量的引用：函数返回后，栈上相应对象被销毁，因此未定义 返回堆空间中局部变量的引用：虽然函数返回后不会释放对象，但是函数返回赋值的变量占有了堆空间的资源，而且极易容易忘记释放（因为一般也基本不会考虑对返回值进行delete），造成内存泄露 返回静态变量的引用：当多次调用该函数返回静态变量的引用时，静态变量只有一个，例子 C++11中可以使用移动语义，减少拷贝带来的消耗 22：将成员变量声明为private 将成员变量声明为public的缺点： 缺乏语法一致性：访问public成员变量，可以直接访问或者调用成员函数 对成员变量处理缺少准确控制：将成员变量设置为private的，可以提供setter/getter函数来控制其读写权限 不利于封装：在成员变量发生变化时，可以在相关函数中通知其他变量，从而进行相应修改 23：宁以non-member、non-friend替换member函数 功能颗粒度较高的函数设置为类外的函数，而非封装为public成员函数\n背景：public成员函数可分为两类： 功能颗粒度较低的函数：public/protected成员函数，内部直接访问private成员 功能颗粒度较高的函数：public/protected成员函数，内部由若干个public成员函数集成而来 尽量将功能颗粒度较高的函数封装为类外的函数： 优化类的封装性：如果封装为public函数，本来希望该函数只是public函数的集成，但是这样没法在代码层面体现出来 允许我们从更多维度组织代码结构，提供更大的包裹弹性：比如将不同public成员函数封装为不同功能的外部函数 优化编译依赖关系：比如不同的public成员函数可以封装为不同功能的外部函数，这些外部函数分别放在不同文件中，但是属于同一个命名空间中；这样使用时，需要哪个功能，就只需要包含该文件即可 24：若所有参数皆需要类型转换，请为此采用non-member函数 如果希望运算符的任意操作数可以发生隐式类型转换，则应该将运算符重载为非成员函数（比如友元）\n背景：运算符可以重载，重载为成员函数呢，还是重载为非成员函数呢？ 规定：如果运算符是成员函数，则它的第一个运算对象不会发生隐式类型转换 因为编译器根据第一个运算对象的类型，确定调用的运算符是属于哪一类的 比如：z = x * y等价于z = x.operator*(y)，x不会发生隐式类型转换 25：考虑写出一个不抛出异常的swap函数 如果Widge是一个类，可以在std命名空间中实现std::swap\u0026lt;T\u0026gt;的Widge全特化版本，同时在Widge中实现类内的swap函数以修改private成员的值 1 2 3 4 5 6 7 8 9 10 11 class Widget{ public: void swap(Widget\u0026amp; other){ // member swap using std::swap; // default swap // 调用std::swap进行private成员的处理 } } namespace std{ template\u0026lt;\u0026gt; // std::swap特例化版本 void swap\u0026lt;Widge\u0026gt; (Widget\u0026amp; a, Widget\u0026amp; b) { a.swap(b);} } 如果Widge是一个类模板 不能偏特例化一个函数模板 1 2 3 4 namespace std{ template\u0026lt;typename T\u0026gt; // non-member swap void swap\u0026lt;Widget\u0026lt;T\u0026gt;\u0026gt; (Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} // 编译报错 } 但是可以偏特例化一个类模板，添加一个重载版本 但是不要在std命名空间中添加新东西 1 2 3 4 namespace std{ template\u0026lt;typename T\u0026gt; void swap(Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} } 解决方法：置于一个新的命名空间中 1 2 3 4 5 6 7 namespace WidgetStuff{ template\u0026lt;typename T\u0026gt; class Widget{ ... }; template\u0026lt;typename T\u0026gt; void swap(Widget\u0026lt;T\u0026gt;\u0026amp; a, Widget\u0026lt;T\u0026gt;\u0026amp; b) {a.swap(b);} } 因此，如果想使得Widget专属版swap在尽可能多的语境下被调用，需要 在Widget中提供一个public swap函数（不可抛出异常），内部调用std::swap 同时可能需要同时实现两个版本： Widget所在命名空间WidgetStuff中，实现一个nom-member swap，内部调用Widget::swap 如果Widget是一个类而非类模板，在std中特化std::swap，内部调用Widget::swap C++11之后，std::swap改用std::move实现，所以几乎不存在性能缺陷 ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch04-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/","summary":"18：让接口容易被正确使用，不易被误用 函数接口传参，使用者可能理解错误或不小心传错 将函数参数封装为新的类型，比如封装新的年月日类，而非直接传","title":"[Effective Cpp Notes] Ch04 设计与声明"},{"content":"13：以对象管理资源 资源获取即初始化（RAII）：使用析构函数确保资源被释放 复制时使用移动语义，移交资源的所有权 背景：使用动态内存分配时，很容易忘记delete，尤其是程序在中间退出（比如if判断后return） RAII（Resource Acquisition Is Initialization）资源获取即初始化： 资源的有效期与持有资源的对象的生命周期严格绑定（即获取资源的时候要通过构造函数初始化） 对象独占资源 即让编译器在每个退出的分支上，对象都进行析构，从而释放资源 使用模板更加方便 移交所有权 背景：如果两个指针同时指向一个资源，会析构两遍；因此RAII类独占资源（类似unique_ptr） 在RAII类中，将拷贝相关的函数设置为=delete，RAII无法进行拷贝 因此只能通过移动构造函数使用std::move进行移交所有权 如何把RAII类作为函数的参数 值传递：各位caller，我不要ownership了，请拿走 非const引用传递：拿不拿走都行，提前商量好（不推荐） const引用传递：可以拿走用一下，但是ownership还是我的 右值引用：同第二条，无法确定caller是否拿走了ownership C++98与C++11 C++98中std::auto_ptr类似于C++11中std::unique_ptr，但是std::unique_ptr不允许所有权被转移 C++98中std::tr1::shared_ptr类似于C++11中std::shared_ptr，weak_ptr只是拥有资源的使用权而非所有权，因此不占用引用计数，可以解决环状引用的问题 梳理：RAII作为一种管理资源的方式（或思想），早期使用auto_ptr作为解决方案，C++11之后使用unique_ptr和move语义作为解决方案 参考： 现代C++学习—— 什么是RAII 14：在资源管理类中小心copying行为 复制RAII对象必须一并处理资源的copy行为\ncopy行为的不同情况： 大部分情况下，对RAII对象的复制操作本身就不合法 对底层资源使用引用计数法（shared_ptr） 复制底层资源（行为像值，进行深拷贝） 转移资源所有权（unique_ptr） 15：在资源管理类中提供对原始资源的访问 将RAII对象转换为对资源的直接访问 通过显示转换：提供一个get()函数返回智能指针内部的原始指针 通过隐式转换 像使用原始指针一样使用智能指针，比如智能指针一样可以使用-\u0026gt;访问成员 直接访问原始指针：在RAII类内实现返回原始指针的类型转换运算符 16：成对使用new和delete时要采取相同形式 new一个对象，使用delete释放；new一个数组，使用delete []进行释放 delete []表示知道释放的是数组，读取数组元素数量，从而多次调用析构函数 尽量避免对数组使用typedef，此时在delete时很容易出现混淆：用delete还是delete[]，可以的话可以使用std::vector等容器 17：以独立语句将new的对象置入智能指针 背景：编译器可能对单一语句中的执行顺序进行重新调整 1 2 3 4 5 6 7 8 9 10 int priority() {} void func(std::shared_ptr\u0026lt;MyResource\u0026gt; sp, int priority) {} func(std::shared_ptr\u0026lt;MyResource\u0026gt;(new MyResource), priority()); /* 该语句的执行顺序可能是： MyResource* tmp_ptr = new MyResource; int priority = priority(); std::shared_ptr\u0026lt;MyResource\u0026gt; sp = std::shared_ptr\u0026lt;MyResource\u0026gt;(tmp_ptr); */ 如果int priority = priority();执行失败，则tmp_ptr指向的临时资源无法被释放，发生内存泄漏 根本原因是：资源被创建和资源被转换成资源管理对象有时间差，中间可能有干扰 解决方法：以独立语句将new的对象置于智能指针中，因为编译器无法对跨语句的操作进行调整 1 2 std::shared_ptr\u0026lt;MyResource\u0026gt; sp(new MyResource); func(sp, priority()); ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch03-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/","summary":"13：以对象管理资源 资源获取即初始化（RAII）：使用析构函数确保资源被释放 复制时使用移动语义，移交资源的所有权 背景：使用动态内存分配时，很","title":"[Effective Cpp Notes] Ch03 资源管理"},{"content":"05：了解C++默默编写并调用了哪些函数 如果没有自定义相应拷贝控制成员，而且需要使用该拷贝控制成员，则编译器进行合成 有时编译器不会进行合成，因为一些操作非法 1 2 3 4 class MyClass {}; MyClass m1; // 生成默认构造函数和析构函数 MyClass m2(m1); // 生成复制构造函数 m2 = m1; // 生成赋值构造运算符 默认构造函数和析构函数 作用：调用{基类和non-static成员变量}的构造函数和析构函数 当自定义构造函数后，编译器就不会自动生成构造函数 生成的析构函数是non-virtual的，除非基类的析构函数是virtual的 复制构造函数 赋值构造运算符 自动生成赋值构造运算符的条件是，相关操作必须合法 比如成员变量是const或引用，则不能进行赋值 比如基类中赋值构造运算符是private的，则派生类中无法调用父类相应的赋值构造运算符对父类成员进行赋值 06：若不想使用编译器自动生成的函数，就该明确拒绝 在声明中将拷贝控制成员标记为=delete，将不会自动生成该拷贝控制成员\n背景：有时不希望类具有拷贝等行为（语义要求） 三种方法：将不需要自动生成的拷贝控制成员 在private中进行定义 虽然类外部无法访问，但不是绝对安全，可以在成员函数和友元中使用 写为空函数体，使其在链接过程中报错 在基类中声明为private 这样即使在成员函数和友元中使用相应拷贝控制成员，也会因为无法拷贝控制相应基类成员，从而将报错从链接期提前到编译期 在声明中标记为=delete 07：为多态基类声明virtual析构函数 声明多态性质的基类的析构函数为virtual的\n背景：当delete一个指向派生类的基类指针时，只会调用non-virtual的基类析构函数，派生类中成员无法释放 只有当类中至少包含一个除析构函数外的virtual函数时（多态性质），才将析构函数声明为virtual的 为了保持可移植性 如果该类不包含virtual函数，则通常该类不会作为基类 将基类析构函数声明为pure virtual函数，从而将基类构造为抽象基类（避免了考虑将其他哪个函数声明为pure virtual函数） 所有的STL容器都不包含virtual析构函数，因此不要将STL容器作为基类 因为STL容器设计不是用来作为基类，不带有多态语义要求，只有多态性质的基类才需要声明一个virtual析构函数 不是所有基类都带有多态性质 08：别让异常逃离析构函数 析构函数不要抛出异常，但是析构函数中可以使用try catch进行异常处理 C++11中，默认将析构函数声明为noexcept，防止在析构函数中抛出异常 try语句块中抛出异常时，会将作用域中对象依次调用析构函数，然后进入catch语句块中 如果此时调用的析构函数中继续报错，则core dumped 可以在析构函数中使用try catch捕获异常，或者重新设计接口，使得防止抛出异常的函数在析构函数中被调用 09：绝不在构造和析构过程中调用virtual函数 不要再构造/析构函数（及其调用的函数中）中调用virtual函数，因为这样虚函数不会呈现多态\n当派生类中的基类部分被构造时，其调用的虚函数只会调用基类中的版本，不会调用派生类中的版本，即不会呈现多态 从安全性角度看，因为此时派生类部分还未构造，使用派生类的虚函数版本可能产生未定义的行为，所以C++规定使用基类的版本 从原理角度看，在构造基类部分时，对象的类型实际上是基类类型 当派生类中的基类部分被析构时，同样不会呈现多态 从安全性角度看，此时派生类部分已经析构，调用派生类的虚函数版本产生未定义的行为 从原理角度看，此时对象为基类类型 构造函数/析构函数内调用的函数，也要保证其中不调用虚函数 10：令operator=返回一个reference to *this 令赋值运算符返回一个*this的引用\n11：在operator=中处理自我赋值 进行重新排列赋值或者copy and swap\n背景：有时可能很隐蔽的进行了自赋值的操作，特别是类管理资源时，很可能被意外delete掉 进行重新排列赋值：先保存当前资源副本，然后new，最后delete原来的资源；可以保证异常安全性，而且identity test没有必要 1 2 3 4 5 6 MyClass\u0026amp; operator= (const MyClass\u0026amp; rhs){ Resource* tmp = MyResource; MyResource = new Resource(); // 如果new失败，则当前资源不会被释放 delete tmp; // new成功 return *this; } copy and swap 12：复制对象时勿忘记其每一个成分 派生类复制时，不要忘记将基类部分也复制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; class Base{ public: Base(int id): base_id(id) {} Base(const Base\u0026amp; b): base_id(b.base_id) {} Base\u0026amp; operator= (const Base\u0026amp; b) { base_id = b.base_id; return *this;} private: int base_id; }; class Derived: public Base{ public: Derived(int id, string name): Base(id), myname(name) {} Derived(const Derived\u0026amp; d): Base(d), myname(d.myname) {} // 将派生类直接赋值给基类，派生类被切掉 Derived\u0026amp; operator= (const Derived\u0026amp; d){ Base::operator=(d); // 调用基类operator= myname = d.myname; return *this; } private: string myname; }; ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch02-%E6%9E%84%E9%80%A0%E6%9E%90%E6%9E%84%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/","summary":"05：了解C++默默编写并调用了哪些函数 如果没有自定义相应拷贝控制成员，而且需要使用该拷贝控制成员，则编译器进行合成 有时编译器不会进行合成，","title":"[Effective Cpp Notes] Ch02 构造、析构、赋值运算"},{"content":"01 视C++为一个语言联邦 C++高效编程守则视状况而变化，取决于你使用C++的哪一部分\nC++支持面向过程、面向对象、面向函数、泛型编程、元编程，因此可以将C++视为一个由相关语言组成的联邦而非单一语言（各个方面的编程范式不太相同）： C：有指针、数组，没有模板、重载和异常 Object-Oriented C++：类、封装、继承、多态、虚函数 Template C++：模板元编程 STL： 编程范式（或者编程技巧）的区别： 对于C而言，传值比传引用更加高效 对于Object-Oriented C++而言，常量引用传递往往更好（可以传递左值、右值） 对于Template C++而言，模板往往不知道处理的对象是什么类型 对于STL而言，迭代器和函数对象是基于C的指针，所以此时应该选择值传递 02：尽量以const,enum,inline替换#define 尽量使用编译器操作代替预处理器操作： 对于常量，尽量使用const对象或enum来替换#define 对于形似函数的宏，最好改用inline替换#define 尽量使用编译器操作代替预处理器操作 #define是在预处理阶段进行替换，宏的名字不会出现在符号表中。 对于常量，尽量使用const对象或enum来替换#define 两个典型场景： 定义常量指针 定义class专属常量，比如const static成员 类内static成员可以进行【声明时初始化】，虽然不是定义（即没有分配空间），但是只要不取地址，此时也可以使用该变量 如果类内static成员进行【声明时初始化】，而且需要取地址，则需要在类外对变量进行定义 1 2 3 4 class Widget{ const static int val = 0; }; const int Widget::val; // 由于const，无法进行赋值 对于形似函数的宏，最好改用inline替换#define 虽然使用宏本身少了一次调用过程，但是有时即使加上括号，结果也不正确 1 2 3 4 5 #define CALL_WITH_MAX(a, b) f((a) \u0026gt; (b) ? (a) : (b)) int a = 5, b = 0; CALL_WITH_MAX(++a, b); // a 累加了一次 CALL_WITH_MAX(++a, b + 10); // a 累加了两次 使用inline可以保证正确性，并且可以使用模板 参考 https://github.com/XiaotaoGuo/Effective-Cpp-Reading-Note/blob/master/1.AccustomingYourselfToCpp/02.PreferConstsEnumsInlinesToDefine.md 03：尽可能使用const 声明为const可以帮助编译器检测错误 const成员函数默认遵循bitwise constness，但是编写程序时应该使用logical constness，必要时将成员声明为mutable来保证可以修改 const和non-const成员函数有实质等价的实现，令non-const版本调用const版本可以避免代码重复 const和指针：顶层const与底层const const和STL：const迭代器是顶层const，const_iterator是底层const const和函数： 函数返回值和函数形参尽量声明为const的，有助于编译器定位相关报错 比如将比较运算符==误写为赋值运算符= 成员函数声明为const的 使得成员函数更容易被理解（这个成员函数不能修改成员），而且此时形参往往也是const引用 一个const成员函数，一个non-const成员函数，可以进行重载 const对象调用const版本成员函数，普通对象调用non-const版本成员函数 常量性转移 背景：const成员函数与non-const成员函数中间逻辑相同，可能存在大量的重复代码，一个方法是将重复的代码写成函数放在private中 更好的办法是，让non-const成员函数调用const成员函数（如果反过来，const成员函数调用non-const成员函数，不能保证对象不被修改） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class TextBlock{ public: const char\u0026amp; operator[] (std::size_t pos) const{ // do something return text[pos]; } char\u0026amp; operator[] (std::size_t pos) { return const_cast\u0026lt;char\u0026amp;\u0026gt;( static_cast\u0026lt;const TextBlock\u0026amp;\u0026gt;(*this) // *this是TextBlock\u0026amp;, 强转加上const [pos] // const TextBlock\u0026amp;调用operator[]，否则TextBlock\u0026amp;调用operator[]一直重复调用自己 ); } private: std::string text; } mutable：使得成员变量即使在const成员函数中也可以被修改，主要是为了实现logical constness 背景：bitwise constness与logical constness bitwise constness：成员函数不应该修改任何non-static成员变量（const成员函数的默认方式） 编译器容易实现，只需要寻找成员变量的赋值操作 logical constness：允许成员函数修改成员变量，对于使用者而言，可以体现出constness即可 比如一个指针成员变量，按照bitwise constness，限定指针为顶层的，但是却无法保证不修改所指对象 参考 https://github.com/XiaotaoGuo/Effective-Cpp-Reading-Note/blob/master/1.AccustomingYourselfToCpp/03.UseConstWheneverPossible.md 04：确定对象被使用前已被初始化 内置类型对象一定要进行手动初始化 构造函数中最好使用初始化列表对成员变量进行初始化，而非在函数体中进行赋值 为了避免跨编译单元的初始化顺序问题，尽量以local static对象代替non-local static对象 内置类型变量的初始化 内置类型变量（即使是类中的内置类型成员变量）是否会初始化，取决于其在内存中的位置（堆空间？栈空间？） 自定义类对象的初始化 初始化与赋值的区别 赋值：比如在构造函数函数体中进行“赋值” 非内置类型的成员变量的初始化发生在进入构造函数之前，每个成员变量的default构造函数被自动调用，构造了两次（默认构造一次，复制构造一次） 但是内置类型的成员变量不会自动初始化，此时无区别 初始化：比如在构造函数初始化列表中 此时相当于只调用了一次成员变量的构造函数（赋值构造） 如果是const或者是引用，此时不能被赋值，只能进行初始化 变量初始化顺序 在初始化列表中，编译器按照父类-\u0026gt;子类的顺序进行成员变量初始化，但尽量还是与成员声明顺序保持一致 不同编译单元内定义的non-local static对象的初始化顺序 一些情况下，不同编译单元内的non-local static对象的初始化顺序有要求，但是C++没有明确定义（比如要求先FileSystem中tfs初始化，后Diectory中tdr初始化） 将每个 non-local static 对象移至自己的专属函数内（变成 local static 对象） ","permalink":"https://qinganzhang.github.io/posts/effective-cpp/ch01-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFc++/","summary":"01 视C++为一个语言联邦 C++高效编程守则视状况而变化，取决于你使用C++的哪一部分 C++支持面向过程、面向对象、面向函数、泛型编程、元编程","title":"[Effective Cpp Notes] Ch01 让自己习惯C++"},{"content":"contact me at: zhangqingannn@gmail.com\n","permalink":"https://qinganzhang.github.io/about/","summary":"contact me at: zhangqingannn@gmail.com","title":"About"},{"content":"1. linux入门 1.1 实用程序 man：查询联机手册\n1 2 man (section) name\t# section:1命令，2系统调用，3库函数，5配置文件（因为可能有同名的） man -k regexp\t# 用正则匹配 date：获取时间和日期\n1 date \u0026#34;+%Y-%m-%d %H:%M:%S Day %j\u0026#34;\t# 格式控制字符串必须以+号开头 bc：计算器\n1 bc -l\t# 类似于ipython的交互式界面 重定向\n1 2 3 ls -l \u0026gt; filelist.txt\t# 输出重定向 sort \u0026lt; filelist.txt\t# 输入重定向 ls -l \u0026gt;\u0026gt; filelist.txt\t# 追加内容 管道\n1 ls -l | sort # 将ls的stdout作为sort的输入 more, less：逐屏显示（文件或输出），less可以向上翻页但是more不行\n1 less -Nm\t# fb翻页，du翻半页，gG第一/最后一行，v编辑，/?向下或上搜索字符串(nN上一个下一个) cat：列出文件内容；od：逐字节打印\n1 2 cat -n test.txt cat \u0026gt; file.txt # 没有命令行参数，从stdin获取输出，直到Ctrl-D，将内容写入文件 head, tail\n1 2 3 head -n 20 file.txt # 显示前20行 hand -n -20 file.txt\t# 除了尾部20行，其余算头并显示 tail -f file.txt\t# 实时打印文件尾部追加的内容 tee：三通，将stdin输出到stdout，同时写入文件中\n1 ls -lh | tee out.txt wc\n-w：字计数 -l：行计数 1 2 ps -ef | wc -l\t# 查看当前进程总数 ls | wc -w # 查看当前文件夹下文件个数 sort：\n-r：降序 -o：结果覆盖原文件 -n：按照数字而非字符串排序 tr str1 str2：替换字符串，将stdin中str1的字符替换为str2的字符，然后标准输出\n1 cat file.txt | tr \u0026#39;[a-z]\u0026#39; \u0026#39;[A-Z]\u0026#39;\t# 将file.txt文件中小写字母替换为大写字母 unique：筛选文件中重复的行\n1.2 了解系统状态 who：确定谁在系统中\n1 2 tty # 输出当前终端设备文件名 who am i # 输出当前终端上的登录用户 uptime：已开机时间\n1 当前时间 开机时间 用户数量 CPU负载（1，5，15分钟内有几个进程在等待调度运行） top：列出资源占用排名靠前的进程\n1 2 3 4 top -d 1 -n 5\t# delay=1, 运行5次 当前时间 开机时间 用户数量 CPU负载 任务（进程） PID USER PR NI VIRT进程虚拟地址空间 RES驻留内存数（占用物理内存数） SHR共享内存数 %CPU %MEM TIME+占用CPU的时间 ps：查询进程状态，列出当前终端上启动的进程\n-e：列出系统中所有进程 -f：以full格式列出 -l：以long格式列出 1 UID PID PPID C（最近几秒占用CPU情况） PRI优先级 SZ进程逻辑地址空间 WCHAN进程在何处睡眠 TTY终端名字 TIME累计占用CPU时间 CMD free：了解内存使用情况\n1 内存总量 已使用内存 空闲内存 共享内存 缓冲使用的内存 现在实际可以使用的内存 vmstat：了解系统负载\n1 2 vmstat 1 -Sm # 每一秒更新一次 最关注的是cpu使用率，us=user, sy=system, id=idle, wa=wait for disk IO 2. 正则表达式 2.1 元字符 [正则表达式](https://www.runoob.com/regexp/regexp-tutorial.html)与文件名通配符规则不同 .：匹配任意单字符\n*：匹配前面单字符0次或任意多次\n[：方括号内的字符为集合，表示其中任意一个，方括号内的. * \\ 表示自己，[ ][ ]表示左右中括号的两个字符，-表示一个区间（如果在最后则不表示区间）\n\\\n^：在中括号内时开头表示补集，[^a-z]表示匹配任一非小写字母（如果不在中括号内开头则不表示补集），在正则表达式开头时表示首部的限制（不在首部则不表示此限制）\n$：在正则表达式尾部时表示尾部的限制（不在尾部则不表示此限制）\n2.2 正则表达式拓展 ()：分组 |：逻辑或 +：匹配前面单字符1次或任意多次 ?：匹配前面单字符0次或1次 {m,n}：匹配前面的单字符m到n次 {m}：匹配前面的单字符m次 {m,}：匹配前面的单字符至少m次 \\d：数字， \\D：非数字，\\s：空白符（包括换行）， \\S：非空白符（不包括换行）， \\w：数字字母下划线（相当于 [A-Za-z0-9_]） 2.3 常用命令 grep -n 模式 文件名列表\n-F：按字符串搜索（同fgrep）\n-G：基本正则语法，默认\n-E：拓展正则语法（同egrep）\n-n：显示行号\n-o：提取匹配的部分\n1 2 grep -n \u0026#39;main\u0026#39; *.cpp\t# 从文件中筛选 ps -ef | grep -n \u0026#39;^zhang\u0026#39;\t# 从输入中筛选 sed：利用正则表达式处理文本（替换、删除等）\n1 sed \u0026#39;s/^zhang/ZHANG/g\u0026#39;\t# 将开头为zhang的替换为ZHNAG，s表示替换，用/划分不同的部分，g表示如果有多个符合则全部替换 awk：逐行扫描进行条件判断，满足条件执行动作\n3. 文件编辑 3.1 vim常用操作 3.2 常见问题 vim编辑结束后Ctrl+S：Linux进入了流量控制状态，Ctrl+Q流量控制解除\nCtrl+Z导致进程挂起（进程还在但是处于Stopped状态）：使用jobs命令查看当前Stopped的进程，使用%1将1号作业恢复到前台运行\nbackspace无法使用：Ctrl+H或者stty erase ^H\nLinux和Windows的文本文件存储格式不同（行尾不同），dos2unix/unix2dos转换\n4. 目录管理 4.1 系统目录 /etc：配置文件 /tmp：临时文件 /var：系统运行时要改变的数据（比如日志） /bin：系统常用命令（eg：ls、cp、cat） /usr/bin：常用命令（eg：ssh，ftp，make， gcc，git） /sbin, /usr/bin：系统管理员专用命令 /dev：设备文件 /usr/include：C语言头文件 /lib, /usr/lib：C语言链接库文件，静态链接库（.a文件)和动态链接库（.so文件，共享的目标代码，多个.o文件的集成，广泛使用） ldd：用来查看程序运行时所需的共享库 4.2 文件通配符 command后面跟着的是参数或文件通配符，shell进行替换，而正则表达式不进行替换 元字符 *：匹配任意长度的文件名字符串（包括空串），当.作为开头或是包含/时，必须显示匹配 ?：匹配任一单字符 []：集合，匹配其中任一字符 ~：当前用户主目录 .：当前目录 /：根目录，斜线/，反斜线\\ 4.3 常用命令 ls\n-F：如果是目录，名字后面带/，如果是可执行文件，名字后面带*，如果是链接文件，名字后面带@，普通文件无标记（现在文件都用颜色表示）\n-l：\n第一个字符为文件类型，-普通文件，d目录文件，l符号链接文件，c字符设备文件，b块设备文件，p管道文件\n访问权限（文件所有者、同组用户、其他用户）\n文件链接数\n文件所有者名字和组名\n文件大小（单位为字节，如果是目录则列出目录表大小不是目录大小）\n最后修改日期和时间，文件名\n-d：列出目录自身的信息\nls *：递归一层列出\n-a：列出所有文件\ncp：复制\ncp file1 file2：将file1复制到file2（如果file2不存在则创建，如果存在则覆盖） cp -r dir1 dir2：如果dir2不存在则复制dir1并改名为dir2，如果dir2存在则将dir1复制到dir2下 cp file1 file2 dir：将file1，file2复制到dir目录 -u：增量拷贝，便于备份目录 mv：移动\nmv file1 file2：相当于将file1改名为file2 mv file1 file2 dir：要求dir存在 mv dir1 dir2：如果dir2不存在则相当于改名，如果dir2存在移动dir1到dir2下 rm\n-r递归删除， -i删除前确认， -f强迫删除只读文件\n--后参数被shell认为是处理对象而不是命令选项\nmkdir和rmdir\n-p：自动创建路径中不存在的目录 touch：将文件最后一次修改时间设置为当前时间（如果文件不存在，则创建文件）\nfind：遍历目录树， find 查找范围 条件 动作\n条件\n-name wildcard：文件名与wildcard匹配，wildcard加单引号，wildcard可以是正则表达式 -regex pattern：整个路径名与pattern匹配 -type：f普通文件，d目录，l符号链接文件，c（char），b（block），p（pipe） -size +-n ：指定文件大小（大于+，默认等于，小于-），单位是c（字符），b（块，512字节），k，M，G，默认b -mtime +-n：文件是最近n天内修改的 -newer file：文件修改时间比file还新 !：非，前后要有空格， 默认是与 \\( 条件1 -o 条件2 \\)：或，因为()是shell的特殊符号 动作\n-print：打印查找的文件路径名\n-exec：对查找到的目标执行命令，在-exec之后和分号之前作为一条命令，{}表示文件路径名\n1 2 find . -type f -name \u0026#39;utils.*\u0026#39; -exec ls -lh {} \\; find . ! -newer file.txt \\( -name \u0026#39;*.c\u0026#39; -o -name \u0026#39;*.h\u0026#39; \\) -exec grep -n -- --help {} /dev/null \\;\t# 查找早于file.txt的.c或.h文件，并且在检索到的文件(用{}表示)中查找包含--help的内容，通过grep添加两个文件（{}和/dev/null）来显示查找到的内容是在哪一个文件中 -ok：类似-exec，在执行命令前需要确认\nxargs：批量处理文件，常用于先列出文件然后再xargs批处理\n1 2 find . -name \u0026#39;*.c\u0026#39; -print | grep -n --help\t# 每找到一个文件都要创建一个进程来grep find . -name \u0026#39;*.c\u0026#39; -print | xargs grep -n --help\t# 找到所有文件后，只创建一个进程来批处理(grep)这些找到的文件，将标准输入追加到参数列表后面,效率高 tar：tar c/t/x vzj f my.tar filelist\n必选参数 c：tar cvf my.tar filelist将filelist中文件打包到my.tar中 t：tar tvf my.tar查看my.tar中有什么文件 x：tar xvf my.tar解包，此时不需要压缩算法 f：指定设备文件名（即.tar文件） 可选参数 v：verbose z：gzip压缩，快，常gz后缀 j：bzip2压缩，压缩率高，常bz2后缀 gzip, gunzip; bzip2, bunzip2：压缩解压缩\ndu：du -d 1 -h显示文件大小，类似windows\n-d：递归深度 5. 文件管理 5.1 运行时获取信息 配置文件 环境变量：env打印当前环境变量，PATH是可执行文件的查找路径，CLASSPATH是类库查找路径，使用export来添加环境变量 命令行参数 交互式键盘输入 5.2 文件系统 文件系统命令\nmkfs：创建文件系统\nmount, umount：安装、卸载文件系统\ndf ：查看文件系统空间空间\n文件系统结构\n引导块：启动系统\n专用块：管理快（或超级块），存放文件系统的管理信息\ni节点区：每个文件一个i-node，包括索引、指针和文件信息\n文件存储区：目录表（文件名和i-node指针）和文件内容\n5.3 链接 硬链接：目录项指定的“文件名 i-node”映射关系\n1 ln file.txt lnk\t# 创建file.txt的硬链接lnk，删除lnk时对应i-node的link数减一，仅限于同一个文件系统中的普通文件 软链接（符号链接）：创建一个“符号链接文件”，里面存储路径（如果时相对路径，则相对于该符号链接文件）\n1 ln -s file.txt lnk # 创建file.txt的软链接lnk 5.4 可执行文件 程序文件：二进制 脚本文件：第一行指定解释程序，在运行中由解释程序创建一个进程进行解释执行 5.5 权限 目录权限：实际上是对目录表的权限，无读权限则无法ls，无写权限则无法创建、删除文件等（但文件可能可以修改），执行权限表示分析路径名中可以检索该目录 chmod [ugoa][+-=][rwxst] file u=user, g=group, o=other, a=all, 6. Shell 6.1 shell 命令解释器，交互式方式下替换、转义、内部外部命令，非交互式方式下编写脚本程序批量处理 6.2 bash启动方式 注册shell，启动时自动执行\n（用户级）：~/.bash_profile\n（系统级）：/etc/profile\n退出时，自动执行\n（用户级）：~/.bash_logout\n（系统级）：/etc/bash.bash.logout\n交互式shell，启动时自动执行\n（用户级）：~/.bashrc\n（系统级）：/etc/bash.bashrc\n脚本解释器：\n新创建子进程，在子进程中执行脚本 bash \u0026lt; test.sh：无法携带命令行参数 bash test.sh ..：-x参数便于调试和观察 chmod u+x test.sh; ./test.sh .. 在当前shell中执行 chmod u+x test.sh; . test.sh .. 6.3 别名 在.bashrc中添加一个别名\n1 alias lls = \u0026#34;ls -lh\u0026#34; 6.4 重定向 输入重定向\n\u0026lt;：从file中获取输入\n\u0026lt;\u0026lt;：从shell脚本中获取输入\n1 2 3 4 5 6 7 8 9 cat \u0026lt;\u0026lt; WORD Now: `date` WORD # WORD是定界符，之间内容进行替换并执行获取输入 cat \u0026lt;\u0026lt; \u0026#39;WORD\u0026#39; Now: `date` WORD # 当定界符有单引号时，之间内容不做替换 \u0026lt;\u0026lt;\u0026lt;：从命令行获取信息作为标准输入\n1 base64 \u0026lt;\u0026lt;\u0026lt; \u0026#39;test\u0026#39; 输出重定向\n\u0026gt;：覆盖，stdout重定向\n\u0026gt;\u0026gt;：追加，stdout重定向\n2\u0026gt;：将句柄2（stderr）重定向（句柄1是stdout）\n2\u0026gt;\u0026amp;1：将句柄2重定向到文件描述符1指向的文件，放在命令最后\n1 gcc test.c \u0026gt; test.err 2\u0026gt;\u0026amp;1 管道|将前一命令的stdout作为后一命令的stdin，同样可以使用2\u0026gt;\u0026amp;1\n1 gcc test.c \u0026gt; test.err 2\u0026gt;\u0026amp;1 | less 6.5 设置 set -u：当引用一个未定义的变量时，产生一个错误 set +u：当引用一个未定义的变量时，视为一个空字符串 set -x：打印出shell替换后的命令和参数，常用于观察命令经过shell替换后哪里错误 set +x：取消set -x 6.6 常用命令 echo：打印命令行参数\n-e：转义打印 printf：类似C语言\n1 printf \u0026#34;home:%s\\n\u0026#34; $HOME read：获取用户输入\n6.7 环境变量 子进程继承父进程的环境变量，以后再不影响\n使用export将局部变量转为环境变量 PATH：命令查找路径，不要将.放入PATH，PATH以:分隔路径 env：列出环境变量 set：列出环境变量、局部变量、函数定义 6.8 替换 文件名生成替换：遵循文件通配符规则\n变量替换：$var\n命令替换：以命令的stdout进行替换， `````` ````(反撇号)或者 $()\n1 2 now = `date` now = $(date) 6.9 语法 6.9.1 变量 shell先替换，再执行 变量都是字符串，可以修改 赋值语句等号两边不能有空格（否则会认为是参数），右侧字符串如果有特殊字符需要用双引号 引用变量：$var或${var}，引用未定义变量认为是空字符串 内部变量：位置参数 $0, $1, $2：第一个命令行参数（脚本文件本身的名字），第二个命令行参数，第三个命令行参数 $#：命令行参数的个数 $*：相当于\u0026quot;$1 $2 $3 ...\u0026quot;将整体作为一个参数 $@：相当于\u0026quot;$1\u0026quot; \u0026quot;$2\u0026quot; \u0026quot;$3\u0026quot; ... 将变长的命令行参数传递给其他命令 shift n ：位置参数的移位操作，位置参数顺次向前移动n个位置 6.9.2 元字符 空格，tab：命令行参数分隔符\n回车：运行命令\n\u0026gt;\u0026lt;|：重定向与管道（还有||）\n;：一个内多个命令（还有;;）\n\u0026amp;：后台运行（还有\u0026amp;\u0026amp;）\n$：引用变量\n````` ：反撇号用于命令替换，出现元字符注意转义，可以嵌套但要转义`\\\\` 、` ````\n1 year=`expr \\`date \u0026#39;+%Y\u0026#39;\\` - 10 ` 文件通配符：*[]?\n()：用于定义shell函数或在子shell中执行一组命令\n\u0026quot;：除了$和````` ，其他的特殊字符都不转义，里面只能有四种转义：`\\\u0026quot;` 、 `\\$`、 ` ````、 \\\\\n'：都不转义，中间不能有单引号（可以拆分成多段）\n1 2 3 4 5 在*.conf文件中匹配\u0026#39;192.168.x.x\u0026#39;结尾 pattern: \u0026#39;192\\.168\\.[0-9.]*\u0026#39;$ grep \\\u0026#39;\u0026#39;192\\.168\\.[0-9.]*\u0026#39;\\\u0026#39;\u0026#39;$\u0026#39; *.conf\t# 使用单引号 grep \u0026#34;\u0026#39;192\\\\.168\\\\.[0-9.]*\u0026#39;\\S\u0026#34; *.conf\t# 使用双引号 grep \\\u0026#39;192\\\\.168\\\\.\\[0-9.]\\*\\\u0026#39;\\$ *.conf\t# 只使用转义,不被引号包括的字符串 6.9.3 条件判断 逻辑判断\n命令的返回码是0，则命令执行成功\n$?输出上一个命令的返回码，用管道连接时以最后一个命令的返回码为准\n\u0026amp;\u0026amp; ||：与，或，可以短路\n1 2 cmd1 \u0026amp;\u0026amp; cmd2\t# cmd1执行失败就不执行cmd2 cmd1 || cmd2\t# cmd1执行成功就不执行cmd2 检测命令：test或[(是一个命令而非词法符号，最后一个参数必须是])\n文件特性检测：\n-f普通文件，-d目录文件，-r可读，-w可写，-x可执行，-ssize\u0026gt;0\n1 2 test -r myfile.txt \u0026amp;\u0026amp; echo readable [ -r myfile.txt] \u0026amp;\u0026amp; echo readable 检测命令是否执行成功\n比较\n字符串比较：shell中有三种字符串\nstr1 = str2或str1 != str2等号两边一定要有空格\n整数的比较\n-eq=，-ne!=， -gt\u0026gt;， -lt\u0026lt;， -ge\u0026gt;=， -le\u0026lt;=\n逻辑运算\n! 非，-o或， -a与\n命令组合：经常命令检测之后执行多条命令\n{}：在当前shell中执行，命令组合最后有分号\n1 [ -d $DIR ] \u0026amp;\u0026amp; { cd ..; ls -l; ps; } | less ()：在子进程中执行，命令组合最后无分号\n1 [ -d $DIR ] $$ ( cd..; ls -l; ps ) | less 条件结构\n1 2 3 4 5 6 7 if condition then list elif condition then list else list fi 6.9.4 表达式运算expr 运算类型：()，五种算术运算，六种关系运算，\u0026amp; |与或， :正则 注意运算符的转义 :正则：expr str : pattern 从最左字符开始尽量匹配，最终输出匹配的长度 使用的是基本正则语法，但是\\+ \\? \\|表示匹配一个或多个，匹配0个或1个，或（两端任选其一） 使用\\( \\)，将其中匹配的内容提取出来 6.9.5 循环结构 while\n1 2 3 while condition do list done for\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 for name in word1, word2, ... do list done # 或者 for name do list done # 相当于 for name in $1, $2, ... do list done for i in `seq 1 255` # 相当于for i in range(1,256) break n：跳出n层循环\ncontinue\nexit val：结束脚本执行，返回值为val\n6.9.6 其他 eval：将参数先进行变量替换或加工，然后将结果作为程序来执行 ","permalink":"https://qinganzhang.github.io/posts/linux%E7%AC%94%E8%AE%B0/","summary":"1. linux入门 1.1 实用程序 man：查询联机手册 1 2 man (section) name # section:1命令，2系统调用，3库函数，5配置文件（因为可能有同名的） man -k regexp","title":"Linux笔记"}]