<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>量化基础 | Paul's Blog</title>
<meta name=keywords content="量化,推理加速"><meta name=description content="1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener"><meta name=author content="Paul"><link rel=canonical href=https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/><link crossorigin=anonymous href=/assets/css/stylesheet.min.css rel="preload stylesheet" as=style><link rel=icon href=https://qinganzhang.github.io/favicon.ico><link rel=apple-touch-icon href=https://qinganzhang.github.io/apple-touch-icon.png><meta name=twitter:title content="量化基础 | Paul's Blog"><meta name=twitter:description content="1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener"><meta property="og:title" content="量化基础 | Paul's Blog"><meta property="og:description" content="1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener"><meta property="og:type" content="article"><meta property="og:url" content="https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-04T20:31:46+08:00"><meta property="article:modified_time" content="2024-03-04T20:31:46+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Post","item":"https://qinganzhang.github.io/posts/"},{"@type":"ListItem","position":2,"name":"量化基础","item":"https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"量化基础 | Paul's Blog","name":"量化基础","description":"1. 背景 从速度看 访存耗时远多于计算 浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积 从ener","keywords":["量化","推理加速"],"wordCount":"2520","inLanguage":"en","datePublished":"2024-03-04T20:31:46+08:00","dateModified":"2024-03-04T20:31:46+08:00","author":{"@type":"Person","name":"Paul"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qinganzhang.github.io/posts/%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80/"},"publisher":{"@type":"Organization","name":"Paul's Blog","logo":{"@type":"ImageObject","url":"https://qinganzhang.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://qinganzhang.github.io/ accesskey=h title="Paul's Blog (Alt + H)">Paul's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://qinganzhang.github.io/posts/ title=Posts class=active>Posts</a></li><li><a href=https://qinganzhang.github.io/archives/ title=Archive>Archive</a></li><li><a href=https://qinganzhang.github.io/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li><li><a href=https://qinganzhang.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://qinganzhang.github.io/categories/ title=Categories>Categories</a></li><li><a href=https://qinganzhang.github.io/about/ title=About>About</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://qinganzhang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://qinganzhang.github.io/posts/>Post</a></div><h1 class=post-title>量化基础</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>2024-03-04</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://qinganzhang.github.io/tags/%E9%87%8F%E5%8C%96/>量化</a><a href=https://qinganzhang.github.io/tags/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>推理加速</a></span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>2520 words</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>6 min</span></span></div></header><div class="toc side right"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%e8%83%8c%e6%99%af aria-label="1. 背景">1. 背景</a></li><li><a href=#2-%e6%95%b0%e5%80%bc%e7%b1%bb%e5%9e%8b%e6%b5%ae%e7%82%b9%e6%95%b0 aria-label="2. 数值类型（浮点数）">2. 数值类型（浮点数）</a></li><li><a href=#3-%e9%87%8f%e5%8c%96%e5%9f%ba%e7%a1%80 aria-label="3. 量化基础">3. 量化基础</a></li><li><a href=#4-%e9%87%8f%e5%8c%96%e7%a7%8d%e7%b1%bb aria-label="4. 量化种类">4. 量化种类</a><ul><li><a href=#41-post-training-quantizationptq aria-label="4.1 Post-Training Quantization(PTQ)">4.1 Post-Training Quantization(PTQ)</a></li><li><a href=#42-quantization-aware-trainingqat aria-label="4.2 Quantization Aware Training(QAT)">4.2 Quantization Aware Training(QAT)</a></li></ul></li><li><a href=#5-%e4%bd%8e%e6%af%94%e7%89%b9%e9%87%8f%e5%8c%96 aria-label="5. 低比特量化">5. 低比特量化</a></li></ul></div></details></div><div class=post-content><h2 id=1-背景>1. 背景<a hidden class=anchor aria-hidden=true href=#1-背景>¶</a></h2><ul><li>从速度看<ul><li>访存耗时远多于计算</li><li>浮点数计算耗时和整型计算耗时差不多？（from 张志），但是浮点数计算单元需要占用更多额外的芯片面积</li></ul></li><li>从energy看<ul><li>访存消耗energy远多于计算（200倍）</li><li>浮点数运算消耗energy多于int8类型（十几倍），因此量化有助于keep efficient</li></ul></li></ul><h2 id=2-数值类型浮点数>2. 数值类型（浮点数）<a hidden class=anchor aria-hidden=true href=#2-数值类型浮点数>¶</a></h2><ul><li>FP32：1+8+23</li><li>FP16：1+5+10，通常使用在混合精度训练中</li><li>BF16：1+8+7，直接将FP32进行截断，方便直接进行转换</li><li>TF32：1+8+19，保留了FP32的范围（8位范围）与FP16的精度（10位精度），用于TensorCore中</li><li>FP24：</li></ul><h2 id=3-量化基础>3. 量化基础<a hidden class=anchor aria-hidden=true href=#3-量化基础>¶</a></h2><ul><li><p>K-Means-based Quantization</p><ul><li>原理：权重进行kmeans聚类（每个类别cluster视为一个模式），每个cluster对应一个浮点数，构成一个codebook（lookup table），权重矩阵中保存的是codebook中的索引<ul><li><span id=kmeans>微调过程</span>：给定权重矩阵对应的梯度矩阵，将梯度矩阵按照模式进行分组（对应不同的cluster），每组梯度进行求和，再更新codebook中对应cluster的浮点数</li></ul></li><li>效果：<ul><li>从pruning ratio看：剪枝+量化同时使用，可以获得更小的pruning ratio（量化后再微调一下，有助于恢复精度）</li><li>从准确率看：剪枝+量化准确率与只进行量化差不多</li></ul></li><li>优化：霍夫曼编码<ul><li>将更频繁的权重使用更短的编码表示（但是这样会导致权重矩阵中各个元素大小不一❓）</li></ul></li><li>特点：量化后存储的是低比特，但是计算仍然是浮点数（只是节省了存储，但是访存翻倍❓）</li></ul></li><li><p>Linear Quantization</p><ul><li><p>原理：直接进行映射，相当于线性的codebook，权重矩阵中存储的是量化值，运算时先反量化到浮点数范围、再使用不同的量化参数量化到int8
$$
量化：&amp;uint &=& round( \frac{float}{scale} + offset) \
反量化：&amp;float &=& (uint - offset) * scale
$$</p></li><li><p>tricks：</p><ul><li><p>公式中的很多部分可以pre-compute</p></li><li><p>scale的浮点乘法可以转换为定点小数的位移</p><blockquote><p>详见<a href=https://arxiv.org/pdf/1712.05877.pdf>Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a> 第2.2章</p><p><a href=https://zhuanlan.zhihu.com/p/149659607>神经网络量化入门&ndash;基本原理</a></p><p><a href=https://zhuanlan.zhihu.com/p/413864742>量化推理是如何把scale转换为定点运算的</a></p></blockquote></li></ul></li><li><p>分类</p><ul><li>对称量化</li><li>非对称量化（由于补码负数比正数多一个，因此区分两种模式，构造成左右对称的形式，不同框架可能使用不同的mode）<ul><li>full range mode：正数128加进来</li><li>restricted range mode：负数-128去掉</li></ul></li></ul></li><li><p>特点：量化后存储的是int8，计算中也是int8</p></li></ul></li></ul><h2 id=4-量化种类>4. 量化种类<a hidden class=anchor aria-hidden=true href=#4-量化种类>¶</a></h2><h3 id=41-post-training-quantizationptq>4.1 Post-Training Quantization(PTQ)<a hidden class=anchor aria-hidden=true href=#41-post-training-quantizationptq>¶</a></h3><ul><li><p>权重量化Weight Quantization：减小模型大小</p><ul><li><p>Per-tensor vs Per-channel</p></li><li><p>Weight Equalization</p><ul><li><p>背景：</p><ul><li>Per-tensor量化简单，但是由于channel之间range差异较大，导致效果很差</li><li>Per-channel量化效果较好，但是需要特殊硬件支持❓</li><li>目标：make weight ranges similar (or equalize the weight range), so that per-tensor quantization can be applied（既想要per-tensor的简单，又想要per-channel的效果）</li></ul></li><li><p>原理：positive scaling equivariance伸缩等价性</p><p>对于conv、fc和relu，满足：</p><p>$$f(s x) = s f(x), where \quad s \gt 0 $$</p></li><li><p>方法：对于连续的两个卷积层，第一个卷积层乘上一个scale，第二个卷积核对应通道除以一个scale，这样与原来是等价的，但是调整了第一个卷积核的range；然后逐渐连续地调整</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/393556057>后量化训练-Data free quantization</a></p></blockquote></li></ul></li><li><p>Adaptive Rounding</p><ul><li><p>背景：</p><ul><li><p>看似符合直觉的round-to-nearest其实精度并不是最优的</p><blockquote><p>因为并非每个单独的weight的量化损失越小越好，weight之间存在相互影响</p></blockquote></li></ul></li><li><p>方法：Adaptive地决定weight量化时将浮点数转到最近右定点还是最近左定点❓</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/363941822>AdaRound解读</a></p></blockquote></li></ul></li></ul></li><li><p>激活值量化Activation Quantization：减小内存占用</p><p>目标：由于激活值无法提前确定，因此要找到激活值的$r_{min}, r_{max}$</p><ul><li><p>During Training</p><ul><li><p>EMA</p><p>在训练时使用exponential moving averages (EMA)来得到$r_{min}, r_{max}$
$$
&\hat{r} ^ {(t)} _ {max, min} = \alpha r ^ {(t)} _ {max, min} + (1 - \alpha) \hat{r} ^ {(t-1)} _ {max, min} \
&其中 \hat{r} ^ {(t)} _ {max, min} 是EMA激活值范围， \
&amp;r ^ {(t)} _ {max, min} 是 epoch=t时的激活值范围
$$</p><blockquote><p><a href=https://arxiv.org/abs/1712.05877>Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a> 3.1段</p></blockquote></li></ul></li><li><p>Use calibration after training</p><ul><li><p>统计calibration中每个sample的$r_{min}, r_{max}$，然后取平均</p></li><li><p>ACIQ</p><ul><li><p>基本思想：最小化激活值X与量化值Q（X）的MSE，具体假设原始激活值的分布，展开求导
$$
\mathop{min}\limits_{|r|_{max}} \mathbb{E} \left[ (X - Q(X))^2 \right]
$$</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/138569083>CNN后量化方法：ACIQ</a></p><p><a href=https://arxiv.org/pdf/1810.05723.pdf>Post training 4-bit quantization of convolutional networks for rapid-deployment</a></p></blockquote></li><li><p>缺点：需要假设原始的激活值浮点分布（因为需要密度函数）</p></li></ul></li><li><p>KL-divergence based</p><ul><li><p>基本思想：使用KL散度来衡量量化的信息损失（原始激活值的分布与量化后的分布）</p><blockquote><p><a href=https://blog.csdn.net/Nichlson/article/details/121085747>TensorRT INT8量化原理与实现（非常详细）</a> 第七部分</p></blockquote></li></ul></li></ul></li></ul></li><li><p>偏置量化Bias Quantization</p><ul><li><p>背景：权重量化之后，权重分布会产生一个shift。一方面希望量化误差尽量小，另一方面希望量化误差的期望为0（但并非如此）</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/393556057>后训练量化——Data free quantization</a> 中<strong>Bias Correction</strong>，可以看到蓝色的量化误差明显左偏</p></blockquote></li><li><p>方法：</p><ul><li>如果当前有数据：全精度和量化模型分别跑一遍，bias减去这个量化误差，注意对于每一个卷积层或全连接层都要跑一遍</li><li>如果当前没有数据：</li></ul></li></ul></li></ul><h3 id=42-quantization-aware-trainingqat>4.2 Quantization Aware Training(QAT)<a hidden class=anchor aria-hidden=true href=#42-quantization-aware-trainingqat>¶</a></h3><ul><li><p><a href=#kmeans>K-means-based Quantization 微调</a></p></li><li><p>STE方法：</p><ul><li><p>想法：权重信息经过伪量化操作，来模拟产生量化误差，反向传播的梯度信息跳过伪量化节点直接更新原始权重，相当于更新权重信息考虑到了量化误差、梯度下降进行优化</p></li><li><p>过程：</p><ul><li><p>拿到训练好的模型</p></li><li><p>在权重、激活值、输入输出等（对应权重量化与激活值量化）前面插入伪量化节点（将浮点权重量化再反量化，模拟推理时的量化）</p><blockquote><p>一开始伪量化节点中量化参数是怎么来的？</p><p>在微调的forward过程中，顺便计算出量化参数：</p><ul><li>如果是针对权重的量化：直接统计权重中的最小值、最大值，从而计算量化参数</li><li>如果是针对激活值的量化：使用指数移动平均EMA来更新量化参数</li></ul></blockquote></li><li><p>前向推理，模拟量化的过程</p></li><li><p>反向传播：正常更新权重（权重是浮点类型），相当于梯度信息跳过了伪量化节点</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/158776813>神经网络量化入门&ndash;量化感知训练</a></p><p><a href=https://zhuanlan.zhihu.com/p/548174416>量化感知训练（Quantization-aware-training）探索-从原理到实践</a></p><p><a href=https://zhuanlan.zhihu.com/p/467841404>再读《神经网络量化白皮书》- 0x04 训练时量化(QAT)</a></p></blockquote></li></ul></li></ul></li><li><p>LSQ方法：在反向传播时可以更新量化参数</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/396001177>量化训练之可微量化参数—LSQ</a></p></blockquote></li></ul><h2 id=5-低比特量化>5. 低比特量化<a hidden class=anchor aria-hidden=true href=#5-低比特量化>¶</a></h2><ul><li>Binary Quantization</li><li>Ternary Quantization</li><li>Mixed-Percision Quantization</li></ul><p>参考：</p><ul><li><a href="https://blog.csdn.net/weixin_37179744/article/details/130079721?spm=1001.2014.3001.5502">MIT 6.S965 韩松课程 05</a></li><li><a href=https://blog.csdn.net/jinzhuojun/article/details/106955059>闲话模型压缩之量化（Quantization）篇</a></li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=https://qinganzhang.github.io/posts/tmux%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>Tmux简单使用</span>
</a><a class=next href=https://qinganzhang.github.io/posts/java%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>Java编译技术分析</span></a></nav></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qinganzhang.github.io/>Paul's Blog</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span><span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>