<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>流和同步 | Paul's Blog</title>
<meta name=keywords content="cuda"><meta name=description content="CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(&amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(&amp;stop)); CHECK(cudaEventRecord(start, 0)); //"><meta name=author content="Paul"><link rel=canonical href=https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/><link crossorigin=anonymous href=/assets/css/stylesheet.min.css rel="preload stylesheet" as=style><link rel=icon href=https://qinganzhang.github.io/favicon.ico><link rel=apple-touch-icon href=https://qinganzhang.github.io/apple-touch-icon.png><meta name=twitter:title content="流和同步 | Paul's Blog"><meta name=twitter:description content="CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(&amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(&amp;stop)); CHECK(cudaEventRecord(start, 0)); //"><meta property="og:title" content="流和同步 | Paul's Blog"><meta property="og:description" content="CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(&amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(&amp;stop)); CHECK(cudaEventRecord(start, 0)); //"><meta property="og:type" content="article"><meta property="og:url" content="https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-01T22:01:43+08:00"><meta property="article:modified_time" content="2024-02-01T22:01:43+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Post","item":"https://qinganzhang.github.io/posts/"},{"@type":"ListItem","position":2,"name":"流和同步","item":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"流和同步 | Paul's Blog","name":"流和同步","description":"CUDA事件 事件：标记stream执行过程的某个特定的点，比如用于计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); // 创建cuda 事件对象。 CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start, 0)); //","keywords":["cuda"],"wordCount":"6056","inLanguage":"en","datePublished":"2024-02-01T22:01:43+08:00","dateModified":"2024-02-01T22:01:43+08:00","author":{"@type":"Person","name":"Paul"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/"},"publisher":{"@type":"Organization","name":"Paul's Blog","logo":{"@type":"ImageObject","url":"https://qinganzhang.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://qinganzhang.github.io/ accesskey=h title="Paul's Blog (Alt + H)">Paul's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://qinganzhang.github.io/posts/ title=Posts class=active>Posts</a></li><li><a href=https://qinganzhang.github.io/archives/ title=Archive>Archive</a></li><li><a href=https://qinganzhang.github.io/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li><li><a href=https://qinganzhang.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://qinganzhang.github.io/categories/ title=Categories>Categories</a></li><li><a href=https://qinganzhang.github.io/about/ title=About>About</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://qinganzhang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://qinganzhang.github.io/posts/>Post</a></div><h1 class=post-title>流和同步</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>2024-02-01</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://qinganzhang.github.io/tags/cuda/>cuda</a></span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>6056 words</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>13 min</span></span></div></header><div class="toc side right"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#cuda%e4%ba%8b%e4%bb%b6 aria-label=CUDA事件>CUDA事件</a></li><li><a href=#cuda%e6%b5%81 aria-label=CUDA流>CUDA流</a><ul><li><a href=#stream%e5%af%b9%e5%b9%b6%e8%a1%8c%e6%80%a7%e7%9a%84%e5%bd%b1%e5%93%8d aria-label=Stream对并行性的影响>Stream对并行性的影响</a></li><li><a href=#%e4%bd%bf%e7%94%a8%e6%b5%81%e9%9a%90%e8%97%8f%e5%bb%b6%e8%bf%9f aria-label=使用流隐藏延迟>使用流隐藏延迟</a><ul><li><a href=#%e5%9c%a8%e9%bb%98%e8%ae%a4%e6%b5%81%e4%b8%ad%e9%87%8d%e5%8f%a0%e4%b8%bb%e6%9c%ba%e5%92%8c%e8%ae%be%e5%a4%87%e8%ae%a1%e7%ae%97 aria-label=在默认流中重叠主机和设备计算>在默认流中重叠主机和设备计算</a></li><li><a href=#%e7%94%a8%e5%a4%9a%e4%b8%aa%e6%b5%81%e9%87%8d%e5%8f%a0%e5%a4%9a%e4%b8%aa%e6%a0%b8%e5%87%bd%e6%95%b0%e7%9a%84%e6%89%a7%e8%a1%8c aria-label=用多个流重叠多个核函数的执行>用多个流重叠多个核函数的执行</a></li><li><a href=#%e7%94%a8%e5%a4%9a%e4%b8%aa%e6%b5%81%e9%87%8d%e5%8f%a0%e6%a0%b8%e5%87%bd%e6%95%b0%e7%9a%84%e6%89%a7%e8%a1%8c%e4%b8%8e%e6%95%b0%e6%8d%ae%e4%bc%a0%e9%80%92 aria-label=用多个流重叠核函数的执行与数据传递>用多个流重叠核函数的执行与数据传递</a></li></ul></li></ul></li><li><a href=#%e5%90%8c%e6%ad%a5 aria-label=同步>同步</a><ul><li><a href=#%e6%a0%b8%e5%87%bd%e6%95%b0%e6%88%96grid%e4%b9%8b%e9%97%b4%e7%9a%84%e5%90%8c%e6%ad%a5 aria-label=核函数（或grid）之间的同步>核函数（或grid）之间的同步</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e5%9d%97%e6%88%96block%e5%86%85%e9%83%a8%e7%9a%84%e5%90%8c%e6%ad%a5 aria-label=线程块（或Block）内部的同步>线程块（或Block）内部的同步</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e5%9d%97%e6%88%96block%e4%b9%8b%e9%97%b4%e7%9a%84%e5%90%8c%e6%ad%a5 aria-label=线程块（或Block）之间的同步>线程块（或Block）之间的同步</a><ul><li><a href=#%e5%85%a8%e5%b1%80%e9%94%81%e5%8e%9f%e5%ad%90%e6%93%8d%e4%bd%9c aria-label=全局锁+原子操作>全局锁+原子操作</a></li><li><a href=#%e6%97%a0%e9%94%81%e6%96%b9%e6%b3%95 aria-label=无锁方法>无锁方法</a></li><li><a href=#%e5%86%85%e5%ad%98fence aria-label=内存fence>内存fence</a></li></ul></li><li><a href=#warp%e5%90%8c%e6%ad%a5 aria-label=warp同步>warp同步</a><ul><li><a href=#warp%e5%86%85inter-warp%e5%90%8c%e6%ad%a5 aria-label=warp内（inter-warp）同步>warp内（inter-warp）同步</a></li><li><a href=#%e5%8d%8f%e4%bd%9c%e7%bb%84 aria-label=协作组>协作组</a></li></ul></li><li><a href=#%e5%8e%9f%e5%ad%90%e6%93%8d%e4%bd%9c aria-label=原子操作>原子操作</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=cuda事件>CUDA事件<a hidden class=anchor aria-hidden=true href=#cuda事件>¶</a></h2><ul><li>事件：标记stream执行过程的某个特定的点，比如用于计时
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:22:38.png style=zoom:50%></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span> <span class=c1>// 创建cuda 事件对象。
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>  <span class=c1>// 将事件start关联到指定的流0
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>cudaEventQuery</span><span class=p>(</span><span class=n>start</span><span class=p>);</span>  <span class=c1>// 强制刷新 cuda 执行流，因为WDDM模式下，CUDA流中的操作显式提交到一个软件队列中（TCC模式不用）
</span></span></span><span class=line><span class=cl><span class=c1>// 此处不能使用CHECK，因为它可能返回cudaErrorNotReady，但是又不代表程序出错
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// run code.
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span> <span class=c1>// 强制同步，让主机等待cuda事件执行完毕。
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>float</span> <span class=n>elapsed_time</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>CHECK</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsed_time</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span> <span class=c1>// 计算 start 和stop间的时间差（ms）。
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>CHEKC</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=nf>CHEKC</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>    
</span></span></code></pre></td></tr></table></div></div><h2 id=cuda流>CUDA流<a hidden class=anchor aria-hidden=true href=#cuda流>¶</a></h2><ul><li><p>CUDA流：由主机发出的、在一个设备中执行的CUDA操作序列</p><ul><li><code>kernal_func&lt;&lt;&lt;grid_size, block_size, 0, stream>>>(params);</code></li><li>一个CUDA流中各个操作的次序是由主机控制的，但是来自于两个不同CUDA流中的操作顺序无法确定</li><li>任何CUDA操作都存在于某个CUDA流中，要么是默认流（也成为空流），要么明确指定的流</li></ul></li><li><p>相关函数</p><ul><li><code>cudaError_t cudaStreamCreate(cudaStream_t *stream);</code></li><li><code>cudaError_t cudaStreamDestory(cudaStream_t stream);</code></li><li><code>cudaError_t cudaStreamSynchronize(cudaStream_t stream);</code><ul><li>同步等待一个流中的所有操作完成</li></ul></li><li><code>cudaError_t cudaStreamQuery(cudaStream_t stream);</code><ul><li>查询一个流中的操作是否全部完成，不会阻塞；若是，则返回 <code>cudaSuccess</code>; 否则，返回 <code>cudaErrorNotReady</code>。</li></ul></li></ul></li></ul><h3 id=stream对并行性的影响>Stream对并行性的影响<a hidden class=anchor aria-hidden=true href=#stream对并行性的影响>¶</a></h3><ul><li>调度队列的个数：<ul><li>单调度队列：虽然Fermi架构支持最多16个流，但是实际调度过程中，所有的流被塞进同一个调度队列，当选中一个操作执行时，runtime会查看操作之间的依赖关系，如果当操作依赖于前面的操作，而且由于只有一个调度队列，因此调度队列阻塞（后面所有操作都等待，即使这些操作来自不同的流）
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:02:57.png alt=image-20231205220257004 style=zoom:40%></li><li>Hyper-Q：最多32个调度队列和32个流
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:03:46.png alt=image-20231205220346922 style=zoom:40%>
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-28-13:49:52.png alt=image-20231228134952484 style=zoom:33%></li></ul></li><li>多个流的操作的发射顺序<ul><li>左边将多个流以DFS方式发射，右边将多个流以BFS方式发射
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:22:17.png alt=image-20231205222217200 style=zoom:40%></li><li>以DFS方式发射时，流的发射顺序对并行性有影响<ul><li>每种资源都有一个队列</li><li>每个流内部很可能有依赖关系</li><li>比如先发射Stream1，后发射Stream2：
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:16:45.png alt=image-20231205221645005 style=zoom:40%></li><li>比如先发射Stream2，后发射Stream1：
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:17:33.png alt=image-20231205221733253 style=zoom:40%></li></ul></li></ul></li><li>每个操作操作具体占用的资源大小差异对并行性也有影响
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-22:25:42.png alt=image-20231205222542219 style=zoom:40%></li></ul><h3 id=使用流隐藏延迟>使用流隐藏延迟<a hidden class=anchor aria-hidden=true href=#使用流隐藏延迟>¶</a></h3><h4 id=在默认流中重叠主机和设备计算>在默认流中重叠主机和设备计算<a hidden class=anchor aria-hidden=true href=#在默认流中重叠主机和设备计算>¶</a></h4><ul><li>一些cuda runtime api具有隐式同步的效果（比如<code>cudaMemcpy</code>函数），会导致主机阻塞等待</li><li>核函数的调用是非阻塞的</li></ul><h4 id=用多个流重叠多个核函数的执行>用多个流重叠多个核函数的执行<a hidden class=anchor aria-hidden=true href=#用多个流重叠多个核函数的执行>¶</a></h4><ul><li>制约加速比的因素：（假设每个CUDA流都执行相同规模的计算）<ul><li>GPU的计算资源（SM数量，每个SM最多允许的线程数量）<ul><li>当CUDA流较少时，增加CUDA流的数量，总耗时只是略微增加，加速比线性增加，此时加速比没有饱和</li><li>当CUDA流的个数到达瓶颈，继续增加CUDA流的数量时，总耗时线性增加，加速比饱和
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:24:15.png style=zoom:80%></li></ul></li><li>单个GPU中能够并发运行的核函数个数的上限
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:24:16.png style=zoom:80%><ul><li>比如此时能够并发运行的核函数上限为32，Tesla K40有15个SM，每个SM最多允许2048个线程</li><li>比如此时一个核函数开1024线程，理论上最多并发运行的核函数$=\min{ \frac{15\times2048}{1024}, 32}=30$，此时限制因素为GPU的计算资源</li><li>比如此时一个核函数开128线程，理论上最多并发运行的核函数$=\min { \frac{15 \times 2048}{128}, 32 }=32$，此时限制因素为并发运行核函数的上限</li></ul></li></ul></li><li>参考<ul><li>《CUDA编程：基础与实践》</li></ul></li></ul><h4 id=用多个流重叠核函数的执行与数据传递>用多个流重叠核函数的执行与数据传递<a hidden class=anchor aria-hidden=true href=#用多个流重叠核函数的执行与数据传递>¶</a></h4><ul><li>将数据与相应操作分成若干份，每个流中依次进行操作，形成流水线
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:24:19.png style=zoom:60%><ul><li>理论上最大加速比为3（假设H2D,KER,D2H运行时间相同）</li></ul></li></ul><h2 id=同步>同步<a hidden class=anchor aria-hidden=true href=#同步>¶</a></h2><h3 id=核函数或grid之间的同步>核函数（或grid）之间的同步<a hidden class=anchor aria-hidden=true href=#核函数或grid之间的同步>¶</a></h3><ul><li>背景：连续发射两个核函数，其调度行为未知<ul><li>使用cuda graph显示指定核函数调度顺序（？不确定）</li></ul></li><li>相关函数<ul><li><code>cudaDeviceSynchronize</code>：阻塞host端，直到所有的kernel调用完毕<ul><li>原理是device设置了<code>cudaDeviceScheduleBlockingSync</code>标志，将host线程阻塞</li><li>在device中使用 <code>cudaDeviceSynchronize</code>已经被逐渐废弃</li></ul></li><li><code>cudaStreamSynchornize</code>：阻塞host端，直到流中的kernel调用完毕</li><li><code>cudaSetDeviceFlags</code>：记录标志，作为活动的host线程执行device代码时使用的标志</li><li><code>cudaLaunchKernel</code>：在CPU端使用<code>&lt;&lt;&lt;>>></code>launch核函数时，实际上调用的是该函数，launch核函数到GPU上执行</li></ul></li></ul><h3 id=线程块或block内部的同步>线程块（或Block）内部的同步<a hidden class=anchor aria-hidden=true href=#线程块或block内部的同步>¶</a></h3><ul><li>barrier：<code>__syncthreads()</code>同步Block内所有线程<ul><li>注意死锁问题：<code>__syncthreads</code>必须能被块内所有线程访问到，即不要将<code>__syncthreads</code>放到if-else语句中</li></ul></li><li><code>__syncthreads</code>的变种：<code>syncthreads_xxx(int predicate)</code><ul><li>与<code>__syncthreads</code>相同，但是有一个额外的功能：</li><li>predicate是一个条件表达式，该变种函数对所有线程评估predicate：<ul><li><code>__syncthreads_or</code>：如果有任意一个线程的predicate值非零，返回非零</li><li><code>__syncthreads_and</code>：如果对所有线程的predicate值非零，返回非零</li><li><code>__syncthreads_count</code>：统计所有线程中predicate值非零的线程数量</li></ul></li><li>应用：last-block guard确定最后一个线程块（编号最后的线程块未必是最后运行结束的）<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>int</span> <span class=n>counter</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>bool</span> <span class=nf>lastBlock</span><span class=p>(</span><span class=kt>int</span><span class=o>*</span> <span class=n>counter</span><span class=p>){</span> <span class=c1>// 方法一：
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>__shared__</span> <span class=kt>int</span> <span class=n>last</span><span class=p>;</span>  <span class=c1>// 表示当前已经调度发射了多少个线程块
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__threadfence</span><span class=p>();</span> <span class=c1>// 确保之前计算的结果已经写入内存，对所有线程块可见
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=c1>// 每个块中第一个线程维护last的值
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>last</span> <span class=o>=</span> <span class=nf>atomicAdd</span><span class=p>(</span><span class=n>counter</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span> <span class=c1>// 原子更新全局内存中的变量，将更新后的值返回到共享内存中
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 块内所有线程同步，有必要。如果没有线程块内同步，则一个线程块内对last的访问有的是新值，有的是旧值，但是又必须要求一个线程块内部的last值都相同。注意没有保证不同的线程块之间是同步的
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>last</span> <span class=o>==</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>bool</span> <span class=nf>lastBlock</span><span class=p>(</span><span class=kt>int</span><span class=o>*</span> <span class=n>counter</span><span class=p>){</span> <span class=c1>// 方法二：
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__threadfence</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>last</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// 寄存器变量
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>last</span> <span class=o>=</span> <span class=nf>atomicAdd</span><span class=p>(</span><span class=n>counter</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span> <span class=c1>// 块内线程不需要完全同步
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=nf>__syncthreads_or</span><span class=p>(</span><span class=n>last</span> <span class=o>==</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span> <span class=c1>// 仍需要使用__syncthreads_or，因为一个线程块内部，只有0号线程的last是用来维护计数的。因此只要0号线程计算完即可确定当前线程块是否为最后一个
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li></ul><h3 id=线程块或block之间的同步>线程块（或Block）之间的同步<a hidden class=anchor aria-hidden=true href=#线程块或block之间的同步>¶</a></h3><h4 id=全局锁原子操作>全局锁+原子操作<a hidden class=anchor aria-hidden=true href=#全局锁原子操作>¶</a></h4><p>线程块内选一个代表，通过维护锁变量，代表先进行同步，从而线程块同步</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>__device__</span> <span class=k>volatile</span> <span class=kt>int</span> <span class=n>g_mutex</span><span class=p>;</span> <span class=c1>// 全局锁变量
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>__deviec__</span> <span class=kt>void</span> <span class=nf>__gpu_sync</span><span class=p>(</span><span class=kt>int</span> <span class=n>goalVal</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid_in_block</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>y</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>tid_in_block</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span> <span class=c1>// 每个线程块中的0号线程 作为线程块的代表
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>atomicAdd</span><span class=p>((</span><span class=kt>int</span><span class=o>*</span><span class=p>)</span><span class=o>&amp;</span><span class=n>g_mutex</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span> 
</span></span><span class=line><span class=cl>        <span class=k>while</span><span class=p>(</span><span class=n>g_mutex</span> <span class=o>!=</span> <span class=n>goalVal</span><span class=p>){</span> <span class=cm>/* Do nothing */</span><span class=p>}</span> <span class=c1>// 死循环，直到g_mutex到达goalVal的值
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// 这里，goalVal个线程块之间达成同步
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=无锁方法>无锁方法<a hidden class=anchor aria-hidden=true href=#无锁方法>¶</a></h4><ul><li>将块间同步转换为块内同步<ul><li>为每个线程块分配一个同步变量，形成一个数组<code>Arrayin</code>
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-27-11:22:43.png style=zoom:40%></li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>void</span> <span class=nf>__gpu_sync</span><span class=p>(</span><span class=kt>int</span> <span class=n>goalVal</span><span class=p>,</span> <span class=k>volatile</span> <span class=kt>int</span><span class=o>*</span> <span class=n>Arrayin</span><span class=p>,</span> <span class=k>volatile</span> <span class=kt>int</span><span class=o>*</span> <span class=n>Arrayout</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid_in_block</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>y</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span> <span class=c1>// 线程在block中的id
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>nBlockNum</span> <span class=o>=</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>y</span><span class=p>;</span> <span class=c1>// block数量
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>bid</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>y</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span> <span class=c1>// 线程块id
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>tid_in_block</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=c1>// 每个线程块的0号线程，基于自己线程块的索引，更新Arrayin数组
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>Arrayin</span><span class=p>[</span><span class=n>bid</span><span class=p>]</span> <span class=o>=</span> <span class=n>goalVal</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// 0号线程块进行控制
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>bid</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span> <span class=c1>// 将块间同步转换为线程块0号内部的块内同步
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span><span class=p>(</span><span class=n>tid_in_block</span> <span class=o>&lt;</span> <span class=n>nBlockNum</span><span class=p>)</span> <span class=p>{</span> <span class=c1>// 0号线程块中，每个线程控制一个线程块
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=k>while</span><span class=p>(</span><span class=n>Arrayin</span><span class=p>[</span><span class=n>tid_in_block</span><span class=p>]</span> <span class=o>!=</span> <span class=n>goalVal</span><span class=p>)</span> <span class=p>{</span> <span class=cm>/* Do nothing */</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 0号线程块内进行同步。
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// 0号线程块执行到这里，表示所有线程块已经完成初始化Arrayin数组
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span><span class=p>(</span><span class=n>tid_in_block</span> <span class=o>&lt;</span> <span class=n>nBlockNum</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>Arrayout</span><span class=p>[</span><span class=n>tid_in_block</span><span class=p>]</span> <span class=o>=</span> <span class=n>goalVal</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>tid_in_block</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span> <span class=c1>// 每个线程块的0号线程
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>while</span><span class=p>(</span><span class=n>Arrayout</span><span class=p>[</span><span class=n>bid</span><span class=p>]</span> <span class=o>!=</span> <span class=n>goalVal</span><span class=p>)</span> <span class=p>{</span> <span class=cm>/* Do nothing */</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 同步所有块内线程
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=内存fence>内存fence<a hidden class=anchor aria-hidden=true href=#内存fence>¶</a></h4><ul><li>背景：CUDA 编程模型假定了一种<a href=https://zhuanlan.zhihu.com/p/94421667>弱顺序(weakly-ordered)</a>一致性的内存模型</li></ul><blockquote><ul><li>内存一致性（memory consistency）：访存操作在全局中生效（或观察到的）顺序问题， 是指令集所规范的，是软硬件接口的一部分</li><li>缓存一致性（cache coherence）：同一个地址在不同的缓存中一致性问题，是完全的硬件实现策略，程序员无关，是集成电路设计者考虑的东西。</li></ul></blockquote><ul><li>内存fence：读写操作可能进行重排or优化，添加fence之后，fence之前的op一定比fence之后的op先执行。即抑制编译器重排、抑制乱序。</li></ul><blockquote><ul><li>内存fence：The CUDA programming model assumes a device with a weakly-ordered memory model. Memory fence functions can be used to enforce a <a href=https://en.cppreference.com/w/cpp/atomic/memory_order>sequentially-consistent</a> ordering on memory accesses.</li><li><code>volatile</code>：声明一个变量，防止编译器优化，防止这个变量存入缓存，如果恰好此时被其他线程改写，那就会造成内存缓存不一致的错误，所以volatile声明的变量始终在全局内存中。</li></ul></blockquote><ul><li>内存fence只会影响自己线程中内存操作的顺序，保证自己的数据fence后能够被其他线程安全的访问，并不能像<code>__syncthreads</code>那样保证内存操作对于同block中的其他线程可见</li><li>相关函数<ul><li><code>__threadfence_block()</code>：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对block内所有线程可见。</li><li><code>__threadfence()</code>：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对grid内所有线程可见。</li><li><code>__threadfence_system()</code>：该函数调用后，该线程在此语句前对全局存储器或共享存储器的访问已经全部完成，且结果对system（CPU+GPU）内所有线程可见。</li></ul></li><li>参考：<ul><li><a href=https://www.bilibili.com/read/cv18722474/>CUDA内存栅栏（Memory Fence）理解</a></li></ul></li></ul><h3 id=warp同步>warp同步<a hidden class=anchor aria-hidden=true href=#warp同步>¶</a></h3><h4 id=warp内inter-warp同步>warp内（inter-warp）同步<a hidden class=anchor aria-hidden=true href=#warp内inter-warp同步>¶</a></h4><ul><li><p>barrier：<code>__syncwarps()</code>同步一个warp中的线程</p></li><li><p>线程束内函数都有 <code>_sync</code> 后缀，表示这些函数都具有隐式的同步功能。</p><ul><li>线程束表决函数（warp vote functions）<ul><li><code>unsigned __ballot_sync(unsigned mask, int predicate)</code>：如果线程束内第n个线程参与计算（旧掩码）且predicate值非零，则返回的无符号整型数（新掩码）的第n个二进制位为1，否则为0</li><li><code>int __all_sync(unsigned mask, int predicate)</code>：线程束内所有参与线程的predicate值均非零，则返回1，否则返回0</li><li><code>int __any_sync(unsigned mask, int predicate)</code>：线程束内所有参与线程的predicate值存在非零，则返回1， 否则返回0</li></ul></li><li>线程束匹配函数（warp match functions）</li><li>线程束洗牌函数（warp shuffle functions）：最后一个参数表示逻辑上的warp大小<ul><li><code>T __shfl_sync(unsigned mask, T v, int srcLane, int w = warpSize)</code>：参与线程返回标号为 srcLane 的线程中变量 v 的值。该函数将一个线程中的数据广播到所有线程。</li><li><code>T __shfl_up_sync(unsigned mask, T v, unsigned d, int w=warpSize)</code>：标号为t的参与线程返回标号为 t-d 的线程中变量v的值，t-d&lt;0的线程返回t线程的变量v。该函数是一种将数据向上平移的操作，即将低线程号的值平移到高线程号。<ul><li>例如当w=8、d=2时，2-7号线程将返回 0-5号线程中变量v的值；0-1号线程返回自己的 v。</li></ul></li><li><code>T __shfl_down_sync(unsigned mask, T v, unsigned d, int w=warpSize)</code>：标号为t的参与线程返回标号为 t+d 的线程中变量v的值，t+d>w的线程返回t线程的变量v。该函数是一种将数据向下平移的操作，即将高线程号的值平移到低线程号。</li></ul><ul><li>例如当w=8、d=2时，0-5号线程将返回2-7号线程中变量v的值，6-7号线程将返回自己的 v。</li></ul><ul><li><code>T __shfl__xor_sync(unsigned mask, T v, int laneMask, int w=warpSize)</code>：标号为t的参与线程返回标号为 t^laneMask 的线程中变量 v 的值。该函数让线程束内的线程两两交换数据。</li></ul></li><li>线程束矩阵函数（warp matrix functions）</li></ul></li><li><p>例子：使用warp shuffle函数进行规约：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>reduce_shfl</span><span class=p>(</span><span class=k>const</span> <span class=n>real</span> <span class=o>*</span><span class=n>d_x</span><span class=p>,</span> <span class=n>real</span> <span class=o>*</span><span class=n>d_y</span><span class=p>,</span> <span class=k>const</span> <span class=kt>int</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> <span class=c1>// tid从0到blockDim.x
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>int</span> <span class=n>bid</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>tid</span> <span class=o>+</span> <span class=n>bid</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>extern</span> <span class=n>__shared__</span> <span class=n>real</span> <span class=n>s</span><span class=p>[];</span> <span class=c1>// 比如大小128
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>)</span> <span class=o>?</span> <span class=n>d_x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>:</span> <span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>unsigned</span> <span class=n>FULL_MASK</span> <span class=o>=</span> <span class=mh>0xffffffff</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 线程块同步函数
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>1</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;=</span> <span class=mi>32</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>offset</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>            <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+=</span> <span class=n>s</span><span class=p>[</span><span class=n>tid</span> <span class=o>+</span> <span class=n>offset</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>real</span> <span class=n>y</span> <span class=o>=</span> <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=mi>16</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>+=</span> <span class=nf>__shfl_down_sync</span><span class=p>(</span><span class=n>FULL_MASK</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>offset</span><span class=p>);</span> <span class=c1>// 线程tid返回线程tid+offset中寄存器变量y的值
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>atomicAdd</span><span class=p>(</span><span class=n>d_y</span><span class=p>,</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li></ul><h4 id=协作组>协作组<a hidden class=anchor aria-hidden=true href=#协作组>¶</a></h4><p>协作组（cooperative groups）:提供了线程块以上级别的同步</p><ul><li><p><code>thread_group</code></p><ul><li>协作组编程模型中最基本的类型，是线程块级别的协作组</li><li>成员函数：<ul><li><code>void sync()</code>，同步组内所有线程；（相当于<code>__syncthreads</code>函数）</li><li><code>unsigned size()</code>，返回组内总的线程数目，即组的大小；</li><li><code>unsigned thread_rank()</code>，返回当前调用该函数的线程在组内的标号（从0计数）</li><li><code>bool is_valid()</code>，如果定义的组违反了任何cuda限制，返回 false，否则true</li></ul></li></ul></li><li><p><code>thread_block</code>继承于<code>thread_group_base&lt;T></code>，<code>thread_group_base&lt;T></code>继承于<code>thread_group</code></p><ul><li><code>dim3 group_index()</code>，返回当前调用该函数的线程的线程块指标，等价于 <code>blockIdx</code>；</li><li><code>dim3 thread_index()</code>，返回当前调用该函数的线程的线程指标，等价于 <code>threadIdx</code>；</li><li><code>this_thread_block()</code>：初始化一个<code>thread_block</code>对象</li><li><code>tiled_partition()</code> ：将一个<code>thread_block</code>划分为若干片（tile），每片构成一个<code>thread_group</code></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cooperative_groups.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=n>using</span> <span class=n>namespace</span> <span class=n>cooperative_groups</span><span class=p>;</span> <span class=c1>// 相关变量和函数定义在该命名空间下
</span></span></span><span class=line><span class=cl><span class=c1>// namespace cg = cooperative_groups; // 取别名
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=n>thread_block</span> <span class=n>g</span> <span class=o>=</span> <span class=nf>this_thread_block</span><span class=p>();</span>  <span class=c1>// g相当于一个之前的线程块，这里将其包装为一个类型
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>thread_group</span> <span class=n>myWarp</span> <span class=o>=</span> <span class=nf>tiled_partition</span><span class=p>(</span><span class=n>g</span><span class=p>,</span> <span class=mi>32</span><span class=p>);</span> <span class=c1>// 将thread_block划分为thread_group
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>thread_group</span> <span class=n>g4</span> <span class=o>=</span> <span class=nf>tiled_partition</span><span class=p>(</span><span class=n>myWarp</span><span class=p>,</span> <span class=mi>4</span><span class=p>);</span> <span class=c1>// 可以将thread_group进一步细分
</span></span></span></code></pre></td></tr></table></div></div></li><li><p><code>thread_block_tile</code></p><ul><li>使用模板，在编译期划分 <strong>线程块片（thread block tile）</strong><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>thread_block_tile</span><span class=o>&lt;</span><span class=mi>32</span><span class=o>&gt;</span> <span class=n>g32</span> <span class=o>=</span> <span class=n>tiled_partition</span><span class=o>&lt;</span><span class=mi>32</span><span class=o>&gt;</span><span class=p>(</span><span class=nf>this_thread_block</span><span class=p>());</span>
</span></span><span class=line><span class=cl><span class=n>thread_block_tile</span><span class=o>&lt;</span><span class=mi>32</span><span class=o>&gt;</span> <span class=n>g4</span> <span class=o>=</span> <span class=n>tiled_partition</span><span class=o>&lt;</span><span class=mi>4</span><span class=o>&gt;</span><span class=p>(</span><span class=nf>this_thread_block</span><span class=p>());</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li><li><p>线程块片具有额外的函数（类似线程束内函数）：</p><ul><li><code>unsigned ballot(int predicate)</code>;</li><li><code>int all(int predicate)</code>;</li><li><code>int any(int predicate)</code>;</li><li><code>T shfl(T v, int srcLane)</code>;</li><li><code>T shfl_up(T v, unsigned d)</code>;</li><li><code>T shfl_down(T v, unsigned d)</code>;</li><li><code>T shfl_xor(T v, unsigned d)</code>;</li></ul><ul><li>与一般的线程束不同，线程组内的所有线程都要参与代码运行计算；同时，线程组内函数不需要指定宽度，因为该宽度就是线程块片的大小。</li></ul></li><li><p>例子：使用协作组进行规约：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>reduce_cp</span><span class=p>(</span><span class=k>const</span> <span class=n>real</span> <span class=o>*</span><span class=n>d_x</span><span class=p>,</span> <span class=n>real</span> <span class=o>*</span><span class=n>d_y</span><span class=p>,</span> <span class=k>const</span> <span class=kt>int</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> <span class=c1>// tid从0到blockDim.x
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>int</span> <span class=n>bid</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>tid</span> <span class=o>+</span> <span class=n>bid</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>extern</span> <span class=n>__shared__</span> <span class=n>real</span> <span class=n>s</span><span class=p>[];</span> <span class=c1>// 比如大小128
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>)</span> <span class=o>?</span> <span class=n>d_x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>:</span> <span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 线程块同步函数
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>1</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;=</span> <span class=mi>32</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>offset</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>            <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+=</span> <span class=n>s</span><span class=p>[</span><span class=n>tid</span> <span class=o>+</span> <span class=n>offset</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>real</span> <span class=n>y</span> <span class=o>=</span> <span class=n>s</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>thread_block_tile</span><span class=o>&lt;</span><span class=mi>32</span><span class=o>&gt;</span> <span class=n>g</span> <span class=o>=</span> <span class=n>tiled_patition</span><span class=o>&lt;</span><span class=mi>32</span><span class=o>&gt;</span><span class=p>(</span><span class=nf>this_thread_block</span><span class=p>());</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>g</span><span class=p>.</span><span class=nf>size</span><span class=p>()</span> <span class=o>&gt;&gt;</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>+=</span> <span class=n>g</span><span class=p>.</span><span class=nf>shfl_down</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>i</span><span class=p>);</span> <span class=c1>// 使用协作组的成员函数与使用warp shuffle函数具有等价的执行效率
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>atomicAdd</span><span class=p>(</span><span class=n>d_y</span><span class=p>,</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>more</p><ul><li><a href=https://www.zhihu.com/question/586453330/answer/3232856921>https://www.zhihu.com/question/586453330/answer/3232856921</a></li></ul></li></ul><h3 id=原子操作>原子操作<a hidden class=anchor aria-hidden=true href=#原子操作>¶</a></h3><ul><li>两类原子函数：<ul><li>atomicAdd_system：将原子函数的作用范围拓展到所有节点（host和device）</li><li>atomicAdd_block：将原子函数的作用范围缩小至一个线程块</li><li>一个特殊的原子函数：<code>atomicCAS</code>，所有其他原子函数都可以使用它来实现</li></ul></li><li>相关语法：<ul><li>原子函数的返回值都是原来的旧值</li><li>原子函数都是<code>__device__</code>函数，只能在核函数中使用</li><li>原子函数操作的地址可以位于全局内存，也可以位于共享内存</li><li>原子操作开销与是否存在竞争相关，且参与竞争者越少，开销越小</li></ul></li><li>例子：使用原子函数进行规约<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>reduce_shared</span><span class=p>(</span><span class=n>real</span> <span class=o>*</span><span class=n>d_x</span><span class=p>,</span> <span class=n>real</span> <span class=o>*</span><span class=n>d_y</span><span class=p>,</span> <span class=k>const</span> <span class=kt>int</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>bid</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>extern</span> <span class=n>__shared__</span> <span class=n>real</span> <span class=n>s_y</span><span class=p>[];</span> <span class=c1>// 动态共享内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>s_y</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>)</span> <span class=o>?</span> <span class=n>d_x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>:</span> <span class=mf>0.0</span><span class=p>;</span> <span class=c1>// 将全局内存中的数据拷贝到线程块对应的共享内存中
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>// 保证一个线程块中的同步，但是不能保证不同线程块之间的同步
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>1</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>offset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>s_y</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+=</span> <span class=n>s_y</span><span class=p>[</span><span class=n>tid</span> <span class=o>+</span> <span class=n>offset</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>atomicAdd</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_y</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>s_y</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span> <span class=c1>// 使用原子操作，将结果累加到d_y[0]
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>内存模型</span>
</a><a class=next href=https://qinganzhang.github.io/posts/cuda-learning-notes/gpu%E6%9E%B6%E6%9E%84%E5%8F%91%E5%B1%95%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%BC%96%E8%AF%91/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>GPU架构发展、兼容性和编译</span></a></nav></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qinganzhang.github.io/>Paul's Blog</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span><span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>