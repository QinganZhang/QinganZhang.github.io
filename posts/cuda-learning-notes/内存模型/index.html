<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[cuda-learning-notes] 内存模型 | Paul's Blog</title>
<meta name=keywords content="cuda"><meta name=description content="内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局"><meta name=author content="Paul"><link rel=canonical href=https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/><link crossorigin=anonymous href=/assets/css/stylesheet.min.css rel="preload stylesheet" as=style><link rel=icon href=https://qinganzhang.github.io/favicon.ico><link rel=apple-touch-icon href=https://qinganzhang.github.io/apple-touch-icon.png><meta name=twitter:title content="[cuda-learning-notes] 内存模型 | Paul's Blog"><meta name=twitter:description content="内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局"><meta property="og:title" content="[cuda-learning-notes] 内存模型 | Paul's Blog"><meta property="og:description" content="内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局"><meta property="og:type" content="article"><meta property="og:url" content="https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-01T22:01:50+08:00"><meta property="article:modified_time" content="2024-03-01T22:01:50+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Post","item":"https://qinganzhang.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[cuda-learning-notes] 内存模型","item":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[cuda-learning-notes] 内存模型 | Paul's Blog","name":"[cuda-learning-notes] 内存模型","description":"内存模型 全局内存 对全局内存变量的理解： 从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作 从设备端看，即为全局","keywords":["cuda"],"wordCount":"7450","inLanguage":"en","datePublished":"2024-03-01T22:01:50+08:00","dateModified":"2024-03-01T22:01:50+08:00","author":{"@type":"Person","name":"Paul"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qinganzhang.github.io/posts/cuda-learning-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},"publisher":{"@type":"Organization","name":"Paul's Blog","logo":{"@type":"ImageObject","url":"https://qinganzhang.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://qinganzhang.github.io/ accesskey=h title="Paul's Blog (Alt + H)">Paul's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://qinganzhang.github.io/posts/ title=Posts class=active>Posts</a></li><li><a href=https://qinganzhang.github.io/archives/ title=Archive>Archive</a></li><li><a href=https://qinganzhang.github.io/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li><li><a href=https://qinganzhang.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://qinganzhang.github.io/categories/ title=Categories>Categories</a></li><li><a href=https://qinganzhang.github.io/about/ title=About>About</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://qinganzhang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://qinganzhang.github.io/posts/>Post</a></div><h1 class=post-title>[cuda-learning-notes] 内存模型</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>2024-03-01</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://qinganzhang.github.io/tags/cuda/>cuda</a></span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>7450 words</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>15 min</span></span></div></header><div class="toc side right"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%86%85%e5%ad%98%e6%a8%a1%e5%9e%8b aria-label=内存模型>内存模型</a><ul><li><a href=#%e5%85%a8%e5%b1%80%e5%86%85%e5%ad%98 aria-label=全局内存>全局内存</a><ul><li><a href=#%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b aria-label=编程模型>编程模型</a></li><li><a href=#%e4%bc%98%e5%8c%96 aria-label=优化>优化</a><ul><li><a href=#%e5%85%a8%e5%b1%80%e5%86%85%e5%ad%98%e7%9a%84%e5%af%b9%e9%bd%90%e5%90%88%e5%b9%b6%e8%ae%bf%e9%97%ae aria-label=全局内存的对齐合并访问>全局内存的对齐合并访问</a></li><li><a href=#%e5%ae%9a%e9%87%8f%e8%a1%a1%e9%87%8f%e6%a0%b8%e5%87%bd%e6%95%b0%e7%9a%84%e6%9c%89%e6%95%88%e5%b8%a6%e5%ae%bd aria-label=定量衡量核函数的有效带宽>定量衡量核函数的有效带宽</a></li><li><a href=#%e7%bb%93%e6%9e%84%e4%bd%93%e6%95%b0%e7%bb%84%e5%92%8c%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84%e4%bd%93 aria-label=结构体数组和数据结构体>结构体数组和数据结构体</a></li><li><a href=#%e5%85%b6%e4%bb%96 aria-label=其他>其他</a></li></ul></li></ul></li><li><a href=#%e5%b8%b8%e9%87%8f%e5%86%85%e5%ad%98 aria-label=常量内存>常量内存</a></li><li><a href=#%e7%ba%b9%e7%90%86%e5%92%8c%e8%a1%a8%e9%9d%a2%e5%86%85%e5%ad%98 aria-label=纹理和表面内存>纹理和表面内存</a></li><li><a href=#%e5%af%84%e5%ad%98%e5%99%a8 aria-label=寄存器>寄存器</a></li><li><a href=#%e5%b1%80%e9%83%a8%e5%86%85%e5%ad%98 aria-label=局部内存>局部内存</a></li><li><a href=#%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98 aria-label=共享内存>共享内存</a><ul><li><a href=#%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b-1 aria-label=编程模型>编程模型</a></li><li><a href=#%e4%bc%98%e5%8c%96-1 aria-label=优化>优化</a></li></ul></li><li><a href=#%e7%bc%93%e5%ad%98 aria-label=缓存>缓存</a></li></ul></li><li><a href=#cpu%e7%9a%84%e4%b8%80%e7%ba%a7%e7%bc%93%e5%ad%98%e6%98%af%e7%9a%84%e6%9b%bf%e6%8d%a2%e7%ae%97%e6%b3%95%e6%98%af%e6%9c%89%e4%bd%bf%e7%94%a8%e9%a2%91%e7%8e%87%e5%92%8c%e6%97%b6%e9%97%b4%e5%b1%80%e9%83%a8%e6%80%a7%e7%9a%84gpu%e5%88%99%e6%b2%a1%e6%9c%89 aria-label=CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有>CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有</a></li><li><a href=#%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86 aria-label=内存管理>内存管理</a><ul><li><a href=#%e5%b8%b8%e8%a7%84%e6%95%b0%e6%8d%ae%e4%bc%a0%e8%be%93%e5%87%bd%e6%95%b0 aria-label=常规数据传输函数>常规数据传输函数</a></li><li><a href=#%e7%bb%9f%e4%b8%80%e5%86%85%e5%ad%98 aria-label=统一内存>统一内存</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=内存模型>内存模型<a hidden class=anchor aria-hidden=true href=#内存模型>¶</a></h2><img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:11:11.png style=zoom:70%><h3 id=全局内存>全局内存<a hidden class=anchor aria-hidden=true href=#全局内存>¶</a></h3><ul><li><p>对全局内存变量的理解：</p><ul><li>从主机端看，全局内存变量只是一个指针，主机端不知道其指向何方。主机端也无法进行操作</li><li>从设备端看，即为全局内存变量</li><li>一个经常会发生的错误就是混用设备和主机的内存地址：主机代码不能直接访问设备变量，设备也不能直接访问主机变量</li></ul></li><li><p>对全局内存的读写</p><ul><li>如果是读操作，有三种部分的访问方式：<ul><li>L1缓存，L2缓存，DRAM</li><li>（禁用L1缓存）L2缓存，DRAM<ul><li>Fermi之后都是默认禁用L1</li><li>禁用L1缓存的原因是，L1缓存被用作缓冲从寄存器中溢出的数据</li></ul></li><li>只读缓存，L2缓存，DRAM</li></ul></li><li>如果是写操作，则无法被缓存，只经过device层次的L2缓存，没有命中再访问DRAM<ul><li>==不是很清楚==</li></ul></li></ul></li></ul><h4 id=编程模型>编程模型<a hidden class=anchor aria-hidden=true href=#编程模型>¶</a></h4><ul><li>动态全局内存：</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>double</span> <span class=o>*</span><span class=n>d_x</span><span class=p>;</span> 
</span></span><span class=line><span class=cl><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)(</span><span class=o>&amp;</span><span class=n>d_x</span><span class=p>),</span> <span class=mi>100</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>));</span> <span class=c1>// d_x改变为指向设备全局内存的指针
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>double</span> <span class=o>*</span><span class=n>h_x</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>h_x</span> <span class=o>=</span> <span class=p>(</span><span class=kt>double</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=mi>100</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>));</span> <span class=c1>// h_x是指向主机内存的指针
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_x</span><span class=p>,</span> <span class=n>h_x</span><span class=p>,</span> <span class=mi>100</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span> 
</span></span></code></pre></td></tr></table></div></div><ul><li>静态全局内存：<ul><li>如果静态全局变量是一个变量（而非数组类型）：此时主机中不可以直接给静态全局内存变量赋值，可以通过 <code>cudaMemcpyToSymbol()</code> 和 <code>cudaMemcpyFromSymbol()</code> 拷贝。 （一个例外：固定内存）<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>double</span> <span class=n>d</span><span class=p>;</span> <span class=c1>// 从设备端来看，d直接就是设备全局内存上的变量；从主机端来看，d是一个指针，但是不知道其指向哪里
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>double</span> <span class=n>h</span> <span class=o>=</span> <span class=mf>0.0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>cudaMemcpyToSymbol</span><span class=p>(</span><span class=n>d</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>h</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>));</span> <span class=c1>// H2D
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>cudaMemcpyFromSymbol</span><span class=p>(</span><span class=o>&amp;</span><span class=n>h</span><span class=p>,</span> <span class=n>d</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>));</span> <span class=c1>// D2H
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 因为使用cudaMemcpy需要得到d的地址，而主机端无法直接操作设备端的变量。如果非要使用cudaMemcpy:
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>double</span> <span class=o>*</span><span class=n>dptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>cudaGetSymbolAddress</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)(</span><span class=o>&amp;</span><span class=n>dptr</span><span class=p>),</span> <span class=n>d</span><span class=p>);</span> <span class=c1>// 因为主机无法对全局内存变量d取地址，只能使用函数间接得到其地址dptr
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>dptr</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=mi>100</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>),</span> <span class=n>cudaMemcpyToDevice</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div></li><li>如果静态全局变量是一个数组，可以使用<code>cudaMemcpy</code>：<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>double</span> <span class=n>d_x</span><span class=p>[</span><span class=mi>100</span><span class=p>];</span> <span class=c1>// d_x[]直接就是设备全局内存上的数组，d_x是其地址
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>double</span> <span class=n>h_x</span><span class=p>[</span><span class=mi>100</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_x</span><span class=p>,</span> <span class=n>h_x</span><span class=p>,</span> <span class=mi>100</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>double</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li></ul><h4 id=优化>优化<a hidden class=anchor aria-hidden=true href=#优化>¶</a></h4><p>全局内存访问速度慢，往往是一个 CUDA 程序的性能瓶颈。
优化目标：</p><ul><li>对齐合并的内存访问，减少带宽浪费</li><li>足够的并发内存操作，隐藏内存延迟</li></ul><h5 id=全局内存的对齐合并访问>全局内存的对齐合并访问<a hidden class=anchor aria-hidden=true href=#全局内存的对齐合并访问>¶</a></h5><ul><li><p>访问粒度：</p><ul><li>L1的缓存粒度为128字节（可以禁用L1缓存，只使用L2缓存）</li><li>L2的缓存粒度为32字节</li><li>只读缓存也可以缓存全局内存中的数据，缓存粒度为32字节<ul><li>使用<code>__ldg()</code>函数将全局内存缓存到只读缓存中</li><li>如果编译器能够判断一个全局内存变量在整个核函数的范围内都可读，则自动使用<code>__ldg()</code>函数进行缓存，但是对于全局的写入，没有相应的函数</li><li>可以使用<code>__restrict__</code>修饰指针，表示该指针专门用来访问特定的数组（该指针不是别名），nvcc使用只读缓存进行加载</li></ul></li></ul></li><li><p>内存对齐：</p><ul><li>一次数据传输中，从全局内存转移到 L2 缓存的一片内存的首地址一定是 32 的整数倍。</li><li>使用cuda runtime api（比如cudaMalloc）分配的内存的首地址至少是256字节的整数倍</li></ul></li><li><p>内存事务：从核函数发起请求，到硬件相应返回数据这个过程</p><ul><li>内存事务可以分为1段，2段，4段</li><li>比如全局内存写入时，经过L2缓存，缓存粒度为32字节，此时一次内存事务可以写入1段32字节，2段64字节，4段128字节，其他字节数量只能组合得到</li></ul></li><li><p>全局内存的访问模式：</p><ul><li>对齐的：内存事务的首地址是缓存粒度的整数倍</li><li>合并的（coalesced）：一个warp对全局内存的访问都在一个缓存粒度中（一个warp对全局内存的访问导致最少数量的数据传输），或者可以理解为缓存利用率<ul><li>合并度=$\frac{warp请求的字节数}{由该请求导致的所有数据传输的字节数}$</li></ul></li></ul></li><li><p>几种常见的内存访问模式：（以一维的grid和一维的block为例）</p><ul><li>理想的内存访问：顺序的合并访问，合并度=100%</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>add</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>y</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>z</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>add</span><span class=o>&lt;&lt;&lt;</span><span class=mi>128</span><span class=p>,</span> <span class=mi>32</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>乱序的合并访问：访问是交叉的，但仍是合并的，合并度=100%</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>add_permuted</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>y</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>z</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid_permuted</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>^</span> <span class=mh>0x1</span><span class=p>;</span> <span class=c1>// 交换两个相邻的数
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>// 比如：threadIdx.x=0, tid_permuted=1; threadIdx.x=1;tid_permuted=0;
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>tid_permuted</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>add_permuted</span><span class=o>&lt;&lt;&lt;</span><span class=mi>128</span><span class=p>,</span> <span class=mi>32</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>不对齐的非合并访问（地址错位）<ul><li>如果使用L1 cache，访问粒度为128字节，速度快，但是带宽利用率更低</li><li>如果不使用L1 cache，访问粒度为32字节，速度慢，但是带宽利用率更高，从而可以提高总线的整体利用率</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>add_offset</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>y</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>z</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>add_offset</span><span class=o>&lt;&lt;&lt;</span><span class=mi>128</span><span class=p>,</span> <span class=mi>32</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c1>// 对于某个thread block，有32个线程
</span></span></span><span class=line><span class=cl><span class=c1>// 假设数组x，y，z首地址都是256字节的倍数，而一次访存至少32字节
</span></span></span><span class=line><span class=cl><span class=c1>// 由于地址错位，需要进行五次访存，合并度=128/(5*32)=80%
</span></span></span></code></pre></td></tr></table></div></div><ul><li>跨越式非合并访问<ul><li>如果使用L1 cache，访问粒度为128字节，合并度很低（而且出现频繁的缓存失效和替换）</li><li>如果不使用L1 cache，访问粒度为32字节，合并度稍微提升</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>add_stride</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>y</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>z</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>add_stride</span><span class=o>&lt;&lt;&lt;</span><span class=mi>128</span><span class=p>,</span> <span class=mi>32</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c1>// 对于0号线程块(blockIdx.x=0)，将访问：0， 128， 256， 384 ... 等位置
</span></span></span><span class=line><span class=cl><span class=c1>// 即stride=gridDim.x=128
</span></span></span><span class=line><span class=cl><span class=c1>// 合并度=128/(32*32)=12.5%，触发32次访存，每次访存32字节
</span></span></span></code></pre></td></tr></table></div></div><ul><li>广播式非合并访问</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span> <span class=n>__global__</span> <span class=nf>add_broadcast</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>y</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>z</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span><span class=p>[</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=c1>// 合并度=4/32=12.5%
</span></span></span><span class=line><span class=cl><span class=c1>// 虽然合并度低，但是整个过程只进行了一次访存
</span></span></span><span class=line><span class=cl><span class=c1>// 其实更适合使用常量内存
</span></span></span></code></pre></td></tr></table></div></div></li></ul><h5 id=定量衡量核函数的有效带宽>定量衡量核函数的有效带宽<a hidden class=anchor aria-hidden=true href=#定量衡量核函数的有效带宽>¶</a></h5><ul><li><p>带宽：</p><ul><li>理论带宽：硬件限制</li><li>有效带宽：核函数实际达到的带宽，$有效带宽=\frac{(读字节数+写字节数)\times 10^{-9}}{运行时间}$</li><li>吞吐量：单位时间内操作的执行速度，比如说FPS或（流水线）每个周期完成都少个指令，不仅取决于有效带宽，而且与带宽的利用率、是否命中缓存有关<ul><li>比如数据经常命中缓存，此时吞吐量就可能超过有效带宽</li></ul></li></ul></li><li><p>例子：使用全局内存进行方阵转置，</p><ul><li>准备工作：测量有效带宽的上限和下限<ul><li>测量有效带宽的上限：对A按行合并读取，对B按行合并写入<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>B</span><span class=p>[</span><span class=n>nx</span> <span class=o>+</span> <span class=n>ny</span> <span class=o>*</span> <span class=n>N</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>nx</span> <span class=o>+</span> <span class=n>ny</span> <span class=o>*</span> <span class=n>N</span><span class=p>];</span>
</span></span></code></pre></td></tr></table></div></div></li><li>测量有效带宽的下限：对A按列交叉读取，对B按列交叉写入<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>B</span><span class=p>[</span><span class=n>ny</span> <span class=o>+</span> <span class=n>nx</span> <span class=o>*</span> <span class=n>N</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>ny</span> <span class=o>+</span> <span class=n>nx</span> <span class=o>*</span> <span class=n>N</span><span class=p>];</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li><li>测试：code部分如果</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>TILE_DIM</span> <span class=o>=</span> <span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>100</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>typedef</span> <span class=kt>double</span> <span class=n>real</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>copy</span><span class=p>(</span><span class=k>const</span> <span class=n>read</span> <span class=o>*</span><span class=n>A</span><span class=p>,</span> <span class=n>real</span> <span class=o>*</span><span class=n>B</span><span class=p>,</span> <span class=k>const</span> <span class=kt>int</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>nx</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>TILE_DIM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int</span> <span class=n>ny</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span> <span class=o>*</span> <span class=n>TILE_DIM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=cm>/*
</span></span></span><span class=line><span class=cl><span class=cm>    code
</span></span></span><span class=line><span class=cl><span class=cm>    */</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=n>dim3</span> <span class=nf>block_size</span><span class=p>(</span><span class=n>TILE_DIM</span><span class=p>,</span> <span class=n>TILE_DIM</span><span class=p>);</span> <span class=c1>// 每个thread block中TILE_DIM*TILE_DIM个线程，每个元素对应一个线程
</span></span></span><span class=line><span class=cl><span class=c1>// 此时一个线程块中32*32个线程，少于1024的限制
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=n>dim3</span> <span class=nf>grid_size</span><span class=p>((</span><span class=n>N</span> <span class=o>+</span> <span class=n>TILE_DIM</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>TILE_DIM</span><span class=p>,</span> <span class=p>(</span><span class=n>N</span> <span class=o>+</span> <span class=n>TILE_DIM</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>TILE_DIM</span><span class=p>);</span> <span class=c1>// grid的维度
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>copy</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid_size</span><span class=p>,</span> <span class=n>block_size</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A</span><span class=p>,</span> <span class=n>B</span><span class=p>,</span> <span class=n>N</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p>将A的一行转成B的一列：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>if</span><span class=p>(</span><span class=n>nx</span> <span class=o>&lt;</span> <span class=n>N</span> <span class=o>&amp;&amp;</span> <span class=n>ny</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>B</span><span class=p>[</span><span class=n>ny</span> <span class=o>+</span> <span class=n>nx</span> <span class=o>*</span> <span class=n>N</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>nx</span> <span class=o>+</span> <span class=n>ny</span> <span class=o>*</span> <span class=n>N</span><span class=p>];</span> 
</span></span></code></pre></td></tr></table></div></div><ul><li>对于A的读取是顺序的，对于B的写入是非顺序的</li></ul></li><li><p>将A的一列转成B的一行：更快</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>if</span><span class=p>(</span><span class=n>nx</span> <span class=o>&lt;</span> <span class=n>N</span> <span class=o>&amp;&amp;</span> <span class=n>ny</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>B</span><span class=p>[</span><span class=n>nx</span> <span class=o>+</span> <span class=n>ny</span> <span class=o>*</span> <span class=n>N</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>ny</span> <span class=o>+</span> <span class=n>nx</span> <span class=o>*</span> <span class=n>N</span><span class=p>];</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>对于A的读取不是顺序的，对于B的写入是顺序的</li></ul></li><li><p>分析：</p><ul><li><p>如果对A按行读取（将A的一行转成B的一列），对A按行读取是合并的，写入过程（交叉写入）不缓存</p></li><li><p>如果对B按行写入（将A的一列转成B的一行），对A按列读取是交叉的，写入过程（合并写入）不缓存，应该更慢</p></li><li><p>但是实际上第二种方式更快，原因在于L1缓存命中率
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-08-16:17:47.png style=zoom:20%></p><ul><li>对A按行读取，每个warp读取$32\times4B=128B$，正好是一次L1缓存的访问粒度，相当于每次访问，L1缓存命中率都为0，数据从全局内存拿到L1缓存后，后续这些数据又不再使用。因此，总体来看L1缓存命中率=0</li><li>对A按列访问，第0个warp中每个线程此时都L1缓存没有命中，此时会有32次128B的访存，然后数据拿到L1缓存中，后面第1~31个warp中线程都可以命中L1缓存。因此，总体来看缓存命中率=$\frac{31}{32}$=0.96875</li><li>可能是对A按列访问由于L1缓存命中率高，隐藏延迟更好，总体耗时更短，==不是很清楚==</li></ul></li></ul></li><li><p>若不能满足读取和写入都是合并的，一般应该尽量做到合并写入</p></li><li></li></ul></li></ul><h5 id=结构体数组和数据结构体>结构体数组和数据结构体<a hidden class=anchor aria-hidden=true href=#结构体数组和数据结构体>¶</a></h5><ul><li><p>结构体数组（Structure of Array，SoA）：一个结构体，其中成员是数组</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>struct</span> <span class=n>SoA</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>a</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>b</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=k>struct</span> <span class=n>SoA</span> <span class=n>myStruct</span><span class=p>;</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>数组结构体（Array of Structure, AoS）：一个数组，每个元素都是一个结构体</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>typedef</span> <span class=k>struct</span> <span class=n>element</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=n>Aos</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>Aos</span> <span class=n>array</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>CUDA中普遍倾向于SoA（结构体数组）因为这种内存访问可以有效地合并
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:23:43.png style=zoom:60%></p></li></ul><h5 id=其他>其他<a hidden class=anchor aria-hidden=true href=#其他>¶</a></h5><ul><li><p>增加每个线程中执行独立内存操作的数量，减少核函数发射的数量</p><ul><li>对于IO密集型的核函数，每个线程多处理一点数据（而非原来只处理一个数据）</li><li>比如reduce中，每个线程可以先累加多个数据，然后再进行两两数据的折叠相加</li></ul></li><li><p>对核函数的运行配置进行调整，提升SM占用率</p><ul><li>提升SM占用率会更好隐藏访存延迟吗？==不是很清楚==<ul><li>参考：<code>Better Performance at Lower Occupancy</code></li></ul></li></ul></li><li><p>参考</p><ul><li><a href=https://mp.weixin.qq.com/s/t4T7u4SqajH8db0Essedog>https://mp.weixin.qq.com/s/t4T7u4SqajH8db0Essedog</a></li></ul></li></ul><h3 id=常量内存>常量内存<a hidden class=anchor aria-hidden=true href=#常量内存>¶</a></h3><ul><li>常量内存属于全局内存，只有64KB</li><li>核函数的参数通过常量内存传递，且限定4KB</li><li>常量内存通过Read-Only Data Cache进行缓存，而且读取到的数据可以广播给warp中的其他线程</li><li>因为是只读的，因此常量内存必须在全局空间内、所有核函数之外进行声明，且必须在kernel启动前由host进行初始化（比如使用<code>cudaMemcpyToSymbol</code>来进行初始化）</li></ul><h3 id=纹理和表面内存>纹理和表面内存<a hidden class=anchor aria-hidden=true href=#纹理和表面内存>¶</a></h3><ul><li>纹理内存专门为那些存在大量空间局部性的内存访问模式设计，可以充分利用空间局部性（比如插值、滤波等操作）</li><li>纹理内存驻留在全局内存中，经过只读纹理缓存进行缓存</li></ul><h3 id=寄存器>寄存器<a hidden class=anchor aria-hidden=true href=#寄存器>¶</a></h3><ul><li>一个寄存器有32bit（4B）的大小，一些常用内建变量存放在寄存器中</li><li>核函数中定义的不加任何限定符的变量一般就存放在寄存器中，不加任何限定符的数组可能存放在寄存器中，或者放在局部内存中（即寄存器溢出，会对性能造成很大影响）</li><li>核函数前显式说明来帮助编译优化：<code>__launch_bounds_(maxThreadaPerBlock, minBlocksPerMulitprocessor)</code><ul><li><code>maxThreadaPerBlock</code>：线程块内包含的最大线程数</li><li><code>minBlocksPerMulitprocessor</code>：可选参数，每个SM中预期的最小的常驻线程块数量</li></ul></li><li>寄存器只能被一个线程可见，因此每个线程都有一个变量的副本，而且该变量的副本可以值不同</li></ul><h3 id=局部内存>局部内存<a hidden class=anchor aria-hidden=true href=#局部内存>¶</a></h3><ul><li>将寄存器放不下的变量、索引值不能再编译时就确定的数组，都存放在局部内存中（编译器进行判断）</li><li>局部内存是全局内存的一部分，因此使用时延迟较高</li><li>对于计算能力2.0以上的设备，局部内存可能会存储在L1缓存或L2缓存上</li></ul><h3 id=共享内存>共享内存<a hidden class=anchor aria-hidden=true href=#共享内存>¶</a></h3><ul><li>主要作用：<ul><li>减少核函数中对全局内存的访问次数，实现高效的线程块内部的通信</li><li>优化对全局内存的访问模式，尤其是针对全局内存的跨越式非合并访问，提高带宽利用率</li></ul></li><li>共享内存一般和L1缓存共享64KB片上内存，可以进行配置<ul><li>按设备进行配置<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>cudaDeviceSetCacheConfig</span><span class=p>(</span><span class=n>cudaFuncCache</span> <span class=n>cacheConfig</span><span class=p>);</span> 
</span></span><span class=line><span class=cl><span class=cm>/* 参数
</span></span></span><span class=line><span class=cl><span class=cm>cudaFuncCachePreferNone: no preference(default)
</span></span></span><span class=line><span class=cl><span class=cm>cudaFuncCachePreferShared: prefer 48KB shared memory and 16 KB L1 cache
</span></span></span><span class=line><span class=cl><span class=cm>cudaFuncCachePreferL1: prefer 48KB L1 cache and 16 KB shared memory
</span></span></span><span class=line><span class=cl><span class=cm>cudaFuncCachePreferEqual: prefer 32KB L1 cache and 32 KB shared memory
</span></span></span><span class=line><span class=cl><span class=cm>*/</span>
</span></span></code></pre></td></tr></table></div></div></li><li>不同核函数自动配置<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>cudaFuncSetCacheConfig</span><span class=p>(</span><span class=k>const</span> <span class=kt>void</span><span class=o>*</span> <span class=n>func</span><span class=p>,</span> <span class=k>enum</span> <span class=nc>cudaFuncCache</span> <span class=n>cacheConfig</span><span class=p>);</span> <span class=c1>// 配置核函数func对应的共享内存大小 
</span></span></span></code></pre></td></tr></table></div></div></li></ul></li></ul><h4 id=编程模型-1>编程模型<a hidden class=anchor aria-hidden=true href=#编程模型-1>¶</a></h4><ul><li>静态分配：<code>__shared__ float mat[5][5];</code></li><li>动态分配：<ul><li>函数内声明方式：<code>extern __shared__ double arr[];</code><ul><li>动态共享内存只支持一维数组</li></ul></li><li>核函数的执行配置中，第三个参数为每个线程块中动态共享内存的字节数：<code>&lt;&lt;&lt;grid_size, block_size, sizeof(float) * block_size>>></code></li></ul></li><li>同步：<code>__syncthreads</code>进行线程块的同步</li></ul><h4 id=优化-1>优化<a hidden class=anchor aria-hidden=true href=#优化-1>¶</a></h4><h3 id=缓存>缓存<a hidden class=anchor aria-hidden=true href=#缓存>¶</a></h3><ul><li><p>L1和L2缓存：缓存局部内存和全局内存的数据</p><ul><li>每个SM都有自己的L1缓存，但是L2缓存是所有SM共用的</li><li>可以配置是否使用L1缓存</li><li>CPU的L1缓存考虑了时间局部性（LRU算法）和空间局部性，GPU的L1缓存只有空间局部性，没有时间局部性（频繁访问一个一级缓存的内存位置不会增加数据留在缓存中的概率）</li><li><h2 id=cpu的一级缓存是的替换算法是有使用频率和时间局部性的gpu则没有>CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有<a hidden class=anchor aria-hidden=true href=#cpu的一级缓存是的替换算法是有使用频率和时间局部性的gpu则没有>¶</a></h2></li><li>与CPU读写都缓存不同，GPU只会针对读过程进行缓存，写过程不缓存</li></ul></li><li><p>每个SM都有一个只读常量缓存</p><ul><li>使用<code>__ldg()</code>函数显示将数据通过只读数据缓存进行加载</li></ul></li><li><p>GPU不是很强调缓存（not dependent on large caches for performance），因为当指令或数据miss时，由于warp切换速度快，所以旧切换warp；即用计算而非cache来隐藏延迟</p></li></ul><h2 id=内存管理>内存管理<a hidden class=anchor aria-hidden=true href=#内存管理>¶</a></h2><img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-07-21:05:54.png alt=image-20231207210554796 style=zoom:80%><h3 id=常规数据传输函数>常规数据传输函数<a hidden class=anchor aria-hidden=true href=#常规数据传输函数>¶</a></h3><ul><li><p><code>cudaMalloc</code>函数：<code>cudaError_t cudaMalloc(void **address, size_t size);</code></p><ul><li>示例：<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>double</span> <span class=o>*</span><span class=n>d_x</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>d_x</span><span class=p>,</span> <span class=mi>100</span><span class=p>);</span> <span class=c1>// &amp;d_x的类型为double**
</span></span></span></code></pre></td></tr></table></div></div></li><li>参数说明：<ul><li><code>address</code>是在分配设备内存的指针</li></ul></li><li>注意事项：<ul><li>==一个经常会发生的错误就是混用设备和主机的内存地址==：主机代码不能直接访问设备变量，设备也不能直接访问主机变量</li><li>因为该函数的功能是改变指针<code>d_x</code>的值（即改变<code>d_x</code>指向的位置，将一个指向内存地址的指针赋值给<code>d_x</code>），而非改变<code>d_x</code>所指内容的值，因此只能传入指针<code>d_x</code>的地址，即指针的指针</li><li>原来<code>d_x</code>是主机上的一个指针，<code>cudaMalloc</code>之后改变为指向设备全局内存的指针，本质上是GPU地址在内存中的虚拟映射地址</li></ul></li></ul></li><li><p><code>cudaMemset</code>函数：<code>cudaError_t cudaMemset(void * devPtr,int value,size_t count)</code></p></li><li><p><code>cudaFree</code>函数：<code>cudaError_t cudaFree(void* address)</code></p><ul><li>设备内存的分配和释放非常影响性能，尽量重用</li><li>CUDA允许在核函数内部使用malloc/free 分配/释放全局内存，但是一般会导致较差的性能</li></ul></li><li><p><code>cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind)</code></p><ul><li>主机端的内存默认是可分页的，如果进行数据拷贝，此时CUDA分配不可分页的固定内存，将可分页内存中的数据复制其中，然后再从固定内存中拷贝数据到显存</li><li>如果主机端的内存是可分页的，使用虚拟内存，当该页面被换出到交换区时，设备此时无法访问或者进行控制</li></ul></li><li><p><code>cudaMemcpyToSymbol</code>函数和<code>cudaMemcpyFromSymbol</code>函数</p><ul><li>symbol是一个驻留在全局或常量内存空间中的变量</li></ul></li><li><p><code>cudaMemcpy</code> 的异步版本 <code>cudaMemcpyAsync</code></p><ul><li><code>cudaError_t cudaMemcpyAsync(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind, cudaStream_t stream)</code></li><li>使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（使用<code>cudaMallocHost</code>或<code>cudaHostAlloc</code>），从而防止在程序执行期间物理地址被修改</li><li>如果将可分页内存传递给<code>cudaMemcpyAsync</code>，则会导致同步传输</li></ul></li><li><p>固定内存：</p><ul><li><code>cudaError_t cudaMallocHost(void **devPtr, size_t count);</code></li><li><code>cudaError_t cudaFreeHost(void *ptr);</code></li><li>固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。</li><li>固定内存有更高的读写带宽，但是分配过多的固定内存可能会降低主机系统的性能，同时固定内存分配和释放的代价更高。<strong>通常, 当传输数据量>=10M时, 使用固定内存是更好的选择</strong>
<img src=https://cdn.jsdelivr.net/gh/QinganZhang/ImageHosting/img/2023-12-05-15:24:06.png style=zoom:60%></li></ul></li><li><p>零拷贝内存</p><ul><li>在零拷贝内存中，主机和设备可以直接访问对方的变量，原理是将host内存直接映射到设备内存空间上，使得设备可以通过DMA的方式访问host的锁页内存</li><li><code>cudaError_t cudaHostAlloc(void **pHost, size_t size, unsigned int flags)</code><ul><li><code>cudaHostAllocDefault</code>：与cudaMallocHost函数行为一致</li><li><code>cudaHostAllocPortable</code>：返回能被所有CUDA上下文使用的固定内存，而不仅是执行内存分配的那一个，分配portable memory，适用于主机多线程，让控制不同GPU的主机端线程操作同一块portable memory，实现GPU线程间通信</li><li><code>cudaHostAllocMapped</code>：分配mapped memory，可以在kernel中直接访问mapped memory中的数据，不必再内存和显存之间进行数据拷贝，即zero-copy功能</li><li><code>cudaHostAllocWriteCombined</code>：分配write-combined memory，提高从CPU向GPU单向传输数据的速度，不使用CPU的L1、L2 cache，将cache资源留给其他程序使用，在PCI-E总线传输期间不会被来自CPU的监视打断<ul><li>将多次写操作写到固定内存的buffer中，将多次写合并；但实际上性能会比普通的write-back更糟糕, 主要是由于其没有使用cache, 而是直接写回内存</li></ul></li></ul></li><li>零拷贝内存虽然不需要显式的将主机的数据复制到设备上，但是设备也不能直接访问主机端的数据，需要通过<code>cudaHostGetDevicePointer</code>函数主机上的地址，然后才能通过<code>pDevice</code>访问主机上的零拷贝内存<ul><li><code>cudaHostGetDevicePointer(void **pDevice, void *pHost, unsigned int flags);</code><ul><li><code>flags</code>设置为0</li></ul></li><li>如果使用统一内存，则无须使用<code>cudaHostGetDevicePointer</code></li></ul></li><li>使用零拷贝内存需要注意同步主机和设备之间的内存访问</li><li>零拷贝内存适合用于少量的数据传输</li></ul></li></ul><h3 id=统一内存>统一内存<a hidden class=anchor aria-hidden=true href=#统一内存>¶</a></h3><ul><li><p>发展：</p><ul><li>统一寻址（Unified Address）：Fermi架构中提出了统一的地址空间，将全局内存、局部内存、共享内存放在一个地址空间中</li><li>统一虚拟地址(UVA)：CUDA 4（开普勒架构，麦克斯韦架构）引入，将CPU和GPU的内存映射到统一的虚拟地址上，可以使用指针访问对方的地址</li><li>统一内存(UM)：CUDA 6（帕斯卡架构之后）引入，实现了一个CPU和GPU之间的内存池<ul><li>对于第一代统一内存，主机与设备不能并发访问统一内存。因此，在主机调用核函数之后，必须加上一个同步函数（比如<code>cudaDeviceSynchornize</code>），确保核函数对统一内存的访问已经结束，然后才能主机访问统一内存变量</li><li>对于第二代统一内存，主机与设备可以并发访问统一内存</li></ul></li></ul></li><li><p>语法相关：</p><ul><li>统一内存在device中当作全局内存来使用，必须由主机来定义或分配内存，不能在设备端（核函数或<code>__device_</code>函数中）进行。因此，在核函数中由malloc分配的堆内存不属于同一内存，因而如果CPU需要访问，需要手工进行移动</li><li>同一个程序中可以同时使用统一内存和非统一内存</li></ul></li><li><p>统一内存的分配</p><ul><li>动态分配：<code>cudaError_t cudaMallocManaged(void **devPtr, size_t size, unsigned flags = 0);</code><ul><li>参数<code>flags</code>默认为<code>cudaMemAttachGlobal</code>，表示分配的全局内存可以由任何设备通过任何CUDA流访问</li></ul></li><li>静态分配：<code>__device__ __managed__</code>修饰，而且只能是全局变量</li></ul></li><li><p>超量分配：</p><ul><li>编译选项：<code>-DUNIFIED</code></li><li><code>cudaMallocManaged</code>申请内存只是表示预定了一段空间，统一内存的实际分配发生在第一次访问预留的内存时</li></ul></li><li><p>优化使用统一内存的程序</p><ul><li>可以手动给编译期一些提示，避免数据缺页、内存抖动，保持数据局部性等，可以使用<code>cudaMemAdvice</code>和<code>cudaMemPrefetchAsync</code></li><li><code>cudaError_t cudaMemPrefetchAsync(const void *devPtr, size_t count, int dstDevice, cudaStream_t stream)</code><ul><li>在CUDA流中将统一内存缓冲区devPtr内count字节的内存迁移到设备dstDevice（<code>cudaCpuDeviceId</code>表示主机的设备号）中的内存区域，从而防止或减少缺页异常，提高数据局部性</li><li>尽可能多的使用<code>cudaMemPrefetchAsync</code></li></ul></li></ul></li><li><p>优势：</p><ul><li>简化编程<ul><li>编程更简单：比如之前多GPU，针对某一个数据使用零拷贝内存，每个设备都需要有对应的一个指针，容易混乱（针对零拷贝的改进）</li><li>方便代码移植</li><li>支持更完整的C++语言要素：比如核函数参数可以使用引用，可以直接使用拷贝构造函数而不用手工进行拷贝或进行很多重载</li></ul></li><li>可能会提供比手工移动数据更好的性能，比如可能会将某部分数据放置到离某个存储器更近的位置<ul><li>可以进行超量分配，超出GPU显存的部分可以放在主机内存中（但是反过来不行）</li></ul></li></ul></li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=https://qinganzhang.github.io/posts/cuda-learning-notes/%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%92%8C%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>[cuda-learning-notes] 硬件抽象和执行模型</span>
</a><a class=next href=https://qinganzhang.github.io/posts/cuda-learning-notes/%E6%B5%81%E5%92%8C%E5%90%8C%E6%AD%A5/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>[cuda-learning-notes] 流和同步</span></a></nav></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qinganzhang.github.io/>Paul's Blog</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span><span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>